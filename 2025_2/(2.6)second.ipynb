{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee268be-0c65-489f-be96-4475a69ba0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: torch in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sk062\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk062\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk062\\miniconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32faaf26-064a-4d94-84c4-85a42acf2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef14bc5-0e9e-488e-bb3a-acb7ea8bfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c57d304-d53a-411a-b3ed-6e1d1d461dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sk062\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltkのストップワードをダウンロード（初回のみ）\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d77543-bb29-45b4-8240-c609ff905966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs( folder_path ):\n",
    "    \"\"\"\n",
    "    指定フォルダ内の複数PDFからテキストを抽出する。\n",
    "    \"\"\"\n",
    "    pdf_texts = {}\n",
    "    for file_name in os.listdir( folder_path ):\n",
    "        if file_name.endswith( '.pdf' ):  # PDFファイルのみ対象\n",
    "            with pdfplumber.open(os.path.join( folder_path, file_name) ) as pdf:\n",
    "                text = ''.join([ page.extract_text () for page in pdf.pages if page.extract_text()])\n",
    "                if text.strip():  # テキストが空でない場合のみ\n",
    "                    pdf_texts[file_name] = text\n",
    "    return pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b964ce-f9ad-4231-afee-68a7aacf595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\sk062\\OneDrive\\デスクトップ\\資料\\Note info\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16dc330-7388-4975-a021-2bf19b242b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_texts = extract_text_from_pdfs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee78832-3898-4fa1-80bf-0fc2a4b8ac3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based on Large Language Models Enhanced by Domain Knowledge Retrieval.pdf': 'A Soft Sensor Method with Uncertainty-Awareness and Self-\\nExplanation Based on Large Language Models Enhanced by\\nDomain Knowledge Retrieval\\nAuthor Information\\nShuo Tong, Han Liu , Runyuan Guo, Wenqing Wang, Xueqiong Tian, Lingyun Wei, Lin Zhang, Huayong\\nWu, Ding Liu, Youmin Zhang\\ne-mail: liuhan@xaut.edu.cn\\nAffiliations\\nSchool of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China.\\nShuo Tong, Han Liu, Runyuan Guo, Wenqing Wang, Xueqiong Tian, Lingyun Wei, Lin Zhang, Huayong Wu,\\nDing Liu\\nDepartment of Mechanical, Industrial, and Aerospace Engineering and the Concordia Institute of\\nAerospace Design and Innovation, Concordia University, Montreal, Canada.\\nYoumin Zhang\\nCorresponding author\\nCorrespondence to: Han Liu\\nAbstract\\nData-driven soft sensors are crucial in predicting key performance indicators in industrial systems.\\nHowever, current methods predominantly rely on the supervised learning paradigms of parameter\\nupdating, which inherently faces challenges such as high development costs, poor robustness, training\\ninstability, and lack of interpretability. Recently, large language models (LLMs) have demonstrated\\nsignificant potential across various domains, notably through In-Context Learning (ICL), which enables\\n1high-performance task execution with minimal input-label demonstrations and no prior training. This\\npaper aims to replace supervised learning with the emerging ICL paradigm for soft sensor modeling to\\naddress existing challenges and explore new avenues for advancement. To achieve this, we propose a\\nnovel framework called the Few-shot Uncertainty-aware and self-Explaining Soft Sensor (LLM-FUESS),\\nwhich includes the LLM-based Zero-shot Auxiliary Variable Selector (LLM-ZAVS) and the LLM-based\\nUncertainty-aware Few-shot Soft Sensor (LLM-UFSS). The LLM-ZAVS retrieves from the Industrial\\nKnowledge Vector Storage (IKVS) to enhance LLMs\\' domain-specific knowledge, enabling zero-shot\\nauxiliary variable selection. In the LLM-UFSS, we utilize text-based context demonstrations of structured\\ndata to prompt LLMs to execute ICL for predicting and propose a context sample retrieval augmentation\\nstrategy to improve performance. Additionally, we explored LLMs\\' AI-Generated Content (AIGC) and\\nprobabilistic characteristics to propose self-explanation and uncertainty quantification methods for\\nconstructing a trustworthy soft sensor. Extensive experiments on industrial datasets from bioprocessing\\nand chemical engineering demonstrate that our method achieved state-of-the-art predictive performance,\\nstrong robustness, and flexibility, effectively mitigates training instability found in traditional methods.\\nTo the best of our knowledge, this is the first work to establish soft sensor utilizing LLMs.\\nIntroduction\\nIn modern industrial processes, accurate monitoring of key quality variables is an indispensable\\nrequirement for ensuring the safe and efficient operation of automation systems1. Unfortunately, direct\\nonline measurement of certain critical variables is often impractical due to high equipment costs, harsh\\nenvironments, and technological constraints2,3. As a result, soft sensor technology has emerged as an\\nefficient solution, utilizing readily accessible process variables (auxiliary variables) to model and predict\\ndifficult-to-measure quality variables (primary variables) in real-time. This technology plays an\\nincreasingly vital role in industrial process optimization, control, and product quality monitoring4.\\nSoft sensor modeling methods can be primarily classified into mechanism-based and data-driven\\napproaches5. Data-driven models rely on historical data from distributed control systems (DCS),\\n2bypassing the intricacies of process mechanisms, which has made them the mainstream approach today6,7.\\nTraditional data-driven soft sensors typically include principal component analysis (PCA) 8,9, partial least\\nsquares regression (PLSR) 10,11, and support vector machines (SVM) 12, along with their variants. Recently,\\ndeep learning has advanced rapidly, garnering significant attention for its powerful capabilities in\\nhandling nonlinear relationships and extracting complex features. Popular deep learning-based soft\\nsensing techniques include multilayer perceptrons (MLP) 13, Long Short-Term Memory networks (LSTM)\\n14, and Stacked Autoencoders (SAE) 15,16.\\nTraditional statistical methods, machine learning-based soft sensors, and emerging deep learning soft\\nsensors (collectively referred to as numerical models) all operates on the paradigm of supervised learning.\\nThis involves optimizing an objective function, whereby the model iteratively adjusts its parameters on\\nthe training dataset to capture complex input-output relationships. However, these numerical models face\\ninherent limitations that significantly hinder their practical application, which we categorize into four\\nmain aspects: (1) High modeling costs and barriers to entry: Developing soft sensors often requires\\ntask-specific design and training tailored to specific on-site conditions. This fragmented and customized\\napproach greatly increases the time and computational costs, along with the complexity of development\\nand maintenance. Moreover, building complex models is knowledge-intensive, necessitating data analysts\\nwith expertise across various data science and algorithmic fields, creating a high entry barrier for soft\\nsensor modeling. (2) Limited robustness and flexibility with input data: Numerical models impose\\nstringent requirements on the format, dimensions, quantity, and types of input data17,18. Raw data must be\\nnormalization and dimensional unification, complicating preprocessing. Additionally, these models\\ncannot handle missing values, which restricts their flexibility19,20. Finally, they rely solely on structured\\ndata from industrial processes, making it difficult to incorporate relevant mechanistic knowledge and\\ncontext, thus limiting their representation learning potential. (3) Instability during the training process:\\nNumerical models are sensitive to initial parameters, sample sizes, and hyperparameter settings21. An\\nexcessive or insufficient number of samples can lead to overfitting or underfitting, while random\\nfluctuations and changes in data distribution during training can result in issues such as gradient explosion\\n3Fig. 1 | Overview of the design of the proposed LLM-FUESS. This two-stage few-shot soft sensing framework consists of\\nLLM-ZAVS, which performs auxiliary variable selection, and LLM-UFSS, which executes the soft sensing tasks. The entire\\npipeline is relies on natural language text input, utilizing ICL, retrieval-augmented generation, and advanced prompting\\ntechniques to achieve accurate predictions and generate detailed AIGC self-explanations, all without model training or parameter\\nupdates.\\nor vanishing gradients22. (4) Lack of Interpretability and Uncertainty Quantification: Numerical\\nmodels feature complex structures involving multiple layers of nonlinear relationships and numerous\\nparameters, making it hard to interpret the connections between input features and outcomes23,24.\\nFurthermore, they identify hidden patterns in a data-driven manner, lacking transparency based on rules\\nor explicitly theories, which complicates the provision of clear decision-making support for prediction.\\nMoreover, these models rely on deterministic algorithms that often yield single-point predictions without\\nquantifying uncertainty in input data or the model itself. This inability to reflect potential risks or error\\nranges remains an unresolved issues in the field of soft sensor25.\\nRecently, large language models (LLMs) pretrained on extensive corpora has provided promising\\nsolutions to these challenges. Models like GPT-426 and Gemini-1.5-pro27 have garnered considerable\\nattention natural language processing (NLP) for their impressive text generation and reasoning abilities28.\\nThey have also achieved remarkable success in complex domains beyond NLP, including dermatological\\ndiagnosis29, mathematical reasoning30, patient records interpretation31, and chemistry32, continuously\\npushing the boundaries of LLMs capabilities. This success is largely attributed to their emergent abilities,\\nwhich develop new advanced capabilities as model parameters scale up33,34. A key ability is In-Context\\n4Fig. 2 | Overview of LLM-ZAVS for zero-shot auxiliary variable selection. This module involves three steps: (a) constructing\\nan industrial knowledge vector store, (b) populating prompt templates, and (c) generating explainable auxiliary results using\\nLLMs. Two query methods are designed to address different task requirements: the global query provides an importance ranking\\nof all variables along with a comprehensive explanation, while the local query evaluates the impact of a specific variable on the\\nprimary variable for localized explanation.\\nLearning (ICL) 35,36, allowing LLMs to rapidly adapt to unseen tasks by learning from a few examples\\n(input-output pairs) in prompts, and to return results without any additional training or parameter updates.\\nEncouraged by this, this paper aims to leverage the new learning paradigm of ICL to replace the\\ntraditional supervised learning pipeline for soft sensor modeling, addressing challenges in data-driven soft\\nsensor without sacrificing predictive performance. As illustrated in Fig. 1, we propose a few-shot soft\\nsensor framework based on LLMs, called LLM-FUESS, which incorporates uncertainty-awareness and\\nself-explanation. LLM-FUESS streamline the soft sensor pipeline into two stages: auxiliary variable\\nselection and soft sensor modeling, named the LLM-Based Zero-Shot Auxiliary Variable Selector (LLM-\\nZAVS) and the LLM-Based Uncertainty-Aware Few-Shot Soft Sensor (LLM-UFSS), respectively.\\nSelecting auxiliary variables is essential in soft sensor modeling, as it minimizes interference from\\nirrelevant variables and reduces prompt token counts37, lowering API costs. As depicted in Fig. 2, we\\npropose a zero-shot auxiliary variable selector (LLM-ZAVS) that uses LLMs and prompt learning to\\n5generate reasonable feature selection results, along with importance rankings and scores, without\\nexamining any data samples. While pretrained LLMs encode extensive knowledge, they may lack\\ndetailed, domain-specific insights about industrial processes, material properties, and reaction\\nmechanisms, leading to \"hallucinations\" and unreliable feature selection. To address this, we integrate\\ndomain-specific industrial knowledge with LLMs using Retrieval-Augmented Generation (RAG)38,39,\\ntransforming LLMs into informed domain experts for selecting auxiliary variables. To ensure the\\nreliability and transparency of LLMs decisions, we introduce the Chain of Thought (CoT) 40,41, enabling\\nLLMs to provide detailed explanations of the decision-making process (both globally and locally).\\nAdditionally, we design a new evaluation metric called the Average Selection Consistency Score (ASCS)\\nto assess the consistency of LLM-ZAVS\\'s results. Experimental reults shows that LLM-ZAVS performs\\ncompetitive against other numerical feature selection methods and exhibits high output consistency.\\nIn the LLM-UFSS (Fig. 3), we format structured process data into text-based input-output pairs as\\ncontext demonstration samples. Unlike supervised methods, LLMs capture hidden nonlinear patterns\\namong variables by learning from few-shot context examples in prompts, enabling accurate predictions of\\nthe target variable for test samples. Since the entire framework relies on prompt strategies without any\\nmodifications to model or training, LLM-UFSS is both code-free and model-free, significantly\\nreducing modeling complexity, time costs, and dependency on specialized knowledge. Given that the\\nperformance of ICL depends on the quality of demonstration samples42, we propose a context sample\\nenhancement strategy inspired by RAG. Unlike traditional RAG, which focuses on document retrieval\\nand augmentation, our method utilizes industrial sample vectors. Specifically, we use the test sample as a\\nquery to retrieve similar samples from the constructed Industrial Process Data Vector Store (IPDVS) for\\nimproved the quality of context demonstrations. Notably, the input to LLM-UFSS is entirely in a user-\\nfriendly natural language format. Due to the inherent robustness of LLMs to prompts, we are able to\\nbypass normalization and imputation for missing values, demonstrating strong flexibility in handling\\ninputs. leveraging LLMs\\' powerful multimodal capabilities, we integrate industrial domain knowledge\\ntexts (such as background, data information, and mechanistic knowledge) into the prompts, combining\\n6Fig. 3 | Overview of the LLM-UFSS for few-shot soft sensing. This module consists of three steps: (a) constructing an\\nindustrial process data vector store, (b) populating templates and enhancing context with sample retrieval, and (c) generating\\nexplainable soft sensor results with uncertainty awareness.\\nthem with numerical data. This multimodal fusion significantly enriches the model\\'s expression by\\nenhancing information from multiple perspectives. Furthermore, we instruct LLMs to provide detailed,\\nstep-by-step, and human-readable explanations of the decision-making process during prediction,\\nenhancing the interpretability and transparency of the proposed method. Finally, we propose two\\nuncertainty quantification methods for soft sensing using LLMs\\' probabilistic characteristics: constructing\\nconfidence intervals and outputting confidence scores, enhancing the method\\'s credibility, reliability,\\nand risk awareness. Through extensive quantitative analysis and ablation experiments, we demonstrate\\nthe strong performance and capabilities of LLM-FUESS from multiple aspects. Remarkably, our\\nexperiments also indicate that LLM-UFSS can effectively prevent training instability issues such as\\noverfitting or underfitting commonly encountered in supervised learning methods.\\nFinally, we incorporate various prompt engineering techniques such as role-play43, CoT, and\\nemotional stimulation44 to create two fixed fill-in-the-blank prompt templates for LLM-ZAVS and LLM-\\n7Fig. 4 | Structure diagrams of AVS-PT and SS-PT. The AVS-PT consists of five elements: Role, Data, Instruction, Context,\\nand Main User Prompt. The SS-PT additionally includes Feature Importance Scores and Ranking, as well as a Detailed\\nExplanation for the Feature Importance Scores, generated by the LLM-ZAVS.\\nUFSS: the Auxiliary Variable Selection Prompt Template (AVS-PT) and the Soft Sensor Prompt\\nTemplate (SS-PT) (Fig. 4). Using LangChain, we encapsulated the entire process framework, allowing\\nusers to simply fill in a few external keywords into the templates according to operational requirements.\\n8The framework then automatically executes the corresponding tasks end-to-end, delivering stable results.\\nThis approach aligns with human interaction methods, making it user-friendly for non-experts without AI\\nor coding backgrounds. By changing only a few keywords, the template can adapt to all soft sensing\\ntasks, simplifying manual configuration and operation.\\nResults\\nCase study\\nTo validate the proposed method\\'s performance and general applicability in industrial process, we\\nselected the penicillin fermentation process (biocatalytic reactions) and the polypropylene production\\nprocess (chemical polymerization) as case studies (Fig. 5).\\n(1) Penicillin fermentation process\\nPenicillin, a secondary metabolite synthesized by the penicillium mold under specific conditions, is\\none of the most widely used antibiotics. As shown in Fig. 5a, the fermentation process is a complex\\nnonlinear batch process. However, the absence of reliable sensors for real-time measurement of product\\nconcentration, a critical quality variable, makes effective control of the fermentation process challenging.\\nTherefore, developing a soft sensor to measure penicillin concentration in real-time and accurately using\\neasily accessible process variables is of significant research interest.\\nIn this study, the industrial-scale penicillin fermentation simulation (IndPensim)45 was selected for\\nexperimentation. IndPensim integrates the complex characteristics of various industrial-scale processes\\nand serves as a simulation platform closely resembling actual industrial penicillin fed-batch fermentation\\nprocesses. We selected three normal batches with different parameter settings from IndPensim, with\\nfermentation times of 226h, 230h, and 278h, and a sampling interval of 0.2h. Each batch comprises two\\nphases: the batch phase and the fed-batch phase. In the initial batch phase, Penicillium consumes the\\nsubstrate, leading to rapid mycelial growth, but penicillin is not produced. After 24 hours, the process\\n9a b\\nFig. 5 | Case study diagrams. a, Schematic diagram of the penicillin fermentation process. b, Schematic diagram of the\\npolypropylene production process.\\ntransitions to the fed-batch phase, during which a substantial amount of penicillin is continuously\\nsynthesized. Our experiments focus on data from fed-batch phase (post-24h), predicting penicillin\\nconcentration as the primary variable, while 22 accessible process variables serve as auxiliary variable for\\nfeature selection and soft sensor modeling. Detailed descriptions and units are in Table 1.\\nTable 1 | Variables of the penicillin fermentation process\\nVariable Description Unit Variable Description Unit\\nV1 Aeration rate m3min−1 V12 Vessel Volume L\\nV2 Sugar feed rate Lh−1 V13 Vessel Weight Kg\\nV3 Acid flow rate Lh−1 V14 pH /\\nV4 Base flow rate Lh−1 V15 Temperature of broth K\\nV5 Heating/cooling water flow rate Lh−1 V16 Generated heat KJ\\nV6 Heating water flow rate Lh−1 V17 carbon dioxide percent in off-gas %\\nV7 Water for injection/dilution Lh−1 V18 PAA flow Lh−1\\nV8 Air head pressure bar V19 Oil flow Lh−1\\nV9 Dumped broth flow Lh−1 V20 Oxygen Uptake Rate g min−1\\nV10 Substrate concentration gL−1 V21 Oxygen in percent in off-gas %\\nV11 Dissolved oxygen concentration mgL−1 V22 Carbon evolution rate gh−1\\n10(2) Polypropylene production process\\nPolypropylene is one of the most widely used and lightest thermoplastic polymers, produced through\\nchain-growth polymerization of the monomer propylene using catalysts under controlled temperature and\\npressure. As depicted in Fig. 5b, the production process begins with the mixing of propylene,\\ncomonomers, and chain transfer agents (such as hydrogen) flowing into a fluidized bed reactor containing\\na high-activity catalyst to produce polypropylene powder. Unreacted gases are recycled back into the\\nreaction system through compressors and heat exchangers. The resulting polypropylene powder is then\\ntransported to a cyclone separator to remove gaseous propylene and hydrogen, followed by further\\nprocessing and molding into various plastic products.\\nDuring production, excessively long or short polymer chains can lead to polymer viscosity levels that\\nare too high or too low, failing to meet customer requirements. Measuring the Melt Flow Rate (MFR) is\\ncrucial for quality control as it indicates the viscosity of the thermoplastic polymer melt. However, MFR\\nis typically estimated in the laboratory every 2-8 hours, limiting real-time quality monitoring. Thus,\\nconstructing a soft sensor to accurately and in real-time predict MFR holds significant practical value.\\nThis study uses a polypropylene dataset to predict the reactor MFR (the primary variable) and includes\\nseven auxiliary variables, with detailed descriptions and units in Table 2.\\nTable 2 | Variables of the polypropylene production process\\nVariable Description Unit\\nV1 Hydrogen Ratio /\\nV2 Reactor Pressure bar\\nV3 Reactor Bed Level m\\nV4 Liquefied Recycle gas to R-310 dome top Lh−1\\nV5 Hydrogen Flow Kg/h\\nV6 Reactor Temperature K\\nV7 Propylene flow Kg/h\\n11Experimental settings\\n(1) Implementation details: All experiments were conducted on a server equipped with a 12th Gen\\nIntel(R) Core(TM) i5-12600KF and 32GB RAM, utilizing Python for implementation. For the\\nproposed method, unless otherwise specified, GPT-4o was employed as the LLM via API calls. To\\nensure consistency in output, the temperature was set to 0.\\n(2) LLM-ZAVS: For all datasets, we selected auxiliary variables comprising 50% of the total features to\\nevaluate the performance of LLM-ZAVS. This was validated using linear regression and support\\nvector regression. To ensure a fair comparison, we employed a fixed set of hyperparameters and 5-\\nfold cross-validation for stable evaluation results. Due to inherent variability in LLMs outputs, we\\nconducted five experiments to obtain five sets of LLM-ZAVS feature selection results, averaging\\nthem to derive the final outcome.\\n(3) The auxiliary variables selected by the LLM-ZAVS were used as input for LLM-UFSS. For LLM-\\nUFSS-FSC (Methods), 200 samples were randomly chosen from the dataset to creat 10 contexts in\\nSS-PT, each containing 20 text-based samples. From each context, 20 different test samples were\\nrandomly selected, ensuring no overlap through sampling without replacement. Each test sample\\nunderwent 10 experimental repetitions to establish prediction confidence intervals, with the average\\nused as the final result. For LLM-UFSS-RAC (Methods), the 200 samples from LLM-UFSS-FSC\\nwere used to construct the IPDVS, matching each test sample with similar ones from the IPDVS to\\nform the context. Due to its superior predictive performance and lower uncertainty, each test sample\\nin LLM-UFSS-RAC was evaluated only once. For other benchmark methods, a grid search was\\nperformed to find the optimal parameters.\\n(4) Evaluation metrics: In this study, four evaluation metrics were employed to assess the effectiveness\\nand accuracy of the proposed model: Mean Absolute Error (MAE), coefficient of determination\\n(R2), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE).\\n121 n\\nMAE= ∑ y − yp (1)\\nn t t\\nt=1\\n∑n ( y − yp)2\\nR2 =1− t=1 t t (2)\\n∑n ( y − y)2\\nt=1 t\\nRMSE=\\n1 ∑n (\\ny −\\nyp)2\\n(3)\\nn t t\\nt=1\\n1 n y − yp\\nSMAPE = ∑ t t ×100% (4)\\n( )\\nn t=1 y\\nt\\n+ y tp /2\\nwhere N represents the number of test samples，and y and yp denote the ground truth and predicted\\nt t\\nvalues, respectively. The MAE, RMSE, and MAPE metrics evaluate the error between the ground truth\\nand predicted values, with smaller values indicating better predictive performance. The R2 metric reflects\\nthe proportion of variance in the target variable that is explained by the model, with values closer to 1\\nindicating superior model fit.\\nAnalysis of LLM-ZAVS feature selection results\\nWe compared the performance of LLM-ZAVS with six common feature selection methods in two case\\nstudies, IndPensim and Polypropylene. These methods include Recursive Feature Elimination (RFE)46,\\npearson correlation47, filtering by Mutual Information (MI)48, spearman correlation49, fisher score50, and\\nrandom feature selection. As shown in Table 3, the text-based LLM-ZAVS achieved optimal or near-\\noptimal results compared to these data-driven methods. Notably, LLM-ZAVS operates in a zero-shot\\nmanner, meaning it does not require direct access to data samples. This highlights the competitive\\nadvantage of LLM-ZAVS, which leverages real-world knowledge reasoning over numerical statistical\\nanalysis. Furthermore, LLM-ZAVS improved the linear regression MAE by 54.41% and 44.69% on\\nIndPensim and Polypropylene, respectively, compared to random feature selection, demonstrates its\\neffectiveness in enhancing model predictive performance and strong applicability.\\n13Table 3 | Comparative results of feature selection using various methods\\nMethod IndPensim Polypropylene\\nLR SVR LR SVR\\nMAE R2 MAE R2 MAE R2 MAE R2\\nRandom 0.136 0.640 0.065 0.936 0.189 0.111 0.145 0.308\\nFisher 0.089 0.859 0.062 0.927 0.151 0.368 0.110 0.546\\nSpearman 0.083 0.876 0.060 0.949 0.142 0.425 0.098 0.649\\nPearson 0.064 0.915 0.057 0.950 0.143 0.420 0.105 0.601\\nMI 0.079 0.896 0.057 0.952 0.142 0.425 0.098 0.649\\nRFE 0.046 0.096 0.055 0.955 0.143 0.420 0.105 0.601\\nLLM-ZAVS 0.062 0.926 0.055 0.955 0.142 0.429 0.100 0.634\\nEven with identical prompts, using LLMs as feature selectors may result in different auxiliary\\nvariables being output. To assess the generative consistency of LLM-ZAVS, we propose a novel\\nevaluation metric called the Average Selection Consistency Score (ASCS). Assuming LLM-ZAVS\\nselects m auxiliary variables from a set of candidates over n repeated experiments, ASCS can be\\ndefined as follows:\\nn n \\uf8eb A \\uf049A \\uf8f6\\nASCS=C2×∑ ∑ \\uf8ec i j \\uf8f7 (5)\\nn \\uf8ec m \\uf8f7\\ni=1 j=i+1\\uf8ed \\uf8f8\\nWhere C2 represents the binomial coefficient, and A \\uf049A denotes the number of common\\nn i j\\nelements between the auxiliary variable selection results of the i-th and j-th experiments. The ASCS\\nvalue ranges from 0 to 1, with higher values indicating greater generative consistency of the feature\\nselector. The ASCS results for LLM-ZAVS from five experiments are shown in Table 4. For IndPensim,\\nwhere 11 auxiliary variables were selected, the ASCS is 0.75, meaning that, on average, 8.25 auxiliary\\nvariables were consistently selected across outputs. For Polypropylene, with four auxiliary variables\\nselected, the ASCS is 1, indicating complete consistency across all five outputs. This demonstrates that\\nLLM-ZAVS provides highly consistent feature selection results, exhibiting strong robustness.\\n14Table 4 | Average selection consistency score for LLM-ZAVS\\nCase Study ASCS\\nIndPensim 0.75\\nPolypropylene 1\\nAfter feature selection with LLM-ZAVS, we identified 11 variables from the IndPensim dataset:\\ndissolved oxygen concentration, aeration rate, oxygen uptake rate, carbon evolution rate, sugar feed rate,\\ntemperature, pH, substrate concentration, acid flow rate, vessel volume, and generated heat. From the\\nPolypropylene dataset, 4 variables were selected: hydrogen ratio, reactor pressure, hydrogen flow, and\\nreactor temperature. These variables served as inputs for LLM-UFSS to implement soft sensing.\\nAnalysis of LLM-UFSS-FSC results\\nTo validate the effectiveness of LLM-UFSS-FSC (Methods), four popular soft sensing algorithms were\\nselected: Random Forest Regression (RFR)51,52 and Multilayer Perceptron (MLP)13, known for their\\nrobust nonlinear processing, k-Nearest Neighbors Regression (k-NN)53 based on instance learning, and\\nPrincipal Component Regression (PCR) 54,55, which combines PCA with multiple linear regression. Due\\nto the extremely limited input training samples, deep learning networks were deemed unsuitable, so no\\ncomparison was made in this study. All comparative methods normalized and denormalized input data for\\noptimal performance, whereas the LLM-UFSS-FSC utilized raw, unprocessed data.\\nThe quantitative comparison results in Table 5 show that the LLM-UFSS-FSC achieved the lowest\\nMAE and RMSE across both datasets without parameter updates or model modifications, outperforming\\ntraditional machine learning and neural network models. Specifically, on the IndPensim and\\nPolypropylene datasets, the MAE for LLM-UFSS showed a reduction of 7.37% and 22.17%, respectively,\\ncompared to the second-best model, RFR. These findings also demonstrate that LLM-UFSS-FSC,\\nleveraging text-based input, effectively learns from context samples and produces competitive results\\nwithout normalization, exhibiting strong robustness to data scale variations.\\n15Table 5 | Performance comparision of LLM-UFSS-FSC with other methods\\nMethods IndPensim Polypropylene\\nMAE RMSE MAE RMSE\\nPCR 6.227 7.290 0.547 0.776\\nKNN 4.898 6.197 0.560 0.615\\nMLP 4.205 5.683 0.524 0.622\\nRFR 3.513 4.944 0.415 0.522\\nLLM-UFSS-FSC 3.254 4.547 0.323 0.454\\nTo visually demonstrate the model\\'s fitting performance, we analyzed the first 80 test samples. Fig. 6\\nshows the actual and predicted curves for IndPensim using different methods. Each set of 20 test samples\\n(separated by gray vertical dashed lines) uses the same 20 training samples for contextualization (LLM-\\nUFSS-FSC) or training (other methods). The results indicate that the predictive curve of LLM-UFSS-FSC\\nmore accurately fits the true curve (Fig. 6e), with RFR performing second best (Fig. 6d), while PCR\\nexhibits significant errors (Fig. 6a), suggesting its difficulty in handling complex nonlinear data. Notably,\\nin the interval of test samples 60-80, other numerical methods show substantial errors and fluctuations,\\nlikely due to overfitting from the limited sample size. In contrast, LLM-UFSS, using the same 20 samples\\nfor SS-PT context, effectively leverages its analytical and reasoning capabilities to accurately track the\\ntrue penicillin concentration values, thereby addressing model generalization issues and achieving precise\\npredictions.\\nTraditional data-driven soft sensors produce fixed, deterministic predictions once trained, but they\\ncan yield high-confidence erroneous outputs when faced with uncertainties like extreme or noisy data56.\\nAdditionally, these models are vulnerable to adversarial attacks57,58, impacting their reliability. They also\\nlack the capability to quantify uncertainty, which is essential for industrial control decisions and safety. In\\ncontrast, LLMs are probabilistic generative models, generating each token through conditional probability\\n16a b\\nc d\\ne\\nFig. 6 | Comparison of prediction results for different soft sensors on the test dataset. Each subfigure illustrates the\\npenicillin concentration predictions compared to true values across test samples. a, PCR. b, KNN. c, MLP. d, Random forest\\nregression. e, LLM-UFSS-FSC.\\ndistributions. By conducting multiple experiments and collecting diverse prediction results, LLMs can\\nprovide an uncertainty-aware prediction confidence interval.\\nWe conducted 10 repeated experiments for each test sample in LLM-UFSS-FSC. Fig. 7 show\\nuncertainty quantification visualizations for IndPensim (Fig. 7a) and Polypropylene (Fig. 7b). The light\\nblue background represents the true values of the 20 context samples, while the light red background\\nillustrates the LLM-UFSS-FSC\\'s predicted fitting curve and its uncertainty confidence interval. The blue\\nline indicates the true value curve, and the red line denotes the mean prediction from the experiments.\\nOther colored dashed lines indicate the primary variable predictions from three random experiments,\\n17a\\nb\\nFig. 7 | Example of LLM-UFSS-FSC prediction uncertainty visualization results. a, Penicillin concentration predictions with\\nassociated confidence intervals. b, Melt flow rate predictions with confidence intervals.\\nwhile the dark red area depicts the 95% confidence interval of LLM-UFSS-FSC predictions. The figures\\nreveal that a smaller confidence interval corresponds to a better fit between the prediction curve and true\\nvalues, while a larger interval suggests greater uncertainty and higher prediction error. By utilizing\\nconfidence intervals, not only can an approximate prediction range be provided, but the size of the\\ninterval can also be used to effectively quantify model uncertainty, offering comprehensive information to\\nenhance decision-making quality.\\nAnalysis of LLM-UFSS-RAC results\\n18Table 6 | Performace comparison of LLM-UFSS-RAC with other methods\\nMethods IndPensim Polypropylene\\nMAE RMSE MAPE MAE RMSE MAPE\\nN-Shot 5 10 5 10 5 10 5 10 5 10 5 10\\nPCR 1.559 1.733 4.040 2.585 0.707 0.598 0.422 0.436 0.591 0.560 0.238 0.249\\nKNN 1.218 1.452 2.450 2.439 0.839 0.787 0.339 0.322 0.463 0.447 0.193 0.181\\nMLP 1.886 1.901 3.471 2.906 1.167 0.782 0.333 0.336 0.496 0.465 0.191 0.199\\nRFR 1.270 1.204 2.479 2.115 2.683 3.262 0.301 0.302 0.428 0.431 0.168 0.169\\nLLM-UFSS- 0.905 0.651 2.535 1.200 0.451 0.360 0.300 0.253 0.494 0.438 0.177 0.148\\nRAC\\nIn this section, we validate the performance of the LLM-UFSS-RAC (Methods), enhanced by IPDVS\\nretrieval. We compare it with the four soft sensors in Fig. 6. To ensure a fair comparison, all context\\nsamples retrieved by LLM-UFSS-RAC are also used as training data for the other methods. However,\\nusing random training samples as model inputs results in poorer outputs for the comparative methods (see\\nTable 5). The quantitative comparison results for all methods under 5-shot and 10-shot training samples\\nare shown in Table 6. LLM-UFSS-RAC achieves competitive results, with a 10-shot MAE reduction of\\n45.93% and 16.23% compared to the second-best RFR across the two datasets, demonstrating the strong\\npredictive capability of the proposed method.\\nFig. 8 | The performance of different models with varying numbers of shots.\\n19Additionally, the MAE of LLM-UFSS-RAC with 10-shot context samples decreased by 28.07% and\\n15.67% compared to the 5-shot scenario, indicating that LLM can achieve more accurate predictions by\\nconsidering more samples. To clearly illustrate the relationship between sample size and model\\nperformance, we visualized the MAE variations of different models under various N-shot conditions (Fig.\\n8). As the number of context samples increases, the prediction MAE of LLM-UFSS-RAC (orange line)\\nconsistently decreases, particularly during the initial 1-5 shot phase, where the reduction is most\\nsignificant. This demonstrates that with more context samples, the proposed method effectively leverages\\nICL to integrate and understand multiple samples, enabling more accurate reasoning and showcasing its\\nfew-shot learning capability.\\nIn the Fig. 8, the MAE of RFR stabilizes as the number of training samples increases, indicating that\\nadditional information from highly similar retrieved samples is limited and does not effectively enhance\\nthe model\\'s predictive capability. The MAE for MLP and PCR even rises, suggesting potential overfitting\\nor insufficient model complexity to handle subtle differences between similar samples. This further\\nillustrates that LLM-UFSS-RAC possesses a finer-grained ability to perceive sample minor differences\\nand make accurate decisions, partially addressing overfitting in numerical models.\\nTo more intuitively reflect the prediction errors, we plotted the error box plots and absolute error\\ncurves (Fig. 9) for different models across all test samples. Fig. 9a and Fig. 9b show that the box plot for\\nLLM-UFSS-RAC is significantly narrower, indicating a more concentrated error distribution and a\\nsmaller error range. Additionally, LLM-UFSS-RAC exhibits a lower median error. Fig. 10a and Fig. 10b\\nfurther illustrate the visualization of absolute prediction errors for five soft sensors across all test samples.\\nIt is evident that the error curve for LLM-UFSS-RAC is generally lower and closer to zero. Moreover, the\\nproposed method exhibits smaller error fluctuations, demonstrating superior stability and accuracy.\\n20a b\\nc\\nd\\nFig. 9 | Comparison of model prediction errors. a, Box plots of errors for different methods on the IndPensim dataset. b, Box\\nplots of errors for different methods on the Polypropylene dataset. c, Error curves of different methods across all test samples on\\nthe IndPensim dataset. d, Error curves of different methods across all test samples on the Polypropylene dataset.\\nAnalysis of robustness to missing values\\nIn industrial settings, factors like data transmission anomalies, sensor failures, and environmental\\ninstability often lead to missing values in DCS-collected data19,59. However, data-driven soft sensors\\n21require strictly preprocessed, uniformly structured numerical data as input, making them ill-equipped to\\nhandle incomplete datasets60. Some soft sensors simply ignore samples with missing values, resulting in\\nsignificant information loss, especially when the missing data rate is high. Others use imputation\\ntechniques to estimate these values, which increases the modeling complexity and development time20.\\nTable 7 | Performance comparision of different missing raitos\\nMissing Ratio (%) IndPensim Polypropylene (10-shot)\\nMAE RMSE MAE RMSE\\n0% 0.905 2.535 0.253 0.438\\n10% 1.079 2.356 0.299 0.483\\n20% 1.278 2.533 0.362 0.581\\n30% 1.585 3.124 0.382 0.582\\n40% 1.735 3.078 0.372 0.597\\n50% 1.912 3.429 0.395 0.607\\nAverage 1.416 2.843 0.344 0.548\\nThe LLM-UFSS differs from traditional data-driven soft sensors by converting numerical inputs into\\nprompt-based textual inputs, thus reducing the strict requirements on input format. To assess its\\napplicability with missing data, we conducted five comparative experiments on two datasets using the\\nLLM-UFSS-RAC 5-shot framework. We simulated missingness by masking auxiliary variables at rates\\nfrom 10% to 50%, replacing missing data with \\'N/A\\'. For instance, a sample like \"Hydrogen Ratio: 0.17,\\nReactor Pressure: 30.576788, Hydrogen Flow: ...\" becomes \"Hydrogen Ratio: 0.17, Reactor Pressure:\\nN/A, Hydrogen Flow: ...\". Results in Table 7 show that while MAE and RMSE increase with higher\\nmissing rates, our method still achieves accurate predictions even with 50% missing data, with MAE as\\nlow as 1.912 and 0.344 for the two datasets, indicating robustness to missing data. Fig. 10 presents a\\nhistogram of prediction error distributions under varying missing rates, revealing that although the error\\ndistribution becomes more dispersed as the missing rate increases, it remains approximately unbiased and\\nnormally distributed, with most errors concentrated between -2 and 2, demonstrating strong predictive\\nperformance.\\n22a b\\nc d\\nFig. 10 | Histogram of prediction errors for the IndPenSim dataset across different missing ratios. a, 0% missing data. b,\\n10% missing data. c, 30% missing data. d, 50% missing data.\\nConfidence score output analysis\\nIn addition to constructing confidence intervals, we also explored an alternative approach for uncertainty\\nperception in soft sensor predictions. This involves using a prompt strategy to instruct LLMs in SS-PT to\\nperform confidence elicitation. By analyzing contextual information, the model outputs a confidence\\nscore ranging from 0 to 1, where scores closer to 1 indicate higher confidence. This approach aims to\\nenhance risk assessment and error mitigation.\\nTo validate the LLM-UFSS\\'s ability to perceive uncertainty, we compared the average confidence\\nscores across two datasets with data missing rates from 0% to 50%. As shown in Fig. 11a, confidence\\n23a b\\nFig. 11 | Sensitivity analysis results of confidence scores. a, Confidence scores of the IndPenSim dataset across various\\nmissing ratios. b, Density plot of confidence scores and error distribution.\\nscores consistently decrease with higher missing rates, indicating that increased missing values reduce\\nLLM-UFSS\\'s confidence in prediction accuracy, thereby highlighting its capability to perceive prediction\\nuncertainty. To further support this, we plotted the error and confidence score density for all samples in\\nFig. 11b. The horizontal axis represents the confidence scores, while the vertical axis represents\\nprediction error, with values closer to 0 indicating better predictions. The figure reveals that the majority\\nof confidence scores fall between 0.8 and 1, with fewer below 0.8. As confidence scores increase, the\\nerror visibly narrows towards the central value of 0. In the range of 0.9 to 1, the error is minimal, and\\npredictive performance is optimal. This demonstrates that by guiding the model to output confidence\\nscores, LLM-UFSS can effectively assess its own prediction accuracy.\\nAnalysis of explanation results\\n(1) Analysis of LLM-ZAVS explainability results\\nThrough global-query, LLM-ZAVS generates importance scores and rankings for auxiliary variables,\\nalong with self-explanatory text regarding their feature importance. Fig. 12 illustrates the LLM-ZAVS \\'s\\noutputs for global auxiliary variable identification and reasoning explanation across two datasets. The\\nresults, highlighted in orange, demonstrate that LLM-ZAVS effectively identifies and incorporates\\n24a\\nb\\nFig. 12 | Two examples of global feature selection explanations delivered by LLM-ZAVS. a, Feature selection global\\nexplanation for the IndPensim dataset. b, Feature selection global explanation for the Polypropylene datase.\\ncontextual embedded knowledge retrieved from the IKVS, providing professional interpretations of\\ndifferent variables based on this contextual information, as shown in blue.\\nDue to the challenge LLMs face in handling multiple tasks with fine granularity simultaneously,\\nglobal-query may struggle to provide deeper reasoning for each variable. To address this, we introduce\\nlocal-query for more detailed explanations, offering more comprehensive information. Fig. 13 presents\\ntwo examples of local explanations generated by LLM-ZAVS.\\n25a\\nb\\nFig. 13 | Two examples of local variable explanations delivered by LLM-ZAVS. a, Local explanation of the importance of\\nsugar feed rate for penicillin concentration in the IndPensim dataset. b, Local explanation of the importance of oxygen uptake\\nrate for melt flow rate in the Polypropylene dataset.\\n26In Fig. 13a, the case illustrates a local explanation of the impact of the sugar feed rate on penicillin\\nconcentration in the IndPenSim dataset. Using the CoT technique in AVS-PT, LLM-ZAVS decomposes\\nthe problem for step-by-step analysis (as shown in blue). Compared to global explanations, local\\nexplanations provide more detailed insights into individual auxiliary variables. Notably, the orange text\\nhighlights how the introduction of RAG allows LLM-UFSS to effectively utilize and comprehend\\nprofessional knowledge from the IKVS, including kinetic equations (points 2 and 6), simulation data\\n(point 3), optimization experiment results (point 4), and empirical models (point 6). This approach\\nenables more professional analysis and reasoning using external database knowledge, mitigating the\\nhallucination phenomenon and enhancing the reliability of the explanations. Fig. 13b further supports this\\nview with a local explanation of the oxygen uptake rate\\'s effect on penicillin concentration.\\n(2) Analysis of LLM-UFSS explainability results\\nA major challenge for data-driven soft sensors during practical deployment is their lack of reliability. This\\nstems from the difficulty in interpreting end-to-end trained black-box models, which hinders users from\\neffectively assessing the reasonableness and trustworthiness of the outputs. To address this issue, we\\nutilize the advanced emergent capabilities of LLMs, including natural language understanding, generation,\\nand step-by-step reasoning, to provide clear, human-readable explanations for complex soft sensor\\nprediction. We first analyze the explainability results of LLM-UFSS-FSC predictions. Fig. 14 presents\\ntextual explanations for soft sensor outputs across two datasets. The orange text indicates that the\\nproposed method considers the auxiliary variable importance conclusions generated by LLM-ZAVS and\\nthe context samples. The purple text signifies the influence of CoT prompting technique. We divide the\\nmain explanation into a reasoning section (blue text) and a conclusion section (green text). The reasoning\\nsection demonstrates how LLM-UFSS uses ICL to position the auxiliary variable values within an\\napproximate range, and the conclusion section then illustrates the specific impact of this range on the\\nmain variable\\'s value, primarily derived from ICL or biochemical knowledge. Finally, the method\\nintegrates these factors to derive accurate predictions (e.g., the true penicillin value is 26.123 in Fig. 14a,\\nand the true MFR value is 1.335 in Fig. 14b).\\n27a\\nb\\nFig. 14 | Two examples of soft sensor explanations delivered by LLM-UFSS-FSC. a, Explanation results for penicillin\\nconcentration prediction in the IndPensim dataset. b, Explanation results for melt flow rate prediction in the Polypropylene\\ndataset.\\nTo validate the effectiveness of the IPDVS and the context-based retrieval augmentation methods\\nproposed in LLM-UFSS-RAC (Methods), we present two explanation examples in Fig. 15. The ground\\ntruth values for the two cases are 19.67 (Fig. 15a) and 1.361 (Fig. 15b), respectively. The explanations in\\nFig. 15 further confirm the conclusions mentioned earlier. Unlike LLM-UFSS-FSC, LLM-UFSS-RAC\\nenhances prediction by retrieving similar samples, positioning predicted values within a more precise\\nrange (e.g., points 2 and 3 in Fig. 15a). By analyzing relevant samples (indicated by the blue text in Fig.\\n15b), LLM-UFSS-RAC achieves finer-grained analysis, enhancing predictive performance.\\n28a\\nb\\nFig. 15 | Two examples of soft sensor explanations delivered by LLM-UFSS-RAC. a, Explanation results for penicillin\\nconcentration prediction in the IndPensim dataset. b, Explanation results for melt flow rate prediction in the Polypropylene\\ndataset.\\nAblation study\\nTo validate the effectiveness and contributions of each key component in the proposed method, we\\nconducted ablation experiments with various variants of LLM-UFSS. The LLM is a critical component,\\nso we compared the default GPT-4o26 model with three other state-of-the-art LLMs (GPT-3.5-turbo61,\\nGPT-426, Gemini-1.5-pro-exp-080127) across two datasets. The MAE results are shown in Fig. 16a. It is\\nevident that GPT-3.5-turbo exhibits a significantly higher MAE of 2.132 on the IndPenSim dataset,\\nindicating a substantial performance gap compared to other models. In contrast, Gemini-1.5-pro-exp-0801\\nachieves the lowest MAE of 0.798, a 62.57% reduction compared to GPT-3.5-turbo, highlighting the\\nimpact of LLMs selection on LLM-UFSS\\'s predictive performance. Furthermore, we believe that Gemini-\\n1.5-pro-exp-0801 offers superior mathematical analysis capabilities compared to the GPT-4 series.\\n29a b\\nFig. 16 Ablation study analysis results. a, Comparison of pediction prformance with dfferent LLMs. b, Comparative analysis\\nof predictive performance between LLM-UFSS-RAC and W/O RAC.\\nTo validate the role of IPDV and vector retrieval enhancement in ICL, we conducted an ablation\\nstudy by removing these components from LLM-UFSS-RAC, denoted as W/O RAC. The fitting\\nperformance of both models on the test set is illustrated in Fig. 16b. The results indicate that LLM-UFSS-\\nRAC demonstrates superior fitting performance, suggesting that ICL can achieve more accurate\\npredictions through the use of enhanced similar samples.\\nTable 8 | Comparison of confidence scores\\nMethods Average Confidence Score\\nIndPensim Polypropylene\\nW/O RAC 0.860 0.865\\nLLM-UFSS-RAC 0.882 0.878\\nTo evaluate the effectiveness and sensitivity of the confidence scores output by LLM-UFSS, we\\ncompared the average confidence scores of W/O RAC and LLM-UFSS-RAC across two datasets (Table\\n8). W/O RAC uses random samples for context, while LLM-UFSS-RAC employs enhanced similar\\nsamples. The results show that LLM-UFSS-RAC achieves higher average confidence scores, indicating\\nthat the confidence score effectively perceives the context samples and assesses the reliability of its own\\npredictions based on the degree of perception. The confidence score aligns with factual patterns and holds\\nsignificant reference value.\\n30Table 9 | Results of the ablation study on prompts\\nModel LLM-UFSS-FSC LLM-UFSS-RAC\\nMAE RMSE MAE RMSE\\nW/O EC 4.410 10.990 1.117 2.694\\nW/O Role 3.694 5.518 1.005 2.663\\nW/O CoT 3.731 5.663 0.953 2.771\\nWith All 3.254 4.547 0.905 2.535\\nTo evaluate the effects of various prompt components, we conducted ablation experiments using\\nthree prompt variants on both LLM-UFSS-FSC and LLM-UFSS-RAC: (1) W/O Role: removing the role\\ncomponent from SS-PT, (2) W/O CoT: excluding chain-of-thought instructions, and (3) W/O EC:\\nremoving instructions related to output explanations and confidence scoring. The results, shown in Table\\n9, indicate that removing any component leads to a decline in the overall performance. The first variant\\ndemonstrate that specifying the LLM\\'s role within the prompt enables more accurate predictions through\\nrole-playing. The second variant, along with results from Fig. 14, shows that the CoT technique\\nincrementally guides the LLM in problem-solving, thereby enhancing task performance. In the third\\nvariant, where the LLM is no longer required to explain and score its predictions, a noticeable drop in\\npredictive performance is observed. This suggests that self-explanation and uncertainty assessment via\\ninstructions encourage deeper reasoning in LLMs, ultimately improving predictive capabilities.\\nDiscussion\\nThis paper introduces LLM-FUESS, the first two-stage soft sensing framework based on the ICL\\nparadigm of LLMs, designed to overcome various challenges in traditional data-driven soft sensors. In the\\nfirst stage, the LLM-ZAVS retrieves domain-specific knowledge from the IKVS and integrates it with the\\ninternal knowledge of LLMs. This integration endows LLMs with expert-level analytical capabilities for\\nauxiliary variable selection. In the second stage, LLM-UFSS employs minimal samples as context task\\ndemonstrations, leveraging the powerful ICL capabilities to achieve robust predictive performance\\nwithout any model training or parameter updates. Additionally, by constructing the IPDVS and\\n31introducing the RAG, we offer an alternative strategy for enhancing context samples when ample data is\\navailable. We exploit the robust text generation and probabilistic features of LLMs in both stages to\\nprovide human-readable, explainable insights, and for LLM-UFSS, we design two methods to quantify\\nprediction uncertainty as a basis for evaluation. To enhance the task adaptability and usability of LLM-\\nFUESS across diverse scenarios, we introduce various prompting strategies, creating two highly\\nencapsulated fill-in-the-blank templates: AVS-PT and SS-PT for each stage, respectively.\\nExtensive experiments were conducted on datasets from two distinct domains, IndPensim and\\nPolypropylene. The results from the first stage demonstrate that LLM-ZAVS can consistently and\\neffectively select auxiliary variables, providing explanations from both local and global perspectives with\\na high degree of professionalism. In the second stage, the experiments reveal that LLM-UFSS not only\\nachieves competitive performance compared to data-driven soft sensors but also exhibits greater\\nrobustness and flexibility regarding input data formats, quantities, and types. Furthermore, the\\nexperiments indicate that LLM-UFSS possesses strong self-explanation and uncertainty awareness\\ncapabilities, enhancing the method\\'s transparency and risk awareness. This provides practitioners with\\nmore comprehensive and valuable decision-making information.\\nMethods\\nOverall design\\nAs the parameters and training corpus of large LLMs continue to expand, they exhibit emergent\\ncapabilities—abilities not present in smaller-scale models. This paper proposes a novel few-shot soft\\nsensor method, LLM-FUESS (Uncertainty-Awareness and Self-Explanation), leveraging these emergent\\nabilities of LLMs. Typically, data selection and soft sensor modeling are considered two independent\\ncomponents of the soft sensor pipeline. As illustrated in Fig. 1, the proposed LLM-FUESS consists of two\\nstages: (a) LLM-ZAVS and (b) LLM-UFSS, which perform feature selection and soft sensing tasks,\\nrespectively. These stages are detailed in \"LLM-based zero-shot auxiliary variable selector (LLM-\\n32ZAVS)\" and \"LLM-based uncertainty-aware few-shot soft sensor (LLM-UFSS)\". The meticulous design\\nof prompt strategies is crucial for eliciting the emergent capabilities. Therefore, we have developed two\\nfill-in-the-blank prompt templates, AVS-PT and SS-PT (AVS-PT and SS-PT with prompt engineering),\\nfor these stages to maximize the reasoning abilities and performance of the models.\\nLLM-Based zero-shot auxiliary variable selector (LLM-ZAVS)\\nIn the context of expanding production scales and increasingly complex industrial processes, the\\ndimensionality of process variables has significantly increased. Redundant variables can impair the\\npredictive performance and computational efficiency of soft sensor. By selecting an appropriate subset of\\nauxiliary variables, we can eliminate redundancy and conserve LLMs input tokens. Additionally,\\nidentifying key quality variables supports product quality control and enhances analysis, interpretation,\\nand prediction by LLMs. To address this, we propose a novel Zero-Shot Auxiliary Variable Selector\\n(LLM-ZAVS). As depicted in Fig. 2, LLM-ZAVS comprises three main components: (a) construction of\\nthe industrial knowledge vector store, (b) filling in the prompt template, and (c) generation of explainable\\nauxiliary variable selection results.\\nIn component (a), we construct a dynamic external industry knowledge vector store tailored to the\\ncurrent task using RAG. This approach address the domain-specific knowledge gaps of LLMs in\\nknowledge-intensive industrial tasks, enhancing variable selection capabilities and reducing\\nhallucinations. Initially, we collect relevant documents from various data sources, including books,\\nresearch papers, web pages, and technical reports, to compile an unified, authoritative internal industrial\\nscenario knowledge base, denoted as D . The text within D is then split into smaller document chunks:\\nkb kb\\nD ={ Dkb, Dkb, ..., Dkb} (6)\\nkb 1 2 n\\nSubsequently, we employ an embedding model f to encode each chunk D into high-dimensional\\ne i\\nvectors:\\nf :Dkb →V ∈\\uf0a1d (7)\\ne i i\\n33where d represents the embedding dimension. The resulting embedding vectors V ={V, V , ..., V } are\\n1 2 n\\nstored in the Industry Knowledge Vector Store (IKVS) to facilitate efficient retrieval.\\nIn step (b), we populate the auxiliary variable selection prompt template (AVS-PT) to creat an\\nauxiliary selection query for the LLMs. The AVS-PT (Fig. 2a) consists of three components: elements (in\\nblue), a fixed template (in black), and task-specific configurations (in green). First, the user inputs task-\\nspecific information—such as the industrial process, facility, number of variables, and primary\\nvariables—into the AVS-PT, replacing the placeholders to form a basic prompt query (see \"AVS-PT and\\nSS-PT with Prompt Engineering\" for more details). Next, we retrieve relevant knowledge from an\\nexternal database to integrate into the AVS-PT as context, enhancing the LLM\\'s generation process. To\\naccommodate different generation requirements, we have designed two retrieval-enhanced generation\\npaths: the global query (blue dashed line) and the local query (yellow dashed line). In the global query,\\nthe user inputs all candidate auxiliary variables names into the IKVS as a query, embedding them into\\nhigh-dimensional query vectors E ∈\\uf0a1d using the embedding function f . We then calculate the\\nq e\\neuclidean distance between E and all vectors in the IKVS to determine vector similarity:\\nq\\nd\\nd( E ,V ) = E −V = ∑( Ej −V j)2 (8)\\nq i q i 2 q i\\nj=1\\nFinally, the top K most relevant vectors are identified, and the corresponding documents\\nT ={T, T , ..., T } are retrieved as context for the AVS-PT, resulting in the final auxiliary variable\\n1 2 K\\nselection query (global). The AVS-PT (global) instructs LLMs to generate scores and importance\\nrankings for all auxiliary variables, along with detailed explanations. In step (c), we input the global query\\ninto the pre-trained LLM M , with all parameters frozen. Using LangChain, we format the LLM\\'s\\nfrozen\\noutput into JSON, obtaining a stable importance ranking r and scoring s , as well as a global\\nj j\\nexplanation (blue box) exp :\\ng\\ns ,r ,exp =M ( AVS-PT( t,c )) , j∈{1,...,l} (9)\\nj j g frozen g\\n34where t represents task-specific configurations, and c denotes the relevant documents retrieved by the\\ng\\nglobal query. In the local query, users select a specific candidate auxiliary variable as the query for the\\nIKVS, and through the same retrieval-augmented process as the global query, generate detailed feature\\nimportance explanations exp for the candidate auxiliary variable (orange box):\\nl\\nexp =M ( AVS-PT(t,c )) (10)\\nl frozen l\\nWhere c represents the relevant documents retrieved by the local query. Without any model\\nl\\nparameter adjustments or prior data inspection, the external knowledge augmentation from both\\nglobal and local queries, along with the LLM\\'s robust reasoning capabilities, enables the\\ngeneration of importance rankings for auxiliary variables and provides detailed text-based self-\\nexplanations of the decision-making process, offering high readability and reference value.\\nLLM-based uncertainty-aware few-shot soft sensor (LLM-UFSS)\\nAfter processing by the first-stage LLM-ZAVS module, we filter a set of auxiliary variables most crucial\\nto the primary variables. In the second stage, these variables serve as inputs for predicting primary\\nvariable values through a soft sensor. Unlike previous approaches, our LLM-Based Uncertainty-Aware\\nFew-Shot Soft Sensor (LLM-UFSS) requires no model training or gradient updates. Instead, it utilizes\\nICL with prompt engineering, using a few examples to leverage the LLM\\'s capabilities to analyze data\\nand prediction. Furthermore, compared to earlier soft sensors that could only generate singular numerical\\npredictions, the LLM-UFSS also provides detailed reasoning explanations, confidence scores, and\\nconfidence intervals for uncertainty quantification of the generated results.\\nThe LLM-UFSS pipeline, similar to LLM-ZAVS, consists three parts: (a) Construction of the\\nindustrial process data vector store, (b) Filling in the prompt template, and (c) Generation of explainable\\nsoft sensor results (Fig. 3). With the widespread application of DCS, collecting and storing large amounts\\nof process variable data has become feasubke. Inspired by RAG, the stage (a) aims to construct a\\n35retrievable industrial process data vector store to provide LLMs with more valuable contextual examples\\nfor improved predictions. Initially, we obtain raw historical process variable data through DCS\\napplications, available in formats such as JSON, Excel, or CSV. We then filter this data using the LLM-\\nZAVS, selecting the auxiliary variables and removing less important, redundant, and spurious variables to\\nform the DCS process variable database D . Subsequently, we segment the database according to\\npv\\nsample time steps, resulting in nindependent data samples:\\nD ={ Dpv, Dpv, ..., Dpv} (11)\\npv 1 2 n\\nwhere Dpv =( x1,x2,...,xm,y ) , m is the number of auxiliary variables, x denotes the auxiliary variable\\ni i i i i i\\nvalues, and y is the true value. Following the LLM-ZAVS，each sample Dpv is encoded into high-\\ni i\\ndimensional vectors for indexing and storage in the industrial process data vector store (IPDVS).\\nIn phase (b), we construct a Soft Sensor Prompt Template (SS-PT) tailored for the soft sensing task\\n(Fig. 4). Users input task-specific industrial background information t to configure the SS-PT.\\nAdditionally, feature importance rankings r and scores s generated by LLM-ZAVS, along with global\\nj j\\nfeature explanations exp , are incorporated as extra contextual information. This provides the LLMs with\\ng\\nfiner-grained prompts, enabling more in-depth and complex reasoning. It is essential to provide high-\\nquality sample examples for ICL inference and generalization, so we designed two pathways to supply\\nICL samples based on varying industrial scenarios. When on-site samples are minimal and insufficient to\\nconstruct the IPDVS, LLM-UFSS employs the available few-shot samples as inputs into the SS-PT,\\ntermed LLM-UFSS Few-Shot Contextualization (LLM-UFSS-FSC). Conversely, if the DCS gathers\\nsubstantial amount of data, a text-based test sample—comprising auxiliary variable names and values—\\nqueries the IPDVS to retrieves several samples with high similarity to the test sample, which are then\\ninput into the SS-PT (orange dashed line), known as LLM-UFSS Retrieval-Augmented Contextualization\\n(LLM-UFSS-RAC). These context samples are denoted as I , with a total of k examples, where I is\\ndefined as follows:\\n36I = f ( x1,x2,...,xm,y ) , f ( x1,x2,...,xm,y ) ,..., f ( x1,x2,...,xm,y ) (12)\\n1 1 1 1 2 2 2 2 k k k k\\nwhere f (⋅) represents a text formatting function that converts numerical samples into a textual format\\nconsistent with the test samples (as indicated by the purple dashed line). Upon constructing the SS-PT, a\\ncomplete input prompt for the LLMs, referred to as the soft sensor query, is obtained. In phase (c), this\\nquery is input into the pre-trained LLMs, which analyze the context samples through ICL to output the\\nsoft sensor predictions y for the primary variables of the test samples.\\np\\nWe have incorporated self-explanation instructions into the SS-PT, leveraging the LLM\\'s robust\\nreasoning and natural language generation capabilities to produce clear, detailed, and human-readable\\nexplanations of model decisions (exp ). This aids operators in making safer, more informed decisions\\nss\\nand conducting causal analysis. Beyond precise point estimates, we have developed two distinct methods\\nfor quantifying output uncertainty. Firstly, by selecting the next token from multiple high-probability\\noptions, the LLM generates diverse textual outputs, allowing us to construct a predictive confidence\\ninterval through repeated experiments. Analyzing the width and boundaries of this interval helps users\\nassess the model\\'s reliability and stability, facilitating more informed decision-making. Secondly, we\\nintroduce instructions in the SS-PT to compel the LLMs to generate a confidence score for its predictions,\\nreflecting the model\\'s confidence level and enabling awareness of prediction performance uncertainty.\\nLastly, our model also exhibits strong robustness to input data uncertainty. Specifically, since the LLMs\\nformats numerical inputs as text-based prompts, any missing values in data samples can be replaced with\\n\\'N/A\\'. Compared to traditional numerical models that require strict normalization and imputation of\\nmissing values, LLM-UFSS simplifies the data preprocessing workflow and avoids inappropriate\\nhandling that could lead to information loss or distortion. This approach enhances readability, robustness,\\nflexibility, and intelligence. Analysis of ablation experiments shows that prompting the LLMs for self-\\nexplanations and confidence scores also improves the predictive performance of the proposed method.\\nAVS-PT and SS-PT with prompt engineering\\n37By incorporating key elements through prompt engineering techniques, we develop a fixed fill-in-the-\\nblank template that allows users to simply input external information into the designated placeholders,\\ngenerating a complete task-specific prompt. The structure and content of the prompt template\\nsignificantly influence the model\\'s output. For the distinct requirements of the LLM-ZAVS and LLM-\\nUFSS modules, we have devised two carefully crafted prompt strategies: the Auxiliary Variable Selection\\nPrompt Template (AVS-PT) and the Soft Sensor Prompt Template (SS-PT) (Fig. 4). These templates are\\ndesigned to activate and guide the LLM\\'s reasoning process effectively.\\nIn designing the AVS-PT, we identified five key components: role, data, instruction, context, and\\nmain user prompt. 1) Role: This element assigns a specific role to the LLMs, allowing it to dynamically\\nadapt to the task and context for more accurate responses. In our study, the LLMs acted as experienced\\nindustrial data analysts. Considering the complexity and potential risks in industrial environments, where\\ndecision-making greatly impacts safety, we employed emotional stimuli44 to emphasize the impact of\\nanalysis on industrial safety. 2) Data: This provides detailed background information on the data\\ncollection process, enabling LLMs to gain a comprehensive understanding of the data context. Users are\\nrequired to input key information into the fill-in-the-blank template, including the specific industrial\\nprocess, equipment, primary variable, and the number of features. 3) Instruction: We have designed two\\ndistinct sets of instructions for local and global queries. Local queries focus on the importance of a\\nspecific auxiliary variable, while global queries rank all auxiliary variables. The CoT prompting technique\\nenhances the accuracy and transparency of LLMs in industrial decision-making by guiding step-by-step\\nreasoning, resulting in detailed self-explanatory texts on feature importance scores. 4) Context: LLMs\\nhave limited ability to handle knowledge-intensive industrial tasks due to a lack of domain-specific\\nknowledge. To address this, we have constructed a IKVS from external sources to expand the\\nfoundational knowledge of LLMs. The relevant knowledge retrieved from IKVS is incorporated into this\\nelement to enhance their reasoning and self-explanatory capabilities. 5）Main User Prompt: This element\\nspecify the variable names to be analyzed and instruct LLMs to generate responses. For local queries, the\\n38auxiliary variable name under analysis replaces the placeholder {Auxiliary Variable}, while for global\\nqueries, all auxiliary variable names are inputted, replacing {Auxiliary Variables}.\\nFor the development of a few-shot soft sensor, we designed the SS-PT template, which consists of\\nseven components: role, data, feature importance score and ranking, global explanation, instruction,\\ncontext prompt, and main user prompt. 1) Role: identical to that in AVS-PT. 2) Data: Similar to AVS-PT,\\nbut includes all auxiliary variables identified by LLM-ZAVS. 3) Feature Importance Score and Ranking:\\nGenerated by LLM-ZAVS, enabling LLMs to perform more granular soft sensor reasoning. 4) Global\\nExplanation: Also generated by LLM-ZAVS. 5) Instruction: Guides LLMs to execute ICL to generate\\npredictions and produce a reasonable explanation based on the CoT. 6) Context Prompt: Formats few-shot\\nlabeled input-output pairs into a text sequence and inserted into this element. 7) Main User Prompt: Users\\ninput the test samples into this element, guiding LLMs to generate the final results.\\nTable 10 | Structured JSON output formats for LLMs query responses\\nMethod JSON Response Formats\\nLLM-ZAVS {\"title\": \"answer\", \"type\": \"object\", \"description\": \"Output parsing structure.\",\\n(Local Query) \"properties\": {\"reasoning\": {\"title\": \"Reasoning\", \"description\": \"The detailed reasoning\\nbehind the feature importance\", \"type\": \"string\"}}, \"required\": [\"reasoning\"]}\\nLLM-ZAVS {\"title\": \"answer\", \"type\": \"object\", \"description\": \"Output parsing structure.\",\\n(Global Query) \"properties\": {\"score and ranking\": {\"title\": \"score and ranking\", \"description\": \"feature\\nscore and ranking for predicting target variable\", \"type\": \"string\"}, \"reasoning\": {\"title\":\\n\"Reasoning\", \"description\": \"The detailed reasoning behind the feature ranking.\", \"type\":\\n\"string\"}}, \"required\": [\"score and ranking\", \"reasoning\"]}\\nLLM-UFSS {\"title\": \"answer\", \"type\": \"object\", \"description\": \"Output parsing structure.\",\\n\"properties\": {\"Reasoning\": {\"title\": \"Reasoning\", \"description\": \"The detailed reasoning\\nbehind the prediction result.\", \"type\": \"string\"}, \"Confidence Score\": {\"title\":\\n\"Confidence Score\", \"description\": \"The confidence score behind the prediction result.\",\\n\"type\": \"number\"}, \"Prediction Result\": {\"title\": \"Prediction result\", \"description\":\\n\"Prediction result of target variable\", \"type\": \"number\"}}, \"required\": [\"Prediction\\nResult\", \"Reasoning\", \"Confidence Score\"]}\\n39To accurately extract model prediction results, confidence scores, and explanations from the LLM\\'s\\noutput, we employ prompt engineering to enforce the model to return structured outputs in JSON format.\\nThis facilitates subsequent data processing. Instruction details are shown in Table 10.\\nReferences\\n1. Yao L, Ge ZQ. Causal variable selection for industrial process quality prediction via attention-based GRU\\nnetwork. Eng Appl Artif Intell 118, 18 (2023).\\n2. Lawrence NP, et al. Machine learning for industrial sensing and control: A survey and practical perspective.\\nControl Eng Practice 145, 16 (2024).\\n3. Zhang TM, Yan GW, Ren MF, Cheng L, Li R, Xie G. Dynamic transfer soft sensor for concept drift adaptation.\\nJ Process Control 123, 50-63 (2023).\\n4. Curreri F, Patanè L, Xibilia MG. Soft Sensor Transferability: A Survey. Appl Sci-Basel 11, 18 (2021).\\n5. Zhai RK, Zheng JH, Song ZH, Ge ZQ. Reliable Soft Sensors With an Inherent Process Graph Constraint. IEEE\\nTrans Ind Inform 20, 8798-8806 (2024).\\n6. Zhang XM, He BC, Zhu HY, Song ZH. Information Complementary Fusion Stacked Autoencoders for Soft\\nSensor Applications in Multimode Industrial Processes. IEEE Trans Ind Inform 20, 106-116 (2024).\\n7. Niresi KF, Bissig H, Baumann H, Fink O. Physics-Enhanced Graph Neural Networks for Soft Sensing in\\nIndustrial Internet of Things. IEEE Internet Things J 11, 34978-34990 (2024).\\n8. Hasnen SH, Shahid M, Zabiri H, Taqvi SAA. Semi-supervised adaptive PLS soft-sensor with PCA-based drift\\ncorrection method for online valuation of NOx emission in industrial water-tube boiler. Process Saf Environ\\nProtect 172, 787-801 (2023).\\n9. Yuan XF, Ye LJ, Bao L, Ge ZQ, Song ZH. Nonlinear feature extraction for soft sensor modeling based on\\nweighted probabilistic PCA. Chemometrics Intell Lab Syst 147, 167-175 (2015).\\n10. Wang ZX, He QP, Wang J. Comparison of variable selection methods for PLS-based soft sensor modeling. J\\nProcess Control 26, 56-72 (2015).\\n11. Li Z, Lee YS, Chen JH, Qian YW. Developing variable moving window PLS models: Using case of NOx\\nemission prediction of coal-fired power plants. Fuel 296, 16 (2021).\\n4012. Liu J, et al. A soft sensing method of billet surface temperature based on ILGSSA-LSSVM. Sci Rep 12, 10\\n(2022).\\n13. Wang HX, Sui L, Zhang MY, Zhang FF, Ma FY, Sun K. A Novel Input Variable Selection and Structure\\nOptimization Algorithm for Multilayer Perceptron-Based Soft Sensors. Math Probl Eng 2021, 10 (2021).\\n14. Bendaouia A, et al. Artificial intelligence for enhanced flotation monitoring in the mining industry: A\\nConvLSTM-based approach. Comput Chem Eng 180, 13 (2024).\\n15. Yan F, Yang CJ, Zhang XM. Stacked Spatial-Temporal Autoencoder for Quality Prediction in Industrial\\nProcesses. IEEE Trans Ind Inform 19, 8625-8634 (2023).\\n16. Wang X, Liu H. Soft sensor based on stacked auto-encoder deep neural network for air preheater rotor\\ndeformation prediction. Adv Eng Inform 36, 112-119 (2018).\\n17. Jiang YC, Yin S, Dong JW, Kaynak O. A Review on Soft Sensors for Monitoring, Control, and Optimization\\nof Industrial Processes. IEEE Sens J 21, 12868-12881 (2021).\\n18. Ge ZQ. Review on data-driven modeling and monitoring for plant-wide industrial processes. Chemometrics\\nIntell Lab Syst 171, 16-25 (2017).\\n19. Yuan XF, et al. Attention-Based Interval Aided Networks for Data Modeling of Heterogeneous Sampling\\nSequences With Missing Values in Process Industry. IEEE Trans Ind Inform 20, 5253-5262 (2024).\\n20. Ma L, Wang MW, Peng KX. A missing manufacturing process data imputation framework for nonlinear\\ndynamic soft sensor modeling and its application. Expert Syst Appl 237, 11 (2024).\\n21. Fortuna L, Graziani S, Xibilia MG. Comparison of Soft-Sensor Design Methods for Industrial Plants Using\\nSmall Data Sets. IEEE Trans Instrum Meas 58, 2444-2451 (2009).\\n22. Tian Y, Xu Y, Zhu QX, He YL. Novel Virtual Sample Generation Using Target-Relevant Autoencoder for\\nSmall Data-Based Soft Sensor. IEEE Trans Instrum Meas 70, 10 (2021).\\n23. Guo RY, Liu H, Xie G, Zhang YM, Liu D. A Self-Interpretable Soft Sensor Based on Deep Learning and\\nMultiple Attention Mechanism: From Data Selection to Sensor Modeling. IEEE Trans Ind Inform 19, 6859-\\n6871 (2023).\\n24. Kay H, et al. Constructing a Symbolic Regression-Based Interpretable Soft Sensor for Industrial Data\\nAnalytics and Product Quality Control. Ind Eng Chem Res 63, 4083-4092 (2024).\\n4125. Rebello CM, et al. Machine Learning-Based Dynamic Modeling for Process Engineering Applications: A\\nGuideline for Simulation and Prediction from Perceptron to Deep Learning. Processes 10, 18 (2022).\\n26. Achiam J, et al. Gpt-4 technical report. arXiv preprint arXiv:230308774, (2023).\\n27. Team G, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv\\npreprint arXiv:240305530, (2024).\\n28. Zhao WX, et al. A survey of large language models. arXiv preprint arXiv:230318223, (2023).\\n29. Zhou JX, et al. Pre-trained multimodal large language model enhances dermatological diagnosis using\\nSkinGPT-4. Nat Commun 15, 12 (2024).\\n30. Imani S, Du L, Shrivastava H. Mathprompter: Mathematical reasoning using large language models. arXiv\\npreprint arXiv:230305398, (2023).\\n31. Gupta S, et al. PRISM: Patient Records Interpretation for Semantic clinical trial Matching system using large\\nlanguage models. npj Digit Med 7, 12 (2024).\\n32. Bran AM, Cox S, Schilter O, Baldassari C, White AD, Schwaller P. Augmenting large language models with\\nchemistry tools. Nat Mach Intell 6, 13 (2024).\\n33. Wei J, et al. Emergent abilities of large language models. arXiv preprint arXiv:220607682, (2022).\\n34. Webb T, Holyoak KJ, Lu HJ. Emergent analogical reasoning in large language models. Nat Hum Behav 7,\\n1526-1541 (2023).\\n35. Dong Q, et al. A survey on in-context learning. In: Proceedings of the 2024 Conference on Empirical Methods\\nin Natural Language Processing (2024).\\n36. Xie SM, Raghunathan A, Liang P, Ma T. An explanation of in-context learning as implicit bayesian inference.\\narXiv preprint arXiv:211102080, (2021).\\n37. Xie SW, Yu YJ, Xie YF, Tang ZH. Sensitive Feature Selection for Industrial Flotation Process Soft Sensor\\nBased on Multiswarm PSO With Collaborative Search. IEEE Sens J 24, 17159-17168 (2024).\\n38. Lewis P, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural\\nInformation Processing Systems 33, 9459-9474 (2020).\\n39. Gao Y, et al. Retrieval-augmented generation for large language models: A survey. arXiv preprint\\narXiv:231210997, (2023).\\n4240. Wei J, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural\\ninformation processing systems 35, 24824-24837 (2022).\\n41. Chu Z, et al. A survey of chain of thought reasoning: Advances, frontiers and future. arXiv preprint\\narXiv:230915402, (2023).\\n42. Gao S, Wen X-C, Gao C, Wang W, Zhang H, Lyu MR. What makes good in-context demonstrations for code\\nintelligence tasks with llms? In: 2023 38th IEEE/ACM International Conference on Automated Software\\nEngineering (ASE)). IEEE (2023).\\n43. Shanahan M, McDonell K, Reynolds L. Role play with large language models. Nature 623, 493-498 (2023).\\n44. Li C, et al. Large language models understand and can be enhanced by emotional stimuli. arXiv preprint\\narXiv:230711760, (2023).\\n45. Goldrick S, Stefan A, Lovett D, Montague G, Lennox B. The development of an industrial-scale fed-batch\\nfermentation simulation. J Biotechnol 193, 70-82 (2015).\\n46. Munir N, et al. Interpretable Machine Learning Methods for Monitoring Polymer Degradation in Extrusion of\\nPolylactic Acid. Polymers 15, 23 (2023).\\n47. Guo XP, Wang QQ, Li Y. Weighted target feature regression neural networks based soft sensing for industrial\\nprocess. Can J Chem Eng 102, 840-852 (2024).\\n48. Li J, Huang H. Mutual Information Deep Sparse Auto-Encoding Hybrid DLSTM Prediction Network.\\nComputer Engineering and Application 58, 277-285 (2022).\\n49. Zheng DD, Shao SM, Liu AN, Wang MS, Li T. Soft measurement model for wet gas flow rate based on\\nultrasonic and differential pressure sensing. Meas Sci Technol 35, 13 (2024).\\n50. Yang L, Liu H, Chen FG. Soft sensor method of multimode BOF steelmaking endpoint carbon content and\\ntemperature based on vMF-WSAE dynamic deep learning. High Temp Mater Process 42, 21 (2023).\\n51. Xu W, Tang J, Xia H, Yu W, Qiao JF. Multi-objective PSO semi-supervised random forest method for dioxin\\nsoft sensor. Eng Appl Artif Intell 135, 16 (2024).\\n52. Hua L, Zhang C, Sun W, Li YM, Xiong JL, Nazir MS. An evolutionary deep learning soft sensor model based\\non random forest feature selection technique for penicillin fermentation process. ISA Trans 136, 139-151\\n(2023).\\n4353. Shin S, Baek K, Choi Y, So H. Utilization of Machine Learning Techniques in Hot-Film Based Airflow Rate\\nSensors for Improving Flow Measurement. Adv Intell Syst 6, 10 (2024).\\n54. Sadeghian A, Jan NM, Wu O, Huang B. Robust probabilistic principal component regression with switching\\nmixture Gaussian noise for soft sensing. Chemometrics Intell Lab Syst 222, 11 (2022).\\n55. Chen N, Dai JY, Yuan XF, Gui WH, Ren WT, Koivo HN. Temperature Prediction Model for Roller Kiln by\\nALD-Based Double Locally Weighted Kernel Principal Component Regression. IEEE Trans Instrum Meas 67,\\n2001-2010 (2018).\\n56. Lee M, Bae J, Kim SB. Uncertainty-aware soft sensor using Bayesian recurrent neural networks. Adv Eng\\nInform 50, 14 (2021).\\n57. Guo RY, Liu H, Liu D. When Deep Learning-Based Soft Sensors Encounter Reliability Challenges: A\\nPractical Knowledge-Guided Adversarial Attack and Its Defense. IEEE Trans Ind Inform 20, 2702-2714\\n(2024).\\n58. Guo RY, Chen QY, Liu H, Wang WQ. Adversarial Robustness Enhancement for Deep Learning-Based Soft\\nSensors: An Adversarial Training Strategy Using Historical Gradients and Domain Adaptation. Sensors 24, 15\\n(2024).\\n59. Chen L, Xu Y, Zhu QX, He YL. Adaptive Multi-Head Self-Attention Based supervised VAE for Industrial\\nSoft Sensing With Missing Data. IEEE Trans Autom Sci Eng 21, 3564-3575 (2024).\\n60. Ren JY, Chen X, Zhao CH. Partial transfer learning network for data imputation and soft sensor under various\\noperation conditions. J Cent South Univ 30, 3395-3413 (2023).\\n61. Ouyang L, et al. Training language models to follow instructions with human feedback. Advances in neural\\ninformation processing systems 35, 27730-27744 (2022).\\n44',\n",
       " 'AI-Driven Diabetic Retinopathy Screening Multicentric Validation of AIDRSS in India.pdf': 'AI-Driven Diabetic Retinopathy Screening: Multicentric Validation\\nof AIDRSS in India\\nAmitKrDeya,PradeepWaliab,GirishSomvanshib,AbrarAlib,SagarnilDas1b,*,Pallabi\\nPaulb,MinakhiGhoshb\\naDiabetologist,HealthPlus,ActionAreaI,Newtown,KolkataWestBengal,700156,India\\nbArtificialLearningSystemsIndiaPvtLtd,R&D,1665/A,14thMainRd,Sector7,HSRLayout,Bengaluru,\\nKarnataka560102,India\\nAbstract.\\nPurpose: Diabeticretinopathy(DR)isamajorcauseofvisionloss,particularlyinIndia,whereaccesstoretinaspe-\\ncialists is limited in rural areas. This study aims to evaluate the Artificial Intelligence-based Diabetic Retinopathy\\nScreeningSystem(AIDRSS)forDRdetectionandprevalenceassessment,addressingthegrowingneedforscalable,\\nautomatedscreeningsolutionsinresource-limitedsettings.\\nApproach: A multicentric, cross-sectional study was conducted in Kolkata, India, involving 5,029 participants and\\n10,058 macula-centric retinal fundus images. The AIDRSS employed a deep learning algorithm with 50 million\\ntrainableparameters,integratedwithContrastLimitedAdaptiveHistogramEqualization(CLAHE)preprocessingfor\\nenhancedimagequality. DRwasgradedusingtheInternationalClinicalDiabeticRetinopathy(ICDR)Scale,catego-\\nrizingdiseaseintofivestages(DR0toDR4). Statisticalmetricsincludingsensitivity,specificity,andprevalencerates\\nwereevaluatedagainstexpertretinaspecialistassessments.\\nResults: TheprevalenceofDRinthegeneralpopulationwas13.7%,risingto38.2%amongindividualswithelevated\\nrandom blood glucose levels. The AIDRSS achieved an overall sensitivity of 92%, specificity of 88%, and 100%\\nsensitivityfordetectingreferableDR(DR3andDR4). Theseresultsdemonstratethesystem’srobustperformancein\\naccuratelyidentifyingandgradingDRinadiversepopulation.\\nConclusions: AIDRSS provides a reliable, scalable solution for early DR detection in resource-constrained envi-\\nronments. ItsintegrationofadvancedAItechniquesensureshighdiagnosticaccuracy,withpotentialtosignificantly\\nreducetheburdenofdiabetes-relatedvisionlossinunderservedregions.\\nKeywords: Artificial Intelligence, diabetic retinopathy screening, deep learning, neural networks, Contrast Limited\\nAdaptiveHistogramEqualization(CLAHE).\\n1 Introduction\\nDiabetic Retinopathy (DR)12 is a serious microvascular complication of diabetes mellitus and a\\nsignificantglobalhealthconcern. Itistheleadingcauseofpreventablevisionlossamongworking-\\nageadultsworldwide,reflectingthegrowingburdenofdiabetesinbothdevelopedanddeveloping\\ncountries. The gradual progression of DR, often without early symptoms, necessitates systematic\\nscreeningtoenabletimelyinterventionandpreventirreversiblevisionimpairment. Earlydetection\\nis crucial to halt the progression of DR, which otherwise may result in costly treatment options or\\npermanentblindness.\\n1\\n5202\\nnaJ\\n31\\n]VI.ssee[\\n2v62850.1052:viXra1.1 Significance\\nIndiaisfacingadualchallengewiththeincreasingprevalenceofdiabetesandlimitedaccesstospe-\\ncializedophthalmiccare,particularlyinruralandunderservedregions.3 Accordingtoanationwide\\nscreening program conducted by the All-India Ophthalmological Society (AIOS) in 2014, 21.7%\\nof individuals with diabetes were found to have DR. This highlights the substantial public health\\nchallenge posed by DR and the need for targeted interventions. Despite this, awareness about\\ndiabetes-related complications and access to regular retina screening remain inadequate, leaving a\\nlargesegmentofthepopulationatriskofvision-threateningstagesofDR.\\nThesignificanceofearlydetectioncannotbeoverstated. Routineretinascreeningfacilitatesthe\\ntimely identification of early-stage DR, which can be managed effectively to prevent progression\\ntoadvancedstages. KeymeasuresforaddressingDRinclude:\\n• Promoting Awareness: Educating the public on maintaining optimal glycemic control and\\nthenecessityofregulareyeexaminations.\\n• RoutineScreening: Encouragingannualfundusexaminations,evenforasymptomaticindi-\\nviduals.\\n• Timely Referrals: Ensuring that treating physicians recognize and prioritize ophthalmic\\nevaluationsfordiabeticpatients.\\n1.2 ResearchObjectives\\nThis study evaluates the effectiveness of the Artificial Intelligence-based Diabetic Retinopathy\\nScreening System (AIDRSS) developed by ARTELUS™, an automated deep learning algorithm\\nforDRdetection. Theprimaryobjectivesofthisresearchare:\\n21. To assess the performance of AIDRSS in classifying retinal fundus images based on the\\nInternationalClinicalDiabeticRetinopathy(ICDR)Scale.\\n2. ToenhancetheaccuracyoftheAIDRSSalgorithmbyincorporatingadvancedimageprepro-\\ncessingtechniques,suchasContrastLimitedAdaptiveHistogramEqualization(CLAHE).\\n3. To determine the prevalence of DR across multiple screening centers in Kolkata, West Ben-\\ngal, India, and examine its correlation with random blood glucose (RBG) levels and other\\nclinicalparameters.\\n1.3 ImplicationsoftheStudy\\nThis research has the potential to significantly influence public health policy and clinical practice.\\nThekeyimplicationsinclude:\\n• Scalability and Accessibility: Demonstrating how AI-based systems like AIDRSS can ad-\\ndressthescarcityofretinaspecialists,especiallyinresource-limitedsettings.\\n• ClinicalAccuracy: ValidatingthereliabilityofAIDRSSthroughrigorousevaluationagainst\\ngold-standardretinaspecialistassessments.\\n• Policy Development: Informing healthcare strategies for integrating AI technologies into\\nnationalDRscreeningprograms,therebyreducingtheburdenofdiabetes-relatedblindness.\\nBy bridging the gap between technology and clinical application, this study highlights the\\ntransformative potential of automated screening systems in addressing the growing burden of DR\\ninIndiaandsimilarhealthcarecontextsglobally.\\n32 MaterialsandMethods\\n2.1 StudyDesign\\nThis was a retrospective study using data collected from routine screenings at multiple centers in\\nKolkata, India. The data comprised retinal fundus images collected between January and March\\n2023. A total of 5,029 participants were screened, and their de-identified retinal images were\\nanalyzedretrospectively. Thevalidationwasperformedonawithhelddatasetfromaseparatesite,\\nensuringanindependentevaluationofAIDRSS.\\n2.2 ValidationMethodology\\nWe validated the AIDRSS system’s performance on a completely withheld dataset from an in-\\ndependent screening site, comprising 1,200 images not included in the training or development\\ndatasets. Additionally, five-fold cross-validation was employed to assess the model’s generaliz-\\nability across diverse patient subsets. Each fold reserved data from a unique center, ensuring no\\noverlapbetweentrainingandtestingimages.\\nThe withheld site validation tested the system’s robustness when applied to a new population,\\nwhile cross-validation provided insight into its consistency across different subsets of the study\\npopulation. Performancemetrics,includingsensitivity,specificity,positivepredictivevalue(PPV),\\nand negative predictive value (NPV), were calculated for both the cross-validation and withheld\\ndatasets.\\nTo ensure statistical robustness, confidence intervals (95% CI) for all performance metrics\\nwere computed using bootstrap resampling with 1,000 iterations. This method provides a non-\\nparametric estimate of the variability in the calculated metrics, offering a reliable measure of the\\nsystem’s performance. Additionally, McNemar’s test was performed to compare the performance\\n4oftheAIDRSSagainstbaselineorothermodelsonpaireddata. Thesestatisticalapproachesensure\\nathoroughandaccurateassessmentofthemodel’sdiagnosticcapabilities.\\n2.3 Participants\\nThe study screened a total of 5,029 adults during the specified study period. Among this pop-\\nulation, a significant proportion, 4,261 individuals (84.7%), were unaware of their diabetes sta-\\ntus. Furthermore, 4,692 participants (93.3%) were uninformed about the potential microvascular\\ncomplications associated with diabetes, including the risk of permanent blindness resulting from\\nuncontrolleddiabetes.\\n2.4 DiabeticRetinopathyScreeningSystem(AIDRSS)\\nThe AIDRSS utilized in this study was the Artelus Fundus camera (Fig 1), a portable and easy-\\nto-operate non-mydriatic automatic device for capturing retinal fundus photographs. The camera\\nsignificantly reduced the time required to capture fundus images and was complemented by the\\nAIDRSS software (DRISTI A.I.),4 an Artificial Intelligence-based program designed to analyze\\nfundus images. The AIDRSS utilized a deep learning algorithm with a modified neural network\\narchitecture comprising approximately 50 million trainable parameters and 250 layers deep. The\\nnetworkparameterswerelearnedusingtheAdamoptimizeralgorithm.\\n2.5 CLAHEasanimageprocessingtechnique\\nToenhancethequality ofretinalimagesandimprovetheaccuracy ofthedeeplearningalgorithm,\\nContrastLimitedAdaptiveHistogramEqualization(CLAHE)5 wasemployedasanimageprepro-\\ncessingtechnique. CLAHEisanon-linearimageenhancementmethodthatenhanceslocalcontrast\\nbyredistributingthepixelintensitiesinawaythatpreservesbothglobalandlocalinformation.\\n5Fig1 ArtelusFundusCameraandDRprevalenceingeneralpopulation.\\nBefore inputting the retinal images into the deep learning algorithm, CLAHE was applied to\\nenhance the visibility of subtle details and features in the images. This preprocessing step aimed\\nto address issues such as uneven illumination, low contrast, and variability in image quality. By\\nequalizing the histogram of localized regions within the image, CLAHE effectively enhanced the\\nvisibility of important structures and abnormalities, thus aiding the accurate detection and grad-\\ning of diabetic retinopathy. The CLAHE preprocessing technique was integrated into the overall\\nimage-processing pipeline of the AIDRSS. By incorporating CLAHE as a preprocessing step, the\\nstudy aimed to optimize the performance of the deep learning algorithm and improve the overall\\neffectiveness of the screening system. The impact of CLAHE on the performance of the AIDRSS\\nwas evaluated through a comparative analysis of the results obtained from images processed with\\nand without CLAHE. The findings of this analysis provided insights into the potential benefits of\\nCLAHE in enhancing the accuracy and reliability of the AI-based diabetic retinopathy screening\\nsystem.\\n62.6 ProposedAlgorithm\\nDeeplearningiscurrentlystate-of-the-artforcomputervision/imageprocessing,speech,textprob-\\nlems,andautomotive. TheAIDRSSutilizedadeeplearningalgorithmwithamodifiedneuralnet-\\nwork architecture comprising approximately 50 million trainable parameters and 250 layers deep.\\nThe proposed network is a modified architecture version presented in.6 The values of the network\\nparameters are learned using the Adam optimizer algorithm. Neural network hyper-parameter\\nlearning is an iterative process based on the loss value computed between ground truths given by\\nophthalmologists and network predictions. This loss value acts as a feedback to the optimizer to\\nlearnthemostrepresentativenetworkparameterstounderstandretinalpathologicallesions.\\nThelossfunctionusedisdefinedas:\\nN\\n1 (cid:88)\\nL = (y −yˆ)2 (1)\\ni i\\nN\\ni=1\\nwherey isthegroundtruth,yˆ isthepredictedvalue,andN isthenumberofsamples.\\ni i\\n2.7 NetworkArchitecture\\nEncoder Architecture for Transfer Learning One of the concerns with medical data is the unavail-\\nability of high-volume, high-quality, labeled data. Even the label available by one single ophthal-\\nmologistmightnotreflectthesameopinionasthatofanotherpractitioner. Foraneffectivesystem,\\nweneeddatatobelabeledbymanyophthalmologists. Sinceit’sveryexpensivetogethigh-volume\\ndata annotated by multiple annotators, we have another effective approach to deal with the same:\\nlabelnoiseminimization. Welabelafractionofthedatasetbymultipleannotators(Goldenset)and\\nleave out the rest of the dataset with a single annotation (TFL set). We train a two-headed model\\n7Fig2 Encoder-basedtransferlearningarchitecture.\\nwith one head to reproduce the sample using avariational encoder and the second headto classify\\nthe sample on the whole dataset. Sample-wise weighted loss is used for the classification head.\\nWesetahighlossweightforGoldensetsamplesandarelativelylowweightforTFLsetsamples.\\nThe weighting strategy is based on sample annotation. The trained encoder parameters will be\\nused to initialize the final deep network for classification. This way, we ensure that all samples’\\npathologicalfeaturesinformationispreservedintheencodernetworkandcanbetransferredtothe\\nfinalnetwork(Fig2).\\n2.7.1 Partialattention\\nWe use a modified version of the partial attention7 over the lower blocks of the classifier feature\\nmaps. Feeding the intermediate feature maps information to the higher layers improves the net-\\nwork’s learning stability and representation power. It also facilitates easier training of very deep\\nmodels by eliminating the vanishing gradient problem. The attention mechanism here only fo-\\n8cuses on the feature maps with spatial resolutions equal to or larger than the target feature map\\noutputs. Stridden convolution with stride sij is used to reduce the spatial resolution of the feature\\nmaps to match the target output size and the number of output feature maps as per the attention\\nconfiguration. Inthepartialattentionmechanism,Eiisthecurrenttargetfeaturemapsforattention\\nto applying (before reducing the feature map width and height for each block) of each convolu-\\ntion block of the classifier (Fig 3). Attention weights are learned using attention parameters W.\\nFeature-wise, attention is applied over the convolved feature maps and summed up using the at-\\ntention weights. The attended features map is again concatenated with the target feature map to\\npreservetheoriginalinformation. Weuseanotherconvolutionallayertogettheattendedoutputto\\nreducethealiasingeffect.\\nThepartialattentionmechanismisdefinedas:\\nEattended = min(heightE ,widthE ),min(heightE ,widthE ) (2)\\ni i i j j\\n2.7.2 DenseResidualInceptionmodule\\nWehaveusedanimprovedinceptionblockproposedin8 asabaselineforournewinceptionblocks,\\nwhereblock-basedconvolutionlayers,residual,andskipconnectionswereusedtoensurerichfea-\\nturerepresentation. Wehaveaddedaprimaryresidualconnectionfromtheclockinputtotheoutput\\n(Fig4)toaugmentthenetworkwithblockinputfeaturesandtosolvethevanishinggradientprob-\\nlem for a very deep network. Apart from that, we have used a residual connection in the block’s\\n3x3 and 5x5 convolutional layers; these connections improve the network feature representation\\ncapability and slightly reduce training convergence time. The block’s final concatenated interme-\\ndiate output features map is convolved with another 3×3 convolutional layer to reduce aliasing. A\\n9Fig3 Partialattentionoverfeaturemaps.\\nFig4 ResidualInceptionArchitecture.\\nresidualconnectionisaddedwith1×1convolvedinputfeaturestomakesurethatbothfeaturesmay\\nhavethesamenumberofoutputfilters. Additionally,wehaveusedaconvolutionfactorizationver-\\nsion (Fig 5) of the same module for the classifier. Convolutional factorization adds the efficiency\\nofdoingaconvolutionofaspecificspatialdimensionwithalowcomputationalcost.\\n10Fig5 ResidualInceptionwithconvolutionfactorizationfortheclassifiernode.\\n2.7.3 Imagegradingandcomparison\\nThe retinal fundus photographs captured using the Artelus Fundus camera were subjected to anal-\\nysis by the AIDRSS. The AI algorithm incorporated in the AIDRSS classified the fundus images\\nbasedontheInternationalClinicalDiabeticRetinopathy(ICDR)Scale,categorizingthemasDR0,\\nDR1, DR2, DR3, or DR4. This grading system allowed for identifying the presence and severity\\nofdiabeticretinopathy.\\nTheaccuracyoftheclassificationcanbeevaluatedusingthefollowingmetrics:\\nTP +TN\\nAccuracy = (3)\\nTP +TN +FP +FN\\nwhere TP is true positives, TN is true negatives, FP is false positives, and FN is false\\nnegatives.\\n113 Results\\n3.1 DatasetandPopulationCharacteristics\\nThis study utilized a dataset of 5,029 de-identified subjects, with two macula-centric retinal im-\\nages captured per individual, resulting in a total of 10,058 images. After quality checks, 4,482\\nadults(89.1%)hadgradablefundusimagesthatwereincludedintheanalysis. Theexcludedcases\\n(n=547; 10.9%) were primarily due to image quality issues, such as poor illumination or motion\\nartifacts.\\nTheanalysisrevealedthattheprevalenceofdiabeticretinopathy(DR)inthegeneralpopulation\\nscreenedwas13.7%(95%CI:12.6%–14.8%). ThebreakdownofDRseveritywasasfollows:\\n• DR1(Mild): 9.16%(95%CI:8.2%–10.1%)\\n• DR2(Moderate): 4.40%(95%CI:3.8%–5.1%)\\n• ReferableDR(DR3andDR4): 0.14%(95%CI:0.05%–0.23%)\\nAmong individuals with elevated random blood glucose (RBG) levels, the prevalence of DR\\nwas significantly higher at 38.2% (95% CI: 35.5%–40.9%). This suggests a strong correlation\\nbetweenuncontrolleddiabetesandthepresenceofDR,underscoringtheimportanceofsystematic\\nscreening.\\n3.2 PerformanceMetricsofAIDRSS\\nThe AIDRSS system was evaluated using a gold standard comparison with retina specialists’ as-\\nsessments. Key performance metrics, including sensitivity, specificity, positive predictive value\\n(PPV), and negative predictive value (NPV), are summarized in Table 1. The overall sensitivity\\n12was 92.0% (95% CI: 89.4%–94.3%), while specificity was 88.0% (95% CI: 85.2%–90.4%). For\\ndetectingreferableDR(DR3andDR4),thesensitivityreached100%.\\nTable1PerformanceMetricsofAIDRSS\\nMetric Value(%) 95%CI\\nSensitivity(Overall) 92.0 89.4–94.3\\nSpecificity(Overall) 88.0 85.2–90.4\\nPositivePredictiveValue(PPV) 85.6 82.9–88.1\\nNegativePredictiveValue(NPV) 93.5 91.0–95.6\\nSensitivity(ReferableDR) 100.0 –\\nSpecificity(ReferableDR) 99.9 99.8–100.0\\n3.3 AnalysisofReferableDRDetection\\nA total of six individuals (0.14%) were identified as having referable DR (grades DR3 and DR4).\\nThe AIDRSS achieved a perfect sensitivity of 100.0% (6/6 cases correctly identified) and a speci-\\nficityof99.9%. Table2detailsthedetectionperformanceforreferableDR.\\nTable2PerformanceMetricsforReferableDR(GradesDR3andDR4)\\nMetric Value(%) 95%CI\\nSensitivity 100.0 –\\nSpecificity 99.9 99.8–100.0\\nPPV 85.7 72.9–98.5\\nNPV 100.0 –\\n3.4 ComparisonwithEstablishedAIModels\\nTo contextualize the performance of AIDRSS, we compared it with established AI models for\\ndiabetic retinopathy screening, specifically IDx-DR,9 EyeArt,10 and AEYE-DS.11 These models\\n13have been previously validated and are widely recognized in the field. Table 3 summarizes the\\nsensitivityandspecificitymetricsforAIDRSSandthebenchmarksystems.\\nTable3PerformanceMetricsComparisonwithEstablishedAIModels\\nMetric AIDRSS IDx-DR EyeArt AEYE-DS\\nSensitivity(%) 92.0 87.4 96.0 93.0\\nSpecificity(%) 88.0 89.5 88.0 91.4\\nTheseresultsdemonstratethatAIDRSSperformscompetitivelywithotherstate-of-the-artsys-\\ntems. Notably, AIDRSS achieves a balance between sensitivity and specificity, which is particu-\\nlarlyadvantageousinresource-limitedsettings. Highsensitivityensuresthatmostcasesofdiabetic\\nretinopathy (DR) are detected, reducing the risk of missed diagnoses and enabling early interven-\\ntion. At the same time, high specificity minimizes false positives, thereby preventing unnecessary\\nreferrals and reducing the burden on limited healthcare resources. This balance enhances the ef-\\nficiency and effectiveness of screening programs, making AIDRSS a valuable tool in areas with\\nconstrainedhealthcareinfrastructure.\\nHowever,itisimportanttoconsiderthelimitationsofcomparingAIDRSSwithotherAImod-\\nels. Differences in datasets, imaging equipment, and population characteristics can significantly\\ninfluence performance metrics. For instance, variations in image quality, camera types, and de-\\nmographic factors such as ethnicity and age may affect sensitivity and specificity outcomes. AI\\nmodelstrainedondatasetsfromoneregionmayunderperformwhenvalidatedonexternaldatasets\\ndue to differences in disease prevalence and imaging conditions. These factors highlight the im-\\nportanceofaccountingfordatasetcompositionandgeneralizabilitywheninterpretingcomparative\\nperformancemetrics.\\nFuture work should focus on validating AIDRSS in diverse geographic and clinical settings to\\n14assess its robustness across different populations. Such efforts will further establish its utility as a\\nscalable,reliablesolutionfordiabeticretinopathyscreening.\\n3.5 Preprocessing\\nTheinputimageswereresizedto256×256×3,andarandomlycroppedpatchof224×224×3was\\nusedfortraining. Extensivedataaugmentationtechniqueswereappliedtoimprovegeneralization,\\nincluding:\\n• Randomflips(horizontalandvertical).\\n• Adjustmentstohue,saturation,andcontrast.\\n• Randommaskingwith5–8occlusionsperimageofvariedsize.\\nAllimageswerestandardizedbysubtractingthemeanpixelvalueanddividingbythestandard\\ndeviation. Thesepreprocessingstepsensuredrobustnessagainstvariabilityinimagequality.\\n3.6 TrainingProcedure\\nThedeeplearningmodelincorporatedseveralstrategiestooptimizetraining:\\n• BatchNormalization: Usedtoreducecovariateshiftandaccelerateconvergence.12\\n• Optimizer: Nesterovmomentumwithapolynomiallearningratedecay.\\n• GradientNormalization: Stabilizedtrainingandmitigatedexplodinggradients.13\\n• Regularization: Labelsmoothing(softtargets)anddropoutlayerstoimprovegeneralization\\nandpreventoverfitting.\\n15The model was trained on five-fold cross-validation to ensure robustness, and five different\\narchitecturesweretrainedandensemble-averagedforfinalpredictions.\\n3.7 ValidationandDiscussion\\nTheAIDRSSdemonstratedexcellentperformanceacrossmultiplemetrics,showinghighsensitiv-\\nity and specificity for DR detection and referable DR identification. However, some limitations\\nwerenoted:\\n• Cases of poor image quality resulted in exclusion, highlighting the importance of standard-\\nizedimagingprotocols.\\n• Thestudywasconductedinasinglegeographicregion,limitinggeneralizability.\\nFutureworkwillfocusonexpandingthedatasettoincludediversepopulationsandintegrating\\nadditionalclinicalparameterstofurtherrefinethediagnosticcapabilitiesofthesystem.\\n4 Discussion\\nDiabetic retinopathy (DR) is a major cause of avoidable blindness, particularly in regions like\\nIndia, where the prevalence of diabetes is rapidly increasing. This study demonstrated the effec-\\ntiveness of the Artificial Intelligence-based Diabetic Retinopathy Screening System (AIDRSS) in\\ndetectingandgradingDR,highlightingitspotentialtoaddresscriticalhealthcaregaps. Thefollow-\\ningdiscussiondelvesintotheimplicationsofthesefindings,contextualizesthemwithinthebroader\\nhealthcareframework,andexaminesthestrengthsandlimitationsoftheproposedapproach.\\n164.1 ImplicationsofFindings\\nTheprevalenceofDRobservedinthestudypopulationunderscorestheurgentneedforsystematic\\nscreening programs. Among the general population, 13.7% of participants had some form of DR,\\nand this prevalence rose to 38.2% among individuals with elevated random blood glucose (RBG)\\nlevels. These findings align with previous studies, emphasizing the strong correlation between\\npoorglycemiccontrolandtheonsetofDR.\\nTheAIDRSSexhibitedexcellentperformancemetrics,achievinganoverallsensitivityof92.0%\\nand specificity of 88.0%. Particularly noteworthy was the system’s ability to detect referable DR\\n(grades DR3 and DR4) with 100% sensitivity and 99.9% specificity. These results highlight the\\nfeasibilityofintegratingAI-driventoolsintoroutineDRscreeningworkflows,reducingthedepen-\\ndencyonretinaspecialistsandmakingearlydetectionmoreaccessibleinresource-limitedsettings.\\n4.2 EvaluationMetricsandTheirSignificance\\nThe evaluation metrics used in this study provide a comprehensive understanding of AIDRSS’s\\nperformance:\\n• Sensitivity: Definedas:\\nTP\\nSensitivity = , (4)\\nTP +FN\\nwhereTP isthenumberoftruepositivesandFN isthenumberoffalsenegatives. Thehigh\\nsensitivity (92.0%) ensures that most cases of DR, particularly referable DR, are accurately\\nidentified.\\n• Specificity: Definedas:\\nTN\\nSpecificity = , (5)\\nTN +FP\\n17where TN is the number of true negatives and FP is the number of false positives. The\\nspecificityof88.0%indicatesalowrateoffalsealarms.\\n• PositivePredictiveValue(PPV):\\nTP\\nPPV = . (6)\\nTP +FP\\nThePPVof85.6%reflectstheprobabilitythatapatientidentifiedashavingDRtrulyhasthe\\ncondition.\\n• NegativePredictiveValue(NPV):\\nTN\\nNPV = . (7)\\nTN +FN\\nWith an NPV of 93.5%, the system ensures confidence in ruling out individuals who do not\\nhaveDR.\\nThe inclusion of confidence intervals (e.g., 95% CI) further strengthens the reliability of these\\nmetricsbyquantifyingtheirstatisticalrobustness.\\n4.3 StrengthsoftheAIDRSSApproach\\n• High Sensitivity for Referable DR: The system’s perfect sensitivity (100%) for referable\\nDRensuresthatnocasesrequiringimmediatemedicalattentionaremissed.\\n• Scalability: The automated nature of AIDRSS enables large-scale deployment, particularly\\ninruralandresource-constrainedsettingswhereaccesstoretinaspecialistsislimited.\\n18• IntegrationofAdvancedTechniques: TheuseofCLAHEpreprocessing,labelsmoothing,\\nandgradientnormalizationcontributedtoenhancedimagequalityandmodelrobustness.\\n4.4 LimitationsandChallenges\\nDespiteitsstrongperformance,certainlimitationsmustbeaddressed:\\n• Image Quality: Approximately 10.9% of images were excluded due to poor quality, under-\\nscoringtheneedforstandardizedimagingprotocolsandimprovedhardware.\\n• Regional Scope: The study was conducted in a single geographic region (Kolkata, India),\\npotentially limiting the generalizability of findings to other populations with varying demo-\\ngraphicandclinicalcharacteristics.\\n• Lack of Longitudinal Validation: This study employed a cross-sectional design, and the\\nlongitudinalperformanceofAIDRSSinmonitoringdiseaseprogressionremainsuntested.\\n4.5 ComparisonwithExistingLiterature\\nThe performance metrics of AIDRSS compare favorably with other AI-based diabetic retinopathy\\n(DR) screening systems reported in the literature. Several established algorithms have demon-\\nstratedsensitivitiesandspecificitiesinsimilarranges,highlightingthecompetitivenessofthepro-\\nposedsystem.\\nForinstance,theFDA-approvedIDx-DRsystemachievedasensitivityof87%andaspecificity\\nof90%fordetectingmorethanmilddiabeticretinopathy(mtmDR).9 Similarly,theEyeArtsystem\\nreported a sensitivity of 96% and a specificity of 88% for identifying mtmDR.10 AEYE-DS, an-\\nother widely studied system, demonstrated a sensitivity of 93% and a specificity of 91.4% using a\\n19desktopcamera,whileutilizingahandheldcameraresultedinasensitivityof91.9%andspecificity\\nof93.6%.11\\nIncomparison,AIDRSSachievedanoverallsensitivityof92.0%(95%CI:89.4%–94.3%)and\\nspecificity of 88.0% (95% CI: 85.2%–90.4%), with a perfect sensitivity of 100.0% for detecting\\nreferable DR (grades DR3 and DR4). These metrics place AIDRSS in close competition with\\nestablishedAIsystems,affirmingitsreliabilityforlarge-scalescreeningindiversesettings.\\nTheslightedgeobservedinAIDRSS’sperformancecanbeattributedtoseveraladvancedtech-\\nniquesintegratedintoitsarchitecture:\\n• Transfer Learning: By leveraging pre-trained models, AIDRSS capitalizes on knowledge\\nfromlarge-scaledatasets,enablingimprovedaccuracyevenwithlimitedlabeleddata.\\n• Attention Mechanisms: These mechanisms allow the system to focus on critical regions\\nin retinal images, enhancing its ability to detect subtle pathological features associated with\\nDR.\\n• CLAHE Preprocessing: Contrast Limited Adaptive Histogram Equalization (CLAHE) ef-\\nfectively enhances image quality by improving local contrast, aiding the accurate detection\\nofmicrovascularabnormalities.\\nIncorporating these innovations has likely contributed to the robust performance of AIDRSS,\\nenabling it to outperform or match other state-of-the-art DR screening tools. These findings high-\\nlight the promise of AI-based systems like AIDRSS in addressing the global burden of diabetic\\nretinopathy.\\n204.6 RecommendationsandFutureWork\\nTomaximizetheimpactofAIDRSS,thefollowingstrategiesarerecommended:\\n• Expand Dataset Diversity: Future studies should include populations from diverse geo-\\ngraphicandsocio-economicbackgroundstoimprovethegeneralizabilityoffindings.\\n• IncorporateLongitudinalTracking: MonitoringDRprogressionovertimewouldprovide\\nvaluableinsightsintothereal-worldeffectivenessofAIDRSS.\\n• Enhance Hardware Compatibility: Developing portable, low-cost imaging devices opti-\\nmizedforAIDRSScouldsignificantlyenhanceaccessibility.\\n• Policy Integration: Collaboration with public health programs, such as the National Pro-\\ngramforControlofBlindnessofIndia,canfacilitatelarge-scaleadoptionofAIDRSS.\\n5 Conclusion\\nArtelusAutomaticfunduscamerasandArtelusAIDRSS(DRISTi)14 canminimizetherequirement\\nfor trained human resources and improve accessibility, affordability, accuracy, ease, and speed,\\nhencehelpingreducetheburdenofblindnessduetodiabeticretinopathy.\\nDisclosure\\nConflictofInterest\\nThe authors declare that there are no financial interests, commercial affiliations, or other potential\\nconflictsofinterestthatcouldhaveinfluencedtheobjectivityofthisresearchorthewritingofthis\\npaper.\\n21FinancialDisclosures\\nTheauthorsdeclarenorelevantfinancialinterestsrelatedtothismanuscript.\\nPatientConsent\\nInformed consent was obtained from all participants for capturing their fundus image using the\\nCrystalVueNFC600device. Participantswereinformedthattheirde-identifieddatamightbeused\\nforfurtherresearchandanalysis.\\nEthicsApproval\\nSince this was a retrospective dataset and no prospective patient studies were involved, no IRB\\napprovalisrequired.\\nCode,Data,andMaterialsAvailability\\nThe data used in this study are proprietary and cannot be made publicly available. However, the\\nauthors are committed to supporting open scientific exchange. Researchers with valid reasons\\ncan request access to the data by submitting a formal request via the contact form available at\\nhttps://artelus.ai/contact. Requests will be evaluated on a case-by-case basis to en-\\nsurecompliancewithethicalandprivacyconsiderations.\\nAcknowledgments\\nThe authors acknowledge the use of Grammarly for language and grammar clean-up during the\\npreparationofthismanuscript. Nofundingwasreceivedforthisresearch.\\nCorrespondingauthoremail: sagarnil.das@artelus.ai\\n22References\\n1 W. H. Organization, Diabetic retinopathy screening: a short guide; Increase effectiveness,\\nmaximizebenefitsandminimizeharm,WorldHealthOrganization(2020).\\n2 N. I. of Health, National Institute of Health: facts about Diabetic Retinopathy disease, Na-\\ntionalInstituteofHealthInformation(2009). No03-2171.\\n3 I.D.Federation,Diabeteseyehealth: Aguideforhealthprofessional(n.d.).\\n4 Artelus, “Artificial intelligence based diabetic retinopathy detection screening system devel-\\nopedbyartificiallearningsystemsinc.(artelus),” AIDRSSisbuiltonDeepLearningmodels.\\n5 G. Alwakid, W. Gouda, and M. Humayun, “Deep learning-based prediction of diabetic\\nretinopathyusingclaheandesrganforenhancement,”Healthcare(Basel)11(6),863(2023).\\n6 C. Szegedy, W. Liu, Y. Jia, et al., “Going deeper with convolutions,” in Proceedings of the\\nIEEEConferenceonComputerVisionandPatternRecognition(CVPR),1–9(2015).\\n7 A. Herna´ndez and J. M. Amigo´, “Attention mechanisms and their applications to complex\\nsystems,”Entropy(Basel)23(3),283(2021).\\n8 W. Muhammad, Z. Bhutto, A. Ansari, et al., “Multi-path deep cnn with residual inception\\nnetworkforsingleimagesuper-resolution,”Electronics10(1979)(2021).\\n9 M. D. Abramoff, P. T. Lavin, M. Birch, et al., “Idx-dr: Automated diabetic retinopathy de-\\ntectionsystem,”JAMAOphthalmology136(7),646–654(2020).\\n10 Y. Kanagasingam, D. Xiao, J. Vignarajan, et al., “Validation of an automated diabetic\\nretinopathy screening system (eyeart) in a primary care setting,” Diabetes Care 41(4), e24–\\ne25(2020).\\n2311 R. Browne, C. Bennett, D. Mannion, et al., “Automated detection of diabetic retinopathy\\nusing adeep learning algorithmin primary caresettings,” BMJ OpenDiabetes Research and\\nCare9(1),e002221(2021).\\n12 S.IoffeandC.Szegedy,“Batchnormalization: Acceleratingdeepnetworktrainingbyreduc-\\ninginternalcovariateshift,”inProceedingsofthe32ndInternationalConferenceonMachine\\nLearning,37,448–456(2015).\\n13 R. Pascanu, T. Mikolov, and Y. Bengio, “On the difficulty of training recurrent neural net-\\nworks,”inICML(3),1310–1318(2013).\\n14 D.P.M.Aduriz-Lorenzo,D.M.H.Farooqi,P.K.Walia,etal.,“Thedeeplearningcomputer\\nmodelinreadingdiabeticretinopathy&normalimages,”DubaiHealthAuthority(2023).\\nList of Figures\\n1 ArtelusFundusCameraandDRprevalenceingeneralpopulation.\\n2 Encoder-basedtransferlearningarchitecture.\\n3 Partialattentionoverfeaturemaps.\\n4 ResidualInceptionArchitecture.\\n5 ResidualInceptionwithconvolutionfactorizationfortheclassifiernode.\\nList of Tables\\n1 PerformanceMetricsofAIDRSS\\n2 PerformanceMetricsforReferableDR(GradesDR3andDR4)\\n3 PerformanceMetricsComparisonwithEstablishedAIModels\\n24',\n",
       " 'Constraints as Rewards Reinforcement Learning for Robots without Reward Functions.pdf': 'Constraints as Rewards:\\nReinforcement Learning for Robots without Reward Functions\\nYu Ishihara1, Noriaki Takasugi1, Kotaro Kawakami2, Masaya Kinoshita1, Kazumi Aoyama1\\nAbstract—Reinforcement learning has become an essential\\nalgorithm for generating complex robotic behaviors. However,\\nto learn such behaviors, it is necessary to design a reward\\nfunctionthatdescribesthetask,whichoftenconsistsofmultiple\\nobjectives that needs to be balanced. This tuning process is\\nknown as reward engineering and typically involves extensive\\ntrial-and-error. In this paper, to avoid this trial-and-error pro-\\ncess,weproposetheconceptofConstraintsasRewards(CaR).\\nCaR formulates the task objective using multiple constraint\\nfunctions instead of a reward function and solves a reinforce- Fig.1:Standing-upmotiongenerationtaskofasix-wheeled-\\nment learning problem with constraints using the Lagrangian- telescopic-leggedrobot:Tachyon3.Theinitialpose(Left)is\\nmethod. By adopting this approach, different objectives are set randomly, and the robot is requested to transition safely\\nautomatically balanced, because Lagrange multipliers serves\\nto the upright pose (Right).\\nas the weights among the objectives. In addition, we will\\ndemonstratethatconstraints,expressedasinequalities,provide\\nan intuitive interpretation of the optimization target designed\\nfor the task. We apply the proposed method to the standing- and removes the reward function from the reinforcement\\nup motion generation task of a six-wheeled-telescopic-legged\\nlearning formulation. By applying this transformation and\\nrobot and demonstrate that the proposed method successfully\\nsolving the problem using the Lagrangian-method [6], we\\nacquires the target behavior, even though it is challenging to\\nlearn with manually designed reward functions. can automatically tune the weights among different objec-\\ntives. As an algorithm to solve the reinforcement learn-\\nI. INTRODUCTION ing problem using CaR, we propose QRSAC-Lagrangian,\\nan extension of the QRSAC algorithm [7]. We show that\\nRecent advances in the field of reinforcement learning\\nQRSAC-Lagrangianachievesfasterandmorestablelearning\\nhave enabled robots to generate complex manipulation and\\ncomparedtopreviousalgorithms[4],[8],[9].Furthermore,to\\nlocomotion behaviors that were previously considered chal-\\nfacilitate constraint design, we propose four specific designs\\nlenging [1], [2], [3], [4], [5]. However, these successes are\\nof constraint functions. The proposed constraint functions\\nnot solely due to algorithmic progress; they also depend on\\nenable an intuitive interpretation of the task objective. As\\nthe tuning of reward functions conducted by the authors.\\na result, we can design each constraint more objectively\\nFor example, Taylor et al. [1] designed a reward function\\ncompared to the design of a conventional reward function.\\nconsisting of four different objectives and tuned the weights\\nWe evaluate the effectiveness of our proposed method by\\namong these objectives to achieve locomotion behavior in\\napplying it to the standing-up motion generation task of a\\na bipedal robot that imitates human movement. Currently,\\nsix-wheeled-telescopic-leggedrobot:Tachyon3[10](Fig.1).\\nthere is no established systematic method for this tuning\\nTo enable the robot to stand up, it is necessary to coordinate\\nprocess, and therefore success often relies on the individual\\neach leg,which requiresmore complex controlthan conven-\\nreward designer’s expertise. For further advancement of\\ntional quadruped robots. In addition, the task requires the\\nrobots utilizing reinforcement learning, we argue that we\\nrobot’s controller to satisfy multiple conditions to stand up\\nneed to avoid this tuning process, widely known as reward\\nsafely without damaging the hardware. We show that the\\nengineering, and establish a design method that does not\\ntask is challenging to learn with manually designed reward\\nheavily rely on individual designers.\\nfunctions,buttheproposedmethodsucceedsinacquiringthe\\nIn this paper, to avoid the trial-and-error involved in\\ndesired behavior. Furthermore, we apply the trained policy\\ndesigning a reward function, we propose a new approach\\nto the robot in a real environment and demonstrate that the\\nto train robots with reinforcement learning: Constraints as\\nlearned policy successfully achieves the task as it did in the\\nRewards (CaR). CaR exclusively uses constraints to solve\\nsimulation.\\nthe reinforcement learning problem. Specifically, CaR for-\\nmulates the robot’s task solely from constraint functions In summary, our contributions are as follows:\\n• Proposal of Constraints as Rewards (CaR), a new ap-\\n1Sony Group Corporation, 1-7-1 Konan Minato-ku, Tokyo, 108-0075, proach to train robots with reinforcement learning that\\nJapan.yu.ishihara@sony.com\\nenables the automatic tuning of weights among objec-\\n2Sony Global Manufacturing & Operations Corporation, 1-7-1 Konan\\nMinato-ku,Tokyo,108-0075,Japan. tives by composing the task solely from constraints.\\nThis work has been submitted to the IEEE for possible publication. Copyright may be transferred\\nwithoutnotice,afterwhichthisversionmaynolongerbeaccessible.\\n5202\\nnaJ\\n9\\n]OR.sc[\\n2v82240.1052:viXra• Proposal of four specific designs of constraint function III. PRELIMINARIES\\nthat enable an intuitive interpretation of the task objec- In this research, we consider the finite-horizon reinforce-\\ntive. ment learning problem [20]. The objective of the problem\\n• Proposal of the QRSAC-Lagrangian algorithm, which is to find an optimal policy π∗ that maximizes the sum of\\nachievesfastandstablelearninginreinforcementlearn- discounted rewards over the horizon T:\\ning with CaR.\\nT\\n• Evaluation of the effectiveness of the proposed method maxE [(cid:88) γtr(s ,a )]. (1)\\nπ t t\\nin both real and simulated environments through the π\\nt=0\\nstanding-up motion generation task of a six-wheeled-\\nHere, s , a , γ, and r denote the state at time t, the action\\nt t\\ntelescopic-legged robot: Tachyon 3.\\nat time t, the discount factor, and the reward function,\\nII. RELATEDWORK respectively.Inthiswork,werevisitthedesignofthereward\\nfunction r(s,a).\\nA. Reinforcement Learning with Constraints\\nAs previously mentioned, in many practical applications,\\nConstraints have been used widely in the field of re-\\nthe reward function r(s,a) is designed as a weighted sum\\ninforcement learning to restrict the training policy from\\nof multiple functions r (s,a) (n=1,...,N)\\nn\\ndeviatingfromthedesiredstate.Oneofthemainpurposesof\\nN\\nconstraintsistoensurethesafetyofthelearningpolicy[11]. (cid:88)\\nr(s,a)= w r (s,a). (2)\\nIn[8],[9],constraintsareemployedtodefinesafetyrequire- n n\\nn=1\\nments, and the Lagrangian method is utilized to solve rein-\\nTherefore, the actual problem that needs to be solved is:\\nforcement learning problems with constraints. Zhang et al.\\nconvertedtheconstraintsintopenaltiesandsolvedanuncon- N (cid:20) T (cid:21)\\n(cid:88) (cid:88)\\nstrained optimization problem to ensure safety [12]. Liu et max w nE π γtr n(s t,a t) . (3)\\nπ\\nal.[13]constrainedthepolicytooperateinaspacetangentto n=1 t=0\\nthe unsafe region to ensure safe exploration. Constraints are From this equation, we can confirm that we need to tune\\nalso used for purposes beyond ensuring safety. Algorithms both weights w and functions r for successful learning.\\nn n\\nsuch as TRPO [14] and PPO [15] constrain the learning However, there is no systematic procedure to tune these\\npolicy from deviation using KL-divergence as a metric. In parameters.\\nthe well-known SAC algorithm [16], [17], constraints were Inthiswork,toalleviatethetrial-and-errorinvolvedinthe\\nintroduced to automatically tune the temperature parameter. designoftherewardfunction,weconsidersolvingreinforce-\\nSimilar to our work, Elliot et al. proposed Constraints as ment learning problem with constraints. The reinforcement\\nTerminations (CaT) [4], which transform constraints into learning problem with constraints is defined as follows:\\nepisode terminations. However, the problem formulation in\\n(cid:20) T (cid:21)\\n(cid:88)\\nprevious research still focus on maximizing cumulative re- max E γtr(s ,a )\\nπ t t\\nwardsandrequiremanualtuningoftheweightsthatbalance π\\nt=0 (4)\\ndifferenttaskobjectives.Inthispaper,weproposecomposing (cid:20) T (cid:21)\\n(cid:88)\\ntaskssolelyfromconstraintstoavoidrewardengineeringand s.t. E γtg (s ,a ) ≥0, m=1,...,M.\\nπ m t t\\nto automatically tune the weights among task objectives. t=0\\nHere, g (s ,a ) is the m-th constraint function. In the next\\nB. Deep Reinforcement Learning for Legged Robots m t t\\nsection, we will show that we can eliminate the tuning pro-\\nThere is no doubt that recent progress in generating com-\\ncess required in the original problem using this formulation.\\nplexlocomotionbehaviorinleggedrobotshasbeenachieved\\nthrough deep reinforcement learning techniques. Taylor et IV. METHOD\\nal. [1] succeessfully retargeted human motion capture data A. Constraints as Rewards (CaR)\\ntoasmallbipedalrobot.Similarly,Jeminetal.[5]succeeded\\nIn this section, we will describe in detail the idea of\\nin making a quadruped robot stand up from a fallen pose. A\\nConstraints as Rewards (CaR). In CaR, we transform the\\nquadrupedrobotcannowperformparkourusingacontroller\\nreinforcement learning problem with constraints described\\ntrainedwithreinforcementlearning[3].Furthermore,various\\nin eq. (4) into an unconstrained problem by incorporating\\nstudieshavedemonstratedtheeffectivenessofreinforcement\\nthe Lagrange dual function L(π,λ) [6]:\\nlearning [17], [4], [18], [19]. However, we assert that there\\nmay have been a significant trial-and-error process involved max maxL(π,λ). (5)\\nin reward tuning behind these successes, which is often\\nλm>0 ∀m π\\nnot described in the papers. In this work, we propose a Where λ=[λ 1,...,λ M]T are the Lagrange multipliers, and\\nnew approach to compose the task objective to mitigate this L(π,λ)\\ntrial-and-error process. We applied the proposed approach\\n(cid:20) T (cid:21) M (cid:20) T (cid:21)\\nto the standing-up motion generation task of a six-wheeled- ≜E (cid:88) γtr(s ,a ) + (cid:88) λ E (cid:88) γtg (s ,a ) .\\nπ t t m π m t t\\ntelescopic-legged robot, Tachyon 3 [10], and demonstrated\\nt=0 m=1 t=0\\nits effectiveness. (6)The transformed problem is known as the Lagrange dual of Here, S′ and A′ are the sets of events of particular interest,\\nthe original problem [6]. The core idea of CaR is to set the 1istheindicatorfunction,P andP aretheundiscounted\\nπ π,γ\\nreward function in eq. (6) to r(s ,a )≜0. By doing so, we and discounted state-action probabilities, and E is the\\nt t π,γ\\nobtain the following problem to solve: expectation under the discounted state-action distribution.\\nM (cid:20) T (cid:21)\\n(cid:88) (cid:88) C. QRSAC-Lagrangian\\nmax max λ E γtg (s ,a ) . (7)\\nm π m t t\\nλm>0 ∀m π\\nm=1 t=0\\nWe propose QRSAC-Lagrangian1, an extension of QR-\\nSAC [7], to solve the reinforcement learning problem when\\nWe can see that this formulation is identical to the standard\\nusing CaR. We extended QRSAC because we expect that\\nreinforcement learning problem with a reward function (eq.\\nthe quantile function, which estimates the distribution of\\n(3)) except for the operator max . The new for-\\nλm>0 ∀m\\nQ values, is effective in our problem setting. In CaR,\\nmulation suggests that Lagrange multipliers, which serves\\nthe algorithm needs to periodically update the Lagrange\\nas weights among constraints, can be tuned automatically.\\nmultipliers. Therefore, the distribution of the target Q value\\nTherefore, if we design the learning objective in terms of\\nchanges during training. In such situations, direct estimation\\nconstraints, we can obtain the desired policy without tuning\\nof Q values performed using conventional algorithms may\\nthe weights among different objectives.\\nbecome unstable. We will compare the performance of\\nB. Constraint Function Design QRSAC-Lagrangian, when used in conjunction with CaR,\\nTo compose the learning objective with constraints, we with variants of Lagrangian-based algorithms, such as SAC-\\npropose the following four designs of constraint function Lagrangian [3] and PPO-Lagrangian [8], and show that\\ng(s,a). Each design provides an intuitive interpretation for QRSAC-Lagrangian achieves faster convergence compared\\nthe optimization target. Timestep constraints enable con- to these algorithms. The pseudo code of the algorithm is\\nstrainingtherobotatspecifictimestep(e.g.,constrainingthe shown in Algorithm 1. In Algorithm 1, π θ is the training\\nfinal pose of the robot.), while episode constraints enable policy, d is the multiplier update interval, and p(s t+1|a t,s t)\\nconstraining the robot during an episode (e.g., constraining is the state transition distribution.\\nthe robot from hitting an obstacle.). We expect that having\\nAlgorithm 1 QRSAC-Lagrangian\\nan intuitive interpretation will make it easier for the task\\ndesigner to compose the objective. In our experiments, we 1: Initialize policy parameters θ, set replay buffer to D =\\ncomposed the task objective using a combination of these {}, and set Lagrange multipliers λ=0.\\nfunctions. Please note that the inequality in each constraint 2: for each iteration i do\\ncanbereversedbysettingtheconstraintfunctionto−g(s,a). 3: a t ∼π θ(a t|s t)\\nSee the appendix section for the derivation of each function. 4: s t+1 ∼p(s t+1|a t,s t)\\n1) Timestep probability constraint: Constrain the proba- 5: D ←D ∪ {(s t,a t,r(s t,a t),g 1,...,M(s t,a t),s t+1)}\\nbility of an event at specific timestep t=t′ to be less 6: Update policy π θ with QRSAC using D and λ\\nthan or equal to p ∈[0...1]: p ≥P (s ∈S′,a ∈ 7: if imodd then\\nϵ ϵ π t′ t′\\nA′). With: 8: for each m do\\ng(s,a)=(cid:40)\\n0 (t̸=t′) (8)\\n19 0:\\n:\\nλ λm\\nm\\n← ←λ mm ax− (λA md ,a 0m\\n)\\n(α λ,∇ λmL(π,λ))\\np ϵ−1 s∈S′,a∈A′ (t=t′). 11: end for\\n12: end if\\n2) Timestep value constraint: Constrain the value com-\\n13: end for\\nputed from a state and/or action in expectation at\\nspecific timestep t = t′ to be less than or equal to\\nϵ: ϵ≥E [gˆ(s ,a )]. With:\\nπ t′ t′\\nV. IMPLEMENTATION\\n(cid:40)\\n0 (t̸=t′)\\nOurrobothassixtelescopiclegs,fourwithdrivingwheels\\ng(s,a)= (9)\\nϵ−gˆ(s,a) (t=t′). and two with omnidirectional passive wheels. Each leg has\\na hip joint with a range of motion of 45deg and a 500mm\\n3) Episode probability constraint: Constrain the probabil-\\nexpandable prismatic knee joint. The policy must coordinate\\nity of an event during an episode to be less than or\\neach leg to enable the robot to stand up during the task. In\\nequal to p ∈ [0...1]: p ≥ P (s ∈ S′,a ∈ A′).\\nϵ ϵ π,γ\\nthis section, we will describe the design of the constraint\\nWith:\\nfunctions used in training and the controller design for this\\ng(s,a)=p −1 . (10)\\nϵ s∈S′,a∈A′\\nrobot. For hardware details of the robot, please refer to [10].\\n4) Episode value constraint: Constrain the value com-\\nA. Constraint Function Design for Standing Up Task\\nputed from a state and/or action during an episode\\nin expectation to be less than or equal to ϵ: ϵ ≥ We designed the following five constraints for the task:\\nE [gˆ(s,a)]. With:\\nπ,γ\\n1We designed the algorithm to be applicable to the general problem\\ng(s,a)=ϵ−gˆ(s,a). (11) settingwherer(st,at)̸=0.TABLE I: Network structure of π\\nθ\\nInputlayer stateinput\\nMiddlelayer1 Fully-connectedfollowedbyReLU(256dim)\\nMiddlelayer2 Fully-connectedfollowedbyReLU(256dim)\\nMiddlelayer3 Fully-connectedfollowedbyReLU(256dim)\\nOutputlayer Gaussianmean(12dim)andvariance(12dim)\\nFig. 2: Relationship between u , v and v . TABLE II: Reward functions for comparison. p denotes a\\nz x y t\\nvector at time t that consists of joint angles, joint angular\\nvelocities, knee positions, and knee velocities of each leg.\\n1) Final pose constraint: The target value of p at upright pose is p=0.\\n(cid:40) Rewarddesign1\\n0 (t̸=T) (cid:40)\\ng(s,a)= 1/(||p ||+1) (t=T)\\n10−3−|s −s | (t=T). Posereward t\\ntarget angle/position 0 (t̸=T)\\n(12) Falldownpenalty -1\\nExisting research [5] uses an episodic reward that Rewarddesign2\\npenalizes the robot’s pose at every timestep to facil- Posepenalty −w×||p t|| (w=0.001)\\nFalldownpenalty -1\\nitate standing up. However, from the perspective of\\nRewarddesign3\\nconstraints, the intermediate pose of the robot should (cid:40)\\n1/(||p ||+1) (t=T)\\nbearbitrary.Therefore,weconstrainthehipjointangle Posereward 1/(||pt ||+1)−1/(||p ||+1) (t̸=T)\\nt t−1\\nand knee position of the robot’s leg only at the final Falldownpenalty -1\\ntimestep T to be below 10−3rad and 10−3m. s Rewarddesign4\\ntarget\\nPosereward 1/(||p ||+1)\\nis the target joint angle/knee position and s t\\nangle/position Falldownpenalty -1\\nis the actual joint angle/knee position. We apply this Rewarddesign5\\nconstraint to each leg, resulting in a total of 12 pose Posereward exp(−||p ||)\\nt\\nconstraints. Falldownpenalty -1\\n2) Fall down constraint:\\n(cid:40)\\n0 (t̸=T) u z =[0,0,1]T is the unit vector along the z-axis, and\\ng(s,a)=\\nv and v are the normalized vectors connecting the\\n−1 (t=T). x y\\nrobotisinafall-downstate.\\nleg joints (Fig. 2).\\n(13)\\nThisfunctionconstrainstheprobabilityoffallingdown\\nB. Robot Controller Design\\nto0. Therobot isconsidered tobe ina fall-down state\\nOur robot is controlled with a PID controller that receives\\nwhenever more than five wheel joints are higher than\\nthe target joint angles and positions of each leg. Therefore,\\nthehipjoints.Thetaskterminateswhentherobotfalls\\nwetrainedacontrollerπ thatoutputsthetargetjointangles\\ndown: therefore, the indicator function is evaluated at θ\\nandpositionstobeinputtothisPID-controller.TableIshows\\nt=T.\\nitsnetworkarchitecture.Thepolicyinputsavectorconsisting\\n3) Body contact constraint:\\nof the following features:\\ng(s,a)=−1 robot’sbodyhitsthefloor.. (14) • Hip joint angles (6 dim)\\n• Knee joint positions (6 dim)\\nThis function constrains the probability of the robot’s\\n• Hip joint angular velocities (6 dim)\\nbody making contact with the floor to 0.\\n• Knee joint velocities (6 dim)\\n4) Leg swing constraint:\\n• Robot’s angular velocities and accelarations (6 dim)\\ng(s,a)=−1 (15) • Timestep since the beginning of the task (1 dim)\\nAngularvelocityexceeds2.0rad/s.\\n• History of policy’s output (12 dim×H steps).\\nThis function constrains the angular velocity of the\\nThe output of the policy is squashed and normalized using\\nrobot’s hip joint to be less than 2.0rad/s, preventing\\nthetanhfunctiontofitwithintherangeof[−1,1].Therefore,\\ndangerous leg swinging actions. To evaluate this con-\\nwe rescaled the policy’s output before feeding it to the PID-\\nstraint,weterminatedtheepisodewheneverthejoint’s\\ncontroller. We fixed the robot’s wheel velocity to 0 for the\\nangular velocity exceeds 2.0rad/s.\\nstanding-uptask.WesetH =3inthesimulationandH =5\\n5) Inclination constraint:\\nin the real robot experiment.\\n(cid:40)\\n0 (t̸=T)\\nVI. EXPERIMENTS\\ng(s,a)= (16)\\n10−2−|uTv | (t=T).\\nz x,y A. Experimental Setup\\nWe add this constraint to ensure that the final pose of In the experiment, we trained the policy to make the\\ntherobotremainsparalleltothefloor.Weconstrainthe robot transition from an arbitrary initial pose to an upright\\nrobot’s body to be perpendicular to the z-axis. Here, pose (See Fig. 1) and tested its performance using 10TABLE III: Ablation results. Each value is the average of\\ndifferent initial poses. We built a simulation environment\\n10 runs. Contact is the ratio of robot’s body making contact\\nusing MuJoCo [21] and trained the policy for 1 million\\nwith the floor during the task. Max ω is the maximum\\niterations. To facilitate faster convergence, we performed joint\\nangular velocity of the leg joint recorded during the task.\\ncurriculum training, starting from an initial pose near the\\nθ and θ are the roll and pitch angles of the robot\\nupright position and gradually increasing the distance from T,roll T,pitch\\nat the final timestep. ↑ and ↓ indicate that a higher value\\nthe upright pose. We did not perform parallel simulations to\\nis better and a lower value is better, respectively. (P: Pose\\ntrain the policy and used only one simulated robot to collect\\nconstraint, F: Fall-down constraint, C: Contact constraint, S:\\ndataduringtraining.Inallexperiments,thetrainedcontroller\\nSwing constraint, I: Inclination constraint)\\noperates at 10Hz. See the appendix for the hyperparameters\\nused in the experiment. Pose Contact Maxω joint θ Troll θ Tpitch\\nIn the simulation, we evaluated the proposed method score↑ [%]↓ [rad/s]↓ [deg]↓ [deg]↓\\ncomparing it with: P+F 0.925 0.5 3.038 3.896 5.672\\nP+F+C 0.920 0.1 8.937 6.933 3.782\\n• A policy learned using manually designed reward func- P+F+C+S 0.901 1.0 1.136 3.839 4.698\\ntions: Table II shows the five different reward functions P+F+C+S+I 0.896 0.6 1.673 0.057 0.057\\ndesigned based on the task’s learnability.\\n• Apolicylearnedusingconventionalmethods:Wecom-\\nCaR, where the distrubution of the target Q value dynam-\\npared the proposed QRSAC-Lagrangian with conven-\\nically changes during training. Also, refer to the appendix\\ntional algorithms such as SAC-Lagrangian [9], PPO-\\nfor results confirming similar findings in the classic inverted\\nLagrangian [8], and CaT [4].\\npendulum task. Fig. 4b shows the tuning results of weight\\nAdditionally, we assessed the robustness of the policy by\\nparameters conducted by the proposed algorithm. We can\\ntesting it on terrains different from the trained environment.\\nconfirmthatweightparametersweretuneddynamicallydur-\\nFurthermore, we conducted an ablation study to evaluate the\\ning training. The weight for fall-down constraint converged\\nefficacy of each constraint designed in the previous section.\\nquicklybecausetherobotlearnedtoavoidfallingdownatthe\\nFor the real robot experiment, we ran the policy trained\\nbeginning of training. In contrast, the weights for the pose\\nwith the proposed method without any fine-tuning on real\\nconstraint, body constraint, and swing constraint gradually\\ndata and evaluated its performance.\\nincresed during the course of training. This result indicates\\nthat these constraints were challenging for the policy to\\nB. Evaluation Results\\nmeet. The weight for inclination constraint increased from\\nFig. 3 shows the final pose of the robot when running\\nthebeginningtothemiddleoftrainingbutdecreasedtowards\\npolicies trained with manually designed rewards and the\\nthe end. This is because the policy succeeded in keeping the\\nproposed method2. The pose score 1/(||p || + 1) is also\\nt final pose parallel to the floor by the middle of training,\\nshown in parenthesis. From the figure, we can confirm that\\nand the algorithm decreased its weight towards the end to\\nCaR succeeds in transitioning to the target pose. In contrast,\\nprioritize the pose, body, and swing constraints more.\\npolicies trained with manually designed rewards fail to\\nFig. 5 shows the execution results of the trained policy in\\ntransitiontothetargetpose.Amongthepoliciestrainedwith\\nthree different environments. The flat terrain environment is\\nmanually designed rewards, Design 3 exhibits the highest\\nthetrainedenvironment.Theroughterrainenvironmenthasa\\nfinalposescore;however,thisscoreremainslowercompared\\nrandomheightofupto0.05m.Theslopeterrainenvironment\\nto the proposed method. We do not claim that there is no\\nhas a slope of 10deg. From the figure, we can confirm\\nrewardfunctionthatcanachievethistask.However,fromthe\\nthe robustness of the policy. The trained policy succeeds in\\nexperiment,wecanconfirmthatdesigningarewardfunction\\ncompleting the task even in environments different from the\\nis not a straightforward task, and the proposed method is\\noriginal trained environment.\\neffective even in such situations.\\nTable III shows the results of the ablation study on\\nFig. 4a shows the learning curve of the proposed al-\\nthe designed constraint functions. From the table, we can\\ngorithm and comparison algorithms in the task. From the\\nconfirm that each constraint succeeded in improving the\\nfigure,wecanconfirmthattheproposedQRSAC-Lagrangian\\nperformanceofthecorrespondingmetric.Additionally,while\\nachieves faster and more robust convergence compared to\\nit is challenging to perfectly satisfy each constraint, the\\nconventional algorithms. PPO-Lagrangian and CaT failed to\\naverage performance of the policy trained with all five\\nlearnthetask.SAC-Lagrangianachievessimilarfinalperfor-\\nconstraints appears reasonable. Based on these results, we\\nmance, but its convergence is slower compared to QRSAC-\\nused the policy trained with all five constraints in the real\\nLagrangian. The difference between SAC-Lagrangian and\\nrobot experiment.\\nQRSAC-Lagrangian lies solely in the underlying reinforce-\\nFig. 6 shows the execution result of the trained policy in\\nmentlearningalgorithm.Thisresultsuggestthatthequantile\\na real environment. From the figure, we can confirm that\\nfunction introduced in QRSAC is effective in the setting of\\nthe policy succeeds in completing the task on the real robot.\\nWe tested 10 poses used in the simulation and 9 challenging\\n2In this experiment, the policy with the proposed method is trained\\nposes with expanded knees, and confirmed that the policy\\nonly with the final pose contraint and the fall-down constraint for a fair\\ncomparison. successfully transitions to the upright pose from all poses.(0.679) (0.477) (0.750) (0.670) (0.640) (0.930)\\n(0.420) (0.476) (0.751) (0.671) (0.458) (0.930)\\nDesign 1 Design 2 Design 3 Design 4 Design 5 CaR (ours)\\nInitial pose Final pose (The number in parenthesis is the final pose score.)\\nFig. 3: Final poses of the robot. Leftmost figure shows the initial pose of each row. The policy trained with manually\\ndesigned rewards fails to transition to the upright pose. In contrast, our proposed method (CaR) succeeds in standing up.\\n(0.902) (0.902) (0.903)\\nFlat Rough Slope\\nFig. 5: Policy execution results on different types of terrain.\\n(Top)Initialpose.(Bottom)Finalpose.Policyisonlytrained\\n(a) Algorithm learning curve. (b) Weight parameters. in a flat terrain environment but works on different types of\\nterrain. The score in parenthesis is the final pose score.\\nFig.4:Algorithmlearningcurveandtuninghistoryofweight\\nparameters. The learning curve shows the average of 5 runs\\ninitialized with different random seeds. The weight of the\\npose parameter shown on the right is the weight of the left-\\nfront hip joint (Other weight parameters for pose constraints\\nalso exhibited similar changes).\\nVII. CONCLUSIONANDFUTUREWORK\\nIn this paper, we introduced the concept of Constraints Fig. 6: Policy execution result on the real robot. (Top)\\nas Rewards (CaR) to mitigate the extensive trial-and-error Pose used in simulation. (Bottom) Challenging pose with\\ninvolved in tuning a reward function. Instead of designing expanded knees.\\na reward function, CaR composes the task objective solely\\nfrom constraint functions. In this approach, unlike conven-\\ntional reward function design, we do not need to manually manually designed reward functions, our proposed method\\ntune the weights among task objectives; the weights are ad- enabled the robot to effectively learn the target behavior.\\njusted automatically during the training process. In addition, We believe that CaR is effective for a wide range of\\nto simplify the design of constraint functions, we proposed robotictasks.However,CaRrequiresthetasktobeexpressed\\nfour specific designs that provide an intuitive interpretation solely in terms of constraint functions. Therefore, it might\\nof the task objective. Furthermore, we introduced QRSAC- be challenging to apply in tasks where pure maximization\\nLagrangian algorithm to solve this reinforcement learning is required (e.g., make the robot walk as fast as possible).\\nproblemwithconstraints.Wedemonstratedtheeffectiveness In such cases, it would be beneficial to combine reward\\nof our method by applying it to the standing-up motion functions with constraint functions. Exploring an effective\\ngeneration task of a six-wheeled-telescopic-legged robot, objectivedesignmethodforsuchtaskscouldbeapromising\\nTachyon 3. While this task is challenging to learn with direction for future work.ACKNOWLEDGMENT [18] J.Lee,L.Schroth,V.Klemm,M.Bjelonic,A.Reske,andM.Hutter,\\n“Evaluation of constrained reinforcement learning algorithms for\\nWe would like to thank Takuma Seno, Sotaro Katayama\\nlegged locomotion,” CoRR, vol. abs/2309.15430, 2023. [Online].\\nandMichaelYeungfortheirhelpfulcommentsandfeedbacks Available:https://doi.org/10.48550/arXiv.2309.15430\\nduring the preparation of this manuscript. [19] T.Haarnoja,B.Moran,G.Lever,S.H.Huang,D.Tirumala,J.Hump-\\nlik, M. Wulfmeier, S. Tunyasuvunakool, N. Y. Siegel, R. Hafner,\\nM. Bloesch, K. Hartikainen, A. Byravan, L. Hasenclever, Y. Tassa,\\nREFERENCES\\nF.Sadeghi,N.Batchelor,F.Casarini,S.Saliceti,C.Game,N.Sreen-\\ndra,K.Patel,M.Gwira,A.Huber,N.Hurley,F.Nori,R.Hadsell,and\\n[1] M.Taylor,S.Bashkirov,J.F.Rico,I.Toriyama,N.Miyada,H.Yanag-\\nN.Heess,“Learningagilesoccerskillsforabipedalrobotwithdeep\\nisawa,andK.Ishizuka,“Learningbipedalrobotlocomotionfromhu-\\nreinforcementlearning,”ScienceRobotics,vol.9,no.89,2024.\\nmanmovement,”in2021IEEEInternationalConferenceonRobotics\\n[20] R.S.SuttonandA.G.Barto,ReinforcementLearning:AnIntroduc-\\nandAutomation(ICRA),2021,pp.2797–2803.\\ntion,2nded. TheMITPress,2018.\\n[2] E.Kaufmann,L.Bauersfeld,A.Loquercio,M.Mu¨ller,V.Koltun,and\\n[21] E. Todorov, T. Erez, and Y. Tassa, “Mujoco: A physics engine for\\nD. Scaramuzza, “Champion-level drone racing using deep reinforce-\\nmodel-basedcontrol.”inIROS. IEEE,2012.\\nmentlearning,”Nature,vol.620,no.7976,pp.982–987,2023.\\n[22] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman,\\n[3] Z.Zhuang,Z.Fu,J.Wang,C.Atkeson,S.Schwertfeger,C.Finn,and\\nJ. Tang, and W. Zaremba, “Openai gym,” 2016. [Online]. Available:\\nH.Zhao,“Robotparkourlearning,”inConferenceonRobotLearning\\narXiv:1606.01540\\n(CoRL),2023.\\n[4] E. Chane-Sane, P.-A. Leziart, T. Flayols, O. Stasse, P. Soue`res, and\\nN.Mansard,“Cat:Constraintsasterminationsforleggedlocomotion\\nAPPENDIXI\\nreinforcement learning,” in IEEE/RSJ International Conference on CONSTRAINTFUNCTIONDERIVATION\\nIntelligentRobotsandSystems(IROS),2024.\\n[5] J. Hwangbo, J. Lee, A. Dosovitskiy, D. Bellicoso, V. Tsounis, In the derivation, we assume discrete state and action sets\\nV. Koltun, and M. Hutter, “Learning agile and dynamic motor skills but the results can also be applied to continuous settings.\\nforleggedrobots,”ScienceRobotics,vol.4,no.26,2019.\\n[6] S. Boyd and L. Vandenberghe, Convex optimization. Cambridge A. Derivation of timestep probability constraint\\nuniversitypress,2004.\\n[7] P.Wurman,S.Barrett,K.Kawamoto,J.MacGlashan,K.Subramanian, By substituting eq. (5) into the optimization objective, we\\nT. Walsh, R. Capobianco, A. Devlic, F. Eckert, F. Fuchs, L. Gilpin,\\nget:\\nP.Khandelwal,V.Kompella,H.Lin,P.MacAlpine,D.Oller,T.Seno,\\nC.Sherstan,M.Thomure,andH.Kitano,“Outracingchampiongran\\nT\\nturismo drivers with deep reinforcement learning,” Nature, vol. 602, E [(cid:88) γtg(s ,a )]\\npp.223–228,022022. π t t\\n[8] J. Achiam and D. Amodei, “Benchmarking safe exploration in t=0\\ndeep reinforcement learning,” 2019. [Online]. Available: https: =E [γt′ (p −1 )] (∵ g(s ,a )=0 t̸=t′)\\n//api.semanticscholar.org/CorpusID:208283920 π ϵ s∈S′,a∈A′ t t\\n[9] S.Ha,P.Xu,Z.Tan,S.Levine,andJ.Tan,“Learningtowalkinthe =γt′ (p −E [1 ])\\nϵ π s∈S′,a∈A′\\nreal world with minimal human effort,” in Proceedings of the 2020\\nConferenceonRobotLearning,ser.ProceedingsofMachineLearning =γt′ (p −P (s∈S′,a∈A′)).\\nϵ π\\nResearch,J.Kober,F.Ramos,andC.Tomlin,Eds.,vol.155. PMLR,\\n16–18Nov2021,pp.1110–1120. Therefore, the constraint can be expressed as follows:\\n[10] N.Takasugi,M.Kinoshita,Y.Kamikawa,R.Tsuzaki,A.Sakamoto,\\nT.Kai,andY.Kawanami,“Real-timeperceptivemotioncontrolusing γt′ (p −P (s∈S′,a∈A′))≥0→p ≥P (s∈S′,a∈A′).\\ncontrol barrier functions with analytical smoothing for six-wheeled- ϵ π ϵ π\\ntelescopic-leggedrobottachyon3,”inIROS. IEEE,2024.\\nB. Derivation of timestep value constraint\\n[11] J. Garc´ıa, Fern, and o Ferna´ndez, “A comprehensive survey on\\nsafereinforcementlearning,”JournalofMachineLearningResearch,\\nSimilar to the above derivation, by substituting eq.6 into\\nvol.16,no.42,pp.1437–1480,2015.\\nthe optimization objective, we get:\\n[12] L. Zhang, L. Shen, L. Yang, S. Chen, X. Wang, B. Yuan, and\\nD.Tao,“Penalizedproximalpolicyoptimizationforsafereinforcement\\nlearning,”072022,pp.3719–3725. γt′ (ϵ−E π[gˆ(s t′,a t′)])≥0→ϵ≥E π[gˆ(s t′,a t′)].\\n[13] P. Liu, D. Tateo, H. B. Ammar, and J. Peters, “Robot reinforcement\\nlearning on the constraint manifold,” in Proceedings of the 5th C. Derivation of episode probability constraint\\nConferenceonRobotLearning,ser.ProceedingsofMachineLearning\\nResearch, A. Faust, D. Hsu, and G. Neumann, Eds., vol. 164, 2022, First,wereformulatetheoptimizationobjectiveasfollows:\\npp.1357–1366.\\n[14] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz, “Trust (cid:88)T\\nregionpolicyoptimization,”inProceedingsofthe32ndInternational E π[ γtg(s t,a t)]\\nConferenceonMachineLearning,ser.ProceedingsofMachineLearn-\\nt=0\\ningResearch,F.BachandD.Blei,Eds.,vol.37. Lille,France:PMLR,\\nT\\n07–09Jul2015,pp.1889–1897. (cid:88) (cid:88)\\n= p(s ,a ,...,s ,a )γtg(s ,a )\\n[15] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and 0 0 T T t t\\nO. Klimov, “Proximal policy optimization algorithms,” CoRR, t=0s0∈S,...,aT∈A\\nvol. abs/1707.06347, 2017. [Online]. Available: http://arxiv.org/abs/\\nT\\n1707.06347 (cid:88)(cid:88)(cid:88)\\n= pπ(s,a)γtg(s,a)\\n[16] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, “Soft actor-critic: t\\nOff-policy maximum entropy deep reinforcement learning with a t=0s∈Sa∈A\\nstochasticactor,”inProceedingsofthe35thInternationalConference\\nT\\nonMachineLearning,ser.ProceedingsofMachineLearningResearch, =(cid:88)(cid:88) g(s,a)(cid:88) pπ(s,a)γt\\nJ. Dy and A. Krause, Eds., vol. 80. PMLR, 10–15 Jul 2018, pp. t\\n1861–1870. s∈Sa∈A t=0\\n[17] VT. . H Ka ua mrn ao r,ja, HA . . ZZ huh ,ou A, .K G. uH pa tart ,ik Pa .in Aen b, beG e. l,T au nc dker S, .S L. eH via n, e,J. “T Sa on ft, =1−γT+1 (cid:88)(cid:88) g(s,a)(cid:88)T pπ(s,a) 1−γ γt.\\nactor-critic algorithms and applications,” 2019. [Online]. Available: 1−γ t 1−γT+1\\nhttps://arxiv.org/abs/1812.05905 s∈Sa∈A t=0TABLE IV: QRSAC-Lagrangian hyperparameters TABLE VI: Noise applied to model input during training.\\nN(µ,σ2) is a Gaussian distribution with mean µ and vari-\\nMA od da em llep aa rr na im ngete rr as\\nte\\nβ1= 30 .0.9 ×,β 12 0= −40.999 ance σ2.\\nMultiplierlearningrate(α λ) 0.1 Jointanglenoise N(µ=0,σ2=0.005)\\nMultiplierupdateinterval(d) 5000\\nKneepositionnoise N(µ=0,σ2=0.005)\\nDiscountfactorγ 0.99\\nJointangularvelocitynoise N(µ=0,σ2=0.01)\\nBatchsize 256\\nKneevelocitynoise N(µ=0,σ2=0.01)\\nQuantilepoints 32\\nRobot’sangularvelocitynoise N(µ=0,σ2=0.01)\\nNetworkupdatecoefficientτ 0.005\\nRobot’saccelarationnoise N(µ=0,σ2=0.1)\\nTimestepnoise N(µ=0,σ2=0.1)\\nTABLE V: Network structure of quantile function\\nInputlayer stateandactioninput\\nMiddlelayer1 Fully-connectedfollowedbyrelu(256dim)\\nMiddlelayer2 Fully-connectedfollowedbyrelu(256dim)\\nMiddlelayer3 Fully-connectedfollowedbyrelu(256dim)\\nOutputlayer Quantilevalues(32dim)\\nHere, pπ(s,a) is the state-action probability distribution at\\nt\\ntimetunderpolicyπ.Bydefiningthediscountedstate-action\\ndistribution as:\\nT\\n(cid:88) 1−γ\\np (s,a)≜ pπ(s,a) γt,\\nπ,γ t 1−γT+1\\nt=0\\nthe original expectation can be rewritten as:\\n(cid:20) T (cid:21) (cid:20) (cid:21)\\n(cid:88)\\nE γtg(s ,a ) ∝E g(s,a)\\nπ t t (s,a)∼pπ,γ\\nFig.7:Learningcurveofeachalgorithmtrainedwitheq.(17)\\nt=0\\n(Left) and eq. (18) (Right). Dotted line is the score when\\nNext, by substituting eq. (7), we get:\\ntrained with original reward function.\\nT (cid:20) (cid:21)\\n(cid:88)\\nE [ γtg(s ,a )]∝E g(s,a)\\nπ t t (s,a)∼pπ,γ\\nt=0 APPENDIXIII\\n(cid:20) (cid:21) EXTRAEXPERIMENTALRESULTS\\n=E (p −1 )\\n(s,a)∼pπ,γ ϵ s∈S′,a∈A′\\nWe present the evaluation results of the proposed algo-\\n(cid:20) (cid:21)\\nrithm in the classic inverted pendulum task implemented\\n=(p −E 1 )\\nϵ (s,a)∼pπ,γ s∈S′,a∈A′ in Gym [22]. We trained the model using two different\\n=p −P (s∈S′,a∈A′). constraint functions:\\nϵ π,γ\\ng(s,a)=10−2−|θ | (17)\\np\\nTherefore, the constraint can be expressed as follows:\\nand\\n(cid:40)\\np −P (s∈S′,a∈A′)≥0.→p ≥P (s∈S′,a∈A′). 0 (t̸=T)\\nϵ π,γ ϵ π,γ\\ng(s,a)= (18)\\n10−2−|θ | (t=T).\\np\\nD. Derivation of episode value constraint\\nHere, θ is the angle of the pendulum. Fig. 7 shows\\nSimilar to the above derivation, by sustituting eq. (8) into p\\nthe learning curves during training. From the figure, we\\nthe optimization objective, we get:\\ncan confirm that conventional PPO-Lagrangian and CaT\\n1−γT+1 failed to learn with the constraint function in eq. (18).\\n1−γ\\n(ϵ−E π,γ[gˆ(s,a)])≥0→ϵ≥E π,γ[gˆ(s,a)]. This result suggests that PPO-Lagrangian and CaT are not\\neffective in environments with constraint functions of the\\nHere, E π,γ is the expectation under the discounted state- form in eq. (18). Conversely, SAC-Lagrangian and QRSAC-\\naction distribution p π,γ. Lagrangian succeeded in learning in both settings. As in\\ntheexperimentsection,QRSAC-Lagrangianconvergedfaster\\nAPPENDIXII than SAC-Lagrangian.\\nHYPERPARAMETERSANDEXPERIMENTALSETTINGS\\nHyperparameters and settings used in the experiments are\\nlisted in Table IV,Table V, and Table VI.',\n",
       " 'CONTINUUM Detecting APT Attacks through Spatial-Temporal Graph Neural Networks.pdf': 'CONTINUUM: Detecting APT Attacks through Spatial-Temporal Graph Neural\\nNetworks\\nAtmaneAyoubMansourBahara,∗,KamelSoa¨ıdFerrahia,∗,Mohamed-LamineMessa¨ıb,HamidaSebac,Karima\\nAmrouchea\\naLCSI,E´coleNationaleSupe´rieured’Informatique(ESIex.INI),OuedSmar,16058,Algiers,Algeria\\nbERIC,Universite´Lyon2,Bron,Lyon,France\\ncUniversiteClaudeBernardLyon1,CNRS,INSALyon,LIRIS,UMR5205,69622Villeurbanne,France\\nAbstract\\nAdvancedPersistentThreats(APTs)representasignificantchallengeincybersecurityduetotheirsophisticatedand\\nstealthynature. TraditionalIntrusionDetectionSystems(IDS)oftenfallshortindetectingthesemulti-stageattacks.\\nRecently,GraphNeuralNetworks(GNNs)havebeenemployedtoenhanceIDScapabilitiesbyanalyzingthecomplex\\nrelationships within networked data. However, existing GNN-based solutions are hampered by high false positive\\nrates and substantial resource consumption. In this paper, we present a novel IDS designed to detect APTs using a\\nSpatio-TemporalGraphNeuralNetworkAutoencoder. Ourapproachleveragesspatialinformationtounderstandthe\\ninteractionsbetweenentitieswithinagraphandtemporalinformationtocapturetheevolutionofthegraphovertime.\\nThis dual perspective is crucial for identifying the sequential stages of APTs. Furthermore, to address privacy and\\nscalability concerns, we deploy our architecture in a federated learning environment. This setup ensures that local\\ndataremainson-premisewhileencryptedmodel-weightsaresharedandaggregatedusinghomomorphicencryption,\\nmaintaining data privacy and security. Our evaluation shows that this system effectively detects APTs with lower\\nfalsepositiveratesandoptimizedresourceusagecomparedtoexistingmethods,highlightingthepotentialofspatio-\\ntemporalanalysisandfederatedlearninginenhancingcybersecuritydefenses.\\nKeywords: GraphNeuralNetworks,IntrusionDetection,AdvancedPersistentThreats,GraphAttentionNetworks,\\nGatedRecurrentUnit,Spatial-TemporalAnalysis,FederatedLearning,HomomorphicEncryption\\n1. Introduction\\nIn recent years, the frequency and sophistication of cyber-attacks have escalated, posing significant challenges\\nto the cybersecurity community. Among these threats, Advanced Persistent Threats (APTs) stand out due to their\\nstealthy, prolonged, and multi-stage nature. APTs are highly targeted attacks typically orchestrated by well-funded\\nadversaries, aiming to gain and maintain unauthorized access to a network while evading detection for extended\\nperiods. These multi-stage attacks often involve a series of coordinated steps, including initial intrusion, lateral\\nmovement,privilegeescalation,anddataexfiltration.\\nTraditionalIntrusionDetectionSystems(IDS)havebeenpivotalinsafeguardingnetworksecuritybymonitoring\\nandanalyzingnetworktrafficforsignsofmaliciousactivities. However,thesophisticatedtacticsemployedbyAPTs\\noftenrenderthesetraditionalsystemsinadequate. APTscanadaptandevolvetheirtechniquestobypassconventional\\nsecuritymeasures,involvingmoreadvanceddetectionmechanisms.\\nOne promising approach to understanding and detecting these complex threats is through the analysis of prove-\\nnance graphs. Provenance graphs capture the history and lineage of data and events within a system, detailing the\\n∗Bothauthorscontributedequallytothisresearch.\\nEmailaddresses:ja_mansourbahar@esi.dz(AtmaneAyoubMansourBahar),jk_ferrahi@esi.dz(KamelSoa¨ıdFerrahi),\\nmohamed-lamine.messai@univ-lyon2.fr(Mohamed-LamineMessa¨ı),{hamida.seba@univ-lyon1.fr}(HamidaSeba),\\nk_amrouche@esi.dz(KarimaAmrouche)\\nPreprintsubmittedtoElsevier January8,2025\\n5202\\nnaJ\\n7\\n]RC.sc[\\n2v18920.1052:viXrainteractions and dependencies between various system-entities. These graphs provide a comprehensive view of the\\nsequenceandcausalityofevents,makingtheminvaluableforidentifyingsuspicious-activitiesandpotentialsecurity\\nbreaches.\\nGraphNeuralNetworks(GNNs)havegainedprominenceinrecentyearsfortheirabilitytoprocessandanalyze\\ngraph-structureddata. GNNsexcelincapturingdeepinformationandcorrelationswithingraphs, makingthempar-\\nticularlysuitedforunderstandingthebehaviorofsystementitiesasrepresentedinprovenancegraphs. UsingGNNs,\\nit is possible to uncover intricate patterns and relationships that traditional methods might miss, thus enhancing the\\ndetectionofAPTs.\\nHowever, traditional IDS and even recent GNN-based solutions often fall short in effectively detecting APTs\\nbecausetheydonotcapturethetimedimensionintheseattacks. Thus,inthispaper,weproposeanovelIDSbased\\nonaSpatial-TemporalGraph-Autoencoder. Ourapproachleveragesspatialinformationtounderstandtheinteractions\\nbetweenentitieswithinagraphandtemporalinformationtocapturetheevolutionofthegraphovertime. Itstartsby\\nprocessingprovenancegraphsfrompublicbenchmarkdatasets,usingamethodtogenerateandcompresssnapshots,\\nmaking the datasets time dependent. We leverage then a Graph Attention Network (GAT)-based Autoencoder to\\nextractspatialinformationfromtheseprovenancegraphs,enablingtheunderstandingofinteractionsbetweenentities.\\nAdditionally,weemployGatedRecurrentUnit(GRU)gatestostoreandtracktheevolutionoftheprovenancegraph\\novertime,crucialfordetectingthemulti-stagenatureofAPTsexecutedindifferentstagesseparatedbytimeintervals.\\nThis dual perspective of spatial and temporal information significantly improves the accuracy and effectiveness of\\nAPTdetection.\\nTheremainderofthepaperisorganizedasfollows:Section2providesdefinitionsofkeyconceptsandpresentsthe\\nthreatmodel. InSection3,wepresentthemotivationsunderlyingthiswork. Section4reviewsrelatedwork. Then,\\nSection 5 details our system design. In Section 6, we present the results of the evaluation of our findings. Finally,\\nSection7concludesthepaperandoutlinessomefutureresearchdirections.\\n2. Preliminaries\\nInthissection,wedefinethekeyconceptsusedinthisworkaswellasthethreatmodel.\\n2.1. Definitions\\nThekeyconceptsdefinedareasfollows:AdvancedPersistentThreats,provenancegraphs,andaspecificcategory\\nofGraphNeuralNetworks,calledSpatialConvolutionalGraphNeuralNetworks.\\nAdvancedPersistentThreats(APts): APTsaresophisticatedandprolongedcyberattacks(Alshamranietal.,2019)\\naimedatstealingsensitiveinformation,disruptingoperations,orcausingdamagetotargetedentities(YasarandRosen-\\nrance,2023). TheprimarycharacteristicsofAPTsincludetheiradvancednature,whichinvolvescomplextechniques,\\ntools, andexploitstocompromisethetarget, theirpersistence, whichensuresthattheyremainwithinthetargetnet-\\nworkforanextendedperiodtoachievelong-termobjectives,andthesignificantthreattheypose,oftencarriedoutby\\nhighlyskilledadversarieswithsubstantialresources,suchasstate-sponsoredorwell-fundedorganizations.\\nUnlike typical cyberattacks, APTs involve multiple stages (Quintero-Bonilla and Mart´ın del Rey, 2020; Ussath\\net al., 2016; Sexton et al., 2015; Vukalovic´ and Delija, 2015; Security, 2019) and employ various techniques to\\nmaintain access and evade detection over long periods, each stage involving specific actions and objectives. For\\nexample,somecommonAPTstagesareasfollows:\\n• InitialIntrusion: Exploitingvulnerabilitiesorusingsocialengineeringtogainaccesstothetargetnetwork.\\n• EstablishingFoothold: Deployingmalwareorbackdoorstomaintainaccess.\\n• Lateral Movement: Moving laterally within the network to identify high-value targets and gain additional\\nprivileges.\\n• PrivilegeEscalation: Obtaininghigher-levelaccesstoperformmoresignificantactions.\\n• DataExfiltrationorAttackExecution: Stealingsensitiveinformationorexecutingdestructiveactions.\\n• Persistence: Ensuringlong-termaccessandevadingdetectionthroughvariousmeans.\\n2ProvenanceGraphs: AprovenancegraphisadirectedacyclicgraphG = (V,E)thatrepresentsthehistoryofdata\\nobjects,whereVisthesetofnodesrepresentingsystementities(files,users,tasks,processes,ect..),andEisthesetof\\ndirectededgesrepresentingtheinteractionsamongtheseentities. AnexampleofanAPTattack’sprovenancegraph\\nisillustratedinFigure1.\\nFigure1:ProvenancegraphofanAPTattack(Hassanetal.,2020)\\nProvenancegraphsarevaluableforintrusiondetectionbecausetheycapturedetailedactivity,providingacompre-\\nhensiverecordofsystemactivitiesthatmakesiteasiertoidentifyanomalousbehavior(Acaretal.,2010). Theyalso\\nrevealhiddendependencies, highlightingrelationshipsbetweendifferententities, whichcanbecrucialfordetecting\\nlateral-movements and other APT stages. In addition, they facilitate forensic analysis by allowing investigators to\\ntracebacktheoriginandpropagationofanattack.\\nGraphNeuralNetworks(GNNs): GNNsareaclassofneuralnetworksspecificallydesignedtooperateongraph-\\nstructureddata(LiuandZhou,2022). AgraphG =(V,E)consistsofasetofnodesV andedgesE,whereeachedge\\n(i, j) ∈ E representsarelationshipbetweennodesiand j. Eachnodev ∈ V mayalsohaveafeaturevector x ∈ Rd,\\ni i\\nrepresentingtheattributesofthenode.GNNsaimtolearnnoderepresentationsbyiterativelyaggregatinginformation\\nfromtheirneighbors. AteachlayerloftheGNN,therepresentationofnodev isupdatedbyaggregatingthefeature\\ni\\nvectorsofitsneighboringnodesN(v),followedbyanon-lineartransformation.\\ni\\nThegeneralformulationofaGNNlayercanbewrittenas:\\n\\uf8eb \\uf8f6\\nh( il+1)\\n=σ\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8edW(l)h(\\nil)+\\n(cid:88)\\nW n(l e) ighh(\\njl)\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\n(1)\\nj∈N(i)\\nwhereh(l) isthefeaturevectorofnodeiatlayerl,N(i)representsthesetofneighborsofnodei,W(l) andW(l) are\\ni neigh\\nlearnable weight-matrices for node i and its neighbors, respectively, and σ is a non-linear activation function (e.g.,\\nReLU). This equation describes how each node’s representation is updated by combining its current representation\\nh(l) withtheaggregatedinformationfromitsneighborsh(l). Thelearnednodeembeddingsh(L) afterLlayerscanthen\\ni j i\\nbeusedforvariousdownstreamtaskssuchasnodeclassification,linkprediction,andgraphclassification.\\nWuetal.(2020)categorizedGNNsbasedontheirarchitectureandmessage-passingmechanismsintofourprimary\\ntypesofGNNs: RecurrentGNNs(recGNN)(Lietal.,2015;GallicchioandMicheli,2010;Scarsellietal.,2008;Dai\\netal.,2018),ConvolutionalGNNs(convGNN)(Velicˇkovic´etal.,2017;Hamiltonetal.,2017;Xuetal.,2018;Gilmer\\netal.,2017;Velickovicetal.,2019;Defferrardetal.,2016;KipfandWelling,2016a;Lietal.,2018;ZhuangandMa,\\n2018;Levieetal.,2018),GraphAutoencoders(GAEs)(KipfandWelling,2016b;Wangetal.,2016;Hajiramezanali\\netal.,2019;Bojchevskietal.,2018;Tuetal.,2018),andSpatial-TemporalGNNs(STGNN)(Chenetal.,2023;Seo\\netal.,2018;Wangetal.,2022b;Yanetal.,2018;Lietal.,2023b;Xuetal.,2020). EachcategoryofGNNservesa\\ndifferentpurpose,offeringuniqueadvantagesdependingonthetaskathand.\\n• RecurrentGraphNeuralNetworks(recGNNs): recGNNsincorporaterecurrentconnectionswithintheirarchi-\\ntecturetoiterativelyupdatenoderepresentationsovermultiplesteps. Thehiddenstateofeachnodeisupdated\\nbasedonitsprevioushiddenstatesandthoseofitsneighboringnodesusingarecurrentneuralnetwork(RNN)\\nlayersuchasGRUorLSTM.ThisiterativeprocessallowsrecGNNstocapturesequentialinformationexchange\\nbetweennodesinagraph.\\n3AgeneralupdatefunctionforrecGNNsisexpressedas:\\n\\uf8eb \\uf8f6\\nh(t)(v)= f\\nRNN\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8edW·h(t−1)(v), (cid:88) h(t−1)(u)\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\nu∈N(v)\\nwhere h(t)(v) is the hidden state of node v at time step t, f is the recurrent neural network function, N(v)\\nRNN\\nrepresentstheneighboringnodesofnodev,andW isthelearnableweightmatrix.\\n• Convolutional Graph Neural Networks (ConvGNNs): ConvGNNs extend the concept of convolutional oper-\\nations from traditional grid-structured data (such as images) to irregular graph-structured data. They can be\\ncategorized into two main types: Spatial Convolutional GNNs (SpGNNs) (Velicˇkovic´ et al., 2017; Hamilton\\net al., 2017; Xu et al., 2018; Gilmer et al., 2017; Velickovic et al., 2019) and Spectral Convolutional GNNs\\n(ScGNNs)(Defferrardetal.,2016;KipfandWelling,2016a;Lietal.,2018;ZhuangandMa,2018;Levieetal.,\\n2018).\\n– SpatialConvolutionalGNNs: SpatialconvolutionalGNNsperformconvolutionsbyaggregatinginforma-\\ntionfromanode’sneighbors(Bernstein,2023). Thekeyideaistoiterativelyupdatetherepresentationof\\nanodebycombiningitsfeatureswiththoseofitsneighbors. Thisprocesscapturesthelocalstructureand\\nfeaturesofthegraph.\\nFormally,theupdateruleforthenoderepresentationsinspatialconvolutionalGNNscanbedescribedas\\nfollows:\\n\\uf8eb \\uf8f6\\nh( ik)\\n=σ\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8edW(k)h\\ni(k−1)+\\n(cid:88)\\nW n(k e) ighh(\\njk−1)\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\n(2)\\nj∈N(i)\\nwhere h(k) is the feature vector of node i at the k-th layer, W(k) and W(k) are learnable weight matrices\\ni neigh\\nforthenodeitselfanditsneighbors,respectively,N(i)denotesthesetofneighborsofnodei,andσisan\\nactivationfunctionsuchasReLU.\\nThe above equation signifies that the new representation of a node hi(k) is obtained by combining its\\nprevious representation hi(k − 1) with the representations of its neighbors hj(k − 1), weighted by the\\nmatrices W(k) and Wneigh(k). This aggregation step effectively captures the spatial dependencies and\\nrelationshipswithinthegraph.\\nSomewell-knownexamplesofSpGNNsareGraphAttentionNetworks(Velicˇkovic´ etal.,2017),Graph-\\nSAGE(Hamiltonetal.,2017),andGraphIsomorphismNetworks(Xuetal.,2018).Byiterativelyapplying\\nthisupdateruleacrossmultiplelayers, theseGNNscancapturehigher-orderneighborhoodinformation,\\nenablingthemtolearnrichrepresentationsofthenodesandtheirinteractions. Thismakesthemparticu-\\nlarlywell-suitedfortaskssuchasnodeclassification,linkprediction,andgraphclassification.\\n– SpectralConvolutionalGNNs:SpectralConvolutionalGNNsperformconvolutionsinthespectraldomain\\nby leveraging the eigenvalues and eigenvectors of the graph Laplacian (Kipf, 2016). The central idea\\nis to transform node features into the spectral domain, apply spectral filters, and then map them back\\nto the spatial domain. This process captures global graph structure while maintaining efficiency using\\napproximationslikeChebyshevpolynomials(MasonandHandscomb,2002).\\nFormally,thespectralconvolutioncanbeexpressedas:\\nh(l+1) =U·diag(θ(l))·U⊤·h(l) (3)\\nv v\\nwhere h(k) and h(k+1) are the feature vectors of node i at the k-th and k +1-th layers respectively, U is\\ni i\\nthematrixofeigenvectorsofthegraphLaplacian,θ(k) representsthespectralfilterparametersforlayerk,\\ndiag(θ(k))isadiagonalmatrixformedfromlayerθ(k).\\nTheequationindicatesthattheupdatednodefeaturesareobtainedbyfilteringthenoderepresentationsin\\nthespectraldomainandtransformingthembacktotheoriginaldomain. ThisprocessallowsScGNNsto\\neffectivelycaptureglobalgraphpropertiesandrelationships.\\n4Examples of ScGNNs include ChebNet (Defferrard et al., 2016), which uses Chebyshev polynomials to\\napproximatespectralfilters,andGraphConvolutionalNetworks(GCN)(KipfandWelling,2016a),which\\nsimplify spectral convolution by truncating the spectral decomposition. These models excel in learning\\nrepresentationsfortaskssuchasnodeclassification,linkprediction,andgraphclassification,particularly\\ninstructureddomains.\\n• GraphAutoencoders(GAEs): GAEsareaclassofGNNsthatuseanautoencoderframeworktoencodenodes\\ninto embeddings and learn low-dimensional representations of graphs. These models are designed to capture\\nthe essential structural properties of a graph while allowing for compression and reconstruction of the graph\\nstructure. GAEs define an unsupervised reconstruction error between the original and predicted adjacency\\nmatrices,ensuringthatthemodellearnsmeaningfulrepresentations(Wardetal.,2022).\\nThegeneralencodingprocesscanbeexpressedas:\\n\\uf8eb \\uf8f6\\nz(v)= f\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ec\\uf8ed (cid:88)\\n√\\nd(u1 )d(v)W·x(u)\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f7\\uf8f8\\n(4)\\nu∈N(v)\\nwherez(v)istheembeddingofnodev,d(v)andd(u)arethedegreesofnodesvandu,W istheweightmatrix,\\nandx(u)istheinputfeaturevector. ExamplesofGAEsincludeVariationalGraphAutoencoders(VGAE)(Kipf\\nandWelling,2016b)andStructureDeepNetworkEmbeddings(SDNE)(Wangetal.,2016).\\n• Spatial-Temporal Graph Neural Networks (STGNNs): Spatial-Temporal Graph Neural Networks (STGNNs)\\nextendGNNstohandletemporaldynamicsbyintegratingspatialandtemporalinformation. Thesemodelsare\\nparticularlyusefulforspatio-temporaldata,suchastrafficforecastingortime-evolvingnetworks. STGNNsuse\\nspatiallayerstoaggregateinformationfromneighboringnodeswithinthesametimestepandtemporallayers\\ntocapturedependenciesacrosstimesteps.\\nAgeneralizedupdateequationforSTGNNsis:\\n(cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17)\\nh(t)(v)= f h(t−1)(v),AGG(t) h(t−1)(u):u∈N(v) ,AGG(t) h(t)(v) (5)\\nspatial temporal\\nwhereAGG istheSpatialaggregation-function,andAGG istheTemporalaggregation-function.\\nspatial temporal\\nExamples include Gated Spatio-Temporal Graph Convolutional Networks (ST-GCN) (Yan et al., 2018) and\\nTemporalGraphNetworks(TGN)(Rossietal.,2020).\\n2.2. ThreatModel\\nIntheproposedmodel,weassumethattheadversaryhasadvancedcapabilities,includingtheabilitytobreachthe\\nsystem perimeter through various attack vectors such as phishing (social engineering) or exploitation of unpatched\\nvulnerabilities. Once inside the system, the attacker seeks to maintain persistent access by installing back-doors or\\nleveraging malware, moving laterally within the network to escalate privileges, and carrying out the attack over an\\nextended period without being detected. We also assume that the attacker can compromise both hosts and servers\\nwithin the organization. However, he leaves behind him abnormal system events and entity interactions, which are\\nrepresentedintheprovenancegraph,andanalyzedtodetectanomaliesindicativeofanAPTattack.\\n3. Motivation\\nTheresearchpresentedinthispaperisdrivenbyseveralkey-motivationsregardingthenatureofAdvancesPersis-\\ntentThreatsandtheirdetectionbyexploitingGNNs. Inthissection,wepresentanoverviewofthesemotivations:\\n• AddressingthestealthinessodAPTs: AdvancedPersistentThreatsarehighlystealthyandsophisticated,of-\\nten blending their activities with legitimate network traffic to avoid detection. Traditional anomaly detection\\nmethodsstrugglewiththevastamountofdataandthesubtletyoftheseanomalies(ADNANetal.,2023;Zimba\\netal.,2020;Luetal.,2019;Suetal.,2017).Toovercomethischallenge,weneedasolutionthatallowslearning\\ncompressed representations of data, and effectively distinguishing normal behavior from anomalies. For this\\n5purpose, weproposetoutilizegraph-autoencoders. Autoencodersarepowerfultoolsforlearningcompressed\\nrepresentationsofdata(PawarandAttar,2019;Bianchietal.,2019;Shenetal.,2016). Bytraininganautoen-\\ncoderonbenignsystembehavior,themodellearnstogeneratepreciseembeddingsfornodesandgraphs. When\\nthe autoencoder encounters anomalous data, such as APT activity, it produces higher reconstruction errors,\\ntherebyfacilitatingdetectionofattacks. Thisapproachnotonlyimprovesdetectionaccuracybutalsoenhances\\ntheefficiencyoftheIDSbyreducingthedimensionalityofthedata.\\n• Encompassing the relationships between system entities: APTs often exploit the relationships between\\nsystementities(users,files,processes,...etc.)tohidetheirmaliciousactivitieswithinbenignsystemoperations\\nand propagate within the system. To effectively detect these threats, it is essential to deeply understand the\\nrelationshipsrepresentedinprovenancegraphs(Yanetal.,2022;Lvetal.,2022), andextractthecorrelations\\nbetweentheirnodesandedges. Forthat,weneedmodelsthatfocusontheinformationtransmittedbetweena\\nnodeanditsneighbourhood,calledthespatialinformation,inordertocapturetherelationshipsandinteractions\\nbetweenentities,whichcanrevealhiddenpatternsindicativeofAPTactivities.\\nThe solution that we propose in this paper is implementing a Spatial convolutional GNN, such as Graph Iso-\\nmorphismNetworks(GIN)(Xuetal.,2018), GraphAttentionNetworks(GAT)(Velicˇkovic´ etal.,2017), and\\nGraphSAGE (Hamilton et al., 2017). This type of GNNs is particularly suited for modelling the spatial dy-\\nnamics of the network (messages passed in a nodes’ neighbourhood), and understanding intricate correlation\\nbetweensystementities(SahiliandAwad,2023;Wuetal.,2020).\\n• CapturingtimespanofAPTs: APTstendtobeprolongedandencompassdifferentstages,includinginitial\\nintrusion, lateral movement, privilege escalation, and data exfiltration. These stages can occur over extended\\nperiods,makingitcrucialtoidentifythetime-dependenciesofAPTcampaigns(Chengetal.,2023b;Zhuetal.,\\n2021;Ghafiretal.,2019). Todetectthesetemporalpatterns,weintegratemachine-learningmodelsthatpossess\\nmemorycapabilitiesandcanretaininformationseparatedbytime. ModelssuchasRecurrentNeuralNetworks\\n(RNNs)(Rumelhartetal.,1986),LongShort-TermMemorynetworks(LSTMs)(Hochreiter,1997),andGated\\nRecurrentUnits(GRUs)(Choetal.,2014),areeffectiveinstoringandprocessingsequential-data,allowingour\\nsystemtotracktheevolutionofAPTsacrossdifferentstages.\\n• Encompassing the dynamic aspects of APTs: APT attackers usually aim to compromise a whole system\\nrather than a specific host, making it crucial to have a model that understands the behavior of the organiza-\\ntion as a whole (Mansour Bahar et al., 2024). Local models often struggle to generalize to new, dynamic,\\nand evolving APT attacks because they are trained on data from a single host, limiting their ability to detect\\nthreats that target an entire organization (Zimba et al., 2020; Li et al., 2023a). Federated Learning (FL), for\\ninstance,offersasolutiontotheseissuesbyenablingcollaborativetrainingacrossdifferenthosts,withouthav-\\ningtosharetheirrawdata(Sonetal.,2023). Thisdecentralizedapproachnotonlyenhancesthedetectionof\\norganization-widethreatsbutalsoreducestrainingtimebyleveragingthecomputationalresourcesofmultiple\\nclients(MansourBaharetal.,2024;Sonetal.,2023). Bycollaborativelytrainingondiversedatafromvarious\\nhosts,themodelcangeneralizebettertonewAPTsandprovideamorecomprehensivedefensemechanism.\\nFederated solutions can also be deployed in a large-scale environment, where different companies or state-\\nrelated organisations collaborate with their respective model weights to build an Intrusion Detection System\\nthat can generalise to various system-behaviours, and effectively detect new APT attacks. This architecture\\nplaystheroleofadefensiveallianceamongorganisationsagainsttargetedandsophisticatedattacks.\\nHowever, Federated Learning introduces new privacy concerns, as model weights are shared between clients\\nandservers,makingthemvulnerabletodataleakage(Shanmugarasaetal.,2023).\\n• Addressing Privacy Concerns: While Federated Learning enhances collaborative training, it also raises\\nsignificant privacy issues. Transmitting model weights in clear text can expose them to Man-in-the-Middle\\n(MitM) attacks, where an adversary can intercept and reverse-engineer the data of clients. In addition, an\\nattackercouldtargetthecentralservertoobtainmodelweightsinwhatisknownasInferenceAttacks(Krumm,\\n2007), compromising the privacy of all participating clients. To mitigate these risks, a solution that can be\\nemployed is Homomorphic Encryption (Yi et al., 2014; Doan et al., 2023), which allows computations to\\n6be performed on encrypted data without the need to decrypt it. This ensures that even if model weights are\\nintercepted, thedataremainssecure, andtheservercannotaccesstherawweights. Italsoopensperspectives\\nonimplementingIntrusionDetectionSystemswithuntrusted-servers, orservelessarchitectures(Zhongetal.,\\n2022;Baughmanetal.,2022;Savazzietal.,2019).\\nOurresearchcombinestheseadvancedtechniquestodeveloparobustIntrusionDetectionSystemcapableofdetecting\\nsophisticated APTs with high accuracy and efficiency. By leveraging autoencoders, Spatial-Convolutional GNNs,\\nMemory-basedmodels,andfederatedlearningwithencryptedweights,weaddressthecriticalchallengesinmodern\\ncybersecurity,providingacomprehensiveandscalablesolutionfordetectingAPTs.\\n4. RelatedWork\\nIn this section we provide a comprehensive background and literature review of recent works in various areas\\nrelevanttoourresearch. Wefocusonseveralkeyaspects: GNN-basedAPTdetection,graph-datageneration,decen-\\ntralisedanddistributedIDSarchitectures,andencryptiontechniquesinfederatedlearning. Thisreviewhighlightsthe\\nexistingmethodologiesandtheirlimitations,settingthestageforthenovelcontributionsofourstudy.\\n4.1. GNNsinCybersecurity\\nGraph Neural Networks have emerged as a highly effective tool for cybersecurity, particularly in the domain of\\nintrusiondetection. TraditionalIntrusionDetectionSystemsoftenrelyonrule-basedorsignature-basedapproaches\\n(Hanetal.,2020),whichstruggletoadapttorapidlyevolvingattackstrategiesandnovelthreats. Incontrast,GNNs\\noffertheabilitytomodelcomplexrelationshipswithinnetworkstructures,enablingthemtoidentifysubtle,concealed-\\npatternscommonlyassociatedwithAPTs.\\nByleveragingtheabilitytocaptureintricateinterconnectionsbetweennetworkentities,GNNscanprovideamore\\nrobust detection mechanism compared to conventional IDS. For instance, Pujol-Perich et al. (2022) demonstrated\\nGNNs’ capability in anomaly detection by capturing network-flow relationships, offering precise identification of\\nmaliciousactivitiessuchasDistributedDenialofService(DDoS),portscans,andnetworkscans. Examplesofgraph\\nmodelisationofattacksisshowninFigure2.\\nAttackers Flows Flows Flows Victims\\nA1 F1 F1 F1 V1\\nVictim Attacker Victim Attacker\\nA2 F2 V A F2 V A F2 V2\\n... ... ... ... ...\\nAn Fn Fn Fn V3\\n(a)DDOS (b)PortScan (c)NetworkScan\\nFigure2:Graphsignatureofwell-knownattacks(Pujol-Perichetal.,2022)\\nRecent studies further emphasize the effectiveness of GNNs in cybersecurity. Wang and Yu (2022) highlighted\\nhowGNNscantacklethechallengesofapplyingdeeplearningtostructuredgraphdata,showingtheirutilityacross\\nvarious domains, including social networks and bioinformatics. The mathematical framework of GNNs aligns well\\nwith real-world network structures, making them an ideal choice for anomaly detection. Additionally, Bilot et al.\\n(2023)exploredtheapplicationofGNNsfordetectingAPTs,underscoringtheirpotentialinenhancingIDSsystems\\nbyidentifyingsophisticatedthreatpatterns.\\nWhileGNNsofferatransformativeapproachtointrusiondetectionbymodelingcomplexnetworkrelationships,\\ntheir effectiveness relies on the availability of high-quality datasets and careful handling of challenges such as data\\nbiases and concept drift (Tsymbal, 2004). Furthermore, implementing GNNs in cybersecurity requires significant\\ntechnicalexpertisetofullyexploittheircapabilities.\\n7While these datasets provide valuable resources for evaluating PIDSes and graph-based APT detection models,\\nthere is still a noticeable gap in publicly available benchmarks specifically tailored for graph detection of APTs, as\\nhighlightedby(LiuandJiang,2023). Manydatasetsareeitheroutdatedorinsufficientlydiversetocapturethecom-\\nplexityofmodernAPTcampaigns. Furthermore,theconfidentialnatureofAPTattackdatarestrictstheavailability\\nof real-world datasets, making it challenging for researchersto apply machine learningand graph-based techniques\\neffectively. Continueddevelopmentofdiverse,high-qualitydatasetsisessentialtoadvancingthefieldofAPTdetec-\\ntion.\\n4.2. GraphGeneration\\nGraphdata,suchasprovenancegraphsusedinintrusiondetection,canbetailoredbasedonthespecificrequire-\\nmentsofeachmodel(Zhongetal.,2024). Dependingonthenatureofthetask,modelsmayoperateoneitherstatic\\nordynamicgraphdata,withthelatterbeingessentialforreal-timeanalysis,suchasflow-basednetworkmonitoring\\n(Kazemietal.,2020).\\n4.2.1. Static-data\\nStaticgraphs,withtheirfixedtopologyandconnections,representthenetworkorsystemataspecificmomentin\\ntime. Thesetypesofgraphsarecommonlyusedingraph-basedIDS,asseeninstudiesby(Protogerouetal.,2021;\\nLoetal.,2022), andWangetal.(2023). Beforebeinginputintomodels, staticgraphdatacanbemodifiedthrough\\ntechniquessuchasenrichmentortransformationtoimprovethemodel’sabilitytodetectanomaliesandcyberthreats.\\nEnriching static graphs involves adding more information to the original graph to enhance its structure. For\\nexample,intheworkofZhengandLi(2019),additionaledgesandhyper-edgeswereintroduced,suchasconnecting\\ntwo-hopneighbors,tocapturemorecomplexrelationshipswithinthedata.Similarly,Chengetal.(2021)usedmethods\\nlike one-hot encoding and similarity measures to extract new attributes for nodes and edges, allowing the model to\\ngaindeeperinsightsintothegraph’sstructureandenhancedetectionaccuracy.\\nAnother approach to modifying static graphs is through transformation, where the graph structure is altered to\\nserve different analytical purposes. Chang and Branco (2021); Zhu and Lu (2022) explored transforming original\\ngraphsintolinegraphs,whereeachvertexcorrespondstoanedgeintheoriginalgraph. Thistransformationcanbe\\nparticularlyusefulforconvertingtaskslikeedgeclassificationintonodeclassification,streamliningtheanalysisand\\nallowingformoreefficientdetectionofmaliciousactivities,asdiscussedbyZhongetal.(2024).\\n4.2.2. Dynamic-data\\nProvenancegraphsaregenerally-speakingstaticdata,i.e,theyrepresentthenetworkorsysteminafixedtopology.\\nHowever,inareal-timeintrusiondetection,dataisdynamic,i.erepresentedinflowsorsequencesprocessedseparately\\novertime. Dynamicmethodsinvolvesmainlytwotechniques,snapshotingandsketching(Zhongetal.,2024).\\nSnapshoting approach involves dividing the data into intervals and creating a snapshot for each interval. Each\\nsnapshot represents the state of the network during a specific time period, allowing for the analysis of temporal\\nchangesandpatterns. Forexample,KingandHuang(2023);Jedhetal.(2021)proposedtechniquesthatusespecific\\ntimeunitsorintervalsassnapshotstoanalyzethenetwork’sstructureandrelationshipsovertime. Xiaoetal.(2021)\\nextendedthisapproachbyconsideringeachtimestampasanode,therebyconstructingagraphwithafixednumberof\\ntimestampsateachinstance. Thismethodeffectivelycapturestemporaldynamicsinthenetworkdata.\\nDifferently, sketching techniques involves creating a summarized or approximate representation of the graph to\\nreduce complexity while retaining essential features. This method focuses on efficiently capturing the essential in-\\nformationfromalargeandcomplexnetwork. PaudelandEberle(2020)introducedagraph-sketchingtechniquethat\\nconvertsagraphintoalow-dimensionalsketchvectorusingasimplifiedhashingtechnique. MessaiandSeba(2023)\\nproposedconstructinganactivitygraphfromnetworkingeventsduringamonitoringperiod. Thisactivitygraphcap-\\ntures both structural and semantic features from network traffic, which are then used to train a neural network to\\ndistinguishbetweennormalactivitiesandattacks.\\n4.3. GNNsinAPTattacksDetection\\nThe utilisation of GNNs in Intrusion Detection Systems has been at the forefront of recent advancements in\\nCybersecurity, particularly for detecting APT attacks. Various GNN-based architectures have been developed to\\n8enhance the detection of these sophisticated threats by leveraging the inherent graph structure of system data. For\\ninstance,MAGIC(Jiaetal.,2023)employsamasked-graphauto-encodertolearnmeaningfulgraphrepresentations.\\nThistechniqueinvolvesmaskingcertainnodesoredgesduringtrainingtoreconstructthesemaskedelements,allowing\\nthemodeltounderstanddeepcorrelationswithintheprovenancegraphs. ByusingmultipleGraphAttentionNetwork\\n(Velicˇkovic´etal.,2017)layersasadecoderintheself-supervisedlearningprocess,MAGIC(Jiaetal.,2023)predicts\\ntheoriginalgraph-structurefromcorruptedversions. Thisapproachenablesthemodeltocaptureoutliersatboththe\\nsystem-entityandbatched-loglevels, facilitatingmulti-granularitydetection. Itcanpreciselyidentifythesub-graph\\ncontainingtheattacksandthespecificnodesinvolved,enhancingtheaccuracyofAPTdetection. Anothersignificant\\nwork, KAIROS, developed by Cheng et al. (2023b), introduces a novel GNN-based encoder-decoder architecture\\nthat focuses on learning the temporal evolution of a graph and assessing the degree of anomalousness in data at\\ndifferenttimestamps. WhenKAIROS(Chengetal.,2023b)detectsanewedgeintheprovenancegraph,itprocesses\\nthe feature vectors of the source node’s neighbors using a Temporal Graph Network (Rossi et al., 2020) encoder.\\nThis encoder generates an embedding for the new edge, which is subsequently reconstructed using a Multilayer\\nPerceptron (MLP) (Popescu et al., 2009) decoder. This architecture not only aids in understanding benign system\\nbehavior,butalsofacilitatestheefficientdetectionofsuspiciousnodes. Furthermore,KAIROS(Chengetal.,2023b)\\ntracks output edges from these nodes to construct a summary graph, enabling system administrators to backtrack\\nandanalyzeattackscenarios. GraphCompetitiveAutoencoder(GCA),proposedbyYeetal.(2023),isanotherGNN-\\nbasedworkthatutilizesaGraphConvolutionalNetwork(GCN)(KipfandWelling,2016a)todiscoverattackscenarios\\nthrough intrusion alert-correlation. This architecture uses a GCN as the graph encoder to generate embeddings,\\nconverting each graph into a vector representation that captures features of both attack and benign graphs. GCA\\nYeetal.(2023)employsseparatedecodersforlabeledbenigngraphsandunlabeledgraphs,enhancingclassification\\naccuracy. Attackgraphsareidentifiedbycomparingreconstructionerrors;iftheattackdecoder’serrorislowerthan\\nthebenigndecoder’sforanunlabeledgraph,itisclassifiedasanattackgraph. Anotherresearch,namedGHUNTER,\\ndepictedbyChengetal.(2023a),aimstoenhancethediscriminatorycapabilityofGraphIsomorphismNetwork(Xu\\netal.,2018)andtheirgeneralisationofWeisfeiler-Lehman(WL)heuristic(LemanandWeisfeiler,1968)forsubgraph\\nmatching in APT detection. GHUNTER Cheng et al. (2023a) operates by using a simple GIN (Xu et al., 2018)\\nto generate node embeddings from provenance graphs. It then seeks a node whose embedding indicates that this\\nnodeservesasananchorforasubgraphresemblingapreviouslyknownmaliciousgraph. Thisapproachbolstersthe\\nmodel’sabilitytodetectsubgraphsthatmatchknownattackpatterns. Furthermore,twootherresearchesexploredthe\\nimplementationofGraphSAGE(Hamiltonetal.,2017)inthedetectionofAPTs;thefirstoneisThreatrace,developed\\nbyWangetal.(2022a),itemploysGraphSAGEtoembedevolvinggraphsfortimelythreatdetection.Thisarchitecture\\nefficiently learns node roles in provenance graphs despite not considering every node’s neighbor. By focusing on\\nthe temporal dynamics of network activities, Threatrace (Wang et al., 2022a) is capable of detecting anomalies and\\nsuspicious activities that span multiple stages and time periods, providing a comprehensive view of potential APT\\ncampaigns. The second one is XFedGraph-Hunter, explored by Son et al. (2023), represents a pioneering effort in\\napplyingFederatedLearningtoPIDSapplicationsusingGraphSAGEforAPTdetection. Thisarchitectureemploysa\\npre-trainedtransformertoaddedgefeaturesandstandardizenodefeaturesbeforeGraphSAGElayers(TGraphSage).It\\nalsousesGNNExplainer(Yingetal.,2019)togenerateexplainabledetectiongraphs. ByleveragingFL,XFedGraph-\\nHunter(Sonetal.,2023)demonstratedimprovedprecisionandF1-scorecomparedtotheoriginalGraphSAGEmodel.\\nThe collaborative training on local data, where each host sends weight updates to a server for aggregation, enabled\\nbettergeneralizationandreducedfalse-positiverates.\\nTheseGNN-basedIDSarchitectureshighlighttheinnovativeapproachestoAPTdetection,leveragingthecapabil-\\nitiesofGNNstomodelcomplexrelationshipsandpatternswithingraphdata. Thesesystemsprovidepowerfultools\\nforcybersecurityprofessionalstoenhancethesecurityofnetworksystemsagainstadvancedcyberthreats. However,\\nakeylimitationoftheseapproachesisthehighrateoffalsepositivesthatoftenaccompaniesGNN-baseddetection\\nmodels(Altaf etal., 2024;Chenget al.,2023b; Jiaet al.,2023). This issueariseswhen benignactivities thatshare\\nsimilaritieswithattackpatternsareincorrectlyflaggedasmalicious,resultinginalertfatigueandreducedefficiency\\nofsecurityteams(Chengetal.,2023b). Additionally,therelianceonpre-constructed,staticgraphsinmanyofthese\\napproacheslimitstheirabilitytodetectdynamic,time-sensitiveattackstagesthatevolveovertime. Asaresult,static\\nmodelsoftenmisscriticalattackbehaviorsunfoldinginreal-time,particularlyinlong-termAPTcampaigns.\\n94.4. DecentralisedandDistributedAPTDetection\\nFew works only have studied the application of decentralised or distributed IDS architecture, especially in the\\ndetectionofAPTattacks. MostAPT-detectors(Jiaetal.,2023;Chengetal.,2023b;Wangetal.,2022a;Chengetal.,\\n2023a)relyoncentralizeddataanalysis,whichcanberesource-intensiveandposesignificantprivacyrisks.\\nInapioneerwork,Wuetal.(2022)introducedadistributedIDSarchitecturenamedParadise,whichutilizesKafka\\nservers(Thein,2014)todistributeclientdatatoIDSserversforparallelattackdetection. Althoughthisarchitecture\\nimprovesresourceefficiencyandenablesparallelprocessing,italsofaceschallengesrelatedtobandwidthconsump-\\ntionanddataprivacy. Bytransmittingsystem-logsandothersensitiveinformationoverthenetwork,thisapproachis\\nvulnerabletosniffingattacks.\\nIn response to these challenges, federated learning offers a more secure alternative. By allowing clients to train\\nlocal models and share only model parameters with the central server, FL facilitates the development of models\\ncapableofidentifyinganomalousbehaviorindicativeofpotentialintrusionswhileensuringthatsensitivedataremains\\nwithinthelocalenvironmentofeachclient,whichminimizestheriskofdataexposureandreducesnetworkstrain.For\\ninstance,Sonetal.(2023)exploredtheapplicationofFLonGNNsforAPTattacksdetectionanddemonstratedthat\\nFLcouldreducethefalse-positiverateandenablethemodeltogeneralizetounknownattacksthroughcollaborative\\nmodel-training.\\n4.5. EncryptioninFederatedLearning\\nWhileFLimprovesdataprivacybykeepingrawdatalocal,itstillinvolvessharingmodelupdates,whichcanbe\\ninterceptedbymaliciousactorswhomcanreconstructtheclients’datausingreverseengineering(Shanmugarasaetal.,\\n2023). Thisvulnerabilityhasledtotheexplorationofvariousencryptiontechniquestosecurethecommunicationof\\nmodelweights.\\nIn our previous research, called FedHE-Graph (Mansour Bahar et al., 2024), we addressed some of these chal-\\nlenges in APT attacks detection by testing federated learning with hybrid encryption, using Advanced Encryption\\nStandard (AES) for the symmetric encryption (Dworkin et al., 2001), and Rivest-Shamir-Adleman (RSA) for the\\nasymmetricone(Rivestetal.,1978). Thisapproachdemonstratedpromisingresultsbyreducingexecutiontimeand\\nenhancingprivacy.However,itshowedlimitationsagainstinferenceattacks(Krumm,2007),whereanattackertargets\\ntheserverduringthedecryptionphasetointerceptthemodelweights. Interceptingthisinformationenablesattackers\\nto conduct Mimicry Attacks, mimicking the usual behavior of a user to evade detection by the IDS (Goyal et al.,\\n2023). Attackersmayalsoleverageintercepteddataforinformationgatheringorforconductingpoisoningattacksto\\ndegradethequalityofmodeltraining-data,posingsignificantrisks(Yangetal.,2017).\\nHomomorphicencryption(Yietal.,2014)offersasolutiontothisissuebyallowingcomputationsonencrypted\\ndata without the need for decryption. This ensures that even if an attacker gains access to the server, they cannot\\naccessthemodelweights. Tothebestofourknowledge,noIDShasexploredtheuseofHomomorphicencryptionin\\nthedetectionofAPTattacks. Yet, onesignificantcontributioninthisfieldistheworkbyChenetal.(2019), which\\nintroducedMulti-keyHomomorphicEncryption(MKHE)forfederatedlearning.Inthisscheme,eachclientgenerates\\napairofprivate/publickeysforencryptinganddecryptingmodelweights. Theservercanperformcomputationson\\ntheencryptedweightswithoutdecryptingthem,thusmaintainingdataconfidentialitythroughoutthelearningprocess.\\nThis method enhances the security of APT detection systems by safeguarding against various attack-vectors. This\\nresearchhasshownthatintegratingHomomorphicEncryptionwithFLcaneffectivelyprotectagainstsecuritythreats,\\nincludingMitMattacksandserver-sidebreaches. However,thecomputationaloverheadintroducedbyencryptioncan\\nbesubstantial,necessitatingefficientimplementation-strategiestobalancesecurityandperformance.\\n5. Ourapproach: CONTINUUM\\nInthissection,weproposeanovelarchitectureforHost-basedIntrusionDetectionSystemsutilizingaheterogeneous-\\ngraphapproach. Thisarchitecture,whichwecalledContinuum,efficientlycapturescomplex-dependenciesbetween\\nsystem entities to detect APT attacks. Designed for scalability, Continuum can easily adapt to new hosts, integrate\\nadditional data streams, and optimize resource usage. It addresses current GNN model limitations, offering a new\\nsolutionforprotectingorganizationsagainstAPTthreats.\\n10ThearchitectureisdepictedinFigure3. Itbeginswithprovenancedatacapturedbyathird-partysystemdata-flow\\nanalyzer. Thisdataincludestherelationshipsanddependenciesbetweenvarioussystementitiessuchasfiles,scripts,\\nusers,andprocesses. Theprovenancedataisstructuredasgraphs,representingsysteminteractionsthatwillserveas\\ntheinputforbothtraininganddetectionphases.\\nData\\nCapturing\\nGNN-based HIDS\\nGNN\\nData- Model\\nData Anomaly\\nstreams\\nTreatment Detection\\nGeneration\\nMalicious Benign\\nFigure3:GlobalarchitectureofContinuum\\nAftercapturingthedata,itundergoespre-processingtoconvertitintodatastreams,alsoreferredtoassnapshots,\\nthat represent specific periods of system activity. These snapshots are subject to quality enhancement processes to\\nensure that the data is ready for use in the GNN model. The GNN model then processes these snapshots to learn\\ncomplex dependencies between the system entities, producing node embeddings that capture detailed relationships\\nwithinthesystem.\\nAsforthetraining,thesystemispre-trainedexclusivelyonbenigndata,whichenablestheGNNmodeltolearn\\nwhatconstitutesnormalbehaviorwithinthehost. Asaresult,themodelcanmoreeffectivelydetectanomalies,which\\nmayindicatethepresenceofanAPTattack. Byanalyzingtheseembeddingsinrealtime,themodelcandifferentiate\\nbetweenbenignandmaliciousactivities,formingthecoreoftheAPTdetectionmechanism.\\nMoreover, Continuum operates by detecting APTs at both the graph level (entire snapshots) and entity level\\n(individualnodes). Duringreal-timeoperation,incomingdata-streamsareprocessedintosnapshotsandfedintothe\\nGNN.Themodelevaluateseachsnapshotsequentially,identifyinganyanomaliesthatdeviatefromnormalbehavior,\\nthusflaggingpotentialAPTs.\\nThisdesignensuresproactivedetectionbyanalyzingreal-timeprovenancedata,providingascalable,GNN-based\\napproachtosafeguardsystemsfromsophisticatedAPTattacks.\\n5.1. Modelconstruction\\nThe Continuum architecture is designed to leverage a Spatial-Temporal Graph Neural Network to detect APTs\\nby capturing both spatial relationships and temporal dynamics between system entities. This section details each\\ncomponentofthemodel,justifyingthedesignchoicesmadetoensurerobustAPTdetection.\\n5.1.1. STGNN\\nAkeytrendinAPTdetectionistheuseofautoencodersinsteadoftraditionalclassifiersinPIDSarchitectures(Ye\\netal.,2023;Chengetal.,2023b;Jiaetal.,2023). Inanautoencoder-basedIDS,theencoderproducesembeddingsfor\\ngraphnodes,whilethedecoderminimizesthesimilarityerrorsbetweenactualandreconstructednode-representations.\\n11Thisprocesspreservesessentialinformationandoriginalattack-patterns. Basedonthis, wechoosetoincorporatea\\nGNN-based autoencoder in our design. Autoencoders are crucial for uncovering complex-patterns related to APT\\nattacksbygeneratingprecise-embeddingsfornodesandextractinghidden-informationfromtheirneighbors.\\nMoreover,detectingAPTattacksreliesontwomaincharacteristics: identifyingabnormalbehaviorsindicativeof\\nanattack,andrecognizingthatAPTpatternsevolveovertime. Therefore,ourIDSmustconsiderthetemporaldimen-\\nsionofAPTattacksacrossvariousstages. Toaddresstheseaspects,weimplementanSTGNNinourautoencoder,as\\nshowninFigure4. STGNNischosenforitsabilitytomodelthecomplexanddynamicnatureofAPTattacks. The\\nSTGNNintegratesspatialinformation(howentitiesinteractwithinasinglesnapshotofthesystem)andtemporalin-\\nformation(howtheseinteractionsevolveovertime). Thisdualmodelingallowsthesystemtodetectbothimmediate,\\nanomalousactivities,andprolongedmalicious-behaviorsthatunfoldgradually.\\nSTGNN Autoencoder\\nInput Data\\nSTGNN Encoder STGNN Decoder Detection Mechanism\\nme T2\\nTi\\nT1\\nT0 GGNGNNNNN GGNGNNNNN\\nLGaGNyGeNNrNNsN RGNGNNNNN LGaGNyGeNNrNNsN RGNGNNNNN K-NN\\nLayers Layers Layers Layers Classifier\\nFigure4:ArchitectureofourGNNautoencoder\\nThechoiceofSTGNNovertraditionalGNNsisessentialbecauseAPTsofteninvolvemultistageattacksthatare\\nnotconfinedtoasingletimeframe. Thetemporaldimensionenablesthesystemtotracktheprogressionoftheattack\\novertime,whichiscriticalinidentifyingthreatsthatdonotexhibitimmediateanomalousbehavior.\\nSpatialInformation. Graph-dataaggregatesinformationfromnodesandtheirneighborhoods,makingitbeneficialto\\nuseaGNNmodelthatemphasizesalocalizedviewofeachnode’ssurroundings.ThisisespeciallyrelevantforSpatial\\nConvolutionalGNNs,whichutilizemessage-passingfunctionstouncoverhiddeninformationfromneighboringnodes\\nandlearncomplexdatacorrelations. TheirapplicationinAPTdetectionisstrategicallysound,asAPTattacksoften\\nrevealcomplexbehaviorsthroughinteractionswithinlocalneighborhoodsratherthanisolatednodes. SpGNNsexcel\\nin capturing these intricate relationships by focusing on local connectivity patterns (Sahili and Awad, 2023). By\\nfocusingontheimmediateneighborsofeachnode,thesystemcancapturefine-grainedanomalies,suchasunexpected\\nfileexecutionsorunauthorizedaccesstoprocesses. ThislocalizedinformationisthenaggregatedovermultipleGNN\\nlayers,buildingaricherrepresentationofeachnode’srolewithinthesystem. NotableSpGNNarchitectures,suchas\\nGraphSAGEandGAT,arerecognizedfortheireffectivenessinlearningfromlocalgraphstructures(Jiaetal.,2023;\\nSon et al., 2023; Wang et al., 2022a). GraphSAGE aggregates information from node neighborhoods, while GATs\\ndynamically weigh node contributions using attention mechanisms. Thus, SpGNNs are crucial for enhancing IDS\\ncapabilitiesagainstsophisticatedcyberthreatslikeAPTattacks.\\nTemporalInformation. GiventheprolongedandstealthynatureofAPTattacks,analyzingthetemporalevolutionof\\nprovenance data is key to detecting anomalies at different stages of an attack. As attackers move through distinct\\nphases over time, monitoring the relationships between system entities across various periods helps reveal evolving\\nattack patterns. To achieve this, a memory-based model, such as an RNN, GRU, or LSTM, is employed in Con-\\ntinuum. The RNN layers track the temporal dependencies of each system entity by maintaining a hidden state that\\nupdates as new snapshots are processed. This hidden state serves as memory for the system, enabling it to identify\\nslow-developingattacksthatmightevadedetectioninsingle-snapshotmodels. Moreover, unlikeconventionalfeed-\\nforwardneuralnetworks(BebisandGeorgiopoulos,1994),whichtreatinputsindependently,memory-basedmodels\\nleveragetheirinternalstatetoprocesssequentialinformation.Thisallowsthemtopredictbehaviorsbasedontemporal\\nrelationships.\\n12TheuseofRNNsiscriticalformodelingtemporaldependenciesandattackpatterns. ManyAPTattacksinvolvea\\nsequenceofseeminglyunrelatedactivitiesthat,whenviewedinisolation,appearbenign. Byleveragingthetemporal\\ndimension, the system can correlate these activities, identifying acoherent attack sequence that might otherwise go\\nunnoticed.\\n5.1.2. Encoder\\nThe encoder plays a key role in transforming raw graph-data into meaningful representations. It consists of\\nmultiple layers of GNNs that produce node-embeddings dense vector representations that encode each node’s local\\ncontext (i.e., relationships with its neighbors) (Jia et al., 2023). These embeddings are passed through the RNN\\nlayers,whichenrichthemwithtemporalinformation. Thisprocessensuresthatthefinalembeddingsreflectnotonly\\nthecurrentstateofeachentitybutalsohowitsbehaviorhasevolvedovertime.\\n(cid:16) (cid:17)\\nnode embeddings=RNN [GNN(G)]T (6)\\nt t=1\\nwhereG is the embedding of graphG at timestamp t, GNN is the update function of the GNN layer, and RNN is\\nt\\ntheupdatefunctionoftheRNNlayer. Thechoiceofthismulti-layeredencoderstructureisjustifiedbytheneedfora\\nhierarchicalunderstandingofsystembehavior. TheGNNlayersfocusonspatialaggregation,whiletheRNNlayers\\naddatemporalperspective,resultinginembeddingsthatarehighlyinformativeandtailoredforanomalydetectionin\\nAPTscenarios,whichareknownforbeingpersistentandprolongedintime.\\n5.1.3. Decoder\\nOnce the embeddings are generated, the decoder attempts to reconstruct the node features and interactions, en-\\nsuring that the embeddings accurately represent the original graph-structure (Jia et al., 2023). This is particularly\\nimportant in an anomaly detection context, where even slight deviations from normal behavior need to be identi-\\nfied. The better the embeddings represent normal system activity, the more sensitive the system will be to subtle\\nAPT-relatedanomalies.\\nOur decoder utilizes an STGNN for this purpose, creating an objective function that boosts the graph repre-\\nsentation module’s performance. It regenerates initial node-embeddings, allowing for the calculation of feature-\\nreconstructionloss,whichhelpsenhancetherelevanceofthegeneratedembeddings.\\nThereconstructionlossiscomputedusingalossfunctionthatcomparestheinitialnodevectorswiththerecon-\\nstructedones,aimingtomaximizethebehavioralinformationintheabstractednodeembeddings.\\nL(I,R)=loss function(I,R) (7)\\nwhere L is the Reconstruction loss, I are the initial node vectors, and R are the reconstructed node vectors. Addi-\\ntionally,incorporatingRNNlayersintothedecoderpreservestemporalinformationbymergingthecurrentsnapshot’s\\noutput with the upcoming one. This continuity captures temporal dependencies between snapshots, improving the\\ndecoder’sabilitytoreconstructnodefeaturesandrefiningthemodel’soverallperformance.\\n5.1.4. DetectionMechanism\\nInGNN-basedIDS,attacksaredetectedthroughtwoprimaryapproaches: classificationandanomalydetection.\\nTheclassificationapproachassignspredefinedlabelstoentitiesbasedonpatternslearnedfrombenignbehaviors.\\nForexample,Manzooretal.(2016)simulatedmachinestatesbymodelingactivitiessuchaswebbrowsing,watching\\nYouTube,orplayingvideogames. Aclassifiercomparesnewentitiestotheseknownbehaviorsandassignsthemto\\noneofthepredefinedclasses. Ifnomatchisfound,theentityislabeledasmalicious.\\nIn contrast, anomaly detection identifies deviations from normal behavior without relying on predefined class\\nlabels,thisisthecaseofsomerecentGNN-basedAPTdetectors(Chengetal.,2023b;Jiaetal.,2023). Thisapproach\\nfunctionsasabinaryclassification,flagginganysignificantdeparturefromtypicalbehavioraspotentiallymalicious.\\nBothclassificationandanomalydetectionarecrucialfordetectingandaddressingthreatsinnetworkenvironments,\\nproviding complementary perspectives on security monitoring and threat detection. In Continuum, we opt for an\\nanomaly-detection model, which classifies nodes as either benign or anomalous, by using a K-Nearest Neighbors\\n(K-NN) algorithm (Peterson, 2009). K-NN is chosen for its flexibility in identifying novel attack patterns. APTs\\n13are constantly evolving, and attackers frequently modify their tactics to evade detection. By comparing the learned\\nembeddingsofeachnodetothoseofknownbenignentities,thesystemcanidentifyoutliers—nodeswhosebehavior\\ndeviatesfromthenorm. Thisallowsthesystemtoadapttonewandunforeseenthreats,makingithighlyeffectivein\\nreal-worldenvironmentswhereAPTsareconstantlyevolving\\nDuring model exploitation in Continuum, the node embeddings generated by the STGNN encoder will be used\\nforeithernodeorgraphclassification. Forgraphclassification,thegraphencoderappliesaveragepoolingtocreatea\\ngraphembeddingfromthenodeembeddingsproducedbythefinalRNNlayer.\\n1 (cid:88)\\nH = H (8)\\ng |V| n\\nn∈V\\nwhereH istheembeddingofgraphG,H istheembeddingofnodenofthelastRNN,andVisthesetofneighboring\\ng n\\nnodesn.\\nFinally, the benign embeddings are clustered using the K-NN model, serving as reference points in classifying\\ninstancesaseithermaliciousorbenignbasedonthedistancetotheirnearestneighbors.\\nThedetailedarchitectureoftheSTGNNisdepictedinFigure5below.\\n2 GNN Encoder 3 GNN Decoder\\nSnap 1 RNN RNN\\nG1 H 1 H\\' 1 H\\' 1 H\"1 H\\'\" 1\\nSnap 2 G2 H 2 RNN H\"2 RNN K-NN Y\\nGNN H\\' GNN Classifier\\nHn\\nHH\\'\\'\\n2\\nH\" n H\\'\"\\nG\\'\\n22 2\\n... ... ...\\nG\\nn H n\\' -1 H\\'n H\\' n\" -1\\nSnap N RNN RNN\\nFigure5:DetailedarchitectureofourGNNautoencoder\\n5.2. Dataconstruction\\nAnother component of our solution involves a data-to-graph methodology centered on provenance graphs, the\\nGraph Neural Network model is trained using data snapshots derived from these graphs. However, current APT\\ndatasetsinprovenancegraphformataretypicallyinlogformandlacksegmentationintosnapshots(Manzooretal.,\\n2016;Han,2018b,a,2020a,b;Torrey,2020;Alsaheeletal.,2021).\\nToaddressthis,wedevelopedapre-processingmethodthatusestimestamps,one-hotencoding,andedgecompres-\\nsion. Timestamps segment the dataset into distinct intervals, creating snapshots, while one-hot encoding is applied\\nto standardize the representation of different edge and node types. Additionally, edge compression reduces redun-\\ndancy,optimizingthedatasetsizeandimprovingmodel-trainingefficiency. Thispre-processingmethodiscrucialin\\npreparingAPTdatasetsforeffectiveuseinourGNN-baseddetectionframework,asitadaptstovariousgraph-based\\ndatasets,enhancingperformanceincybersecurityapplications.\\n5.2.1. Snapshotsgeneration\\nInthecontextofAPTdetection,datasetsplittingplaysacriticalroleinfacilitatingthetemporalanalysisofevents.\\nEach row in APT datasets typically represents system interactions as nodes and edges in a graph (Manzoor et al.,\\n2016),accompaniedbymetadatasuchastimestamps. Thesetimestampsindicatethespecificmomentswhenevents\\nwerecaptured,providingchronologicalinsightintosystemactivities.\\n14To effectively process and analyze APT datasets, we leverage this chronological information by segmenting the\\ndatasetsintodiscretetime-intervalsbasedonthetimestampsoftheevents. Thisprocessoftimestamp-basedsegmen-\\ntationallowsustosplitthedataintodistinctsetsofevents,eachcorrespondingtoaspecifictime-range. Forinstance,\\nwedepictinFigure6asimplifiedexample-datasetwith600eventsoccurringatvarioustimestamps.Wecandividethe\\ntimestampsintothreedistinct-intervals. Thefirstintervalmaycovereventsfromtimestamp0to199,thesecondfrom\\n200 to 399, and the final interval includes the remaining events. These segmented sets are referred to as snapshots,\\nandtheyenableamoregranularanalysisofthedataset,focusingontheevolutionofeventsovertime.\\nsource-id source-type destination-id destination-type edge-type graph-id\\nTimestamp 0\\nTimestamp 199\\nTimestamp 200\\nTimestamp 399\\nTimestamp 400\\nTimestamp 599\\n.....\\n.....\\n.....\\n1 1 Snapshot 1\\n2 2 Snapshot 2\\n3 3 Snapshot 3\\nFigure6:Datasetsplittinginsnapshots\\nThefirstphaseofpre-processinginvolvesextractingnodes,edges,andtheirassociatedattributesfromthedataset.\\nEachlineinthedatasetrepresentsaspecificactionorevent,whichvariesinformatdependingonthedatasetinuse.\\nTheprocessissummarizedinAlgorithm1,whereeachlineisprocessedindividuallytoextractrelevantinformation\\nsuchasnodetypes,edgetypes,andtimestamps.\\nAlgorithm1:Informationextractionfromdatasets\\nInput: Datasetfile\\nOutput: Preparedfile\\n1 -Initializethegraph\\n2 foreachlineinthedataset-filedo\\n3 -Separatethefieldsofthelineusingadelimiter\\n4 -Storeeachfieldinaspecificvariable\\n5 -Createthenodesoftheedgeifnotalreadypresentinthegraphwiththeirtypes\\n6 -Createtheedgeinthegraphwithitstypeanditstimestamp.\\n7 -Appendthenewlinetotheoutputfile\\n8 -Closetheinputfile\\n9 returnthegraph\\nThesnapshotgenerationprocessfollowsthestepsoutlinedinAlgorithm2.\\nBy organizing the dataset into these snapshots, we not only streamline the pre-processing phase but also gain\\ntheabilitytoobserveandstudytemporalpatterns,correlations,andrelationshipswithinthedatasetmoreeffectively.\\nThisstructuredapproachenhancesourabilitytodetectandanalyzeAPTattacksthatevolveinstagesovertime,asit\\nprovidesacleartemporal-frameworkforthebehaviorofsystementities.\\n5.2.2. One-Hotencoding\\nToeffectivelymanipulatetheprovenancegraphswithineachsnapshot,itiscrucialtoencodeboththenodesand\\nedgesintoastandardizedformat. Thisencodingprocessenablesthesystemtoprocessthediversetypesofnodesand\\nedgesfoundinAPTdatasets,facilitatingtheiruseinthesubsequentstagesofGNNprocessing. Inourframework,we\\nemployone-hotencodingforbothnodesandedgestorepresentthevarioustypesofinteractionsandentitiescaptured\\nwithinthesystem.\\n15Algorithm2:Snapshotdivisionfromdatasets\\nInput: Formatteddataset,Numberofsnapshots\\nOutput: Graphs,Nodedimension,Edgedimension\\n1 foreachgraph(file)ofthedatasetdo\\n2\\n-Extractnode/edgetypes,timestamps,andmaximumtimestampfromthegraph\\n3\\n-Extractnode/edgedimensionwhichisthenumberofnode/edgetypes\\n4 -Dividethemaximumtimestampbythenumberofsnapshotstocalculatethelengthofthetimesequence\\nofeachsnapshot\\n5 foreachsnapshotdo\\n6 -Generateadirectedgraph\\n7 -Appendallthenodestothegraph\\n8 -Appendonlytheedgesappearinginthetime-sequencewiththesameindexasthesnapshot\\n9 -SavethesnapshotinPKLformat\\n10\\nreturnthesnapshotsandtheirnode/edgedimensions\\nNode encoding. Each node in the provenance graph represents a system entity such as a process, file, or network\\nsocket. Sincethedatasetmayincludedifferenttypesofnodesdependingonthesource,weassignaone-hotencoded\\nvectortorepresenteachnodetype. Forexample,consideragraphwiththefollowingtypesofnodes:\\nV =(Process,File,Socket)\\ni i i i\\nEachnodev inthissetisencodedasaone-hotvectorwhereeachentrycorrespondstoanodetype. Theencodingis\\nk\\nasfollows:\\n\\uf8f1\\nv =\\n\\uf8f4\\uf8f4\\uf8f21, ifnodetypeofv imatchestypek\\n;∀k∈[0,2] (9)\\nk \\uf8f4\\uf8f4\\uf8f30,\\notherwise\\nThis method ensures that each node type is uniquely represented, enabling the system to differentiate between pro-\\ncesses,files,andsockets. Byapplyingone-hotencoding,thedatasetistransformedintoastructuredformatthatGNN\\nmodelscanefficientlyinterpret,allowingfortheidentificationofentitybehaviorswithinthegraph.\\nEdge encoding. Similar to nodes, the edges in the provenance graph are also encoded using a one-hot encoding\\nscheme. Eachedgerepresentsaninteractionbetweentwonodes,suchasaprocessreadingfromafile,oranetwork\\nsocket sending data. Since datasets contain various types of edges corresponding to different system-actions, it is\\nimportanttostandardizetheserepresentationstoensureconsistencyacrossdifferentdatasets.\\nFor example, we encode the following four types of actions: Read, Write, Send, and Execute. The edge e\\nij\\nbetweentwonodes(i, j)isrepresentedbyatupleE asfollows:\\nij\\nE =(Read ,Write ,Send ,Exec )\\nij ij ij ij ij\\nEachcomponente ∈ E isencodedas:\\nk ij\\n\\uf8f1\\ne =\\n\\uf8f4\\uf8f4\\uf8f21, ifedgetypeofe ijmatchesactionk\\n;∀k∈[0,3] (10)\\nk \\uf8f4\\uf8f4\\uf8f30,\\notherwise\\nThis standardized-encoding approach ensures that the provenance graph maintains consistency across datasets and\\nprovidesthefoundationforsubsequentdataset-compression. Thecompressionprocessoptimizesthedataforstorage\\nandcomputationalefficiencywithoutsacrificingtherichnessofthegraph’sstructure.\\nByusingtheseone-hotencodingtechniquesforbothnodesandedges,thedatasetbecomesreadyforGNN-based\\nanalysis,enablingefficient-processingandmanipulationoftheprovenancegraphs.\\nAnexampleofedgeencodingisdepictedinFigure7. Inthisscenario,wesimulateatoy-datasetprolongedover\\ntwosnapshots,eachcontainingaspecificnumberandtypeofedges. Edgesofeachsnapshotareencodedseparately.\\n16b r b\\nr r\\na w a w ww\\ns r s r x\\nc c\\nd\\ns s\\nc b c b r\\nb\\nT1 T2\\n(a)Graphrepresentationoftwosnapshotsbeforeencoding\\nb (1,0,0,0) b\\n(0,1,0,0)\\nc(0,0,1,0 () 0,0,1,0)a (1,0,0,0\\nb)\\nc\\nc(0,0,0,0 () 0,0,0,0)a\\n(0\\n,0\\n,0 ,0\\n)\\nc d\\nb b\\nT1 T2\\n(0,0,0,0)\\n(1,0 (, 00 ,, 00 ,) 0,0)\\n(0,1,0,0)\\n(0,0,0,1)\\n(1,0,0,0)\\n(b)Graphrepresentationoftwosnapshotsafterencoding\\nFigure7:Exampleofedgeencodingfortwosnapshots.TheactionsrepresentedareRead(r),Write(w),Send(s),andExecute(x).\\nNote that an edge appearing in the first snapshot should not appear in the second one as each snapshot describes a\\nset of events happening in a fixed interval of time. However, we choose to represent them in the referred figure for\\nillustration only. The information represented on edges of the first snapshot is transmitted to the second snapshot\\nthroughthememoryoftheRNN-layerspresentedinFigure4.\\n5.2.3. Edgecompression\\nAfterencodingthedatasetintothenewformat,weoptimizeitssizethroughcompressionbycombiningedgeswith\\nidenticalsourceanddestinationnodeswithineachsnapshot. Theseedgesaresummedintoasinglecompressed-edge,\\nasrepresentedby:\\n(cid:88) (cid:88) (cid:88) (cid:88) (cid:88)\\nC = E =( Read , Write , Send , Exec ) (11)\\nij ij ij ij ij ij\\nwhereC is the compressed edge between the pair of nodes (i, j), and E is the encoded edge between the pair of\\nij ij\\nnodes(i, j). Toillustratethismethod,weshowanexampleofcompressiononasimplegraphinFigure8below.\\n1 + 2\\n1\\nb b\\n(1,0,0,0) (2,0,0,0)\\n(0,1,0,0) (0,1,0,0)\\nc(0,0,1,0 ()\\n0,0,1,0)\\na (1,0,0,0) b2\\nc\\nc(0,0,1,0 () 0,0,1,0)a\\nc\\nFigure8:Compressionoftwoedges\\n17For further explanations, we depict in Figure 9 the application of the compression methods on three snapshots\\ngeneratedfromthepreviousedge-encodingscenario(RefertoFigure7).\\nWenoticethatthismethodreducesthenumberofedgesinthedataset,effectivelyminimizingitssize,whichcan\\noftenbeinthetensofgigabytes.Toconfirmthisclaim,weshowinTable1asizecomparisonbetweendatasetsbefore\\nandaftercompressingtheiredges.\\nc(0,0,1,0 () 0,0,1,0)a(1 (, 1,00, ,0,0\\n0\\nb, )0) cb (0,1,0,0) a(1,0,0,0) cb\\nb\\n(0,0,0\\n(1( ,0\\n1\\n,, 01 ), ,0 0,0 ,)\\n0)\\nd\\na (1,0( ,00, ,0(1 ), 0,0 1, ,0 0)\\n,0)\\nbb c (( 00 ,, 00 ,, 10 ,, 0(1\\n(0\\n1))\\n,,1 0,,0 0,,0 0)\\n)\\nd\\nT1 T2 T3\\n(a)Graphrepresentationofthreesnapshotsbeforecompression\\nb\\nc(0,0,1,0 ()\\n0,0,1,0)a(2,0,0,0) cb\\n(0,1,0,0)\\na(1,0,0,0)\\nc\\n(0,0,0( ,1 1,1 ),0,0)\\nd\\na\\n(1,2,0,0) bc (0,0,1,1( (0\\n1)\\n,,1 0,,0 0,,0 0)\\n)\\nd\\nT1 T2 T3\\n(b)Graphrepresentationofthreesnapshotsaftercompression\\nFigure9:Exampleofedgecompressionforthreesnapshots.\\nForinstance,thesizeofTheia-E3dataset(Torrey,2020)wasreducedbyover3.7millionedge,andClearscope-\\nE3 (Torrey, 2020) saw a reduction of over 2.3 million edges. This comparison reveals an average 70.8% reduction\\nofedgesingeneral,whichmeansasignificantreductionindatasetscomplexity,trainingtimes,resource,andenergy\\nconsumption,whichdirectlyimprovesthemodel-trainingefficiency.\\nTable1:Numberofedgesperdatasetbeforeandaftercompression\\nDetectionmechanism Dataset #Edgesbeforecompression #Edgesaftercompression\\nCadets-Unic 5625 5625\\nClrscope-E3 2344070 15240\\nSC-2 917608 715338\\nGraph-level\\nStreamspot 149618 13190\\nWget 148982 99171\\nWget-HL 106738 83134\\nCadets-E3 1648006 840299\\nNode-level Theia-E3 4319197 574964\\nTrace-E3 1178021 811205\\nThecompressionprocessisoutlinedinAlgorithm3.\\n18At the end of the compression process, the compressed snapshots are transformed into Deep Graph Library\\n(DGL)graphsusingthedgl.from networkxmethod,whichpreparesthemforinputintotheGNNmodel.DGLoffers\\nbuilt-in GNN architectures and graph-structured data classes that are essential for implementing machine-learning\\ntasksongraphdata.\\nAlgorithm3:Edgecompressioninsnapshots\\nInput: Snapshot,Nodesdimension,Edgesdimension\\nOutput: Graph\\n1 -Appendthenodesofthesnapshottothenewgraph\\n2 foreachedgeofthesnapshotdo\\n3 -Extracttheattributesoftheedge\\n4 if thesourceanddestinationnodesofthisedgealreadyhaveanedgeinthenewgraphthen\\n5 -Addtheedgetypeofthenewedgetotheexistingone\\n6 else\\n7 -Appendtheedgetothenewgraph\\n8 returnthenewgraph\\n5.3. Modeldeployment\\nEstablishinganefficientmodel-deploymentstrategyiscriticalforoptimizingAPT-detectionperformance. Tradi-\\ntionalapproachesusinglocalmodelsandcentralizeddeployments(Hanetal.,2020;Wangetal.,2022a;Yanetal.,\\n2022;Yeetal.,2023;Chengetal.,2023b;Jiaetal.,2023)areresource-intensiveandmayhinderIntrusionDetection\\nSystems’ adaptability to evolving APT threats. Some efforts, like the Paradise framework (Wu et al., 2022), have\\nexplored distributed deployment using Kafka servers (Thein, 2014). Paradise distributes client data to IDS servers\\nvia load-balancing, which alleviates resource strain on hosts; but is bandwidth-intensive, and exposes client data to\\npotentialprivacyrisks,suchassniffingattacks.\\nFederated Learning offers a more efficient alternative by enabling clients to train models on their benign-data\\nlocallyandshareonlymodel-parameterswiththeserver. Thisapproachreducesnetworkstrainandtheriskofdata\\nleaks,asonlymodel-weightsareexchanged. FLallowstheservertoaggregatetheseparameters,avoidingtheneed\\ntotrainseparatemodelsforeachclient. Similarapproaches,likeXFedGraph-Hunter(Sonetal.,2023),haveapplied\\nFL to Graph Neural Networks for APT detection, reducing false positives and improving model-generalization to\\nunknownattacks.\\nHowever, FL is still vulnerable to data leaks through Reverse Engineering (Shanmugarasa et al., 2023), where\\na Man-in-the-Middle attacker could intercept model weights and reconstruct the original data. To address this, we\\nproposeanFL-baseddeploymentstrategythatincludesencryptingmodel-weightsbeforetransmission. Thisensures\\nsecurecommunicationandclientprivacy,preventingMitMattackswhileoptimizingnetwork-resources.Thisstrategy\\nallowscollaborativelearningofbenignbehaviorsacrossthesystem,addressingthethirdhypothesis.\\n5.3.1. Large-scaledeployment\\nFederated learning within Intrusion Detection Systems enables the creation of models that generalize well to\\nnewdatathroughcollaborativelearningandknowledge-sharing. Thisallowsthegeneratedmodeltoadapttobenign\\nhost-behaviorsobservedduringtrainingandintegratenewly-identifiedAPTattackpatternsfromparticipatinghosts.\\nKnowledgeexchangeoccursthroughthesharingofmodelparametersbetweenthecentralserverandclienthosts.\\nByaggregatingmodel-parametersacrossvariousnetworks,thesystemfacilitatesextensiveknowledge-sharingon\\nAPTattacks.Forexample,organizationswithinthesameindustryorresearchlabsinaregioncancontributetheirlocal\\nserverweightstodevelopamoregeneralizedmodel. Thisprocessinvolvessharingencrypted-modelweightswitha\\ncentral server for aggregation, using homomorphic encryption to ensure the confidentiality of each organization’s\\nmodeldetailsfromtheexternalserver.\\nThismethodpromotesacollaborativecybersecurity-allianceamongorganizations,improvingtheoverallknowl-\\nedge base of the Graph Neural Network model. Leveraging this collaborative approach enhances the precision and\\n19efficiencyofAPTdetection,offeringcriticalsupportinaneraofincreasedtargetingofcompaniesandgovernments\\nbythreatactors.\\n5.3.2. Encryptionmethodology\\nBased on the literature review presented earlier, our IDS must be resilient against both Reverse Engineering\\nandInferenceattackstopreventMan-in-the-Middleattacksaimedatstealingclientdataorinjectingnoisydatainto\\nthe server (Krumm, 2007). Such attacks can introduce biases during the server’s weight aggregation, impairing the\\nmodel’sabilitytodifferentiatebetweenbenignandmaliciousdata,thusincreasingFalsePositiveandFalseNegative\\nrates.\\nTocountertheserisks, theservermustbetreatedasanuntrustedentity, preventingaccesstoclientdata. Thisis\\nachievedthroughHomomorphicEncryption(Yietal.,2014),amethodproveneffectiveinFederatedLearningwithin\\nsensitiveenvironmentslikehospitalmanagementsystems(viensea1106,2023). Similarly,inAPTdetection,clients’\\ndatareflectsmachineanduserbehaviors,makingitvaluabletoattackerswhocanuseitforMimicryAttacks,evading\\nIDS detection (Goyal et al., 2023), or for data poisoning to degrade model quality (Yang et al., 2017). A general\\noverviewofthedeploymentarchitectureisshowninFigure10.\\nServer\\nFedereated averaging\\n4\\n5\\n1 ........\\nn Homomorphic Homomorphic HHoommoommoorrpphhiicc\\nAveraged multiplication Encrypted addition EEnnccrryypptteedd aaddddiittiioonn Encrypted\\nencrypted weights weights n wweeiigghhttss 22 weights 1\\n3 Host n 2 3 Host 1 2\\nHE pair-key HE pair-key\\nWeights encryption generation 5 5 Weights encryption generation\\n........\\n1 1\\nLocal model Local provenance- Local model Local provenance-\\ntraining data gathering training data gathering\\nFigure10:HomomorphicencryptioninContinuum\\nMoretechnically,weoptforimplementingMulti-keyHomomorphicEncryption(Chenetal.,2019),whereeach\\nclientgeneratesaprivate/publickeypair. Theprivatekeyencryptsanddecryptsmodelweights,whiletheserveruses\\npublic keys to compute on encrypted weights without decrypting them, thus protecting data from malicious actors.\\nThisencryption,deployedwithinFL,safeguardsagainstMimicryAttacks,datainterception,andothersecuritythreats,\\nreinforcingtheIDS’sdefensesinAPTdetection.\\nWe integrated Homomorphic Encryption into our federated learning system using FedML-HE (Jin et al., 2023),\\nwhich employs a threshold key management scheme based on Shamir’s secret sharing (Shamir, 1979). In this ap-\\nproach, atrustedkeyauthoritygeneratesasecretkey, whichissplitintosharesdistributedamongtheclients. Each\\nclient uses its key-share to encrypt local model-weights before sending them to the server through an MQTT or MPI\\ncommunication.\\nTheserveraggregatestheencryptedweightsusingaSomewhat-HomomorphicEncryptionsystem1,allowingop-\\nerations on encrypted data without access to the underlying values. The aggregated ciphertext is then sent back to\\n1Somewhathomomorphicisahomomorphicencryption-systemthatsupportsbothadditionandmultiplication,butonlyalimitednumberof\\ntimesduetonoiseaccumulation\\n20theclients,whereeachclientpartiallydecryptstheweightsusingitskey-share. Theclientsexchangetheirpartially-\\ndecryptedweightsandcollaborativelyreconstructthefully-decryptedweightsinplaintext.\\nThemainstepsofthisprocessareoutlinedinAlgorithm4.\\nAlgorithm4:FedML-HEwiththreshold-keymanagement\\nInput: Aggregator(server),Nclients\\nOutput: Plaintextweights\\n// Key Generation\\n1 -KeyAuthoritygeneratesasecretkeyK dividedintoN sharesk 1,k 2,...,k N\\n// Weights Encryption\\n2 foreachclientiofN do\\n3 -Encryptthelocal-parametersW iusingthekey-sharek i\\n4 -SendtheencryptedparametersW itotheserver\\n// Aggregation Phase\\n5 -Theserveraggregatestheencrypted-parametersW 1,W 2,...,W n\\n6 -Theserversendstheaggregatedencrypted-parametersW totheclients\\n// Decryption Phase\\n7 foreachclientiofN do\\n8 -PartiallydecryptWusingk i\\n9\\n-Sendthepartially-decryptedparametersW′totheotherclients\\ni\\n10 -Waittoreceivethedecrypted-parametersfromalltheotherclients\\n11 -Mergethedecrypted-weightsW 1′,W 2′,...,W n′\\n12 returntheplaintextweights\\n6. Performanceevaluation\\nInthissection,wefocusontotheconcreteimplementationoftheCONTINUUMframework. Wedetailthetech-\\nnicalaspectsofthesystem, specificallythedevelopmentofthecomponentswithintheContinuumarchitecture. We\\ncovermainlythedevelopmentoftheGNNmodel,focusingonthetraining,validation,andevaluationstages.\\n6.1. Testenvironment\\nWeimplementedourGNN-basedIDS-Continuum-usingPython,leveragingpopularlibrariesformachinelearn-\\ning,graphmanipulation,andfederatedlearning,includingFedML2 forfederated-learningdeployment,andTenSEAL\\n(Benaissaetal.,2021)forencryption. Theselibrarieswereinstrumentalinsimplifyingthecomplexitiesofbothdata\\nprocessingandmodeldeployment,whileensuringthatthesystemremainedsecureandscalable.\\nFor the model training, we utilized a virtual machine (VM) equipped with NVIDIA Graphics Processing Units\\n(GPUs), and the CUDA3 platform. CUDA, a parallel-computing platform developed by NVIDIA, enabled significant\\nacceleration in the training process by offloading heavy computations to the GPU. This GPU-accelerated training\\nenvironmentwasessentialinhandlingthelarge-scaledatasetsandcomputationally-intensivetasksinvolvedingraph-\\nbasedmachinelearning.CUDA’sefficientparallel-processingdramaticallyreducedthetimerequiredformodeltraining\\ncomparedtotraditionalCentralProcessingUnit(CPU)-basedtrainingparticularlywhenworkingwithcomplex,deep\\nlearningarchitectures.\\nToensurecompatibilityandstabilityacrossdifferentdependencies,weusedPythonversion3.10.14alongwith\\nthelatestversionsofkeylibrariesinMachineLearningandGraphLearning.\\nAll the experiments were conducted on a machine equipped with 16GB of RAM, a 12GB VRAM GPU (RTX\\n3060), and a6-core CPU (i5-12400F). These resources arewell-suited for training on large APTdatasets, although\\nlighterresourceswouldsufficeforsmallerdatasets.\\n2https://www.fedml.ai/\\n3https://developer.nvidia.com/cuda-toolkit\\n216.2. Datasets\\nVarious provenance-based datasets for APT attacks detection have been introduced in the literature, with some\\nserving as benchmarks and others remaining relatively-unexplored. In this work, we select datasets from both cat-\\negories to train and evaluate our solution. This approach allows us to compare our results with state-of-the-art IDS\\nbenchmarkswhilealsopromotingnewdatasetsforfutureresearchinthefield.\\nThe datasets chosen for our evaluation include Wget (Han, 2018a), Wget-HourLong (Han, 2018b), SC-2 (Han\\net al., 2020), Streamspot (Manzoor et al., 2016), and the E3-Darpa datasets, which consist of Cadets, Clearscope,\\nTrace,andTheia(Torrey,2020). Thesedatasetsexhibitdifferentcharacteristicsintermsofsize,thenumberofnodes,\\nedges,andgraphstheycontain,assummarizedinTable2. Thiscomparisonhighlightsthevariationincomplexityand\\ndiversityacrossthedatasets.\\nTable2:Datasetsdescription\\nGranularity Dataset Scenario Avg. #Graphs Avg. #Nodes Avg. #Edges\\nBenign 125 37,296 148,982\\nWget\\nAttack 25 39,215 152,879\\nBenign 100 28,664 107,589\\nWget-HourLong\\nAttack 5 29,384 104,438\\nBenign 44 2,307 2,097,957\\nClearscopeE3\\nAttack 50 11,972 2,560,650\\nBenign 110 2,704 3,017\\nCadets-Unicorn\\nAttack 3 56,303 100,474\\nGraph-level\\nBenign 125 238,338 911,153\\nSC-2\\nAttack 25 243,658 949,887\\nCNN 100 8,989 294,903\\nStreamspot\\nDownload 100 8,830 310,814\\nGmail 100 6,826 37,382\\nVGame 100 8,636 112,958\\nYoutube 100 8,292 113,229\\nAttack 100 8,890 28,423\\nBenign - 1,598,647\\nTheiaE3 2,874,821\\nAttack - 25,319\\nBenign - 1,614,189\\nCadetsE3 3,303,264\\nAttack - 12,846\\nNode-level\\nBenign - 3,220,594\\nTraceE3\\nExt. Backdoor - 732\\n4,080,457\\nPineBackdoor - 67,345\\nPhishingExe. - 5\\nDespitetheirdifferences,thedatasetssharecommontypesandattributesrelatedtothenodesandedges,providing\\ninsightsintothecommunicationpatternsanddatatransfersamongsystementities.Asummaryofthesecommonalities\\nispresentedinTable3,offeringaclearerunderstandingofthesimilaritiesanddifferencesindatasetstructures.\\n6.3. Modelconstruction\\nOuroverallsolutionisbuiltaroundaSpatial-TemporalGraphAuto-encoder,asoutlinedinthesystemdesign(Re-\\nfertoSection5.1.1). ThissectiondetailsthekeychoicesmadefortheGNNandRNNlayerswithinourarchitecture,\\nexplaininghowthesecomponentscontributetothedetectionofAdvancedPersistentThreatsthroughbothspatialand\\ntemporaldata-modeling.\\nIn order to find the best combination of layers, we explored multiple spatial-convolutional GNNs, including\\nGATConv, GCNConv, GINConv, and SageConv from the dgl.nn library in Python, alongside various RNN layers\\n22Table3:CommoninformationamongAPTdatasets\\nSubject CommonTypes CommonAttributes\\nNodes File,Process,Socket,Task Path,PID,TTY,TIME CPU,NodeType\\nEdges Read,Write,Execute,Send,Receive,Open,Close,Clone Src/DstNode,EdgeType,Timestamp\\nsuchasGRUCell,RNNCell,andLSTMCellfromtorch.nn.Thek-NNlayerwasimplementedusingthekneighbors\\nmethodfromsklearn.neighbors.NearestNeighbors.\\nAfterextensivehyperparametertuningandempiricalevaluation,weidentifiedGraphAttentionNetworks(Velicˇkovic´\\net al., 2017) as the optimal choice for capturing spatial-dependencies, and Gated Recurrent Units for temporal-\\nsequence modeling. However, instead of the standard GAT implementation from dgl.nn, we adopted the GAT\\nlayerfromMagic(Jiaetal.,2023),whichintegratesedgefeaturesintotheattentionmechanism. Unliketheadditive\\nattentioninthedgl.nn.GATConvclass,wheretheattentionweightαiscomputedas:\\nα= Droupout(Softmax(LeakyReLU(Linear(feat |feat )))) (12)\\nsrc dst\\nMagicincorporatesedgefeatures,enhancingtheexpressivenessofthemodelbyadjustingtheattentionweightαas:\\n(cid:16) (cid:16) (cid:16) (cid:16) (cid:17)(cid:17)(cid:17)(cid:17)\\nα= Droupout Softmax LeakyReLU Linear feat |feat |feat (13)\\nsrc edge dst\\nThisarchitecturalchoiceimprovesthemodel’sabilitytocapturebothnodeandedge-levelinteractions,provingcritical\\nfordetectingcomplexpatternsinthecontextofAPTattacks.\\nTrainingphase: The training of our model is conducted using a supervised-learning approach, employing either\\ngraph-level or entity-level methods. In both cases, a batch-based strategy is adopted, where the model iterates over\\nmultipleepochs,processingsnapshotsofasinglebenign-graphatatime.\\nEachbatchconsistsoftheentirebenign-graph,allowingthelossfunctiontoaccountforthereconstructionfeatures\\nof all nodes simultaneously. The training begins by activating the training mode via model.train() and resetting\\ngradientsusingoptimizer.zero grad(). Foreachbenigngraph, wecomputethelossbycomparingtheoriginal\\nnode features with the reconstructed features, leveraging symmetric binary cross-entropy (Wang et al., 2019) for\\naccuracy. TheimplementationprovidedbyJiaetal.(2023)isemployedforthislossfunction.\\nModel weight-updates are done through back-propagation using loss.backward() and optimizer.step().\\nWeutilizedtheAdamoptimizer(torch.optim.Adam)forefficientgradient-basedoptimization, andemployedthe\\nPreLuactivationfunctionintheGNNlayers. Themodelwastrainedfor50epochsinthecaseofentity-leveltraining\\nand6epochsforgraph-leveltraining,reflectingoptimalsettingsderivedfromourexperimentalanalysis.\\nValidationphase: Thevalidationprocessplaysakeyroleintuninghyper-parametersduringtraining. Inthegraph-\\nlevelapproach,graphembeddingsarederivedfromnodeembeddingsgeneratedbytheencoder,usingthetorch.mean()\\nfunction to aggregate them. For the entity-level approach, we directly utilize the node embeddings without further\\naggregation.\\nToevaluatethemodel’sperformance,weclusterthetrainingembeddingsbyemployingthesklearn.neighbors.\\nNearestNeighbors method, and compute the mean distance between each benign point and its neighbors using\\nkneighbors(). Thisestablishesabaselineforcomparisonduringvalidation.\\nForthevalidationset,embeddingsaregeneratedusingtheSTGNNencoder,whicharethenfedintothepre-trained\\nk-NNmodel. Wecalculatethemeandistancesbetweeneachvalidationpointanditsneighborsinthesamemanneras\\nforthetrainingset.\\nThe validation score is computed by dividing the mean distance of validation points by that of the training\\npoints. Performance is evaluated through precision-recall and Receiver Operating Characteristic (ROC)-Area Un-\\ndertheCurve(AUC)metrics,calculatedrespectivelyusingthesklearn.metrics.precision recall curveand\\nthe sklearn.metrics.roc auc score methods. The optimal threshold for classifying test points as benign or\\nmaliciousisdeterminedbasedonthesemetrics.\\n23Evaluationphase: Similar to the validation phase, the evaluation begins by generating clusters of benign data-\\npoints. Theclassificationoftestdata-pointsisbasedontheirproximitytothenearestneighborswithinthesebenign\\nclusters. Specifically, a test point is classified as malicious or benign by measuring its distance from its nearest\\nbenign-neighbors,followingthesamemethodologyappliedduringvalidation.\\nIntegrationofFederatedLearning: We implemented Federated Learning in our GNN model using FedGraphNN\\nbenchmark (He et al., 2021) from FedML to avoid building the FL system from scratch. FedML provides built-in\\nfunctionality to configure a federated server and its clients, handling communication via, eitherMessage Queuing\\nTelemetry Transport (MQTT) for real-world scenarios, or Message Passing Interface (MPI) for simula-\\ntions.\\n6.4. Metrics\\nToaccuratelyevaluatetheperformanceofourmodel,weemployedfourkeymetrics: Precision,Recall,F1-Score,\\nand AUC. These metrics offer insights into different aspects of the model’s classification performance, especially\\nwhendealingwithimbalanceddatasets, whichistypicalinAPTdetection. Themetricsarecalculatedbasedonthe\\nfollowingclassificationoutcomes:\\nTruePositives(TP):Malicioussamples(APTattacks)correctlyidentified.\\nTrueNegatives(TN):Benignsamplescorrectlyidentified.\\nFalsePositives(FP):Benignsamplesincorrectlyclassifiedasmalicious.\\nFalseNegatives(FN):Malicioussamplesincorrectlyclassifiedasbenign.\\nOurfocuswasprimarilyonoptimizingPrecisionandF1-Scoreduringhyper-parametertuning,asourgoalwasto\\nminimizefalsenegativestocatchundetectedattacksandreducefalsepositivestolimitfalsealarms.\\nPrecision:Theratioofcorrectly-predictedpositiveobservationstothetotalpredicted-positives.Highprecision\\nindicatesalowfalse-positive-rate(FPR),makingitcrucialforminimizingfalsealarms.\\nTP\\nPrecision= (14)\\nTP+FP\\nRecall: The ratio of correctly-predicted positive observations to all actual positive-observations. High recall\\nensuresthatthemodelcapturesmost-relevantresults,thoughitmayincreasefalsepositives.\\nTP\\nRecall= (15)\\nTP+FN\\nAUC:UsedtomeasurethequalityofthemodelbyevaluatingtheareaundertheROCcurve, whichplotsthe\\ntrue-positiverate(TPR)againsttheFPRacrossdifferentthresholdvalues. AhigherAUCscoreindicatesbetter\\nperformanceindistinguishingbetweenclasses.\\n(cid:88)\\n(cid:0) (cid:1)\\nAUC ≈ widthofFPRinterval∗averageheightofTPR (16)\\nF1-Score:Theharmonicmeanofprecisionandrecall,providingabalancedmeasurethataccountsforbothFPs\\nandFNs. AhigherF1-Scoresignifiesabettertrade-offbetweenprecisionandrecall.\\nPrecision∗Recall\\nF1−Score=2∗ (17)\\nPrecision+Recall\\nThesemetricsprovideacomprehensiveevaluationofourmodel,helpingusgaugeitsabilitytodetectAPTattacks\\nwhileminimizingmisclassifications.\\n24Table4:Bestperformancesofoursolutionondifferentdatasets\\nDetection Dataset Solution Precision Recall F1-Score AUC\\nWithoutFL 1.0 1.0 1.0 1.0\\nCadets-Unicorn\\nWithFL 1.0 1.0 1.0 1.0\\nWithoutFL 1.0 1.0 1.0 1.0\\nClearscope-E3\\nWithFL 1.0 1.0 1.0 1.0\\nWithoutFL 0.85 0.92 0.88 0.92\\nSC-2\\nWithFL 0.77 0.96 0.86 0.88\\nGraph-level\\nWithoutFL 1.0 1.0 1.0 1.0\\nStreamspot\\nWithFL 1.0 1.0 1.0 1.0\\nWithoutFL 1.0 1.0 1.0 1.0\\nWget\\nWithFL 1.0 0.96 0.98 0.97\\nWithoutFL 0.83 1.0 0.91 0.99\\nWget-HourLong\\nWithFL 0.83 1.0 0.91 0.99\\nWithoutFL 0.97 0.99 0.98 0.99\\nCadets-E3\\nWithFL 0.95 0.99 0.97 0.99\\nWithoutFL 0.98 0.99 0.99 0.99\\nNode-level Theia-E3\\nWithFL 0.97 0.99 0.99 0.99\\nWithoutFL 0.99 0.99 0.99 0.99\\nTrace-E3\\nWithFL 0.99 0.99 0.99 0.99\\n6.5. Resultsandcomparison\\nWe begin by showcasing the results obtained from our Graph Neural Network (GNN)-based model across all\\ndatasets, considering two distinct configurations: without Federated Learning and with Federated Learning. These\\nresultsaresummarizedinTable4.\\nWe see that our model scores high-performance across different datasets, but applying FL reduces the precision\\ninsomecases,asinoursimulationstrategywearesplittingthesamedatasetovermultipleclients,whichreducesits\\nquality.\\nWealsocomparetheaverageexecutiontimeofoursolutionbeforeandafterapplyingFLacrosstwoenvironments:\\nCPU-basedandGPU-based. TheresultsaredetailedinTable5.\\nTable5:Comparisonofexecutiontimeperexecutionenvironment\\nExecutiontimewithoutFL ExecutiontimewithFL\\nDataset OnCPU(s) OnGPU(s) OnCPU(s) OnGPU(s)\\nCadets-E3 1510.2 151.2 322 67\\nCadets-Unic 25 12 9 8\\nClearscope-E3 14 6 5 3\\nSC-2 4489.2 445.8 427 218\\nStreamspot 865.8 210 278 93\\nTheia-E3 852 55 285 24\\nTrace-E3 3028.8 307.2 465 93\\nWget 369 34 67 14\\nWget-HourLong 129 60 62 24\\nFromthedata,itisevidentthatrunningthesolutiononaGPUsignificantlyacceleratestheexecutiontime,achiev-\\ninguptoa10-foldspeedincreasecomparedtoexecutiononaCPU.Thishighlightsthecrucialroleofparallelization\\n25inenhancingtheperformanceoftheworkingenvironment. Moreover,theintegrationofFederatedLearningfurther\\noptimizesexecutiontime. EvenwhenusingaCPU,FLreducestheexecutiontimebyfivetotentimescomparedto\\nthemodelwithoutFL,bringingtheperformanceclosetothatofGPU-basedexecution. Althoughaslightreduction\\nin precision was observed in certain datasets, such as SC-2 (Han et al., 2020) and Cadets-E3 (Torrey, 2020), after\\napplyingFL,thetrade-offresultedinasubstantialreductioninexecutiontime. Forexample,theaveragetrainingand\\ndetectiontimedecreasedfrom1254.78seconds(≈21minutes)to213seconds(≈4minutes),representinganatleast\\n5-foldimprovementinefficiency.\\nWe compare the performance of our solution—both with and without FL—against state-of-the-art GNN-based\\nIDS in detecting Advanced Persistent Threats. The comparisons for Graph-level datasets are presented in Table 6,\\nwhilethoseforNode-leveldatasetsareshowninTable7.\\nTable6:Comparisonwithstate-of-the-artonGraph-leveldatasets\\nDataset IDS Precision Recall F1-Score AUC FP%\\nKairos 0.714 1.0 0.83 0.991 1.68\\nClearscope-E3 Ours 1.0 1.0 1.0 1.0 0\\nOurs-FL 1.0 1.0 1.0 1.0 0\\nThreatrace 0.923 0.960 0.941 - 4\\nSC-2 Ours 0.85 0.92 0.88 0.92 8\\nOurs-FL 0.77 0.96 0.86 0.88 14\\nGCA 1.0 0.925 0.961 - 0\\nMagic 1.0 1.0 1.0 1.0 0\\nKairos 1.0 1.0 1.0 1.0 0\\nStreamspot\\nThreatrace 1.0 1.0 1.0 1.0 0\\nOurs 1.0 1.0 1.0 1.0 0\\nOurs-FL 1.0 1.0 1.0 1.0 0\\nMagic 0.96 0.96 0.96 0.962 2\\nThreatrace 0.926 1.0 0.98 - 4\\nWget\\nOurs 1.0 1.0 1.0 1.0 0\\nOurs-FL 1.0 0.96 0.98 0.97 0\\nOur solution demonstrates superior performance in Graph-level detection across almost all datasets compared\\nto state-of-the-art IDS. Notably, our model achieved perfect detection of APT attacks in the Wget (Han, 2018a),\\nStreamspot (Manzoor et al., 2016), and Clearscope-E3 (Torrey, 2020) datasets. However, a slight reduction in per-\\nformancewasobservedfortheSC-2dataset(Hanetal.,2020),primarilyduetothelackofadequatedocumentation,\\nwhichcomplicatedthepre-processingphase.\\nIn Node-level detection, our model performed best on the Theia and Trace datasets from DARPA E3 (Torrey,\\n2020),underscoringitsefficiencyindetectingAPTattackswithinNode-levelbenchmarks. However,fortheCadets-\\nE3dataset(Torrey,2020),aslightdegradationinperformancewasobservedwhenusingFederatedLearning. While\\nthenon-FLversionofourmodeloutperformedstate-of-the-artsystems,thedivisionofdataacrossFLclientsresulted\\ninlowerprecision. Inreal-worldapplications,whereclientstrainontheirowndatasets,thisissuewouldbemitigated.\\nOverall, the evaluation of Continuum showcased its superior performance in detecting APT attacks, optimizing\\nresources, and surpassing the capabilities of existing models. This demonstrates the potential of our solution in\\nsignificantlyenhancingIntrusionDetectionSystems. Furthertestsandparametertuningcanbeperformedusingour\\nsolution,whichisavailableonGitHub4.\\n4https://github.com/kamelferrahi/Continuum_FL\\n26Table7:Comparisonwithstate-of-the-artonNode-leveldatasets\\nDataset IDS Precision Recall F1-Score AUC FP%\\nGHunter 0.96 0.95 0.95 - -\\nMagic 0.94 0.99 0.97 0.99 0.22\\nThreatrace 0.90 0.99 0.95 - 0.2\\nCadets-E3\\nXFedGraph 0.93 1.0 0.96 - -\\nOurs 0.97 0.99 0.98 0.99 0.1\\nOurs-FL 0.95 0.99 0.97 0.99 0.18\\nGHunter 0.98 0.97 0.97 - -\\nMagic 0.98 0.99 0.99 0.99 0.14\\nTheia-E3\\nThreatrace 0.87 0.99 0.93 - 0.1\\nOurs 0.98 0.99 0.99 0.99 0.14\\nOurs-FL 0.97 0.99 0.99 0.99 0.17\\nMagic 0.991 0.998 0.996 0.999 0.09\\nTrace-E3 Threatrace 0.72 0.99 0.83 - 1.1\\nOurs 0.998 0.999 0.999 0.999 0.01\\nOurs-FL 0.998 0.999 0.999 0.999 0.01\\n7. Conclusion\\nAkeycontributionofthisworkisthedevelopmentoftheSpatial-TemporalGNNautoencoderthatleveragesboth\\nspatialandtemporaldata-modeling.Thisenablesthemodeltoextractdeepcorrelationswithintheprovenancegraphs,\\nprovidingacomprehensiveunderstandingofsystembehavior. Additionally,weimplementedtheIDSinafederated-\\nlearningenvironmentwithhomomorphicencryption,ensuringdataprivacyandsecurityduringcollaborativetraining\\nacross multiple devices and networks. This approach protects the model’s weights from potential interception and\\nreverse-engineeringattacks.\\nOur experimental results demonstrate the effectiveness of the proposed IDS in accurately detecting APTs while\\nreducing false-positives and resource consumption. By addressing privacy, security, and scalability challenges, our\\nsystemoffersarobustsolutionforAPTdetectionacrossdifferentnetworksandenvironments.Thisresearchshowcases\\nthe potential of GNNs and federated learning in enhancing IDS capabilities and improving the security of modern\\ncomputing-environments.\\nThis work also paves the way for several future directions: First, reducing the computational and storage over-\\nheadsassociatedwithgeneratingdynamic-snapshotsandprocessinglargeprovenance-graphsespeciallyinreal-time\\nor large-scale deployment scenarios is an interesting issue. Second, the centralized nature of our FL deployment\\nexposes it to risks such as Single-Point-Of-Failure (SPOF) (Kirvan, 2021). These vulnerabilities suggest the need\\nformoreadvanced,decentralizedFLapproachesthatcanmitigatetheserisksbydistributingtheaggregationprocess\\nacrossmultiplenodes,insteadofrelyingonasingleserver. Lastly,itisalsoofoutmostimportancetoworkondataset\\navailability and quality. In fact, current datasets for APT detection are often outdated, insufficiently documented,\\nand represent only a few stages of APT attacks. Moreover, these datasets are not always formatted as graphs and\\nsnapshots, necessitating extensive pre-processing and conversion before they can be used for GNN-based Intrusion\\nDetectionSystems.\\nAcknowledgment\\nThisworkissupportedbytheFrenchNationalResearchAgency(ANR)undergrantANR-20-CE39-0008andby\\nBourg-en-Bressecity.\\n27References\\nAcar,U.A.,Buneman,P.,Cheney,J.,VandenBussche,J.,Kwasnikowska,N.,Vansummeren,S.,2010. Agraphmodelofdataandworkflow\\nprovenance.,in:TaPP.\\nADNAN,M.,Bshara,D.,Awad,A.,2023. Forensicanalysisofaptattacksbasedonunsupervisedmachinelearning. EuropeanJournalofScience\\nandTechnologydoi:10.31590/ejosat.1265586.\\nAlsaheel,A.,Nan,Y.,Ma,S.,Yu,L.,Walkup,G.,Celik,Z.B.,Zhang,X.,Xu,D.,2021.{ATLAS}:Asequence-basedlearningapproachforattack\\ninvestigation,in:30thUSENIXsecuritysymposium(USENIXsecurity21),pp.3005–3022.\\nAlshamrani,A.,Myneni,S.,Chowdhary,A.,Huang,D.,2019. Asurveyonadvancedpersistentthreats: Techniques,solutions,challenges,and\\nresearchopportunities.IEEECommunicationsSurveys&Tutorials21,1851–1877.\\nAltaf,T.,Wang,X.,Ni,W.,Yu,G.,Liu,R.P.,Braun,R.,2024. Gnn-basednetworktrafficanalysisforthedetectionofsequentialattacksiniot.\\nElectronics13,2274.\\nBaughman,M.,Foster,I.,Chard,K.,2022. Exploringtradeoffsinfederatedlearningonserverlesscomputingarchitectures. 2022IEEE18th\\nInternationalConferenceone-Science(e-Science),433–434doi:10.1109/eScience55777.2022.00074.\\nBebis,G.,Georgiopoulos,M.,1994.Feed-forwardneuralnetworks.IeeePotentials13,27–31.\\nBenaissa,A.,Retiat,B.,Cebere,B.,Belfedhal,A.E.,2021. Tenseal: Alibraryforencryptedtensoroperationsusinghomomorphicencryption.\\nArXivabs/2104.03152.URL:https://api.semanticscholar.org/CorpusID:233169040.\\nBernstein,M.N.,2023. Graphconvolutionalneuralnetworks—mbernste.github.io. https://mbernste.github.io/posts/gcn/. [Accessed\\n06-04-2024].\\nBianchi, F., Livi, L., ØyvindMikalsen, K., Kampffmeyer, M.C., Jenssen, R., 2019. Learningrepresentationsofmultivariatetimeserieswith\\nmissingdata.PatternRecognit.96.doi:10.1016/J.PATCOG.2019.106973.\\nBilot,T.,ElMadhoun,N.,AlAgha,K.,Zouaoui,A.,2023.Graphneuralnetworksforintrusiondetection:Asurvey.IEEEAccess.\\nBojchevski,A.,Shchur,O.,Zu¨gner,D.,Gu¨nnemann,S.,2018. Netgan: Generatinggraphsviarandomwalks,in: Internationalconferenceon\\nmachinelearning,PMLR.pp.610–619.\\nChang,L.,Branco,P.,2021.Graph-basedsolutionswithresidualsforintrusiondetection:Themodifiede-graphsageande-resgatalgorithms.arXiv\\npreprintarXiv:2111.13597.\\nChen,H.,Chillotti,I.,Song,Y.,2019.Multi-keyhomomorphicencryptionfromtfhe,in:AdvancesinCryptology–ASIACRYPT2019:25thInter-\\nnationalConferenceontheTheoryandApplicationofCryptologyandInformationSecurity,Kobe,Japan,December8–12,2019,Proceedings,\\nPartII25,Springer.pp.446–472.\\nChen, S., Wang, S., Liu, Y., Ma, D., 2023. Thest-grnncooperativetrainingmodelbasedoncomplexnetworkforairqualityprediction, in:\\nComputerGraphicsInternationalConference,Springer.pp.449–461.\\nCheng, Q., Wu, C., Zhou, S., 2021. Discovering attack scenarios via intrusion alert correlation using graph convolutional networks. IEEE\\nCommunicationsLetters25,1564–1567.\\nCheng,Z.,Dai,R.,Wang,L.,Yu,Z.,Lv,Q.,Wang,Y.,Sun,D.,2023a. Ghunter: Afastsubgraphmatchingmethodforthreathunting,in: 2023\\n26thInternationalConferenceonComputerSupportedCooperativeWorkinDesign(CSCWD),IEEE.pp.1014–1019.\\nCheng, Z., Lv, Q., Liang, J., Wang, Y., Sun, D., Pasquier, T., Han, X., 2023b. Kairos:: Practicalintrusiondetectionandinvestigationusing\\nwhole-systemprovenance.arXivpreprintarXiv:2308.05034.\\nCho,K.,VanMerrie¨nboer,B.,Gulcehre,C.,Bahdanau,D.,Bougares,F.,Schwenk,H.,Bengio,Y.,2014. Learningphraserepresentationsusing\\nrnnencoder-decoderforstatisticalmachinetranslation.arXivpreprintarXiv:1406.1078.\\nDai,H.,Kozareva,Z.,Dai,B.,Smola,A.,Song,L.,2018. Learningsteady-statesofiterativealgorithmsovergraphs,in:Internationalconference\\nonmachinelearning,PMLR.pp.1106–1114.\\nDefferrard,M.,Bresson,X.,Vandergheynst,P.,2016. Convolutionalneuralnetworksongraphswithfastlocalizedspectralfiltering. Advancesin\\nneuralinformationprocessingsystems29.\\nDoan,T.V.T.,Messai,M.L.,Gavin,G.,Darmont,J.,2023. Asurveyonimplementationsofhomomorphicencryptionschemes. TheJournalof\\nSupercomputing79,15098–15139.\\nDworkin,M.J.,Barker,E.B.,Nechvatal,J.R.,Foti,J.,Bassham,L.E.,Roback,E.,DrayJr,J.F.,2001.Advancedencryptionstandard(aes).\\nGallicchio,C.,Micheli,A.,2010. Graphechostatenetworks,in:The2010internationaljointconferenceonneuralnetworks(IJCNN),IEEE.pp.\\n1–8.\\nGhafir,I.,Kyriakopoulos,K.,Lambotharan,S.,Aparicio-Navarro,F.J.,AsSadhan,B.,Binsalleeh,H.,Diab,D.M.,2019. Hiddenmarkovmodels\\nandalertcorrelationsforthepredictionofadvancedpersistentthreats.IEEEAccess7,99508–99520.doi:10.1109/ACCESS.2019.2930200.\\nGilmer,J.,Schoenholz,S.S.,Riley,P.F.,Vinyals,O.,Dahl,G.E.,2017.Neuralmessagepassingforquantumchemistry,in:Internationalconference\\nonmachinelearning,PMLR.pp.1263–1272.\\nGoyal,A.,Han,X.,Wang,G.,Bates,A.,2023. Sometimes,youaren’twhatyoudo: Mimicryattacksagainstprovenancegraphhostintrusion\\ndetectionsystems,in:30thNetworkandDistributedSystemSecuritySymposium.\\nHajiramezanali,E.,Hasanzadeh,A.,Narayanan,K.,Duffield,N.,Zhou,M.,Qian,X.,2019.Variationalgraphrecurrentneuralnetworks.Advances\\ninneuralinformationprocessingsystems32.\\nHamilton,W.,Ying,Z.,Leskovec,J.,2017.Inductiverepresentationlearningonlargegraphs.Advancesinneuralinformationprocessingsystems\\n30.\\nHan,X.,2018a.WgetDataset.URL:https://doi.org/10.7910/DVN/IA8UOS,doi:10.7910/DVN/IA8UOS.\\nHan,X.,2018b.WgetHour-LongDataset.URL:https://doi.org/10.7910/DVN/8GKEON,doi:10.7910/DVN/8GKEON.\\nHan,X.,2020a.Wget-TrojanAPTAttackDataset.URL:https://doi.org/10.7910/DVN/69SMQB,doi:10.7910/DVN/69SMQB.\\nHan,X.,2020b.Wget-TrojanAPTNormalDataset.URL:https://doi.org/10.7910/DVN/KUNDIU,doi:10.7910/DVN/KUNDIU.\\nHan,X.,Pasquier,T.,Bates,A.,Mickens,J.,Seltzer,M.,2020.Unicorn:Runtimeprovenance-baseddetectorforadvancedpersistentthreats.arXiv\\npreprintarXiv:2001.01525.\\n28Hassan,W.U.,Bates,A.,Marino,D.,2020.Tacticalprovenanceanalysisforendpointdetectionandresponsesystems.2020IEEESymposiumon\\nSecurityandPrivacy(SP),1172–1189URL:https://api.semanticscholar.org/CorpusID:216263050.\\nHe,C.,Balasubramanian,K.,Ceyani,E.,Yang,C.,Xie,H.,Sun,L.,He,L.,Yang,L.,Yu,P.S.,Rong,Y.,etal.,2021. Fedgraphnn: Afederated\\nlearningsystemandbenchmarkforgraphneuralnetworks.arXivpreprintarXiv:2104.07145.\\nHochreiter,S.,1997.Longshort-termmemory.NeuralComputationMIT-Press.\\nJedh,M.,Othmane,L.B.,Ahmed,N.,Bhargava,B.,2021.Detectionofmessageinjectionattacksontothecanbususingsimilaritiesofsuccessive\\nmessages-sequencegraphs.IEEETransactionsonInformationForensicsandSecurity16,4133–4146.\\nJia,Z.,Xiong,Y.,Nan,Y.,Zhang,Y.,Zhao,J.,Wen,M.,2023. Magic: Detectingadvancedpersistentthreatsviamaskedgraphrepresentation\\nlearning.arXivpreprintarXiv:2310.09831.\\nJin,W.,Yao,Y.,Han,S.,Joe-Wong,C.,Ravi,S.,Avestimehr,S.,He,C.,2023. Fedml-he: Anefficienthomomorphic-encryption-basedprivacy-\\npreservingfederatedlearningsystem.arXivpreprintarXiv:2303.10837.\\nKazemi,S.M.,Goel,R.,Jain,K.,Kobyzev,I.,Sethi,A.,Forsyth,P.,Poupart,P.,2020. Representationlearningfordynamicgraphs: Asurvey.\\nJournalofMachineLearningResearch21,1–73.\\nKing,I.J.,Huang,H.H.,2023. Euler: Detectingnetworklateralmovementviascalabletemporallinkprediction. ACMTransactionsonPrivacy\\nandSecurity26,1–36.\\nKipf, T., 2016. How powerful are Graph Convolutional Networks? — tkipf.github.io. https://tkipf.github.io/\\ngraph-convolutional-networks/.[Accessed06-04-2024].\\nKipf,T.N.,Welling,M.,2016a.Semi-supervisedclassificationwithgraphconvolutionalnetworks.arXivpreprintarXiv:1609.02907.\\nKipf,T.N.,Welling,M.,2016b.Variationalgraphauto-encoders.arXivpreprintarXiv:1611.07308.\\nKirvan, P., 2021. Whatisasinglepointoffailure(spof)andhowtoavoidthem? https://www.techtarget.com/searchdatacenter/\\ndefinition/Single-point-of-failure-SPOF.\\nKrumm, J., 2007. Inferenceattacksonlocationtracks, in: PervasiveComputing: 5thInternationalConference, PERVASIVE2007, Toronto,\\nCanada,May13-16,2007.Proceedings5,Springer.pp.127–143.\\nLeman,A.,Weisfeiler,B.,1968.Areductionofagraphtoacanonicalformandanalgebraarisingduringthisreduction.Nauchno-Technicheskaya\\nInformatsiya2,12–16.\\nLevie,R.,Monti,F.,Bresson,X.,Bronstein,M.M.,2018. Cayleynets:Graphconvolutionalneuralnetworkswithcomplexrationalspectralfilters.\\nIEEETransactionsonSignalProcessing67,97–109.\\nLi,G.,Zhao,Y.,Wei,W.,Liu,Y.,2023a.Few-shotmulti-domainknowledgerearmingforcontext-awaredefenceagainstadvancedpersistentthreats.\\n2023InternationalConferenceonSmartApplications,CommunicationsandNetworking(SmartNets),1–8doi:10.1109/SmartNets58706.\\n2023.10216058.\\nLi,J.,Pan,W.,Huang,H.,Pan,J.,Wang,F.,2023b. Stgate: Spatial-temporalgraphattentionnetworkwithatransformerencoderforeeg-based\\nemotionrecognition.FrontiersinHumanNeuroscience17,1169949.\\nLi,R.,Wang,S.,Zhu,F.,Huang,J.,2018. Adaptivegraphconvolutionalneuralnetworks,in: ProceedingsoftheAAAIconferenceonartificial\\nintelligence.\\nLi,Y.,Tarlow,D.,Brockschmidt,M.,Zemel,R.,2015.Gatedgraphsequenceneuralnetworks.arXivpreprintarXiv:1511.05493.\\nLiu,H.,Jiang,R.,2023.Acausalgraph-basedapproachforaptpredictiveanalytics.Electronics12,1849.\\nLiu,Z.,Zhou,J.,2022.Introductiontographneuralnetworks.SpringerNature.\\nLo,W.W.,Layeghy,S.,Sarhan,M.,Gallagher,M.,Portmann,M.,2022. E-graphsage: Agraphneuralnetworkbasedintrusiondetectionsystem\\nforiot,in:NOMS2022-2022IEEE/IFIPNetworkOperationsandManagementSymposium,IEEE.pp.1–9.\\nLu,J.,Chen,K.,Zhuo,Z.,Zhang,X.,2019. Atemporalcorrelationandtrafficanalysisapproachforaptattacksdetection. ClusterComputing22,\\n7347–7358.doi:10.1007/s10586-017-1256-y.\\nLv,Y.,Qin,S.,Zhu,Z.,Yu,Z.,Li,S.,Han,W.,2022. Areviewofprovenancegraphbasedaptattackdetection:applicationsanddevelopments.\\n20227thIEEEInternationalConferenceonDataScienceinCyberspace(DSC),498–505doi:10.1109/dsc55868.2022.00075.\\nMansourBahar,A.A.,Ferrahi,K.S.,Messai,M.L.,Seba,H.,Amrouche,K.,2024. Fedhe-graph: Federatedlearningwithhybridencryptionon\\ngraphneuralnetworksforadvancedpersistentthreatdetection,in:Proceedingsofthe19thInternationalConferenceonAvailability,Reliability\\nandSecurity,pp.1–10.\\nManzoor,E.,Milajerdi,S.M.,Akoglu,L.,2016. Fastmemory-efficientanomalydetectioninstreamingheterogeneousgraphs,in:Proceedingsof\\nthe22ndACMSIGKDDinternationalconferenceonknowledgediscoveryanddatamining,pp.1035–1044.\\nMason,J.C.,Handscomb,D.C.,2002.Chebyshevpolynomials.ChapmanandHall/CRC.\\nMessai, M.L., Seba, H., 2023. Iot network attack detection: Leveraging graph learning for enhanced security, in: Proceedings of the 18th\\nInternationalConferenceonAvailability,ReliabilityandSecurity,pp.1–7.\\nPaudel,R.,Eberle,W.,2020. Snapsketch:Graphrepresentationapproachforintrusiondetectioninastreaminggraph,in:Proceedingsofthe16th\\nInternationalWorkshoponMiningandLearningwithGraphs(MLG).\\nPawar,K.,Attar,V.,2019. Assessmentofautoencoderarchitecturesfordatarepresentation. DeepLearning:ConceptsandArchitecturesdoi:10.\\n1007/978-3-030-31756-0_4.\\nPeterson,L.E.,2009.K-nearestneighbor.Scholarpedia4,1883.\\nPopescu,M.C.,Balas,V.E.,Perescu-Popescu,L.,Mastorakis,N.,2009. Multilayerperceptronandneuralnetworks. WSEASTransactionson\\nCircuitsandSystems8,579–588.\\nProtogerou,A.,Papadopoulos,S.,Drosou,A.,Tzovaras,D.,Refanidis,I.,2021.Agraphneuralnetworkmethodfordistributedanomalydetection\\niniot.EvolvingSystems12,19–36.\\nPujol-Perich, D., Sua´rez-Varela, J., Cabellos-Aparicio, A., Barlet-Ros, P., 2022. Unveiling the potential of graph neural networks for robust\\nintrusiondetection.ACMSIGMETRICSPerformanceEvaluationReview49,111–117.\\nQuintero-Bonilla,S.,Mart´ındelRey,A.,2020.Anewproposalontheadvancedpersistentthreat:Asurvey.AppliedSciences10,3874.\\nRivest,R.L.,Shamir,A.,Adleman,L.,1978. Amethodforobtainingdigitalsignaturesandpublic-keycryptosystems. Communicationsofthe\\nACM21,120–126.\\n29Rossi,E.,Chamberlain,B.,Frasca,F.,Eynard,D.,Monti,F.,Bronstein,M.,2020.Temporalgraphnetworksfordeeplearningondynamicgraphs.\\narXivpreprintarXiv:2006.10637.\\nRumelhart,D.E.,Hinton,G.E.,Williams,R.J.,1986.Learningrepresentationsbyback-propagatingerrors.nature323,533–536.\\nSahili,Z.A.,Awad,M.,2023.Spatio-temporalgraphneuralnetworks:Asurvey.arXivpreprintarXiv:2301.10569.\\nSavazzi,S.,Nicoli,M.,Rampa,V.,2019. Federatedlearningwithcooperatingdevices: Aconsensusapproachformassiveiotnetworks. IEEE\\nInternetofThingsJournal7,4641–4654.doi:10.1109/JIOT.2020.2964162.\\nScarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M., Monfardini, G., 2008. Thegraphneuralnetworkmodel. IEEEtransactionsonneural\\nnetworks20,61–80.\\nSecurity, S.S.L.G., 2019. Targeted Attacks Cyber Security Report 2019. Technical Report. Swisscom (Switzerland) Ltd.. Bern,\\nSwitzerland. URL: https://documents.swisscom.com/product/filestore/lib/7657c513-a231-4725-9d04-eeb343c164e1/\\nSwisscom_Security_Report_2019_EN.pdf.\\nSeo,Y.,Defferrard,M.,Vandergheynst,P.,Bresson,X.,2018. Structuredsequencemodelingwithgraphconvolutionalrecurrentnetworks,in:\\nNeuralInformationProcessing: 25thInternationalConference,ICONIP2018,SiemReap,Cambodia,December13-16,2018,Proceedings,\\nPartI25,Springer.pp.362–373.\\nSexton,J.,Storlie,C.,Neil,J.,2015.Attackchaindetection.StatisticalAnalysisandDataMining:TheASADataScienceJournal8,353–363.\\nShamir,A.,1979.Howtoshareasecret.CommunicationsoftheACM22,612–613.\\nShanmugarasa,Y.,Paik,H.y.,Kanhere,S.S.,Zhu,L.,2023. Asystematicreviewoffederatedlearningfromclients’perspective: challengesand\\nsolutions.ArtificialIntelligenceReview56,1773–1827.\\nShen,H.,Pan,W.,Dong,Y.,Alim,M.,2016. Losslesscompressionofcuratederythrocyteimagesusingdeepautoencodersformalariainfection\\ndiagnosis.2016PictureCodingSymposium(PCS),1–5doi:10.1109/PCS.2016.7906393.\\nSon,N.D.H.,Thi,H.T.,Duy,P.T.,Pham,V.H.,2023. Xfedgraph-hunter: Aninterpretablefederatedlearningframeworkforhuntingadvanced\\npersistentthreatinprovenancegraph,in:InternationalConferenceonInformationSecurityPracticeandExperience,Springer.pp.546–561.\\nSu,Y.,Li,M.,Tang,C.,Shen,R.,2017.Aptdetectionwithconcolicexecution.InternationalJournalofHybridInformationTechnology10,1–10.\\ndoi:10.14257/IJHIT.2017.10.7.01.\\nThein,K.M.M.,2014.Apachekafka:Nextgenerationdistributedmessagingsystem.InternationalJournalofScientificEngineeringandTechnology\\nResearch3,9478–9483.\\nTorrey,J.,2020.GitHub-darpa-i2o/Transparent-Computing:MaterialfromtheDARPATransparentComputingProgram—github.com.https:\\n//github.com/darpa-i2o/Transparent-Computing.\\nTsymbal,A.,2004.Theproblemofconceptdrift:definitionsandrelatedwork.ComputerScienceDepartment,TrinityCollegeDublin106,58.\\nTu,K.,Cui,P.,Wang,X.,Yu,P.S.,Zhu,W.,2018.Deeprecursivenetworkembeddingwithregularequivalence,in:Proceedingsofthe24thACM\\nSIGKDDinternationalconferenceonknowledgediscovery&datamining,pp.2357–2366.\\nUssath,M.,Jaeger,D.,Cheng,F.,Meinel,C.,2016. Advancedpersistentthreats:Behindthescenes,in:2016AnnualConferenceonInformation\\nScienceandSystems(CISS),IEEE.pp.181–186.\\nVelicˇkovic´,P.,Cucurull,G.,Casanova,A.,Romero,A.,Lio,P.,Bengio,Y.,2017.Graphattentionnetworks.arXivpreprintarXiv:1710.10903.\\nVelickovic,P.,Fedus,W.,Hamilton,W.L.,Lio`,P.,Bengio,Y.,Hjelm,R.D.,2019.Deepgraphinfomax.ICLR(Poster)2,4.\\nviensea1106, 2023. Viensea1106/federated-learning-meets-homomorphic-encryption: Homomorphic encryption and federated learning based\\nprivacy-preserving. URL: https://github.com/viensea1106/Federated-Learning-meets-Homomorphic-Encryption/tree/\\nmain.\\nVukalovic´,J.,Delija,D.,2015. Advancedpersistentthreats-detectionanddefense,in: 201538Thinternationalconventiononinformationand\\ncommunicationtechnology,electronicsandmicroelectronics(MIPRO),IEEE.pp.1324–1330.\\nWang,D.,Cui,P.,Zhu,W.,2016. Structuraldeepnetworkembedding,in: Proceedingsofthe22ndACMSIGKDDinternationalconferenceon\\nKnowledgediscoveryanddatamining,pp.1225–1234.\\nWang,S.,Wang,Z.,Zhou,T.,Sun,H.,Yin,X.,Han,D.,Zhang,H.,Shi,X.,Yang,J.,2022a. Threatrace:Detectingandtracinghost-basedthreats\\ninnodelevelthroughprovenancegraphlearning.IEEETransactionsonInformationForensicsandSecurity17,3972–3987.\\nWang, S., Yu, P.S., 2022. Graphneuralnetworksinanomalydetection. GraphNeuralNetworks: Foundations, Frontiers, andApplications,\\n557–578.\\nWang,Y.,Jing,C.,Xu,S.,Guo,T.,2022b. Attentionbasedspatiotemporalgraphattentionnetworksfortrafficflowforecasting. Information\\nSciences607,869–883.\\nWang,Y.,Li,J.,Zhao,W.,Han,Z.,Zhao,H.,Wang,L.,He,X.,2023. N-stgat: Spatio-temporalgraphneuralnetworkbasednetworkintrusion\\ndetectionfornear-earthremotesensing.RemoteSensing15,3611.\\nWang,Y.,Ma,X.,Chen,Z.,Luo,Y.,Yi,J.,Bailey,J.,2019. Symmetriccrossentropyforrobustlearningwithnoisylabels,in:Proceedingsofthe\\nIEEE/CVFinternationalconferenceoncomputervision,pp.322–330.\\nWard,I.R.,Joyner,J.,Lickfold,C.,Guo,Y.,Bennamoun,M.,2022. Apracticaltutorialongraphneuralnetworks. ACMComputingSurveys\\n(CSUR)54,1–35.\\nWu, Y., Xie, Y., Liao, X., Zhou, P., Feng, D., Wu, L., Li, X., Wildani, A., Long, D., 2022. Paradise: real-time, generalized, anddistributed\\nprovenance-basedintrusiondetection.IEEETransactionsonDependableandSecureComputing20,1624–1640.\\nWu,Z.,Pan,S.,Chen,F.,Long,G.,Zhang,C.,Philip,S.Y.,2020.Acomprehensivesurveyongraphneuralnetworks.IEEEtransactionsonneural\\nnetworksandlearningsystems32,4–24.\\nXiao,T.,Chen,Z.,Wang,D.,Wang,S.,2021. Learninghowtopropagatemessagesingraphneuralnetworks,in: Proceedingsofthe27thACM\\nSIGKDDConferenceonKnowledgeDiscovery&DataMining,pp.1894–1903.\\nXu,K.,Hu,W.,Leskovec,J.,Jegelka,S.,2018.Howpowerfularegraphneuralnetworks? arXivpreprintarXiv:1810.00826.\\nXu,M.,Dai,W.,Liu,C.,Gao,X.,Lin,W.,Qi,G.J.,Xiong,H.,2020. Spatial-temporaltransformernetworksfortrafficflowforecasting. arXiv\\npreprintarXiv:2001.02908.\\nYan,N.,Wen,Y.,Chen,L.,Wu,Y.,Zhang,B.,Wang,Z.,Meng,D.,2022. Deepro:Provenance-basedaptcampaignsdetectionviagnn,in:2022\\nIEEEInternationalConferenceonTrust,SecurityandPrivacyinComputingandCommunications(TrustCom),IEEE.pp.747–758.\\n30Yan,S.,Xiong,Y.,Lin,D.,2018. Spatialtemporalgraphconvolutionalnetworksforskeleton-basedactionrecognition,in: Proceedingsofthe\\nAAAIconferenceonartificialintelligence.\\nYang,C.,Wu,Q.,Li,H.,Chen,Y.,2017.Generativepoisoningattackmethodagainstneuralnetworks.arXivpreprintarXiv:1703.01340.\\nYasar, K., Rosenrance, L., 2023. What is an advanced persistent threat (APT)? — Definition from TechTarget — techtarget.com. https:\\n//www.techtarget.com/searchsecurity/definition/advanced-persistent-threat-APT.\\nYe,M.,Men,S.,Xie,L.,Chen,B.,2023. Detectadvancedpersistentthreatingraph-levelusingcompetitiveautoencoder,in: Proceedingsofthe\\n20232ndInternationalConferenceonNetworks,CommunicationsandInformationTechnology,pp.28–34.\\nYi,X.,Paulet,R.,Bertino,E.,Yi,X.,Paulet,R.,Bertino,E.,2014.Homomorphicencryption.Springer.\\nYing,Z.,Bourgeois,D.,You,J.,Zitnik,M.,Leskovec,J.,2019. Gnnexplainer:Generatingexplanationsforgraphneuralnetworks. Advancesin\\nneuralinformationprocessingsystems32.\\nZheng, J., Li, D., 2019. Gcn-tc: combining trace graph with statistical features for network traffic classification, in: ICC 2019-2019 IEEE\\nInternationalConferenceonCommunications(ICC),IEEE.pp.1–6.\\nZhong,L.,Zhang,L.,Xu,L.,Wang,L.,2022. Mpc-basedprivacy-preservingserverlessfederatedlearning. 20223rdInternationalConferenceon\\nBigData,ArtificialIntelligenceandInternetofThingsEngineering(ICBAIE),493–497doi:10.1109/ICBAIE56435.2022.9985933.\\nZhong,M.,Lin,M.,Zhang,C.,Xu,Z.,2024.Asurveyongraphneuralnetworksforintrusiondetectionsystems:Methods,trendsandchallenges.\\nComputers&Security,103821.\\nZhu,H.,Lu,J.,2022. Graph-basedintrusiondetectionsystemusinggeneralbehaviorlearning,in: GLOBECOM2022-2022IEEEGlobalCom-\\nmunicationsConference,IEEE.pp.2621–2626.\\nZhu,T.,Wang,J.,Ruan,L.,Xiong,C.,Yu,J.,Li,Y.,Chen,Y.,Lv,M.,Chen,T.,2021. General,efficient,andreal-timedatacompactionstrategy\\nforaptforensicanalysis.IEEETransactionsonInformationForensicsandSecurity16,3312–3325.doi:10.1109/TIFS.2021.3076288.\\nZhuang,C.,Ma,Q.,2018. Dualgraphconvolutionalnetworksforgraph-basedsemi-supervisedclassification,in:Proceedingsofthe2018world\\nwidewebconference,pp.499–508.\\nZimba,A.,Chen,H.,Wang,Z.,Chishimba,M.,2020. Modelinganddetectionofthemulti-stagesofadvancedpersistentthreatsattacksbasedon\\nsemi-supervisedlearningandcomplexnetworkscharacteristics. FutureGener.Comput.Syst.106,501–517. doi:10.1016/j.future.2020.\\n01.032.\\n31',\n",
       " 'DiReCT Diagnostic Reasoning for Clinical Notes via Large Language Models.pdf': 'DiReCT: Diagnostic Reasoning for Clinical Notes\\nvia Large Language Models\\nBowenWang♣♢∗,JiuyangChang♡∗,YimingQian♠†,GuoxinChen⋆,JunhaoChen♢,\\nZhouqiangJiang♢,JiahaoZhang♢,YutaNakashima♢♣,HajimeNagahara♢♣\\n♣PremiumResearchInstituteforHumanMetaverseMedicine(WPI-PRIMe),OsakaUniversity,\\n♡DepartmentofCardiology,TheFirstAffiliatedHospitalofDalianMedicalUniversity,\\n⋆InstituteofComputingTechnology,ChineseAcademyofScience\\n♢D3Center,OsakaUniversity,♠AgencyforScience,TechnologyandResearch(A*STAR),\\n{wang,n-yuta,nagahara}@ids.osaka-u.ac.jp\\nchangjiuyang@firsthosp-dmu.com\\nqiany@ihpc.a-star.edu.sg,gx.chen.chn@gmail.com\\n{junhao,zhouqiang,jiahao}@is.ids.osaka-u.ac.jp\\nAbstract\\nLargelanguagemodels(LLMs)haverecentlyshowcasedremarkablecapabilities,\\nspanningawiderangeoftasksandapplications,includingthoseinthemedical\\ndomain. ModelslikeGPT-4excelinmedicalquestionansweringbutmayface\\nchallenges in the lack of interpretability when handling complex tasks in real\\nclinicalsettings. Wethusintroducethediagnosticreasoningdatasetforclinical\\nnotes(DiReCT),aimingatevaluatingthereasoningabilityandinterpretabilityof\\nLLMscomparedtohumandoctors. Itcontains511clinicalnotes, eachmeticu-\\nlouslyannotatedbyphysicians,detailingthediagnosticreasoningprocessfrom\\nobservationsinaclinicalnotetothefinaldiagnosis. Additionally, adiagnostic\\nknowledgegraphisprovidedtoofferessentialknowledgeforreasoning,which\\nmaynotbecoveredinthetrainingdataofexistingLLMs. Evaluationsofleading\\nLLMsonDiReCTbringoutasignificantgapbetweentheirreasoningabilityand\\nthatofhumandoctors,highlightingthecriticalneedformodelsthatcanreason\\neffectivelyinreal-worldclinicalscenarios‡.\\n1 Introduction\\nRecentadvancementsoflargelanguagemodels(LLMs)[Zhaoetal.,2023]haveusheredinnew\\npossibilities and challenges for a wide range of natural language processing (NLP) tasks [Min\\netal.,2023]. Inthemedicaldomain, thesemodelshavedemonstratedremarkableprowess[Anil\\netal.,2023,Hanetal.,2023],particularlyinmedicalquestionanswering(QA)[Jinetal.,2021].\\nLeading-edgemodels,suchasGPT-4[OpenAI,2023a],exhibitprofoundproficiencyinunderstanding\\nandgeneratingtext[Bubecketal.,2023],evenachievedhighscoresontheUnitedStatesMedical\\nLicensingExamination(USMLE)questions[Norietal.,2023].\\nDespitetheadvancements,interpretabilityiscritical,particularlyinmedicalNLPtasks[Liévinetal.,\\n2024] because these tasks directly impact patient health and treatment decisions. Without clear\\ninterpretability,there’sariskofmisdiagnosisandimpropertreatment,makingitvitalforensuring\\nmedicalsafety. SomestudiesassessthiscapabilityovermedicalQA[Paletal.,2022,Lietal.,2023,\\n*Equalcontribution.\\n†Correspondingauthor.\\n‡Dataandcodeareavailableathttps://github.com/wbw520/DiReCT.\\n38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024)TrackonDatasetsandBenchmarks.\\n5202\\nnaJ\\n31\\n]LC.sc[\\n4v33910.8042:viXraSuspected Hemorrhagic\\nStroke Stroke\\nChief Complaint: Right Radiology: A 3.0 x 1.1 cm\\nweakness and aphasia. left thalamic hematoma\\nEvents: He had episode of appears stable when ......\\nmaurosis fugax in right eye MR HEAD: Only ***** T1,\\n******** ago ...... axial T1, and axial FLAIR\\nPast Medical History: sequences were ...... Final\\nHTN, COPD on home 1L CT HEAD: Stable **** basal Diagnosis\\nAdmission Consultation ...... Examination ganglia ......\\nDiagnosis Procedure\\nFigure1: Whenapatientisadmitted,aninitialconsultationtakesplacetocollectsubjectiveinforma-\\ntion. Subsequentobservationsmaythenrequirefurtherexaminationtoconfirmthediagnosis.\\nChenetal.,2024]ornaturallanguageinference(NLI)[Jullienetal.,2023]. Puttingmoreattentionon\\ninterpretability,theyuserelativelysimpletasksastestbeds,takingshorttextasinput. Nevertheless,\\nreal-worldclinicaltasksareoftenmorecomplex[Gaoetal.,2023a], asillustratedinFigure1, a\\ntypicaldiagnosisrequirescomprehendingandcombiningvariousinformation,suchashealthrecords,\\nphysicalexaminations,andlaboratorytests,forfurtherreasoningofpossiblediseasesinastep-by-step\\nmanner following the established guidelines. This observation suggests that both perception, or\\nreading(e.g.,findingnecessaryinformationinthemedicalrecord)andreasoning(determiningthe\\ndiseasebasedontheobservations)shouldbecountedwhenevaluatinginterpretabilityinLLM-based\\nmedicalNLPtasks.\\nForamorecomprehensiveevaluationofLLMsforsupportingdiagnosisinamorerealisticsetting,\\nwe propose a Diagnostic Reasoning dataset for Clinical noTes (DiReCT). The task basically is\\npredictingthediagnosisfromaclinicalnoteofapatient,whichisacollectionofvariousmedical\\nrecords,writteninnaturallanguage. Ourdatasetcontains511clinicalnotesspanning25disease\\ncategories, sampled from a publicly available database, MIMIC-IV [Johnson et al., 2023]. Each\\nclinicalnoteundergoesfine-grainedannotationbyprofessionalphysicians. Theannotators(i.e.,the\\nphysicians)areresponsibleforidentifyingthetext, ortheobservation, inthenotethatleadstoa\\ncertaindiagnosis,aswellastheexplanation. Thedatasetalsoprovidesadiagnosticknowledgegraph\\nbased on existing diagnostic guidelines to facilitate more consistent annotations and to supply a\\nmodelwithessentialknowledgeforreasoningthatmightnotbeencompassedinitstrainingdata.\\nTounderscorethechallengeofferedbyourdataset,weproposeasimpleAI-agentbasedbaseline[Xi\\netal.,2023,Tangetal.,2023]thatutilizestheknowledgegraphtodecomposethediagnosisintoa\\nsequenceofdiagnosesfromasmallernumberofobservations. Ourexperimentalfindingsindicate\\nthatcurrentstate-of-the-artLLMsstillfallshortofaligningwellwithhumandoctors.\\nContribution. DiReCToffersanewchallengeindiagnosisfromacomplexclinicalnotewithexplicit\\nknowledgeofestablishedguidelines. Thischallengealignswitharealisticmedicalscenariothat\\ndoctorsareexperiencing. Intheapplicationaspect,thedatasetfacilitatesthedevelopmentofamodel\\ntosupportdoctorsindiagnosis,whichiserror-prone[Middletonetal.,2013,Liuetal.,2022]. From\\nthetechnicalaspect,thedatasetcanbenchmarkmodels’abilitytoreadlongtextandfindnecessary\\nobservationsformulti-evidenceentailmenttreereasoning,anextensionoftheoriginalentailmenttree\\nexplanation[Dalvietal.,2021]forcomplexscenariosinmedicalNLPtasks. AsshowninFigure3,\\nthisisnottrivialbecauseofthevariationsinwriting;superficialmatchingdoesnothelp,andmedical\\nknowledgeisvital. Meanwhile,reasoningitselfisfacilitatedbytheknowledgegraph. Themodel\\ndoesnotnecessarilyhavetheknowledgeofdiagnosticguidelines. Withthischoice,theknowledge\\ngraph explains the reasoning process, which is also beneficial when deploying such a diagnosis\\nassistantsysteminpracticaluses.\\n2 RelatedWorks\\nNatural language explanation. Recent advancements in NLP have led to significant achieve-\\nments[Minetal.,2023]. However,existingmodelsoftenlackexplainability,posingpotentialrisks\\n[Danilevskyetal.,2020,Gurrapuetal.,2023]. Numerouseffortshavebeenmadetoaddressthis\\nchallenge. One effective approach is to provide a human-understandable plain text explanation\\nalongsidethemodel’soutput[Camburuetal.,2018,Rajanietal.,2019]. Anotherstrategyinvolves\\nidentifyingevidencewithintheinputthatservesasarationaleforthemodel’sdecisions,aligningwith\\n2Table1: Comparisonofexistingdatasetsformedicalreasoningtasksandours. “t”and“w”mean\\ntokensandwordsforthelengthofinput,respectively.\\nDataset Task DataSource Length Explanation #Cases\\nMedMCQA[Paletal.,2022] QA Examination 9.93t PlainText 194,000\\nExplainCPE[Lietal.,2023] QA Examination 37.79w PlainText 7,000\\nJAMAChallenge[Chenetal.,2024] QA ClinicalCases 371w PlainText 1,524\\nMedbullets[Chenetal.,2024] QA OnlineQuestions 163w PlainText 308\\nN2N2[Gaoetal.,2022] Sum ClinicalNotes 785.46t Evidences 768\\nNLI4CT[Jullienetal.,2023] NLI ClinicalTrailReports 10-35t Multi-hop 2,400\\nNEJMCPC[Zacketal.,2023] CD ClinicalCases - PlainText 2,525\\nDiReCT(Ours) CD ClinicalNotes 1074.6t EntailmentTree 511\\nhumanreasoning[DeYoungetal.,2020]. Expandingonthisconcept,[JhamtaniandClark,2020]\\nintroduceschain-structuredexplanations,giventhatadiagnosiscandemandmulti-hopreasoning.\\nThisideaisfurtherrefinedbyProofWriter[Tafjordetal.,2021]throughaproofstageforexplanations,\\nandby[Zhaoetal.,2021]throughretrievalfromacorpus.[Dalvietal.,2021]proposestheentailment\\ntree,offeringmoredetailedexplanationsandfacilitatinginspectionofthemodel’sreasoning. More\\nrecently,[Zhangetal.,2024]employedcumulativereasoningtotapintothepotentialofLLMsto\\nprovide explanation via a directed acyclic graph. Although substantial progress has been made,\\ninterpretingNLPtasksinmedicaldomainsremainsanongoingchallenge[Liévinetal.,2024].\\nBenchmarksofinterpretabilityinthemedicaldomainSeveraldatasetsaredesignedtoassess\\namodel’sreasoningtogetherwithitsinterpretabilityinmedicalNLP(Table1). MedMCQA[Pal\\netal.,2022]andothermedicalQAdatasets[Lietal.,2023,Chenetal.,2024]provideplaintextas\\nexplanationsforQAtasks. NLI4CT[Jullienetal.,2023]usesclinicaltrialreports,focusingonNLI\\nsupportedbymulti-hopreasoning. N2N2[Gaoetal.,2022]proposesasummarization(Sum)task\\nforadiagnosisbasedonmultiplepiecesofevidenceintheinputclinicalnote. NEJMCPC[Zack\\netal.,2023]interpretsclinicians’diagnosticreasoningasplaintextforreasoningclinicaldiagnosis\\n(CD).DR.BENCH[Gaoetal.,2023b]aggregatespubliclyavailabledatasetstoassessthediagnostic\\nreasoningofLLMs. Utilizinganmulti-evidenceentailmenttreeexplanation,DiReCTintroducesa\\nmorerigoroustasktoassesswhetherLLMscanalignwithdoctors’reasoninginrealclinicalsettings.\\n3 AbenchmarkforClinicalNotesDiagnosis\\nThis section first detail clinical notes (Section 3.1). We also describes the knowledge graph that\\nencodesexistingguidelines(Section3.2). Ourtaskdefinition,whichtasksaclinicalnoteandthe\\nknowledgegraphasinputisgiveninSection3.4. Wethenpresentourannotationprocessforclinical\\nnotes(Section3.3)andtheevaluationmetrics(Section3.5).\\n3.1 ClinicalNotes\\nClinicalnotesusedinDiReCTarestoredintheSOAPformat[Weed,1970].Aclinicalnotecomprises\\nfourcomponents: Inthesubjectivesection,thephysicianrecordsthepatient’schiefcomplaint,the\\nhistoryofpresentillness,andothersubjectiveexperiencesreportedbythepatient. Theobjective\\nsectioncontainsstructuraldataobtainedthroughexaminations(inspection,auscultation,etc.) and\\nothermeasurablemeans. Theassessmentsectioninvolvesthephysician’sanalysisandevaluationof\\nthepatient’scondition. Thismayincludeasummaryofcurrentstatus,etc. Finally,theplansection\\noutlines the physician’s proposed treatment and management plan. This may include prescribed\\nmedications, recommended therapies, and further investigations. A clinical note also includes a\\nprimarydischargediagnosis(PDD)intheassessmentsection.\\nDiReCT’sclinicalnotesaresourcedfromtheMIMIC-IVdataset[Johnsonetal.,2023](PhysioNet\\nCredentialedHealthDataLicense1.5.0),whichencompassesover40,000patientsadmittedtothe\\nintensivecareunits. Eachnotecontainsclinicaldataforapatient. ToconstructDiReCT,wecurateda\\nsubsetof511noteswhosePDDsfellwithinoneof25diseasecategoriesiin5medicaldomains.\\nInourtask,anoteR={r}isanexcerptof6clinicaldatainthesubjectiveandobjectivesections(i.e.,\\n|R|=6): chiefcomplaint,historyofpresentillness,pastmedicalhistory,familyhistory,physical\\n3exam,andpertinentresults.1 WealsoidentifiedthePDDd⋆associatedwithR.2 Thesetofd⋆’sfor\\nallR’scollectivelyformsD⋆. WemanuallyremovedanydescriptionsthatdisclosethePDDinR.\\n3.2 DiagnosticKnowledgeGraph\\nExistingknowledgegraphsforthemedicaldomain,e.g.,UMLSKG[Bodenreider,2004],lackthe\\nabilitytoprovidespecificclinicaldecisionsupport(e.g.,diagnosticthreshold,context-specificdata,\\ndosageinformation,etc.),whicharecriticalforaccuratediagnosis.\\nOurknowledgegraphsK = {k }isacollectionofgraphk fordiseasecategoryi. k isbasedon\\ni i i\\nthediagnosiscriteriainexistingguidelines(refertosupplementarymaterialfordetails). k ’snodes\\ni\\nareeitherpremisep∈P (medicalstatement,e.g.,Headache is a symptom of)anddiagnoses\\ni\\nd∈D (e.g.,Suspected Stroke). k consistsoftwodifferenttypesofedges. Oneispremise-to-\\ni i\\ndiagnosisedgesS ={(p,d)};anedgeisfromptod. Thisedgerepresentsthenecessarypremisep\\ni\\ntomakeadiagnosisd. Werefertothemassupportingedges. Theotherisdiagnosis-to-diagnosis\\nedgesF ={(d,d′)},whered,d′ ∈D andtheedgeisfromdtod′,whichrepresentsthediagnostic\\ni i\\nflow. Theseedgesarereferredtoasproceduraledges.\\nAdiseasecategoryisdefinedaccordingtoanexistingguideline,whichstartsfromacertaindiagnosis;\\ntherefore, a procedural graph g = (D ,F ) (G = {g }) has only one root node and arbitrarily\\ni i i i\\nbranches toward multiple leaf nodes that represent PDDs (i.e., the clinical notes in DiReCT are\\nchosentocoverallleafnodesofg ). Thus,g isatree. Wedenotethesetoftheleafnodes(orPDDs)\\ni i\\nasD⋆ ⊂D . Theknowledgegraphisdenotedbyk =(D ,P ,S ,F ).\\ni i i i i i i\\nFigure 2 shows a part of k ,\\nwhere i is Acute Coronaryi ...... iB s r ae a st yh mle ps ts on me s .s .. S isT c E ritle ev ria at i .o ..n STEMI-ACS Exh cs e- ec dT edn ... TrC oa pr od nia inc ↑\\nSyndromes (ACS). Premises in\\nP ianddiagnosesinD iaregiven Arrhythmias Suspected ACS SusS petr co tn eg dl y ACS NSTEMI-ACS\\nintheblueandgrayboxes,while is ... NSTE-ACS\\n...... UA\\nPDDsinD i⋆areoneswithoutout- T Sh oir ud n H de .a ..rt PreA sn ey n S tae tv ioe nr se ... non-ST No Obvious\\ngoingedges(i.e.,STEMI-ACSand Elevation ... ECG ...\\nNSTEMI-ACS,andUA).Theblack Figure2: Apartofk iforibeingAcute Coronary Syndromes.\\nandredarrowsareedgesinS and\\nF, respectively, where the black\\narrowsindicatethesupportingedges.\\nKservestwoessentialfunctions: (1)Theyserveasthegoldstandardforannotation,guidingdoctors\\ninthepreciseanduniforminterpretationofclinicalnotes. (2)Ourtaskalsoallowsamodeltouse\\nthem to ensure the output from an LLM can be closely aligned with the reasoning processes of\\nmedicalprofessionals.\\n3.3 DataAnnotation\\nLetd⋆ ∈D⋆denotethePDDofdiseasecategoryiassociatedwithR. Wecanfindasubgraphk (d⋆)\\ni i\\nofk thatcontainsallancestorsofd⋆,includingpremisesinP . Wealsodenotethesetofsupporting\\ni i\\nedges in k (d⋆) as S (d⋆). Our annotation process is, for each supporting edge (p,d) ∈ S (d⋆),\\ni i i\\nto extract observation o ∈ O in R (highlighted text in the clinical note in Figure 3) and provide\\nrationalization z of this deduction why o is a support for d or corresponds to p.3 They form the\\nexplanation E = {(o,z,d)} for (R,d⋆). This annotation process was carried out by 9 clinical\\nphysiciansandsubsequentlyverifiedforaccuracyandcompletenessbythreeseniormedicalexperts.\\nTable2summarizesstatisticsofourdataset.Thesecondandthirdcolumns(“#cats.”and“#samples”)\\nshowthenumbersofdiseasecategoriesandsamplesintherespectivemedicaldomains. |D |and\\ni\\n|D⋆|arethetotalnumbersofdiagnoses(diseases)andPDDs,summedoveralldiagnosticcategories\\ni\\n1Weexcludeddata,suchasreviewsystemandsocialhistory,becausetheyareoftenmissingintheoriginal\\nclinicalnotesandarelessrelevanttothediagnosis.\\n2AllclinicalnotesinDiReCTarerelatedtoonlyonePDD,andthereisnosecondarydischargediagnosis.\\n3All annotations strictly follow the procedural flow in k , and each observation is only related to one\\ni\\ndiagnosticnode.IfRdoesnotprovidesufficientobservationsforthePDD(whichmayhappenwhenacertain\\ntestisomitted),theannotatorswereaskedtoaddplausibleobservationstoR.Refertoamendeddatapointsin\\nsupplementaryfordetails.\\n4Chief Complaint: Scrotal and leg swelling ... Peripheral oedema is\\nHistory of Present Illness: ... In the last 3 days his ***** has become quite a sign of heart failure Suspected HF\\nswollen. It is similar ***** swelling when he was admitted with acute CHF ... EKG ......\\nwas consistent with priors (NSR, NANI, ********** changes). The left ventricle is\\nmildly enlarged. He was given ********* with good UOP ... Hypertension is the risk factor\\nPast Medical History: ... -Diabetes, -Hypertension, -CKD, stage 3, -GERD, - of heart failure\\nDepression, - Amputation of ***********, Pneumonia, - Osteoarthritis- History of ...... Strongly\\nSuspected HF\\n*********, Asthma ...\\nFamily History：There is no family history of **************** artery ... NT-proBNP 3843≥125pg/ml is a\\nPhysical Exam: ... LUNG: bibasilar rales that do not clear with deep inspiration. diagnostic criteria of strong HF\\n... ABDOMEN: nondistended, ********* all quadrants. EXTREMITIES: bilateral ......\\np ...it t Hin Eg E e Nd Te : m ATa /Nto C t ,h Ee Osa Mc Ir ,u Pm E, R e Rxt Le .n .d ..ing to the up abdomen. Warm, well perfused. Cardiac structure abnormalities are HF\\nPertinent Results: __03:50PM BLOOD WBC-8.0 RBC-3.26* Hgb-9.3* Hct- diagnostic criteria of heart failure\\n30.9* MCHC-29.9* ... __ 11:30AM BLOOD proBNP-3843 ... Overall left ventricular ......\\nsystolic function is mildly depressed (LVEF= 45-50 %) without regional wall motion\\nCardiac systolic dysfunction ~49%\\nabnormalities. *********** imaging suggests an increased ******* filling pressure can lead to the diagnosis of HFmrEF HFmrEF\\n(PCWP>******Hg) ...\\nClinical Note Rationale Diagnosis\\nFigure3: AnannotationsampleofHeart Failure(HF).Theleftpartistheclinicalnotealongside\\nextractedobservationsbyadoctor. Themiddlepartoutlinesthestepsoftherationaleforthepremise\\ncorrespondingtoeachdiagnosticnodeshownintherightpart.\\ninthemedicaldomain,respectively. |O|istheaveragenumberofannotatedobservations. “Length”\\nistheaveragenumberoftokensinR.\\n3.4 TaskDefinition\\nWeproposetwotaskswithdifferentlevelsof Table2: StatisticsofDiReCT.\\nsuppliedexternalknowledge. Thefirsttask\\nis,givenRandG,topredicttheassociated Medicaldomain #cat. #samples |Di| |Di⋆| |O| Length\\nPDDd⋆ andgenerateanexplanationE that Cardiology 7 184 27 16 8.7 1156.6t\\nexplains the model’s diagnostic procedure Gastroenterology 4 103 11 7 4.3 1026.0t\\nNeurology 5 77 17 11 11.9 1186.3t\\nfromRtod⋆,i.e.,lettingM denoteamodel: Pulmonology 5 92 26 17 10.7 940.7t\\nEndocrinology 4 55 20 14 6.9 1063.5t\\ndˆ⋆,Eˆ=M(R,G), (1) Overall 25 511 101 65 8.5 1074.6t\\nwheredˆ⋆ ∈∪ D⋆ andEˆarepredictionsforthePDDandexplanation,respectively. Withthistask,\\ni i\\ntheknowledgeofspecificdiagnosticproceduresinexistingguidelinescanbeusedforprediction,\\nfacilitatinginterpretability. ThesecondtasktakesKasinputinsteadofG,i.e.,:\\ndˆ⋆,Eˆ=M(R,K). (2)\\nThistaskallowsfortheuseofbroaderknowledgeofpremisesforprediction. Onemayalsotryatask\\nwithoutanyexternalknowledge.\\n3.5 EvaluationMetrics\\nWedesignedthreemetricstoquantifythepredictiveperformanceoverourbenchmark.\\n(1)AccuracyofdiagnosisAccdiagevaluatesifamodelcancorrectlyidentifythediagnosis.Accdiag =1\\nifd⋆ =dˆ,andAccdiag =0otherwise. Theaverageisreported.\\n(2)CompletenessofobservationsObscompevaluateswhetheramodelextractsallandonlynecessary\\nobservationsfortheprediction. LetOandOˆdenotethesetsofobservationsinE andEˆ,respectively.\\nThe metric is defined as Obscomp = |O ∩ Oˆ|/|O ∪ Oˆ|, where the numerator is the number of\\nobservationsthatarecommoninbothOandOˆ.4 Thismetricsimultaneouslyevaluatesthecorrectness\\nofeachobservationandthecoverage. Tosupplementit,wealsoreporttheprecisionObspreandrecall\\nObsrec,givenbyObspre =|O∩Oˆ|/|Oˆ|andObsrec =|O∩Oˆ|/|O|.\\n(3)FaithfulnessofexplanationsevaluatesifthediagnosticflowtowardthePDDisfullysupportedby\\nobservationswithfaithfulrationalizations. Thisinvolvesestablishingaone-to-onecorrespondence\\nbetweendeductionsinthepredictionandthegroundtruth.Weusethecorrespondencesestablishedfor\\ncomputingObscomp. Leto∈Oandoˆ∈Oˆdenotecorrespondingobservations. Thiscorrespondence\\n4WefindthecommonobservationswithanLLM(refertothesupplementarymaterialformoredetail).\\n5R U\\nNarrowing- Observations ① ② ③ ④ ⑤\\ndown ① Elevated blood pressures\\nW ② CXR showed mild pulmonary edema\\nd0\\nPerception ③ CHF/Cardiomyopathy\\nClinical V ① ② ③ ④ ⑤\\nNote ④ Severe LV diastolic dysfunction\\nReasoning\\n⑤ BPs: 148/98, 156/93\\nr1: Chief Complaint ...... d0 d1\\nr2: History of Present Illness\\nr3: Past Medical History Diagnostic KG ......\\nr4: Family History V ① ② ③ ④ ⑤\\nReasoning\\nr5: Physical Examination\\nr6: Pertinent Results\\nd0 d1 ... dt\\nFigure4: Pipelineofourbaseline. Thedottedlineintheright-mostboxesmeansdeductionsfroman\\nobservationtoadiagnosis.\\nisconsideredsuccessfulifzandzˆaswellasdanddˆassociatedwithoandoˆmatches. Letm(E,Eˆ)\\ndenote the number of successful matches. We use the ratio of m(E,Eˆ) to |O∩Oˆ| and |O∪Oˆ|\\nas evaluation metrics Expcom and Expall, respectively, to see failures come from observations or\\nexplanationsanddiagnosis.\\n4 Baseline\\nFigure 4 provides an overview of our baseline, which comprises three LLM-based modules:\\nnarrowing-down(U),perception(W),andreasoning(V). Inourexperiments,eachmoduleutilizes\\nthesametypeofLLMwithdifferentprompts(refertothesupplementarymaterialformoredetails).\\nU analyzetheentirenoteRtodeterminethepossiblediseasetypeˆi. W extractsobservationsthat\\nmay lead to diseases from each r, producing a list of original disease descriptions. V iteratively\\nderives possible diseases from observations based on the diagnosis knowledge graph, providing\\nrationalesforeachdeduction(o,z,d).\\nThenarrowing-downmoduleU takesRasinputtomakeapredictionˆiofthediseasecategory,i.e.,\\nˆi = U(R). Letd ∈ D bethediagnosisthathasbeenreachedwithtiterationsoverk , wheret\\nt ˆi ˆi\\ncorrespondstothedepthofnoded andsoislessthanorequaltothedepthofk . d istherootnode\\nt ˆi 0\\nofk . Ford ,weapplytheperceptionmoduletoextractallobservationsinRandexplanationE to\\nˆi 0 0\\nsupportd as\\n0\\nOˆ,Eˆ =W(d ,k ). (3)\\n0 0 ˆi\\nk issuppliedtofacilitatethemodeltoextractallobservationsforthefollowingreasoningprocess.5\\nˆi\\nAftertheperceptionmoduleW (iterationt=0),weobtainallobservationsOˆ,therootnodeofthe\\ndiagnosisd ,andanexplanationEˆ fortheinitialiteration. Assumingthatbyiterationt,wealready\\n0 0\\nknowthediagnosisforiterationtasd . {d }isthesetofd ’schildren,andP ({d })representsthe\\nt n t ˆi n\\ncorrespondingpremisesthatsupporteachd . V identifiesthediagnosisforthenextstep,d ,and\\nn t+1\\nprovidesajustificationE . V willverifyifthereisanyoˆinOˆthatsupportsad . Iffullysupported,\\nt+1 n\\nd isidentifiedasd forthe(t+1)-thiteration,i.e.,\\nn t+1\\nd ,Eˆ =V(Oˆ,{d },P ({d })), (4)\\nt+1 t+1 n ˆi n\\nV continuesuntild inD∗isidentified. Ifnoobservationsupportsad ,thereasoningprocesswill\\nt+1 n\\nbestopped.\\nInourannotation,anobservationoisassociatedwithonlyoned. However,ourmethodemploys\\naniterativereasoningpipeline. Initially,theperceptionmoduleW generatesanexplanationsetEˆ ,\\n0\\nlinkingalloˆtod . Duringthet-thiterationofV,theexplanationsetisEˆ,whereatleastoneoˆis\\n0 t\\n5Weusedonlypairsofanobservationandapremise.WeabuseKtomeanthisfornotationsimplicity.The\\nperceptionmodelcanalsoutilizeg insteadofk forthefirsttask.\\ni i\\n6Table3: EvaluationofdiagnosticreasoningabilityusingG orKasinput.\\nDiagnosis Observation Explanation\\nTask Models Acccat Accdiag Obspre Obsrec Obscomp Expcom Expall\\nZephyr7B 0.274 0.151 0.123 0.115 0.092 0.071 0.014\\n±0.200 ±0.166 ±0.108 ±0.139 ±0.037\\nMistral7B 0.507 0.306 0.211 0.317 0.173 0.230 0.062\\n±0.190 ±0.253 ±0.157 ±0.312 ±0.088\\nMixtral8×7B 0.413 0.237 0.147 0.266 0.124 0.144 0.029\\n±0.165 ±0.261 ±0.138 ±0.268 ±0.056\\nWithG LLama38B 0.569 0.364 0.248 0.410 0.211 0.325 0.087\\n±0.157 ±0.218 ±0.138 ±0.375 ±0.118\\nLLama370B 0.822 0.606 0.306 0.543 0.279 0.409 0.124\\n±0.151 ±0.183 ±0.146 ±0.328 ±0.120\\nGPT-3.5turbo 0.679 0.455 0.389 0.351 0.275 0.331 0.103\\n±0.212 ±0.192 ±0.167 ±0.366 ±0.127\\nGPT-4turbo 0.804 0.610 0.486 0.481 0.391 0.481 0.210\\n±0.207 ±0.180 ±0.189 ±0.362 ±0.188\\nLLama38B 0.576 0.344 0.235 0.394 0.199 0.327 0.087\\n±0.162 ±0.227 ±0.142 ±0.375 ±0.114\\nLLama370B 0.786 0.652 0.268 0.524 0.258 0.549 0.152\\nWithK ±0.147 ±0.211 ±0.142 ±0.372 ±0.130\\nGPT-3.5turbo 0.652 0.413 0.347 0.279 0.232 0.374 0.121\\n±0.241 ±0.203 ±0.184 ±0.408 ±0.152\\nGPT-4turbo 0.808 0.611 0.470 0.459 0.371 0.645 0.273\\n±0.209 ±0.190 ±0.192 ±0.385 ±0.216\\nlinkedtod . ThefinaldiagnosisexplanationisthecombinationofEˆ ,...,Eˆ andd ,...,d ,where\\nt 0 T 0 T\\nT representsthefinaliteration. Inthiscombination,ifanoˆiseventuallyprocessedintheiterationfor\\nEˆ,thecorresponding(o,z,d)inallprecedingEˆ ,...,Eˆ willberemoved. Thatis,oˆwillalways\\nt 0 t−1\\nbepossessedbythed closesttotheleafPDDnode.\\nt\\n5 Experiments\\n5.1 ExperimentalSetup\\nWe assess the reasoning capabilities of 7 recent LLMs from diverse families and model sizes,\\nincluding5instruction-tunedmodelsthatareopenlyaccessible: LLama38Band70B[AI@Meta,\\n2024],Zephyr7B[Tunstalletal.,2023],Mistral7B[Jiangetal.,2023],andMixtral8×7B[Jiang\\netal.,2023]. WehavealsoobtainedaccesstoprivateversionsoftheGPT-3.5turbo[OpenAI,2023b]\\nandGPT-4turbo[OpenAI,2023a]6,whicharehigh-performanceclosed-sourcemodels. EachLLM\\nisutilizedtoimplementourbaseline’snarrowing-down,perception,andreasoningmodules. The\\ntemperatureissetto0. Forcomputingevaluationmetrics,weuseLLama38Bwithfew-shotprompts\\nto make correspondences between O and Oˆ as well as to verify a match between predicted and\\nground-truthexplanations(refertothesupplementarymaterialformoredetails).\\n5.2 Results\\nComparisonamongLLMs. Table3showstheperformanceofourbaselinebuiltontopofvarious\\nLLMs. WefirstevaluateavariantofourtaskthattakesgraphG ={G }consistingofonlyprocedural\\ni\\nflowasexternalknowledgeinsteadofK. ComparisonbetweenG andKdemonstratestheimportance\\nof supplying premises with the model and LLMs’ capability to make use of extensive external\\nknowledgethatmaybesuperficiallydifferentfromstatementsinR. Subsequently,somemodelsare\\nevaluatedwithourtaskusingK. InadditiontothemetricsinSection3.5,wealsoadopttheaccuracy\\nofdiseasecategoryAcccat,whichgives1whenˆi=i,asourbaseline’sperformancedependsonit.\\nWithG,wecanseethatGPT-4achievesthebestperformanceinmostmetrics,especiallyrelated\\ntoobservationsandexplanations,surpassingLLama370Bbyalargemargin. Intermsofaccuracy\\n(inbothcategoryanddiagnosislevels),LLama370BiscomparabletoGPT-4. LLama370Balso\\nhasahigherObsrecbutlowObspreandObscomp,whichmeansthatthismodeltendstoextractmany\\nobservations. Modelswithhighdiagnosticaccuracyarenotnecessarilyexcelinfindingessential\\ninformationinlongtext(i.e.,observations)andgeneratingreasons(i.e.,explanations).\\nWhenKisgiven,allmodelsshowbetterdiagnosticaccuracy(inLLama370B)andexplanations,\\nwhileobservationsareslightlydegraded(thismayrelatedtotheinstructionfollowingabilitydueto\\ntheinputlengthwhengivingKasinput). GPT-4withKenhancesAccdiag,Expcom,andExpallscores.\\nThissuggeststhatpremisesandsupportingedgesarebeneficialfordiagnosisandexplanation. Lower\\n6ThesetwomodelsarehousedonaHIPPA-compliantinstancewithinMicrosoftAzureAIStudio.Nodatais\\ntransferredtoeitherMicrosoftorOpenAI.Thissecureenvironmentenablesustosafelyconductexperiments\\nwiththeMIMIC-IVdataset,incompliancewiththeDataUseAgreement.\\n7Table4: Evaluationofdiagnosticreasoningabilitywithoutexternalknowledge.\\nObservation Explanation\\nTask Models Accdiag Obspre Obsrec Obscomp Expcom Expall\\nLLama38B 0.070 0.154 0.330 0.135 0.020 0.004\\n±0.139 ±0.244 ±0.122 ±0.100 ±0.016\\nLLama370B 0.502 0.257 0.509 0.237 0.138 0.034\\nWithD⋆ ±0.150 ±0.213 ±0.145 ±0.209 ±0.054\\nGPT-3.5turbo 0.223 0.164 0.149 0.116 0.091 0.025\\n±0.242 ±0.212 ±0.174 ±0.231 ±0.065\\nGPT-4turbo 0.636 0.461 0.482 0.378 0.186 0.074\\n±0.206 ±0.160 ±0.174 ±0.221 ±0.090\\nLLama38B 0.023 0.137 0.258 0.119 0.018 0.006\\n±0.159 ±0.274 ±0.141 ±0.083 ±0.026\\nLLama370B 0.037 0.246 0.504 0.227 0.022 0.007\\nNoKnowledge ±0.148 ±0.222 ±0.148 ±0.093 ±0.030\\nGPT-3.5turbo 0.059 0.161 0.148 0.113 0.036 0.011\\n±0.238 ±0.215 ±0.171 ±0.131 ±0.039\\nGPT-4turbo 0.074 0.410 0.443 0.324 0.047 0.019\\n±0.208 ±0.191 ±0.182 ±0.143 ±0.058\\n\\x00$\\x00F\\x00F \\x00&\\x00R\\x00P\\x00S \\x00)\\x00D\\x00L\\x00W\\x00K\\n\\x00\\x14\\x00\\x11\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x1b\\n\\x00\\x13\\x00\\x11\\x00\\x19\\n\\x00\\x13\\x00\\x11\\x00\\x17\\n\\x00\\x13\\x00\\x11\\x00\\x15\\n\\x00\\x13\\x00\\x11\\x00\\x13\\n\\x00/\\x00/\\x00D\\x00P\\x00D\\x00\\x16\\x00*\\x003\\x007\\x00\\x10\\x00\\x16\\x00\\x11\\x00\\x18 \\x00*\\x003\\x007\\x00\\x10\\x00\\x17 \\x00/\\x00/\\x00D\\x00P\\x00D\\x00\\x16\\x00*\\x003\\x007\\x00\\x10\\x00\\x16\\x00\\x11\\x00\\x18 \\x00*\\x003\\x007\\x00\\x10\\x00\\x17 \\x00/\\x00/\\x00D\\x00P\\x00D\\x00\\x16\\x00*\\x003\\x007\\x00\\x10\\x00\\x16\\x00\\x11\\x00\\x18 \\x00*\\x003\\x007\\x00\\x10\\x00\\x17 \\x00/\\x00/\\x00D\\x00P\\x00D\\x00\\x16\\x00*\\x003\\x007\\x00\\x10\\x00\\x16\\x00\\x11\\x00\\x18 \\x00*\\x003\\x007\\x00\\x10\\x00\\x17 \\x00/\\x00/\\x00D\\x00P\\x00D\\x00\\x16\\x00*\\x003\\x007\\x00\\x10\\x00\\x16\\x00\\x11\\x00\\x18 \\x00*\\x003\\x007\\x00\\x10\\x00\\x17\\n\\x00&\\x00D\\x00U\\x00G\\x00L\\x00R\\x00O\\x00R\\x00J\\x00\\\\ \\x00*\\x00D\\x00V\\x00W\\x00U\\x00R\\x00H\\x00Q\\x00W\\x00H\\x00U\\x00R\\x00O\\x00R\\x00J\\x00\\\\ \\x001\\x00H\\x00X\\x00U\\x00R\\x00O\\x00R\\x00J\\x00\\\\ \\x003\\x00X\\x00O\\x00P\\x00R\\x00Q\\x00R\\x00O\\x00R\\x00J\\x00\\\\ \\x00(\\x00Q\\x00G\\x00R\\x00F\\x00U\\x00L\\x00Q\\x00R\\x00O\\x00R\\x00J\\x00\\\\\\nFigure5: PerformanceofLLama370B,GPT-3.5,andGPT-4underdifferentmedicaldomains. We\\nusethetaskwithG.\\nobservationalperformancemayindicatethatthemodelslacktheabilitytoassociatepremisesand\\ntextinR,whichareoftensuperficiallydifferentthoughsemanticallyconsistent.\\nLLMsmayundergoinherentchallengesforevaluationwhennoexternalknowledgeissupplied. They\\nmayhavetheknowledgetodiagnosebutcannotmakeconsistentobservationsandexplanationsthat\\nour task expects through K. To explore this, we evaluate two settings: (1) giving D⋆ and (2) no\\nknowledgeissuppliedtoamodel(showninTable4). Thepromptsusedforthissetuparedetailed\\nin the supplementary material. We do not evaluate the accuracy of disease category prediction\\nas it is basically the same as Table 3. We can clearly see that with D⋆, GPT-4’s diagnostic and\\nobservationalscoresarecomparabletothoseofthetaskwithK,thoughexplanatoryperformance\\nis much worse. Without any external knowledge, the diagnostic accuracy is also inferior.7 The\\ndeterioratedperformancecanbeattributedtoinconsistentwordingofdiagnosisnames,whichmakes\\nevaluationtough. HighobservationalscoresimplythatobservationsinRcanbeidentifiedwithout\\nrelyingonexternalknowledge. Therecanbesomecuestospotthem.\\nPerformanceinindividualdomains. Figure5summarizestheperformanceofLLama370B,GPT-\\n3.5, and GPT-4 across different medical domains, evaluated using Accdiag, Obscomp (Comp), and\\nExpall(Faith). Neurologygivesthebestdiagnosticaccuracy,whereLLama3achievedanaccuracyof\\n0.779.GPT-4alsoperformedwell(0.753).IntermsofObscompandExpall,GPT-4’sresultswere0.437\\nand0.280,respectively. However,GPT-4yieldsahigherdiagnosticaccuracyscorewhilealower\\nexplanatoryscore,suggestingthattheobservationscapturedbythemodelortheirrationalizations\\ndifferfromhumandoctors.\\nDiagnosticreasoningunderconditionsofincompleteobservation.Inreal-worldscenarios,doctors\\noften have to make diagnoses based on incomplete information. To explore this, we conducted\\nexperimentsonthe73amendedcaseswhichoriginallylackobservationtothefinaldiagnosis(refer\\nto supplementary for detailed introduction of amended data point). One set of experiments used\\nthe unmodified original notes, labeled as \"Original,\" while the other set used notes with added\\nobservations labeled as \"Amended.\" We tested three models—Llama3 70B, GPT-3.5-turbo, and\\nGPT-4 turbo—under two settings: one with only the procedural graph G and the other with the\\ncompleteknowledgegraphK. TheresultsarepresentedinTables5and6. Wecanobservethatin\\nbothGandKsettings,theperformanceontheAmendeddatawasconsistentlybetteracrossallmetrics\\ncomparedtotheOriginaldata. Thissuggeststhatevenasingleaddedobservationcansignificantly\\nimpactthemodel’sdiagnosticreasoning.\\n7Weunderstandthiscomparisonisunfair,asthepromptsdiffer.Weintendtogivearoughideaaboutthe\\nchallengewithoutexternalknowledge.\\n8Table5: AmendmentablationstudyusingG.\\nDiagnosis Observation Explanation\\nSetting Models Acccat Accdiag Obspre Obsrec Obscomp Expcom Expall\\nLLama370B 0.547 0.273 0.225 0.472 0.253 0.216 0.073\\n±0.143 ±0.144 ±0.138 ±0.271 ±0.087\\nOriginal GPT-3.5turbo 0.507 0.273 0.393 0.355 0.278 0.207 0.062\\n±0.216 ±0.174 ±0.151 ±0.305 ±0.093\\nGPT-4turbo 0.616 0.328 0.446 0.418 0.340 0.242 0.098\\n±0.211 ±0.164 ±0.178 ±0.324 ±0.137\\nLLama370B 0.698 0.534 0.250 0.507 0.240 0.296 0.133\\n±0.173 ±0.134 ±0.129 ±0.354 ±0.142\\nAmended GPT-3.5turbo 0.671 0.411 0.487 0.351 0.310 0.272 0.092\\n±0.206 ±0.152 ±0.145 ±0.321 ±0.118\\nGPT-4turbo 0.726 0.547 0.546 0.465 0.412 0.391 0.180\\n±0.184 ±0.148 ±0.171 ±0.374 ±0.186\\nTable6: AmendmentablationstudyusingK.\\nDiagnosis Observation Explanation\\nSetting Models Acccat Accdiag Obspre Obsrec Obscomp Expcom Expall\\nLLama370B 0.575 0.219 0.109 0.443 0.203 0.304 0.114\\n±0.233 ±0.171 ±0.186 ±0.388 ±0.135\\nOriginal GPT-3.5turbo 0.548 0.233 0.293 0.218 0.184 0.251 0.072\\n±0.243 ±0.198 ±0.166 ±0.357 ±0.106\\nGPT-4turbo 0.616 0.260 0.452 0.410 0.349 0.467 0.220\\n±0.241 ±0.211 ±0.223 ±0.437 ±0.256\\nLLama370B 0.685 0.537 0.261 0.493 0.277 0.452 0.185\\n±0.195 ±0.230 ±0.171 ±0.407 ±0.194\\nAmended GPT-3.5turbo 0.657 0.465 0.390 0.272 0.232 0.401 0.127\\n±0.227 ±0.194 ±0.156 ±0.394 ±0.145\\nGPT-4turbo 0.712 0.589 0.534 0.452 0.401 0.607 0.286\\n±0.214 ±0.180 ±0.201 ±0.442 ±0.258\\nForCardiologyandEndocrinology,thediagnosticaccuracyofthemodelsisrelativelylow(GPT-\\n4 achieved 0.458 and 0.468, respectively). Nevertheless, Obscomp and Expall are relatively high.\\nEndocrinologyresultsinlowerdiagnosticaccuracyandhigherexplanatoryperformance. Asmaller\\ngapmayimplythatinthesetwodomains,successfulpredictionsareassociatedwithobservations\\nsimilar to those of human doctors, and the reasoning process may be analogous. Conversely, in\\nGastroenterology,higherAcccat)isaccompaniedbylowerObscompandExpall(especiallyforLLama3),\\npotentiallyindicatingasignificantdivergenceinthereasoningprocessfromhumandoctors. Overall,\\nDiReCTdemonstratesthatthedegreeofalignmentbetweenthemodel’sdiagnosticreasoningability\\nandthatofhumandoctorsvariesacrossdifferentmedicaldomains.\\nReliabilityofautomaticevaluation. Werandomlypickout100samplesfromDiReCTandtheir\\nprediction by GPT-4 over the task with G to assess the consistency of our automated metrics\\nto evaluate the observational and explanatory performance in Section 3.3 to human judgments.\\nThree physicians joined this experi-\\nment.Foreachpredictionoˆ∈Oˆ,they Table7: Consistencyofautomatedevaluationwithhuman\\nareaskedtofindasimilarobservation judgments. Evaluatedbymeanandconfidenceinterval(CI).\\nin ground truth O. For explanatory\\nmetrics,theyverifyifeachprediction Observation Rationalization\\nzˆ ∈ Eˆfor oˆ ∈ Oˆ align with ground- Model Mean 95%CI Mean 95%CI\\ntruthz ∈E correspondingtoo. Apre- LLama38B 0.887 0.844∼0.878 0.835 0.759∼0.818\\ndictionandagroundtrutharedeemed GPT-4turbo 0.902 0.830∼0.863 0.876 0.798∼0.853\\nalignedforbothassessmentsifatleast\\ntwospecialistsagree. WecompareLLama3’sandGPT-4’sjudgmentstoexploreifthereisagap\\nbetweentheseLLMs. AssummarizedinTable7,GPT-4achievesthebestresults,withLLama38B\\nalsodisplayingasimilarperformance. Fromtheseresults,wearguethatourautomatedevaluation\\nmetricsareconsistentwithhumanjudgments,andLLama3issufficientforthisevaluation,allowing\\nthecost-efficientoption. Detailedanalysisisavailableinthesupplementarymaterial.\\nPrediction examples. Figure 6 shows a sample generated by GPT-4. The ground-truth PDD of\\nthe input clinical note is Hemorrhagic Stroke. In this figure, purple, orange, and red indicate\\nexplanationsonlyinthegroundtruth,onlyinprediction,andcommoninboth,respectively;therefore,\\nredisasuccessfulpredictionofanexplanation,whilepurpleandorangeareafalsenegativeandfalse\\npositive. GPT-4treatstheobservationofaurosis fugaxasthecriteriafordiagnosingIschemic\\nStroke. However, this observation only supports Suspected Stroke. Conversely, observation\\nthalamic hematoma,whichisthekeyindicatorofHemorrhagic Stroke,isregardedasaless\\nimportantclue. Suchobservation-diagnosiscorrespondenceerrorsleadtothemodel’smisdiagnosis.\\nInFigure7, wecanobservethatGPT-4canfindthekeyobservationforthediagnosisofGERD,\\n9Present Illne: He underwent a right carotid ********************,\\nand per notes, it was uneventful. This was done as an elective Transient vision loss typically Carotid artery stenosis is an\\nprocedure after he had episodes of amaurosis fugax in *********** indicates a transient ischemic important cause of insufficient Suspected\\n******** days ago, which, on evaluation, showed significant (more attack, often associated with blood flow to the brain and is Stroke\\nthan ******* percent) carotid stenosis. ... carotid artery disease. associated with risk of stroke\\nPast Medical History: +HTN, +Diverticulosis, +CHF ...\\nPhysical Exam: Mental status: Awake, *****, doesn\\'t verbalize.\\nCan only say ****** words. Comprehension is relatively spared,\\ncan answer with ********** to yes and No type questions. ... CHF reduced ability of the heart to pump blood may\\nPertinent Results: CT HEAD W/O CONTRAST Study Date lead to increase the risk of stroke\\nFINDINGS: A ****** cm left thalamic hematoma appears stable\\nwhen compared to ********** from outside the ******** imaged\\napproximately ******** ago. There is an increased amount of The presence of a thalamic Thalamus hematoma\\nlayering hemorrhage in the ************ of the left lateral ventricle. A hematoma is directly related means brain bleeding Hemorrhagic Ischemic\\nsmall amount of intraventricular blood is noted in the to symptoms of stroke, which is a common Stroke Stroke\\n***************** of the right lateral ventricle, ******. There is indicating brain bleeding diagnostic criterion for\\nsurrounding *******, which appears ****** from prior CT. ... which can lead to stroke hemorrhagic stroke\\nClinical Note Rationale Diagnosis\\nFigure6: AnexamplepredictionforaclinicalnotewithPDDofHemorrhagic StrokebyGPT-4.\\nChief Complaint: epigastric and substernal chest pain\\nPresent Illne: suspected PBC with severe epigastric pain that Common symptoms of GERD Epigastric and substernal chest\\nradiates to her mid-sternal area beginning at ** AM. She noted include chest pain that can be pain are atypical and typical\\ngradual ************************minutes. It did not radiate to her substernal or epigastric. symptoms of GERD,respectively. Suspected\\nback, and was similar in character to past episodes. However, she GERD\\nfelt the pain was much more severe, and did not respond to her\\nusual reflux techniques (drinking water, taking tums, and drinking a Hiatal hernia and erosions Erosions at the GE junction\\nlidocaine water mixture). She denied SOB, chest pain, palpitations, at the gastroesophageal may be an endoscopic\\nnausea, *****************is. She also denies change in **********, junction are common finding of GERD but was\\nsuch as melena or BRBPR. Endoscopy showed hiatal hernia and findings in GERD not graded.\\nerosions at the GE junction that were shown to be benign on\\npathology ...\\nPast Medical History: ... Indicates absence of erosive damage typically seen in severe\\nPertinent Results: EGD: Normal mucosa in the esophagus, GERD, but does not rule out GERD as symptoms can occur\\nstomach, and duodenum. *********** polyp in the upper without visible mucosal damage.\\nstomach. *********************************** part of the GERD\\nduodenum. EKG: upright axis, sinus rhythm, regular rate at ~60\\nbpm, intervals wnl, no acute ST changes. ************* reflux AET greater than 4% on pH-impedance\\nmonitor: total AET:6.5% on pH-impedance monitoring. monitoring supports the diagnosis of GERD\\nClinical Note Rationale Diagnosis\\nFigure7: AnexamplepredictionforaclinicalnotewithPDDofGERDbyGPT-4\\nwhichisconsistentwithhumaninbothobservationandrationale. However,itstilllackstheabilityto\\nidentifyallobservations. Moresamplesareavailableinthesupplementarymaterial.\\n6 ConclusionandLimitations\\nWeproposedDiReCTasthefirstbenchmarkforevaluatingthediagnosticreasoningabilityofLLMs\\nwithinterpretabilitybysupplyingexternalknowledgeasagraph. Ourevaluationsrevealanotable\\ndisparitybetweencurrentleading-edgeLLMsandhumanexperts,underscoringtheurgentneedfor\\nAImodelsthatcanperformreliableandinterpretablereasoninginclinicalenvironments. DiReCT\\ncanbeeasilyextendedtomorechallengingsettingsbyremovingtheknowledgegraphfromtheinput,\\nfacilitatingevaluationsoffutureLLMs.\\nLimitations. DiReCTencompassesonlyasubsetofdiseasecategoriesandconsidersonlyonePDD,\\nomittingtheinter-diagnosticrelationshipsduetotheircomplexity—asignificantchallengeevenfor\\nhumandoctors. Additionally,ourbaselinemaynotuseoptimalpromptsoraddressissuesrelated\\ntohallucinationsintaskresponses. Ourdatasetissolelyintendedformodelevaluationbutnotfor\\nuseinclinicalenvironments. Theuseofthediagnosticknowledgegraphisalsolimitedtoserving\\nmerelyasapartoftheinputandonceaknowledgegraphisprovided,thefocusshiftstowhetherthe\\nLLMfollowsthegraph’sruleswell(refertosupplementary). Futureworkwillfocusonconstructing\\namorecomprehensivediseasedatasetanddevelopinganextensivediagnosticknowledgegraph.\\nAcknowledgmentsandDisclosureofFunding\\nThisworkwassupportedbyWorldPremierInternationalResearchCenterInitiative(WPI),MEXT,\\nJapan. ThisworkisalsosupportedbyJSTACT-XGrantNumberJPMJAX24C8,JSPSKAKENHI\\nNo. 24K20795andNo. JP23H00497,CRESTGrantNo. JPMJCR20D3,JSTFORESTGrantNo.\\nJPMJFR216O,andDalianHaichuangProjectforAdvancedTalents.\\n10A DetailsofDiReCT\\nA.1 DataStatistics\\nTable8: DiseasestatisticsofDiReCT.\\nDomains Categories #samples |Di| |Di⋆| References\\nAcuteCoronarySyndromes 65 6 3 [Byrneetal.,2024,Kitaokaetal.,2020]\\nAorticDissection 14 3 2 [Membersetal.,2022]\\nAtrialFibrillation 10 3 2 [Joglaretal.,2024]\\nCardiology Cardiomyopathy 9 5 4 [Ommenetal.,2020]\\nHeartFailure 52 6 3 [Heidenreichetal.,2022]\\nHyperlipidemia 2 2 1 [Suetal.,2021,Machetal.,2020]\\nHypertension 32 2 1 [Ungeretal.,2020]\\nGastritis 27 5 3 [Shahetal.,2021,ofGastroenterologyetal.,2023,Banksetal.,2019,Chowetal.,2010]\\nGastroenterology G Pea ps tt ir coe Us lo cp eh ra Dge isa el aR seefluxDisease 4 21 8 2 3 1 2 [Kavitteta[G l.,y 2a 0w 1a 9li ,Tet ara al. s, c2 o0 n2 i4 e] tal.,2020]\\nUpperGastrointestinalBleeding 7 2 1 [Barkunetal.,2019]\\nAlzheimer 10 2 1 [McKhannetal.,1984]\\nEpilepsy 8 3 2 [Igaku-Shoin-Ltd.,2018]\\nNeurology Migraine 4 3 2 [Liptonetal.,2001,Eigenbrodtetal.,2021,HeadacheClassificationCommitteeoftheInternationalHeadacheSociety(IHS),2018]\\nMultipleSclerosis 27 6 4 [Lublin,2005,Brownleeetal.,2017]\\nStroke 28 3 2 [Kleindorferetal.,2021]\\nAsthma 13 7 5 [Qaseemetal.,2011,Batemanetal.,2007,Baosetal.,2018]\\nCOPD 19 6 4 [Guptaetal.,2013]\\nPulmonology Pneumonia 20 4 2 [OlsonandDavis,2020,RECOMMENDATIONS,2012,Niedermanetal.,2001]\\nPulmonaryEmbolism 35 5 3 [Konstantinidesetal.,2020]\\nTuberculosis 5 3 2 [Lewinsohnetal.,2017]\\nAdrenalInsufficiency 20 4 3 [Charmandarietal.,2014,Yanaseetal.,2016,Bornsteinetal.,2016]\\nEndocrinology D Pii ta ub ite at re ys 1 13 2 4 4 2 3 [TritosandMiller,2023,Drummondetal[ .,E 2lS 0a 1y 9e ,d Ce ot oa pl e., r2 a0 n2 d3 M] elmed,2012,MaysonandSnyder,2014]\\nThyroidDisease 10 6 4 [AlexanderEriketal.,2017]\\nTable8providesadetailedbreakdownofthediseasecategoriesincludedinDiReCT.Thecolumn\\nlabeled#samplesindicatesthenumberofdatapoints. Thesymbols|D |and|D⋆|denotethetotal\\ni i\\nnumberofdiagnoses(diseases)andPDDs,respectively. Existingguidelinesfordiagnosingdiseases\\nwereusedasReferences,formingthefoundationforconstructingthediagnosticknowledgegraphs.\\nAssomepremisemaynotincludedinthereferredguidelines. Duringannotation,physicianswill\\nincorporatetheirownknowledgetocompletetheknowledgegraph.\\nA.2 AmendedDataPoints\\nOurproposeddatasetaimstoevaluatewhetherLLMscanprovideacompletediagnosticreasoning\\nprocess comparable to that of human doctors. To achieve this, we intended to select notes from\\nthe MIMIC database that contain comprehensive signs and symptoms as observations, enabling\\nphysicians to annotate the notes leading to a final PDD. For disease category like heart failure,\\nMIMICoffersampledata,allowingustochoosenoteswithcompleteobservations. However,for\\nPDDssuchasbacterialpneumonia,thenumberofrelevantnotesislimited,andmanylackcritical\\nevidencenecessaryfordiagnosis(e.g.,sputumculture). Weobservedthatinsomenotes,thesection\\nunderthetitle’sputumculture’wasleftblank. Wesuspectthatthismightbeduetosomeinformation\\nbeingmissedinMIMIC.Toannotatesuchcases,weaskphysiciansaddthenecessaryobservationsto\\nsupportthediagnosis. Intotal,wemadeamendmentsto73notes. Thesenotesalllackedevidence\\nfor a final PDD diagnosis, and in each note, only one observation was added as evidence. Thus,\\nthemodificationstotheoriginalcontentofthenoteswereminimal. Forexample,inanotewhere\\nthePDDisbacterialpneumonia,weonlyaddedthefollowingdescriptionunder’pertinentresults’:\\n’MultipleorganismsconsistentwithHaemophilusinfluenzae.’\\nTo better illustrate the structure of our dataset and identify which data has been amended\\nand what content has been added, we have provided a detailed CSV file on GitHub\\n(https://github.com/wbw520/DiReCT/tree/master/utils/data_loading_analysisi). Thisfilecontains\\nsixcolumns,whichrecordthefollowinginformation: DiseaseCategory,PDD,DataRoot,Whether\\nAmended, Amended Part, and Amended Content. The Data Root column records the path and\\nfilenameofeachnote. Wehavestoredtheoriginalnoteinformationandourannotationswithina\\nJSONfile. TheversionsubmittedforreviewtoPhysioNetfollowsthesamestorageformat. Inthe\\nWhetherAmendedcolumn,notesthathavebeenamendedaremarkedas’Yes,’withtheAmended\\nPartandAmendedContentcolumnsspecifyingwhichpartofthenotewasmodifiedandwhatcontent\\nwasadded. Additionally,wehaveprovidedseveralsyntheticannotatedsamples(non-MIMICdata)\\nonGitHub,alongwithdetailedinstructionsontheformatoftheannotateddataandhowtoparseeach\\nJSONfile.\\nA.3 StructureofKnowledgeGraph\\nWefirstshowthenotationsdefinitiononTable9. Theentireknowledgegraph,denotedasK,isstored\\ninseparateJSONfiles,eachcorrespondingtoaspecificdiseasecategoryiasK . EachK comprises\\ni i\\naproceduralgraphG andthecorrespondingpremisepforeachdisease. AsillustratedinFigure8,\\ni\\ntheproceduralgraphG isstoredunderthekey\"Diagnostic\"inadictionarystructure. Akeywith\\ni\\nan empty list as its value indicates a leaf diagnostic node as d⋆. The premise for each disease is\\n11Notation Description Notation Description\\nR Thewholecontentofinputnote. U Thenarrowing-downmodule.\\nr Onedatasectionoftheinputnote. W Theperceptionmodule.\\nD Diseasecollection. V Thereasoningmodule.\\nD⋆ PDDcollection. {d } Collectionofchildrendiagnosis.\\nn\\nD⋆ PDDcollectionfordiseasei. Accdiag Diagnosisaccuracyford⋆.\\ni\\nd⋆ APDDdisease. Acccat Diagnosisaccuracyforcategory.\\nd Diagnosisatt-thiteration. Obspre Precisionofobservation.\\nt\\nd AdiagnosisinG. Obsrec Recallofobservation.\\nG Proceduralgraphs. Obscomp Completenessofobservation.\\ng Proceduralsubgraphfordisease Expcom Completenessofexplanation.\\ni\\nK knowledgegraphs. Expall Completenessofallexplanation.\\nk knowledgesubgraphsfordiseasei. M Anlanguagemodel.\\ni\\nP Supportingedgecollectionfork . E Collectionofannotateddeductions.\\ni i\\np ApremisedefinedinK.\\nF Proceduraledgecollectionforg .\\ni i\\nO Collectionofannotatedobservation.\\no Anannotatedobservation.\\nz Rationaleforadeduction.\\nd Rootdiagnosisforg .\\n0 i\\nTable9: Notationsdefinedinthispaper.\\n{\"Diagnostic\":\\n{\"Suspected Heart Failure\":\\n{\"Strongly Suspected Heart Failure\":\\n{\"Heart Failure\":\\n{\"HFrEF\": [],\\n\"HFmrEF\": [],\\n\"HFpEF\": []}}}},\\n\"Knowledge\":\\n{\"Suspected Heart Failure\":\\n{\"Risk Factors\": \"CAD; Hypertension; Valve disease; Arrhythmias; CMPs; Congenital heart disease; Infective; Drug-induced;\\nInfiltrative, Storage disorders, Endomyocardial disease, Pericardial disease, Metabolic, Neuromuscular disease\",\\n\"Symptoms\": Breathlessness; Orthopnoea; Paroxysmal nocturnal dyspnoea; Reduced exercise tolerance; Fatigue; tiredness; increased\\ntime to recover after exercise; Ankle swelling; Nocturnal cough; Wheezing; Bloated feeling; Loss of appetite;\\nConfusion (especially in the elderly); Depression; Palpitation; Dizziness; Syncope\",\\n\"Signs\": \"Elevated jugular venous pressure; Hepatojugular reflux; Third heart sound (gallop rhythm); Laterally displaced apical\\nimpulse; Weight gain (>2 kg/week); Weight loss (in advanced HF); Tissue wasting (cachexia); Cardiac murmur; Peripheral\\nedema (ankle, sacral, scrotal); Pulmonary crepitations; Pleural effusion; Tachycardia; Irregular pulse; Tachypnoea; Cheyne-Stokes\\nrespiration; Hepatomegaly; Ascites; Cold extremities; Oliguria; Narrow pulse pressure.\"},\\n\"Strongly Suspected Heart Failure\": \"NT-proBNP > 125 pg/mL; BNP > 35 pg/mL\",\\n\"Heart Failure\": \"Abnormal findings from echocardiography\\\\uff1aLV mass index>95 g/m2 (Female), > 115 g/m2 (Male); Relative wall thickness >0.42;\\nLA volume index>34 mL/m2; E/e ratio at rest >9; PA systolic pressure >35 mmHg; TR velocity at rest >2.8 m/s\",\\n\"HFrEF\": \"LVEF<40%\",\\n\"HFmrEF\": \"LVEF41-49%\",\\n\"HFpEF\": \"LVEF>50%\"}}\\nFigure 8: A sample of knowledge graph for Heart Failure. Each premise under the key of\\n\"Knowledge\"isseparatedwith\";\".\\nsavedunderthekeyof\"Knowledge\"withthecorrespondingdiseasenameasanindex. Forallthe\\nrootnodes(e.g.,Suspected Heart Failure),wefurtherdividethepremiseinto\"RiskFactors\",\\n\"Symptoms\",and\"Signs\". Notethateachpremiseisseparatedby\";\".\\nOur knowledge graph was directly constructed by human physicians who followed authoritative\\ndiagnosticguidelinesandincorporatedtheirclinicalexperience. ForCardiology,Gastroenterology,\\nNeurology,Pulmonology,andEndocrinology,theknowledgegraphwasbuiltby2,1,2,2,and1\\nspecialists from the respective departments. The construction process involved first defining the\\nprocedural graph g for each category, followed by supplementing g with the detailed premises\\ni i\\ncorresponding to each diagnosis d to build k . The complete knowledge graphs are available on\\ni\\nGitHub(https://github.com/wbw520/DiReCT/tree/master/utils/data_annotation).\\n12Figure9: Demonstrationofourannotationtool.\\nTable10: Promptfornarrowing-downmodule.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreviewaclinical’Note’andyour’Response’istodiagnosethediseasethatthepatienthaveforthisadmission.\\nAllpossiblediseaseoptionsareinaliststructure:{disease_option}.\\nNotethatyoucanonlychooseonediseasefromthediseaseoptionsanddirectlyoutputtheoriginnameofthatdisease.\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour’Response’.\\n’Note’:\\n{note}\\nYour’Response’:\\nA.4 AnnotationandTools\\nWehavedevelopedproprietarysoftwareforannotationpurposes. AsdepictedinFigure9,annotators\\narepresentedwiththeoriginaltextasobservationsoandarerequiredtoproviderationales(z)to\\nexplainwhyaparticularobservationosupportsadiseased. Theleftsectionofthefigure,labeled\\nInput1toInput6,correspondstodifferentpartsoftheclinicalnote,specificallythechiefcomplaint,\\nhistoryofpresentillness,pastmedicalhistory,familyhistory,physicalexam,andpertinentresults,\\nrespectively. Annotatorswilladdtherawtextintothefirstlayerbyleft-clickinganddraggingto\\nselect the original text, then right-clicking to add it. After each observation, a white box will be\\nusedtorecordtherationales. Finally,aconnectionwillbemadefromeachrationaletoadisease,\\nrepresentedinagreybox. Theannotationprocessstrictlyfollowtheknowledgegraph. Boththefinal\\nannotationandtherawclinicalnotewillbesavedinaJSONfile. Weprovidethecodetocompile\\ntheseannotationsanddetailedinstructionsforusingourtoolonGitHub.\\nA.5 AccesstoDiReCT\\nImplementationcodeandannotationtoolareavailablethroughhttps://github.com/wbw520/DiReCT.\\nDatawillbereleasedthroughPhysioNetduetosafetyissuesaccordingtothelicenseofMIMIC-IV\\n(PhysioNetCredentialedHealthDataLicense1.5.0). WewillusethesamelicenseforDiReCT.The\\ndownloadlinkwillbeaccessibleviaGitHub. WeconfirmthatthisGitHublinkanddatalinkare\\nalwaysaccessible. Weconfirmthatwewillbearallresponsibilityincaseofviolationofrights.\\n13Table11: Promptforperceptionmodule.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreviewapartofclinical\"Note\"fromapatient.\\nThediseaseforwhichthepatientwasadmittedtohospitalthistimeis{disease}.\\nYourtaskistoextracttheoriginaltextasconfidence\"Observations\"thatleadto{disease}.\\nHerearesomepremiseforthediagnosisofthisdiseasecategory.Youcanreferthemforyourtask.Premiseare:{premise}\\nNotethatyoualsoneedtobrieflyprovidethe\"Reason\"foryourextraction.\\nNotethatboth\"Observations\"and\"Reason\"shouldbestring.\\nNotethatyour\"Response\"shouldbealiststructureasfollowing\\n:[[\"Observation\",\"Reason\"],......,[\"Observation\",\"Reason\"]]\\nNotethatifyoucan’tfindany\"Observation\"your\"Response\"shouldbe:[].\\nNow,starttocompleteyourtask.\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\n\"Note\":\\n{note}\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\nYour\"Response\":\\nTable12: Promptforreasoningmodule.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreceivealistof\"Observations\"fromaclinical\"Note\".These\"Observations\"arepossiblesupporttodiagnose{disease}.\\nBasedonthese\"Observations\",youneedtodiagnosethe\"Disease\"fromthefollowingoptions:{disease_option}.\\nHerearesomegoldenstandardstodiscriminatediseases.Youcanreferthemforyourtask.Goldenstandardsare:{premise}\\nNotethatyoucanonlychooseone\"Disease\"fromthediseaseoptionsanddirectlyoutputthenameindiseaseoptions.\\nNotethatyoualsorequiredtoselectthe\"Observations\"thatsatisfythegoldenstandardtodiagnosethe\"Disease\"youchoose.\\nNotethatyoualsorequiredtoprovidethe\"Reason\"foryourchoice.\\nNotethatyour\"Response\"shouldbealiststructureasfollowing\\n:[[\"Observation\",\"Reason\",\"Disease\"],......,[\"Observation\",\"Reason\",\"Disease\"]]\\nNotethatifyoucan’tfindany\"Observation\"tosupportadiseaseoption,your\"Response\"shouldbe:None\\nNow,starttocompleteyourtask.\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\n\"Observations\":\\n{observation}\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\nYour\"Response\":\\nB ImplementationofBaselineMethod\\nB.1 PromptSettings\\nInthissection,wedemonstratethepromptweusedforeachmodule(FromTable10-12fornarrowing-\\ndown,perception,andreasoningmodule,respectively).\\nInTable10,{disease_option}isthenameforalldiseasecategories,and{note}isthecontentforthe\\nwholeclinicalnote. Theresponseforthemodelisthenameofapossiblediseaseˆi.\\nInTable11,{disease}isthediseasecategorynamepredictedinnarrowing-down.Thecontentmarked\\nblueisthepremise,whichisonlyprovidedduringtheKsetting. Inthismodule,{premise}isoffered\\nwithallinformationintheknowledgegraph. Differenttonarrowing-down,{note}isimplemented\\nforeachclinicaldataR={r}andtheoutputsarecombinedtogetherforOˆandEˆ.\\nInTable12,{disease}isthediseasecategorynameand{disease_option}isconsistedbythechildren\\nnodes{d }. Similarly,thepremiseontheblueisonlyavailablefortheKsetting. Itprovidesthe\\nn\\npremisethatarecriteriaforthediagnosisofeachchildrennode. {observation}istheextractedOˆin\\npreviousstep. WeprovideallthepromptsandthecompleteimplementationcodeonGitHub.\\nB.2 DiagnosticReasoningUnderConditionsofIncompleteObservation\\nIn real-world scenarios, doctors often have to make diagnoses based on incomplete information.\\nToexplorethis,weconductedexperimentsonthe73amendedcases. Onesetofexperimentsused\\nthe unmodified original notes, labeled as \"Original,\" while the other set used notes with added\\nobservations, labeled as \"Amended.\" We tested three models—Llama3 70B, GPT-3.5-turbo, and\\nGPT-4 turbo—under two settings: one with only the procedural graph G and the other with the\\ncompleteknowledgegraphK. TheresultsarepresentedinTables5and6. Wecanobservethatin\\n14bothGandKsettings,theperformanceontheAmendeddatawasconsistentlybetteracrossallmetrics\\ncomparedtotheOriginaldata. Thissuggeststhatevenasingleaddedobservationcansignificantly\\nimpactthemodel’sdiagnosticreasoning.\\nAdditionally,wefoundthatundertheAmendeddata,usingKledtobothbetterdiagnosticoutcomes\\nandimprovedexplanability,aligningwiththeanalysisinourpaper. However,whenusingKonthe\\nOriginaldata,whileexplanabilityimproved,diagnosticaccuracyactuallydecreased.\\nWeconductedadetailedanalysisofthe73Originaldata’sresultsfromGPT-4. WefoundthatGPT-4\\nwas still able to correctly deduce the final PDD in 24 cases using G and 19 cases using K. This\\nindicates that the model possesses some level of uncertain reasoning capability. However, upon\\nfurtherinspection,wefoundthatinsomecases,themodelusedcompletelyirrationalobservations\\nas evidence, such as directly using \"cough\" as evidence for diagnosing \"bacterial pneumonia\".\\nAdditionally,therewere7casesusingG and13casesusingKwherethereasoningstoppedbefore\\nthefinalPDDdiagnosis. Thissuggeststhatthemodelrecognizedthelackofsufficientevidenceto\\nderivethePDDandadheredfaithfullytothediagnosticknowledgegraph. Moreover,usingappeared\\ntohelpthemodelbetterunderstandthislimitation,however,decreasetheaccuracy. Theseresults\\nindicatethatemployingtheknowledgegraphactsmorelikeatrade-off: usingonlyG resultsina\\nhighertendencyforuncertainreasoning,whileusingthefullKmakesthemodelmorecautious.\\nLimitationofcurrentimplementation. Onceaknowledgegraphisprovided,thefocusshiftsto\\nwhethertheLLMfollowsthegraph’sruleswell. However,weconsidertheknowledgegraphasan\\ninferentialframeworkratherthanasetofrules. Thisframeworkprovidesdecision-makingpathsfor\\ntheLLM,buttheLLMstillneedstoperformreasoningwithinit. Evenwhenstrictlyfollowingthe\\nknowledgegraph,theLLMstillneedstoperformsemanticanalysisandcontextunderstandingin\\nordertoselectthenodethatbestsuitsthecurrentsituationamongmultiplepossiblepaths(sub-nodes)\\nintheknowledgegraph. Therefore,theroleoftheLLMinthisprocessisnotmerelyto’followthe\\nrules,’buttomakelogicalpathselectionsbasedonitsunderstandingoftheinputdata,whichitself\\nisareflectionofreasoningability. Thisoftenrequiresthemodeloralgorithmtoconsiderprevious\\nstepsineachstageofreasoningandtoupdateobservationsaccordingly. Evenreviseorbacktrack\\nthe diagnosis step. However, our baseline method did not account for this and thus cannot fully\\nexploitthiscapabilityoftheLLM,whichisacurrentlimitation. Wedidtrysomedesignstogive\\nthoseabilitiestoLLMs,suchasprovidingpreviousstepsofreasoningforthecurrentstageasinput\\npromptsorupdateobservations. However,evenGPT-4cannotshowhighinstructionfollowingability\\ntorealizethem(maybetheinputistoolongorpromptsettingproblems).\\nForevaluation,weuseddiagnosticprocessesannotatedbyhumandoctorsasgroundtruth. Therefore,\\nwhethertheKGisprovidedornot, themodel’soutputneedstoalignwiththegroundtruth. Our\\ndatasetallowsforevaluationwithandwithouttheKG,butourbaselinemethodisnoteffectiveat\\nhandlingscenarioswithouttheKG(thisismuchmorechallenging). Howtoutilizeandexplorethe\\nLLM’sreasoningabilityinthisscenarioisoneofourfutureresearchdirections.\\nB.3 DetailsofAutomaticEvaluation\\nTheautomaticevaluationisrealizedbyLLama38B.Wedemonstratethepromptforthisimplement\\ninTable13(forobservation)andTable14(forrationalization). Notethatwedonotusefew-shot\\nsamplesfortheevaluationofobservation. InTable13,{gt_observation}and{pred_observation}are\\nfrommodelpredictionandground-truth.Asthisisasimplesimilaritycomparisontasktodiscriminate\\nwhetherthemodelfindssimilarobservationstohumans,LLama3itselfhavesuchability. Wedonot\\nstricttoexactlymatchduetothedifferenceinlengthofextractedrawtext(aslongastheobservation\\nexpressesthesamedescription). InTable14,{gt_reasoning}and{pred_reasoning}arefrommodel\\npredictionandground-truth. Werequiretherationaletobecomplete(contentoftheexpressioncan\\nbeunderstoodfromtherationalealone)andmeaningful;therefore,weprovidefivesamplesforthis\\nevaluation. WealsoprovideallthepromptsandthecompleteimplementationcodeonGitHub.\\nFor human evaluation, among the three specialists, two are from Cardiology and one is from\\nGastroenterology. Giventhatthenotesoriginatefromdifferentmedicaldomains,thereisapossibility\\nthatthespecialistsmaynotbeentirelyaccurate. However,thisevaluationdoesnotdemandhighly\\nspecializedknowledge,anditcanbeadequatelycoveredbytheirexpertise.\\nWealsoincludedanexperimentalresultcomparingthejudgmentdifferencesbetweenLlama38B\\nand GPT-4 Turbo. The evaluation was performed on the diagnostic outcomes (across the entire\\n15Table13: Promptforevaluationofobservation.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreceivetwo\"Observations\"extractedfromapatient’sclinicalnote.\\nYourtaskistodiscriminatewhethertheytextuallydescriptionissimilar?\\nNotethat\"Response\"shouldbeoneselectionfrom\"Yes\"or\"No\".\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour\"Response\".\\n\"Observation1\":{gt_observation}\\n\"Observation2\":{pred_observation}\\nYour\"Response\":\\nTable14: Promptforevaluationofrationalization.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreceivetwo\"Reasoning\"fortheexplanationofwhyanobservationcauseadisease.\\nYourtaskistodiscriminatewhethertheyexplainasimilarmedicaldiagnosispremise?\\nNotethat\"Response\"shouldbeoneselectionfrom\"Yes\"or\"No\".\\nHerearesomesamples:\\nSample1:\\n\"Reasoning1\":Facialsaggingisaclassicsymptomofstroke\\n\"Reasoning2\":Indicatespossiblefacialnervepalsy,acommonsymptomofstroke\\n\"Response\":Yes\\nSample2:\\n\"Reasoning1\":FamilyhistoryofDiabetesisanimportantfactor\\n\"Reasoning2\":Patient’smotherhadahistoryofDiabetes,indicatingapossiblegeneticpredispositiontostroke\\n\"Response\":Yes\\nSample3:\\n\"Reasoning1\":headacheisoneofthecommonsymptomsofHTN\\n\"Reasoning2\":PossiblesymptomofHTN\\n\"Response\":No\\nSample4:\\n\"Reasoning1\":Acutebleedingisoneofthetypicalsymptomsofhemorrhagicstroke\\n\"Reasoning2\":Thepresenceofhigh-densityareasonNon-contrastCTScanisagoldenstandardforHemorrhagicStroke\\n\"Response\":No\\nSample5:\\n\"Reasoning1\":Lossofstrengthononesideofthebody,especiallywhencomparedtotheotherside,isacommonsignofstroke\\n\"Reasoning2\":Supportsischemicstrokediagnosis\\n\"Response\":No\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour\"Response\".\\n\"Reasoning1\":{gt_reasoning}\\n\"Reasoning2\":{pred_reasoning}\\nYour\"Response\":\\ndataset)fromLlama370BandGPT-4Turbo,usingG asadditionalknowledge. Wecalculatedthe\\nconsistencyrateformatchingobservationsandthecorrespondingrationalization. AsshowninTable\\n15,thedifferencesinjudgmentbetweenthetwomodelsarenotobviousandaremoreconsistentin\\nobservationdiscrimination. Therearealsosomevariationsacrossdifferentdiseasedomains,withthe\\nhighestsimilarityinobservationdiscriminationfoundinEndocrinology,whiletherationalizationis\\nmostsimilarinNeurology.\\nAdditionally,weprovidedresultsusingGPT-4Turboforautomaticevaluation,comparedtothose\\nshowninTable16(whichusedLlama38B).TheresultsindicatethatGPT-4Turbotendstoyield\\nhigherobservationmatchingandmorestringentrationalizationdiscrimination. However,thelargest\\ndifferencedoesnotexceed5%. ConsideringthecostofGPT-4,Llama38Bisamoreefficientoption.\\nB.4 MorePredictionSamples\\n10showsanothersamplegeneratedbyGPT-4. Theground-truthPDDoftheinputclinicalnoteis\\nandHeart Failure (HF).Inthesefigures,purple,orange,andredindicateexplanationsonlyin\\nthegroundtruth,onlyinprediction,andcommoninboth,respectively;therefore,redisasuccessful\\npredictionofanexplanation,whilepurpleandorangeareafalsenegativeandfalsepositive.\\n16Table15: JudgementconsistencybetweenLLama38BandGPT-4turbo.\\nLLama370B GPT-4turbo\\nDomain Observation Rationalization Observation Rationalization\\nCardiology 0.885 0.761 0.827 0.861\\n±0.095 ±0.268 ±0.146 ±0.273\\nGastroenterology 0.862 0.676 0.810 0.755\\n±0.088 ±0.361 ±0.167 ±0.316\\nNeurology 0.846 0.831 0.856 0.963\\n±0.090 ±0.211 ±0.124 ±0.106\\nPulmonology 0.808 0.703 0.786 0.779\\n±0.131 ±0.317 ±0.152 ±0.287\\nEndocrinology 0.911 0.783 0.868 0.793\\n±0.104 ±0.304 ±0.145 ±0.340\\nOverall 0.869 0.734 0.838 0.806\\n±0.102 ±0.321 ±0.144 ±0.305\\nTable16: ResultofusingGPT-4turboandLLama38Bforautomaticevaluation.\\nObservation Explanation\\nJudgement Models Obspre Obsrec Obscomp Expcom Expall\\nLLama370B 0.317 0.576 0.294 0.348 0.107\\nGPT-4turbo ±0.161 ±0.195 ±0.159 ±0.300 ±0.118\\nGPT-4turbo 0.465 0.514 0.408 0.437 0.187\\n±0.190 ±0.157 ±0.201 ±0.335 ±0.191\\nLLama370B 0.277 0.537 0.256 0.395 0.112\\nLLama38B ±0.146 ±0.192 ±0.142 ±0.320 ±0.110\\nGPT-4turbo 0.446 0.491 0.371 0.475 0.199\\n±0.207 ±0.180 ±0.186 ±0.363 ±0.181\\nInFigure10,themodel’spredictionsdonotalignwellwiththoseofahumandoctor.Keyobservations,\\nsuch as the relationships between BNP and LVEF, are incorrectly identified, leading to a final\\nmisdiagnosis.\\nB.5 ExperimentsforNoExtraKnowledge\\nWe demonstrate the prompt used for D⋆ and no knowledge settings in Table 17 and Table 18,\\nrespectively. {note}isthetextofwholeclinicalnoteand{disease_options}inTable17isthename\\nofallleafnodeD⋆.\\nB.6 ExperimentalSettings\\nAll experiments are implemented with a temperature value of 0. All close sourced models are\\nimplementedinalocalserverwith4NVIDIAA100GPU.\\nC FailedAttemptsonDiReCT\\nInthissection,wediscusssomeunsuccessfulattemptsduringtheexperiments.\\nExtract observation from the whole clinical note. We try to diagnose the disease and extract\\nobservation, andthecorrespondingrationaleusingthepromptshowninTable19. The{note}is\\nofferedbythewholecontentintheclinicalnote. Wefindthateventhoughthemodelcanmakethe\\ncorrectdiagnosis,onlyafewobservationscanbeextracted(nomorethan4),whichdecreasesthe\\ncompletenessandfaithfulness.\\nWealsoconductedanexperimenttodemonstratethedifferencesbetweentwomethodsofobservation\\nextraction. The \"Iteration\" method is the one used in our paper, while the \"Once\" method is the\\none-timeextractionmethodshowninTable9. Eachmethodwasimplementedundertheconditionof\\nusingGPT-4turboandLlama370BwithG asinputandwasevaluatedbasedontheCompletenessof\\nObservations(Obs)metric. TheresultsarepresentedinTable20. Wefoundthatwhilethe\"Once\"\\nextractionmethodresultedinhigherprecision,itledtoasignificantdropinrecall,severelyimpacting\\nthefinalcompletenessmetric. The\"Once\"methodtendstocapturefewerobservations,whichhinders\\ntheoverallreasoningprocess.\\nEnd-to-Endprediction. Wealsotrytooutputthewholereasoningprocessinonestep(without\\niteration)whengivenobservations. WeshowourpromptinTable21. Wefindthatusingsucha\\npromptmodelcannotcorrectlyrecognizetherelationbetweenobservation,rationale,anddiagnosis.\\n17Chief Complaint: scrotal and leg swelling. Swelling in the legs can be a sign Peripheral oedema is a Suspected\\nPresent History: He was seen ********************** anasarca. At of fluid retention, which is a sign of heart failure HF\\nthat time, his lasix was increased from *********** to ****** BID. In common symptom of heart failure.\\nthe ED initial vitals ***************************98% RA. Blood\\np sir ge ns is fiu cr ae n tr e fm ora i *n *e **d * *2 **0 *0 */ *9 **0 * *t *h *r *o **u *g *h **o u st i nth cee E __D _ c (o 1u .r *s **e *. * *L *a **b *s -> w 3e .2r )e . aC ssa ord ci ia ac te e df f wus iti ho n hs e aa rr te f ao if lt ue rn e, BNP ≥ 35 pg/mL is a strong Strongly\\nEKG was consistent with priors (NSR, NANI, no ischemic indicating fluid overload or value for heart failure Suspected HF\\nchanges). CXR showed mild pulmonary edema. He was given heart dysfunction\\n*********with good UOP. Bedside cardiac ultrasound w/mild\\neffusion no evidence of tamponade physiology. Bedside scrotal Elevated proBNP levels are a BNP ≥ 35 pg/mL is a strong\\n*****************, no evidence of vascular compromise.... biomarker for heart failure, indicating value for heart failure HF\\nPertinet Results: 07:10AM BLOOD C3-142 C4-27 proBNP-5145 cardiac stress and heart dysfunction\\n... The left atrium is moderately dilated. No atrial septal defect is\\nseen **************** Doppler. ... Overall left ventricular systolic LVEF in the range of 45-50% suggests\\nf mu on tc iotio nn a i bs n m ori mldl ay l id tiee sp .r essed (LVEF= 45-50 %) without regional wall pre fs ue nr cv te iod n o , r a m ligil nd il ny g r e wd iu thc e Hd F psy Es Ftolic 40 c≤ riL tiV erE aF f＜ or 5 H0 F% m i rs E t Fhe HFmrEF HFpEF\\nClinical Note Rationale Diagnosis\\nFigure10: AnexamplepredictionforaclinicalnotewithPDDofHFbyGPT-4\\nTable17: PromptforD⋆setting.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreviewaclinical’Note’andyour’Response’istodiagnosethediseasethatthepatienthaveforthisadmission.\\nAllpossiblediseaseoptionsareinaliststructure:{disease_options}.\\nNotethatyoucanonlychooseonediseasefromthediseaseoptionsanddirectlyoutputtheoriginnameofthatdisease.\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour’Response’.\\n’Note’:\\n{note}\\nYour’Response’:\\nD EthicalConsiderations\\nUtilizing real-world EHRs, even in a de-identified form, poses inherent risks to patient privacy.\\nTherefore,itisessentialtoimplementrigorousdataprotectionandprivacymeasurestosafeguard\\nsensitiveinformation,inaccordancewithregulationssuchasHIPAA.WestrictlyadheretotheData\\nUseAgreementoftheMIMICdataset,ensuringthatthedataisnotsharedwithanythirdparties. All\\nexperimentsareimplementonaprivateserver. TheaccesstoGPTisalsoaprivateversion.\\nAImodelsaresusceptibletoreplicatingandevenintensifyingthebiasesinherentintheirtraining\\ndata. Thesebiases,ifnotaddressed,canhaveprofoundimplications,particularlyinsensitivedomains\\nsuchashealthcare. Unconsciousbiasesinhealthcaresystemscanresultinsignificantdisparities\\ninthequalityofcareandhealthoutcomesamongdifferentdemographicgroups. Therefore, itis\\nimperativetorigorouslyexamineAImodelsforpotentialbiasesandimplementrobustmechanisms\\nforongoingmonitoringandevaluation. Thisinvolvesanalyzingthemodel’sperformanceacross\\nvariousdemographicgroups,identifyinganydisparities,andmakingnecessaryadjustmentstoensure\\nequitable treatment for all. Continual vigilance and proactive measures are essential to mitigate\\ntheriskofbiaseddecision-makingandtoupholdtheprinciplesoffairnessandjusticeinAI-driven\\nhealthcaresolutions.\\n18Table18: Promptfornoknowledgesetting.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreviewaclinical’Note’andyour’Response’istodiagnosethediseasethatthepatienthaveforthisadmission.\\nNotethatyoucanonlygiveonediseasenameanddirectlyoutputthenameofthat\"Disease\".\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour’Response’.\\n’Note’:\\n{note}\\nYour’Response’:\\nTable19: Promptforextractingobservationinonestep.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreviewaclinical’Note’,andyour’Response’istodiagnosethediseasethatthepatienthasforthisadmission.\\nAllpossiblediseaseoptionsareinaliststructure:{disease_options}.\\nNotethatyoucanonlychooseonediseasefromthediseaseoptionsanddirectlyoutputtheoriginnameofthatdisease.\\nNotethatyoualsoneedtoextractoriginaltextasconfidence\"Observations\"thatleadtothe\"Disease\"youselected.\\nNotethatyoushouldextractallnecessary\"Observation\".\\nNotethatyoualsoneedtobrieflyprovidethe\"Reason\"foryourextraction.\\nNotethatboth\"Observations\"and\"Reason\"shouldbestring.\\nNotethatyour\"Response\"shouldbealiststructureasfollowing\\n:[[\"Observation\",\"Reason\",\"Disease\"],......,[\"Observation\",\"Reason\",\"Disease\"]]\\nNow,starttocompleteyourtask.\\nDon’toutputanyinformationotherthanyour’Response’.\\n’Note’\\n:{note}\\nYour’Response’:\\n19Table20: ComparisonforusingIterationandOnceforobservationextraction.\\nIteration Once\\nModels Obspre Obsrec Obscomp Obspre Obsrec Obscomp\\nLLama370B 0.277 0.537 0.256 0.325 0.324 0.185\\n±0.146 ±0.192 ±0.142 ±0.207 ±0.147 ±0.107\\nGPT-4turbo 0.446 0.491 0.371 0.567 0.287 0.244\\n±0.207 ±0.180 ±0.186 ±0.268 ±0.156 ±0.147\\nTable21: PromptforEnd-to-Endprediction.\\nInputPrompt\\nSupposeyouareoneofthegreatestAIscientistsandmedicalexpert.Letusthinkstepbystep.\\nYouwillreceivealistof\"Observations\"fromaclinical\"Note\"forthediagnosisofstroke.\\nHereisthediagnosticrouteofstrokeinatreestructure:\\n-SuspectedStroke\\n-HemorrhagicStroke\\n-IschemicStroke\\nHerearesomepremiseforthediagnosisofthisdisease.Youcanreferthemforyourtask.Premiseare:{premise}\\nBasedonthese\"Observations\",startingfromtherootdisease,yourtargetistodiagnoseoneoftheleafdisease.\\nNotethatyoualsorequiredtoprovidethe\"Reason\"foryourreasoning.\\nNotethatyour\"Response\"shouldbealiststructureasfollowing\\n:[[\"Observation\",\"Reason\",\"Disease\"],......,[\"Observation\",\"Reason\",\"Disease\"]]\\nNotethatifyoucan’tfindany\"Observation\"tosupportadiseaseoption,your\"Response\"shouldbe:None\\nNow,starttocompleteyourtask.\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\n\"Observations\":\\n{observation}\\nNotethatyoushouldnotoutputanyinformationotherthanyour\"Response\".\\nYour\"Response\":\\nReferences\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,\\nBeichenZhang,JunjieZhang,ZicanDong,YifanDu,ChenYang,YushuoChen,ZhipengChen,\\nJinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and\\nJi-RongWen. Asurveyoflargelanguagemodels. arXivpreprintarXiv:2303.18223,2023.\\nBonanMin,HayleyRoss,EliorSulem,AmirPouranBenVeyseh,ThienHuuNguyen,OscarSainz,\\nEnekoAgirre,IlanaHeintz,andDanRoth. Recentadvancesinnaturallanguageprocessingvia\\nlargepre-trainedlanguagemodels: Asurvey. ACMComputingSurveys,56(2):1–40,2023.\\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,\\nSiamakShakeri,EmanuelTaropa,PaigeBailey,ZhifengChen,etal. Palm2technicalreport. arXiv\\npreprintarXiv:2305.10403,2023.\\nTianyuHan,LisaCAdams,Jens-MichalisPapaioannou,PaulGrundmann,TomOberhauser,Alexan-\\nderLöser,DanielTruhn,andKenoKBressem. Medalpaca–anopen-sourcecollectionofmedical\\nconversationalaimodelsandtrainingdata. arXivpreprintarXiv:2304.08247,2023.\\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What\\ndiseasedoesthispatienthave? alarge-scaleopendomainquestionansweringdatasetfrommedical\\nexams. AppliedSciences,11(14):6421,2021.\\nOpenAI. GPT-4TechnicalReport. CoRR,abs/2303.08774,2023a. doi: 10.48550/arXiv.2303.08774.\\nURLhttps://doi.org/10.48550/arXiv.2303.08774.\\nSébastienBubeck,VarunChandrasekaran,RonenEldan,JohannesGehrke,EricHorvitz,EceKamar,\\nPeterLee,YinTatLee,YuanzhiLi,ScottLundberg,etal. Sparksofartificialgeneralintelligence:\\nEarlyexperimentswithgpt-4. arXivpreprintarXiv:2303.12712,2023.\\nHarshaNori,NicholasKing,ScottMayerMcKinney,DeanCarignan,andEricHorvitz. Capabilities\\nofgpt-4onmedicalchallengeproblems. arXivpreprintarXiv:2303.13375,2023.\\n20ValentinLiévin,ChristofferEgebergHother,AndreasGeertMotzfeldt,andOleWinther. Canlarge\\nlanguagemodelsreasonaboutmedicalquestions? Patterns,5(3),2024.\\nAnkitPal,LogeshKumarUmapathi,andMalaikannanSankarasubbu. MedMCQA:Alarge-scale\\nmulti-subject multi-choice dataset for medical domain question answering. In Conference on\\nhealth,inference,andlearning,pages248–260.PMLR,2022.\\nDongfangLi,JindiYu,BaotianHu,ZhenranXu,andMinZhang.ExplainCPE:Afree-textexplanation\\nbenchmarkofchinesepharmacistexamination. arXivpreprintarXiv:2305.12945,2023.\\nHanjieChen,ZhouxiangFang,YashSingla,andMarkDredze. Benchmarkinglargelanguagemodels\\nonansweringandexplainingchallengingmedicalquestions. arXivpreprintarXiv:2402.18060,\\n2024.\\nMael Jullien, Marco Valentino, Hannah Frost, Paul O’Regan, Donal Landers, and André Freitas.\\nSemeval-2023 task 7: Multi-evidence natural language inference for clinical trial data. arXiv\\npreprintarXiv:2305.02993,2023.\\nYanjunGao,RuizheLi,JohnCaskey,DmitriyDligach,TimothyMiller,MatthewMChurpek,and\\nMajidAfshar. Leveragingamedicalknowledgegraphintolargelanguagemodelsfordiagnosis\\nprediction. arXivpreprintarXiv:2308.14321,2023a.\\nAlistairE.W.Johnson,LucasBulgarelli,LuShen,AlvinGayles,AyadShammout,StevenHorng,\\nTomJ.Pollard,SichengHao,BenjaminMoody,BrianGow,Li-weiH.Lehman,LeoA.Celi,and\\nRogerG.Mark. MIMIC-IV,afreelyaccessibleelectronichealthrecorddataset. Scientificdata,10\\n(1):1,2023.\\nZhihengXi,WenxiangChen,XinGuo,WeiHe,YiwenDing,BoyangHong,MingZhang,Junzhe\\nWang,SenjieJin,EnyuZhou,RuiZheng,XiaoranFan,XiaoWang,LimaoXiong,YuhaoZhou,\\nWeiranWang,ChanghaoJiang,YichengZou,XiangyangLiu,ZhangyueYin,ShihanDou,Rongx-\\niang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing\\nHuang,andTaoGui. Theriseandpotentialoflargelanguagemodelbasedagents: Asurvey,2023.\\nXiangruTang,AnniZou,ZhuoshengZhang,YilunZhao,XingyaoZhang,ArmanCohan,andMark\\nGerstein. Medagents: Largelanguagemodelsascollaboratorsforzero-shotmedicalreasoning.\\narXivpreprintarXiv:2311.10537,2023.\\nBlackford Middleton, Meryl Bloomrosen, Mark A Dente, Bill Hashmat, Ross Koppel, J Marc\\nOverhage,ThomasHPayne,STrentRosenbloom,CharlotteWeaver,andJiajieZhang. Enhancing\\npatientsafetyandqualityofcarebyimprovingtheusabilityofelectronichealthrecordsystems:\\nrecommendationsfromamia. JournaloftheAmericanMedicalInformaticsAssociation,20(e1):\\ne2–e8,2013.\\nJinghui Liu, Daniel Capurro, Anthony Nguyen, and Karin Verspoor. “note bloat” impacts deep\\nlearning-basednlpmodelsforclinicalpredictiontasks. Journalofbiomedicalinformatics,133:\\n104149,2022.\\nBhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan Xie, Hannah Smith, Leighanna Pi-\\npatanangkura, and Peter Clark. Explaining answers with entailment trees. In Proceedings of\\nthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7358–7370,\\n2021.\\nMarinaDanilevsky,KunQian,RanitAharonov,YannisKatsis,BanKawas,andPrithvirajSen. A\\nsurveyofthestateofexplainableAIfornaturallanguageprocessing. InProceedingsofthe1st\\nConferenceoftheAsia-PacificChapteroftheAssociationforComputationalLinguisticsandthe\\n10thInternationalJointConferenceonNaturalLanguageProcessing,pages447–459,2020.\\nSaiGurrapu,AjayKulkarni,LifuHuang,IsminiLourentzou,andFerasABatarseh. Rationalization\\nforexplainablenlp: Asurvey. FrontiersinArtificialIntelligence,6,2023.\\nOana-MariaCamburu,TimRocktäschel,ThomasLukasiewicz,andPhilBlunsom. e-snli: Natural\\nlanguageinferencewithnaturallanguageexplanations.AdvancesinNeuralInformationProcessing\\nSystems,31,2018.\\n21NazneenFatemaRajani,BryanMcCann,CaimingXiong,andRichardSocher. Explainyourself!\\nleveraging language models for commonsense reasoning. In Proceedings of the 57th Annual\\nMeetingoftheAssociationforComputationalLinguistics,pages4932–4942,Florence,Italy,2019.\\nJayDeYoung,SarthakJain,NazneenFatemaRajani,EricLehman,CaimingXiong,RichardSocher,\\nandByronC.Wallace. ERASER:AbenchmarktoevaluaterationalizedNLPmodels. InPro-\\nceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages\\n4443–4458,2020.\\nHarshJhamtaniandPeterClark. Learningtoexplain: Datasetsandmodelsforidentifyingvalid\\nreasoning chains in multihop question-answering. In Proceedings of the 2020 Conference on\\nEmpiricalMethodsinNaturalLanguageProcessing,page137–150,2020.\\nOyvindTafjord,BhavanaDalviMishra,andPeterClark.Proofwriter:Generatingimplications,proofs,\\nandabductivestatementsovernaturallanguage. InFindingsoftheAssociationforComputational\\nLinguistics: ACL-IJCNLP,page3621–3634,2021.\\nChenZhao,ChenyanXiong,JordanBoyd-Graber,andHalDauméIII. Multi-stepreasoningover\\nunstructured text with beam dense retrieval. In Proceedings of the 2021 Conference of the\\nNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguage\\nTechnologies,pages4635–4641,2021.\\nYifanZhang,JingqinYang,YangYuan,andAndrewChi-ChihYao. Cumulativereasoningwithlarge\\nlanguagemodels. InICLR2024WorkshoponBridgingtheGapBetweenPracticeandTheoryin\\nDeepLearning,2024. URLhttps://openreview.net/forum?id=XAAYyRxTlQ.\\nYanjunGao,DmitriyDligach,TimothyMiller,SamuelTesch,RyanLaffin,MatthewM.Churpek,and\\nMajidAfshar. Hierarchicalannotationforbuildingasuiteofclinicalnaturallanguageprocessing\\ntasks: Progressnoteunderstanding. InProceedingsoftheThirteenthLanguageResourcesand\\nEvaluationConference,pages5484–5493,Marseille,France,2022.EuropeanLanguageResources\\nAssociation.\\nTravisZack,GurpreetDhaliwal,RabihGeha,MaryMargaretten,SaraMurray,andJulianCHong. A\\nclinicalreasoning-encodedcaselibrarydevelopedthroughnaturallanguageprocessing. Journalof\\nGeneralInternalMedicine,38(1):5–11,2023.\\nYanjunGao,DmitriyDligach,TimothyMiller,JohnCaskey,BrihatSharma,MatthewMChurpek,\\nand Majid Afshar. Dr. bench: Diagnostic reasoning benchmark for clinical natural language\\nprocessing. JournalofBiomedicalInformatics,138:104286,2023b.\\nL.L.Weed. MedicalRecords,MedicalEducation,andPatientCare: TheProblem-orientedRecord\\nasaBasicTool. PressofCaseWesternReserveUniversity,1970. ISBN9780815191889.\\nOlivierBodenreider.Theunifiedmedicallanguagesystem(umls):integratingbiomedicalterminology.\\nNucleicacidsresearch,32(suppl_1):D267–D270,2004.\\nAI@Meta. Llama3modelcard. 2024. URLhttps://github.com/meta-llama/llama3/blob/\\nmain/MODEL_CARD.md.\\nLewisTunstall,EdwardBeeching,NathanLambert,NazneenRajani,KashifRasul,YounesBelkada,\\nShengyiHuang,LeandrovonWerra,ClémentineFourrier,NathanHabib,etal. Zephyr: Direct\\ndistillationoflmalignment. arXivpreprintarXiv:2310.16944,2023.\\nAlbertQJiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,DevendraSinghChaplot,\\nDiegodelasCasas,FlorianBressand,GiannaLengyel,GuillaumeLample,LucileSaulnier,etal.\\nMistral7b. arXivpreprintarXiv:2310.06825,2023.\\nOpenAI. IntroducingChatGPTandWhisperAPIs. 2023b. URLhttps://openai.com/blog/\\nintroducing-chatgpt-and-whisper-apis.\\nRobertAByrne, XavierRossello, JJCoughlan, EmanueleBarbato, ColinBerry, AlaideChieffo,\\nMarcJClaeys,Gheorghe-AndreiDan,MarcRDweck,MaryGalbraith,etal. 2023escguidelines\\nforthemanagementofacutecoronarysyndromes: developedbythetaskforceonthemanagement\\nofacutecoronarysyndromesoftheeuropeansocietyofcardiology(esc). EuropeanHeartJournal:\\nAcuteCardiovascularCare,13(1):55–161,2024.\\n22HiroakiKitaoka,ChisatoIzumi,YasuhiroIzumiya,TakayukiInomata,MitsuharuUeda,ToruKubo,\\nJun Koyama, Motoaki Sano, Yoshiki Sekijima, Nobuhiro Tahara, et al. Jcs 2020 guideline on\\ndiagnosisandtreatmentofcardiacamyloidosis. CirculationJournal,84(9):1610–1671,2020.\\nWritingCommitteeMembers,EricMIsselbacher,OuraniaPreventza,JamesHamiltonBlackIII,\\nJohnGAugoustides,AdamWBeck,MichaelABolen,AlanCBraverman,BruceEBray,MayaM\\nBrown-Zimmerman,etal. 2022acc/ahaguidelineforthediagnosisandmanagementofaortic\\ndisease: areportoftheamericanheartassociation/americancollegeofcardiologyjointcommittee\\nonclinicalpracticeguidelines. JournaloftheAmericanCollegeofCardiology,80(24):e223–e393,\\n2022.\\nJosé A Joglar, Mina K Chung, Anastasia L Armbruster, Emelia J Benjamin, Janice Y Chyou,\\nEdmondMCronin,AnitaDeswal,LeeLEckhardt,ZacharyDGoldberger,RakeshGopinathannair,\\netal. 2023acc/aha/accp/hrsguidelineforthediagnosisandmanagementofatrialfibrillation: a\\nreportoftheamericancollegeofcardiology/americanheartassociationjointcommitteeonclinical\\npracticeguidelines. Circulation,149(1):e1–e156,2024.\\nSteve R Ommen, Seema Mital, Michael A Burke, Sharlene M Day, Anita Deswal, Perry Elliott,\\nLaurenLEvanovich,JudyHung,JoséAJoglar,PaulKantor,etal. 2020aha/accguidelinefor\\nthediagnosisandtreatmentofpatientswithhypertrophiccardiomyopathy: executivesummary: a\\nreportoftheamericancollegeofcardiology/americanheartassociationjointcommitteeonclinical\\npracticeguidelines. JournaloftheAmericanCollegeofCardiology,76(25):3022–3055,2020.\\nPaulAHeidenreich,BiykemBozkurt,DavidAguilar,LarryAAllen,JoniJByun,MonicaMColvin,\\nAnitaDeswal,MarkHDrazner,ShannonMDunlay,LindaREvers,etal. 2022aha/acc/hfsaguide-\\nlineforthemanagementofheartfailure: areportoftheamericancollegeofcardiology/american\\nheartassociationjointcommitteeonclinicalpracticeguidelines. JournaloftheAmericanCollege\\nofCardiology,79(17):e263–e421,2022.\\nLillySu,ReaMittal,DevyaniRamgobin,RahulJain,andRohitJain. Currentmanagementguidelines\\nonhyperlipidemia: thesilentkiller. Journaloflipids,2021(1):9883352,2021.\\nFrançoisMach,ColinBaigent,AlbericoLCatapano,KonstantinosCKoskinas,ManuelaCasula,\\nLinaBadimon,MJohnChapman,GuyGDeBacker,VictoriaDelgado,BrianAFerence,etal.\\n2019 esc/eas guidelines for the management of dyslipidaemias: lipid modification to reduce\\ncardiovascularrisk: Thetaskforceforthemanagementofdyslipidaemiasoftheeuropeansociety\\nofcardiology(esc)andeuropeanatherosclerosissociety(eas). Europeanheartjournal,41(1):\\n111–188,2020.\\nThomasUnger,ClaudioBorghi,FadiCharchar,NadiaAKhan,NeilRPoulter,DorairajPrabhakaran,\\nAgustinRamirez,MarkusSchlaich,GeorgeSStergiou,MaciejTomaszewski,etal. 2020inter-\\nnationalsocietyofhypertensionglobalhypertensionpracticeguidelines. Hypertension, 75(6):\\n1334–1357,2020.\\nShailjaCShah,MBlancaPiazuelo,ErnstJKuipers,andDanLi. Agaclinicalpracticeupdateon\\nthe diagnosis and management of atrophic gastritis: expert review. Gastroenterology, 161(4):\\n1325–1332,2021.\\nChineseSocietyofGastroenterology,CancerCollaborationGroupofChineseSocietyofGastroen-\\nterology,andChineseMedicalAssociation. Guidelinesfordiagnosisandtreatmentofchronic\\ngastritisinchina(2022,shanghai). JournalofDigestiveDiseases,24(3):150–180,March2023.\\ndoi: 10.1111/1751-2980.13193.\\nMatthewBanks,DavidGraham,MarnixJansen,TakujiGotoda,SergioCoda,MassimilianoDiPietro,\\nNoriya Uedo, Pradeep Bhandari, D Mark Pritchard, Ernst J Kuipers, et al. British society of\\ngastroenterologyguidelinesonthediagnosisandmanagementofpatientsatriskofgastricadeno-\\ncarcinoma. Gut,68(9):1545–1575,2019.\\nChungMChow,AlexanderKCLeung,andKamLHon. Acutegastroenteritis: fromguidelinesto\\nreallife. Clinicalandexperimentalgastroenterology,pages97–112,2010.\\nCPrakashGyawali,RenaYadlapati,RonnieFass,DavidKatzka,JohnPandolfino,EdoardoSavarino,\\nDanielSifrim,StuartSpechler,FrankZerbib,MarkRFox,etal. Updatestothemoderndiagnosis\\nofgerd: Lyonconsensus2.0. Gut,73(2):361–371,2024.\\n23Robert T Kavitt, Anna M Lipowska, Adjoa Anyane-Yeboa, and Ian M Gralnek. Diagnosis and\\ntreatmentofpepticulcerdisease. TheAmericanjournalofmedicine,132(4):447–456,2019.\\nAntonioTarasconi,FedericoCoccolini,WalterLBiffl,MatteoTomasoni,LucaAnsaloni,Edoardo\\nPicetti,SarahMolfino,VishalShelat,StefaniaCimbanassi,DieterGWeber,etal. Perforatedand\\nbleedingpepticulcer: Wsesguidelines. Worldjournalofemergencysurgery,15:1–24,2020.\\nAlanNBarkun,MajidAlmadi,ErnstJKuipers,LorenLaine,JosephSung,FrancesTse,GrigoriosI\\nLeontiadis,NeenaSAbraham,XavierCalvet,FrancisKLChan,etal. Managementofnonvariceal\\nupper gastrointestinal bleeding: guideline recommendations from the international consensus\\ngroup. Annalsofinternalmedicine,171(11):805–822,2019.\\nGuyMcKhann,DavidDrachman,MarshallFolstein,RobertKatzman,DonaldPrice,andEmanuelM\\nStadlan. Clinical diagnosis of alzheimer’s disease: Report of the nincds-adrda work group*\\nundertheauspicesofdepartmentofhealthandhumanservicestaskforceonalzheimer’sdisease.\\nNeurology,34(7):939–939,1984.\\nIgaku-Shoin-Ltd. Clinicalpracticeguidelinesforepilepsy2018. 2018.\\nRichard B Lipton, Seymour Diamond, Michael Reed, Merle L Diamond, and Walter F Stewart.\\nMigrainediagnosisandtreatment: resultsfromtheamericanmigrainestudyii. Headache: The\\nJournalofHeadandFacePain,41(7):638–645,2001.\\nA.K.Eigenbrodt,H.Ashina,S.Khan,H.C.Diener,D.D.Mitsikostas,A.J.Sinclair,P.Pozo-Rosich,\\nP.Martelletti,A.Ducros,M.Lantéri-Minet,M.Braschinsky,M.S.DelRio,O.Daniel,A.Özge,\\nA.Mammadbayli,M.Arons,K.Skorobogatykh,V.Romanenko,G.M.Terwindt,K.Paemeleire,\\nS.Sacco,U.Reuter,C.Lampl,H.W.Schytz,Z.Katsarava,T.J.Steiner,andM.Ashina. Diagnosis\\nandmanagementofmigraineintensteps.NatureReviewsNeurology,17(8):501–514,August2021.\\ndoi: 10.1038/s41582-021-00509-5. URLhttps://doi.org/10.1038/s41582-021-00509-5.\\nEpub2021Jun18.\\nHeadacheClassificationCommitteeoftheInternationalHeadacheSociety(IHS). Theinternational\\nclassification of headache disorders, 3rd edition. Cephalalgia, 38(1):1–211, Jan 2018. doi:\\n10.1177/0333102417738202.\\nFredDLublin. Clinicalfeaturesanddiagnosisofmultiplesclerosis. Neurologicclinics,23(1):1–15,\\n2005.\\nWJBrownlee,TAHardy,FFazekas,andDHMiller. Diagnosisofmultiplesclerosis: progressand\\nchallenges. Lancet,389(10076):1336–1346,Apr12017. doi: 10.1016/S0140-6736(16)30959-X.\\nURLhttps://doi.org/10.1016/S0140-6736(16)30959-X.\\nDawn O Kleindorfer, Amytis Towfighi, Seemant Chaturvedi, Kevin M Cockroft, Jose Gutierrez,\\nDebbie Lombardi-Hill, Hooman Kamel, Walter N Kernan, Steven J Kittner, Enrique C Leira,\\netal. 2021guidelineforthepreventionofstrokeinpatientswithstrokeandtransientischemic\\nattack: aguidelinefromtheamericanheartassociation/americanstrokeassociation. Stroke,52(7):\\ne364–e467,2021.\\nAmirQaseem,TimothyJWilt,StevenEWeinberger,NicolaAHanania,GerardCriner,Thysvander\\nMolen,DarcyDMarciniuk,TomDenberg,HolgerSchünemann,WisiaWedzicha,etal. Diagnosis\\nandmanagementofstablechronicobstructivepulmonarydisease: aclinicalpracticeguideline\\nupdatefromtheamericancollegeofphysicians,americancollegeofchestphysicians,american\\nthoracicsociety,andeuropeanrespiratorysociety. Annalsofinternalmedicine,155(3):179–191,\\n2011.\\nEricDBateman,SuzanneSHurd,PeterJBarnes,JeanBousquet,JeffreyMDrazen,MarkFitzGerald,\\nPeterGibson,KenOhta,PaulO’Byrne,SorenErikPedersen,etal. Globalstrategyforasthma\\nmanagement and prevention: Gina executive summary. European respiratory journal, 31(1):\\n143–178,2007.\\nSeleneBaos,DavidCalzada,LucíaCremades-Jimeno,JoaquínSastre,CésarPicado,JoaquínQuiralte,\\nFernando Florido, Carlos Lahoz, and Blanca Cárdaba. Nonallergic asthma and its severity:\\nbiomarkersforitsdiscriminationinperipheralsamples. FrontiersinImmunology,9:1416,2018.\\n24DheerajGupta,RiteshAgarwal,AshutoshNathAggarwal,VNMaturu,SahajalDhooria,KTPrasad,\\nInderpaulSSehgal,LakshmikantBYenge,AdityaJindal,NavneetSingh,etal. Guidelinesfor\\ndiagnosisandmanagementofchronicobstructivepulmonarydisease: Jointics/nccp(i)recommen-\\ndations. LungIndia,30(3):228–267,2013.\\nGregoryOlsonandAndrewMDavis. Diagnosisandtreatmentofadultswithcommunity-acquired\\npneumonia. Jama,323(9):885–886,2020.\\nSYNOPSISOFRECOMMENDATIONS. Guidelinesfordiagnosisandmanagementofcommunity\\nandhospitalacquiredpneumoniainadults: Jointics/nccp(i)recommendations. IndianJChestDis\\nAlliedSci,54:267–281,2012.\\nMichaelSNiederman,LionelAMandell,AntonioAnzueto,JohnBBass,WilliamABroughton,\\nGDouglasCampbell,NathanDean,ThomasFile,MichaelJFine,PeterAGross,etal. Guidelines\\nfor the management of adults with community-acquired pneumonia: diagnosis, assessment of\\nseverity,antimicrobialtherapy,andprevention. Americanjournalofrespiratoryandcriticalcare\\nmedicine,163(7):1730–1754,2001.\\nStavrosVKonstantinides,GuyMeyer,CeciliaBecattini,HéctorBueno,Geert-JanGeersing,Veli-\\nPekkaHarjola,MennoVHuisman,MarcHumbert,CatrionaSianJennings,DavidJiménez,etal.\\n2019escguidelinesforthediagnosisandmanagementofacutepulmonaryembolismdeveloped\\nincollaborationwiththeeuropeanrespiratorysociety(ers)thetaskforceforthediagnosisand\\nmanagementofacutepulmonaryembolismoftheeuropeansocietyofcardiology(esc). European\\nheartjournal,41(4):543–603,2020.\\nDavid M Lewinsohn, Michael K Leonard, Philip A LoBue, David L Cohn, Charles L Daley,\\nEdDesmond,JosephKeane,DeborahALewinsohn,AnnMLoeffler,GeraldHMazurek,etal.\\nOfficialamericanthoracicsociety/infectiousdiseasessocietyofamerica/centersfordiseasecon-\\ntrolandpreventionclinicalpracticeguidelines: diagnosisoftuberculosisinadultsandchildren.\\nClinicalInfectiousDiseases,64(2):e1–e33,2017.\\nEvangeliaCharmandari,NicolasCNicolaides,andGeorgePChrousos. Adrenalinsufficiency. The\\nLancet,383(9935):2152–2167,2014.\\nToshihiko Yanase, Toshihiro Tajima, Takuyuki Katabami, Yasumasa Iwasaki, Yusuke Tanahashi,\\nAkira Sugawara, Tomonobu Hasegawa, Tomoatsu Mune, Yutaka Oki, Yuichi Nakagawa, et al.\\nDiagnosisandtreatmentofadrenalinsufficiencyincludingadrenalcrisis: ajapanendocrinesociety\\nclinicalpracticeguideline[opinion]. Endocrinejournal,63(9):765–784,2016.\\nStefanRBornstein,BrunoAllolio,WiebkeArlt,AndreasBarthel,AndrewDon-Wauchope,GaryD\\nHammer,EysteinSHusebye,DeborahPMerke,MHassanMurad,ConstantineAStratakis,etal.\\nDiagnosisandtreatmentofprimaryadrenalinsufficiency: anendocrinesocietyclinicalpractice\\nguideline. TheJournalofClinicalEndocrinology&Metabolism,101(2):364–389,2016.\\nNuha A ElSayed, Grazia Aleppo, Vanita R Aroda, Raveendhara R Bannuru, Florence M Brown,\\nDennisBruemmer,BillySCollins,KennethCusi,MarisaEHilliard,DianaIsaacs,etal. 4.compre-\\nhensivemedicalevaluationandassessmentofcomorbidities: Standardsofcareindiabetes—2023.\\nDiabetesCare,46(Suppl1):s49,2023.\\nNicholasATritosandKarenKMiller. Diagnosisandmanagementofpituitaryadenomas: areview.\\nJama,329(16):1386–1398,2023.\\nJulianaDrummond,FedericoRoncaroli,AshleyBGrossman,andMártaKorbonits. Clinicaland\\npathological aspects of silent pituitary adenomas. The Journal of Clinical Endocrinology &\\nMetabolism,104(7):2473–2489,2019.\\nOdeliaCooperandShlomoMelmed. Subclinicalhyperfunctioningpituitaryadenomas: thesilent\\ntumors. Bestpractice&researchClinicalendocrinology&metabolism,26(4):447–460,2012.\\nSarahEMaysonandPeterJSnyder. Silent(clinicallynonfunctioning)pituitaryadenomas. Journal\\nofneuro-oncology,117:429–436,2014.\\n25K AlexanderErik, N PearceElizabeth, A BrentGregory, S BrownRosalind, A GrobmanWilliam,\\nH LazarusJohn, J MandelSusan, P PeetersRobin, et al. 2017 guidelines of the american thy-\\nroidassociationforthediagnosisandmanagementofthyroiddiseaseduringpregnancyandthe\\npostpartum. Thyroid,2017.\\n26',\n",
       " 'DPO Kernels  A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization.pdf': '- A Semantically-Aware, Kernel-Enhanced, and Divergence-\\nRich Paradigm for Direct Preference Optimization\\nKERNELS\\nAmitavaDas1,SuranjanaTrivedy1,DanushKhanna1,RajarshiRoy1,GurpreetSingh1,\\nBasabGhosh1,YaswanthNarsupalli1,VinijaJain2*,VasuSharma2*,\\nAishwaryaNareshReganti3,AmanChadha3†\\n1ArtificialIntelligenceInstitute,UniversityofSouthCarolina,USA\\n2MetaAI,USA3AmazonAI,USA\\nAbstract large-scalesemanticmodeling. Thisapproach\\nautomaticallyselectstheoptimalkernelmix-\\nTherapidadvancementoflargelanguagemod- tureduringtraining,enhancingmodelingflexi-\\nels(LLMs)hasrevolutionizednumerousappli- bility. Evaluationson12datasetsdemonstrate\\ncations,butpresentssignificantchallengesin thatDPO-Kernelsachievestate-of-the-artgen-\\naligningthesemodelswithdiversehumanval- eralizationinfactuality,safety,reasoning,and\\nues,ethicalstandards,andspecificuserprefer- instruction following. While alignment gen-\\nences. DirectPreferenceOptimization(DPO) erallycarriestheriskofoverfitting,grounded\\nhasbecomeacornerstoneforpreferencealign- inHeavy-TailedSelf-Regularization(HT-SR)\\nment but is constrained by reliance on fixed theory,weshowthatDPO-Kernelsmaintainro-\\ndivergencemeasuresandlimitedfeaturetrans- bustgeneralizationboundsinLLMs. Compre-\\nformations. We introduce DPO-Kernels, an hensiveresourcesareavailabletofacilitatefur-\\ninnovativeenhancementofDPOthatintegrates therresearchandapplicationofDPO-Kernels.\\nkernelmethodstoovercomethesechallenges\\nthroughfourkeycontributions: (i)Kernelized 1 DPORevisited: Mathematical\\nRepresentations: These representations lay\\nComponentsandScopefor\\nthegroundworkforenhanceddivergencemea-\\nEnhancement\\nsuresbyleveragingpolynomial,RBF,Maha-\\nlanobis,andspectralkernelsforricher,more The Direct Preference Optimization (DPO)\\nexpressivefeaturetransformations. Addition-\\n(Rafailovetal.,2024)frameworkaimstooptimize\\nally, we introduce a hybrid loss that com-\\napolicyπ(y | x)bybalancingtwoobjectives: im-\\nbinesembedding-basedlosswithprobability-\\nprovingthepolicy’srankingonpreferredoutcomes\\nbased loss, enhancing the optimization pro-\\ncessbeyondtraditionalDPO;(ii)Divergence andregularizingitagainstareferencedistribution\\nAlternatives: IncorporatingJensen-Shannon, usingtheKullback–Leibler(KL)divergence. The\\nHellinger,Rényi,Bhattacharyya,Wasserstein, DPOobjectivecanbeexpressedas:\\nandf-divergencestobooststabilityandrobust-\\nn t ch oe es ms o; bp i( t ni ii ami t) ia oD l nka seta (r 4n-D e klr - edi rv i nve en e lr sgS ×ee nle c 7c et di po ia vn i er: rgaC emh noo cno eg ss )in 2 ig 8\\ns\\nm πax E (cid:124)x,y+,y C− on(cid:20) trl ao s(cid:123)g\\nt(cid:122)\\niveππ L(( oyy s−+\\ns\\n|| xx ))(cid:21) (cid:125)−α (cid:124)E x(cid:34) (cid:88)\\ny\\nπ(y| (cid:123)x (cid:122))log ππ re( fy (y| |x x) )(cid:35)\\n(cid:125)\\nKLDivergence\\nchallenging. Weintroduceautomaticmetrics\\nwhere: x: The input prompt/context; y+: The\\nthat analyze the data to select the best pair,\\npreferred output; y−: The less preferred output,\\neliminatingtheneedformanualtuning;(iv)Hi-\\nerarchicalMixtureofKernels(HMK):Com- π(y | x): Thepolicybeingoptimized;π ref(y | x):\\nbininglocalandglobalkernelsforpreciseand Thereferencepolicy(oftenapre-trainedmodel’s\\ndistribution);α > 0: Hyperparameterscontrolling\\n* WorkdoneoutsideofroleatMeta.\\n† WorkdoneoutsideofroleatAmazon. thestrengthoftheregularization.\\n5202\\nnaJ\\n8\\n]GL.sc[\\n2v17230.1052:viXraDPO-Kernels(at-a-glance)\\nlimitationssection,pavingthewayforcost-efficientfuture\\nimplementations.(cf.Sec.7andAppendixJ).\\n▶ Representation:Weenrichtherepresentationspaceby ▶ Safevs.UnsafeClusterEffects:Kernel-inducedclus-\\nteringduringsafetyfine-tuningprojectsunsafeinputsinto\\ncombiningthestandardprobability-basedcontrastiveloss\\nnullspaces(Jainetal.,2024a),creatingdistinctandcom-\\nwithsemanticembeddings,ensuringthatmodelprefer-\\npactclustersforsafeandunsafedata. Metricslikethe\\nencesreflectbothstatisticallikelihoodsandmeaningful,\\nDavies-BouldinScore(DBS)areusedtoquantifythesep-\\ncontext-sensitivequalities.(cf.Sec.2)andAppendixD.\\narationandcohesionoftheseclusters,ensuringrobust\\n▶\\nKernels: WeenhancetheDPOcontrastivelossmaxi- safetyalignment.(cf.Sec.7.4andAppendixL).\\nmizationbyintegratingkernel-basedmeasures,allowing ▶\\nforflexiblealignmentintransformedfeaturespacesrather Heavy-TailedSelf-Regularization(HT-SR):Grounded\\nthanrelyingsolelyondirectdistributioncomparisons.In- inHT-SRtheory,theWeightedAlphametric(Martinetal.,\\ncorporatingpolynomial,RBF,spectral,andMahalanobis 2021a)providesanovelframeworktoevaluategeneral-\\nkernels.(cf.Sec.3andAppendixE). izationandoverfittinginLLMswithoutrelyingontraining\\n▶ ortestdata.Ouranalysisexploreswhetheralignedmod-\\nDivergence:Explorationofalternativedivergencemea- els,particularlyHMK,exhibitoverfittingandquantifiesthe\\nsures (e.g., Jensen-Shannon, Hellinger, Rényi, Bhat- extentifpresent.(cf.Sec.7.5andAppendixM).\\ntacharyya,Wasserstein,andf-divergences)addresses ▶\\nknownlimitationsofKLdivergence,suchasinstability FAQSection:Thissectioncoverscommonlyaskedques-\\nandlackofrobustness(cf.Sec.4andAppendixF). tionsalongwiththosedebatedinternallyduringthedevel-\\n▶ opmentprocess,offeringinsightsintokeydesignchoices,\\nProposed DPO-Kernels: The DPO-kernels could be challenges,andtheirresolutions.cf.Sec.11.\\nexplainedusingasimplifiedequation: ▶\\nContrastiveLoss EmbeddingBasedLoss HyperparametersandBestPractices:Weoutlinekey\\nm πaxE x,y+,y−κ(cid:34)(cid:122) log ππ (((cid:125) yy(cid:124) −+| |x x) )(cid:123) +(cid:122) γlog(cid:18) ee(cid:125) yy(cid:124) −+| |e ex x(cid:19)(cid:123)(cid:35) −αEx(cid:34) (cid:88)\\ny\\nπ(y|x)log ππ re( fy (y| |x x) )(cid:35) h timyp ize erp Da Pra Om -e Kt ee rr ns ee lt pti en rg fos rman ad ncp era ac cti rc oa sl sg du ii vd ee rl sin ee ts asto kso ip n-\\n(cid:124) Kernelized(cid:123) H(cid:122) ybridLoss (cid:125) (cid:124) KLDiv(cid:123) e(cid:122) rgence (cid:125) AppendixN.\\n▶\\nTheequationmaximizestheKernelizedContrastiveLoss, Discussion,Limitations,andEthicalConsiderations:\\nwhichdifferentiatespositiveandnegativesamplesusing Sec.9discusseslimitations,includingcomputationalover-\\nprobability ratios and embedding similarities. Concur- head,kernelcollapse,adversarialrobustness,hyperpa-\\nrently,itincorporatesanAlternativeDivergenceRegu- rametersensitivity, andmultimodalalignment. Ethical\\nlarizerscaledbyα,whichenforcesthemodel’sdistribu- considerations-Sec.10coversfairness,bias,privacy\\ntionπθ(y|x)toremainclosetoareferencedistribution risks,interpretability,environmentalimpact,andpoten-\\nπref(y|x)usingagenericdivergencemeasureD.This tialmisuse. Bothsectionsprovideconcisetabularand\\ndual-objectiveframeworkenhancesthemodel’sdiscrimi- graphicalsummaries.\\nnativepowerwhileensuringdistributionalstability. ▶\\nBroaderImpact: ThebroaderimpactofDPO-Kernels\\n▶\\nData-DrivenSelectionofKernelTypeandDivergence liesinitspotentialtotransformhowAIsystemsalignwith\\nFunctions: Selecting the best kernel-divergence pair humanpreferences,withpossiblefutureextensionsto\\nfrom 28 combinations (4 kernels × 7 divergences) is text-to-image(Yoonetal.,2024;Wallaceetal.,2023;Liu\\nnon-trivial. To simplify this, we propose 4 metrics for etal.,2024),text-to-video(Yoonetal.,2024),andVision-\\nkernelselection—Positive-NegativeDivergence(PND), LanguageModels(Wangetal.,2024;Yuetal.,2024).\\nPositive-Negative Alignment Variance (PNAV), Triplet Beyonditstechnicalcontributions,DPO-Kernelsprovides\\nAlignmentTightness(TAT),andNormalizedAlignment afoundationforadvancingalignmentmechanisms,and\\nGap(NAG)—and4metricsfordivergenceselection:Sup- weencouragethecommunitytoexploreandexperiment\\nportOverlap,DriftMagnitude,Kurtosis,andSmoothness. withitscapabilities.\\n(cf.Sec.5andAppendixG).\\n▶\\nKernelMixtureandHMKIntroduction: Thediversity\\nofalignmenttasksnecessitatesakernelmixturemodel (cid:16) (cid:17)\\nπ(y+|x)\\ntoleveragethecomplementarystrengthsofdifferentker- ContrastiveLoss log encouragesthe\\nnels,suchaslocal(e.g.,RBF)andglobal(e.g.,Spectral)\\nπ(y−|x)\\npatterns. However,naivemixturesarepronetokernel policyπ toassignhigherprobabilitiestopreferred\\ncollapse,whereonekerneldominates,reducingadapt- outputs y+ compared to less preferred outputs\\nabilityandgeneralization. Toaddressthis,wepropose\\ntheHierarchicalMixtureofKernels(HMK),arobust y−, given the same input x. This term effec-\\nframeworkthatbalancesfine-grainedandlarge-scalede-\\npendencies, maintainingkerneldiversityandensuring tivelypushesthepolicytorankpreferredresponses\\noptimalalignment.(cf.Sec.6andAppendixH).\\nhigher,aligningitwithobservedpreferences.\\n▶\\nGradient Computation, Computational Complexity,\\nand Overhead: Mathematical derivations for gradi-\\n(cid:16) (cid:17)\\nentcomputationsforHybridLossanddifferentkernels- KL Divergence (cid:80) π(y | x)log π(y|x)\\ndivergences,computationalcomplexityanalysisofdiffer- y πref(y|x)\\nentkernels-divergences,andDPO-Kerneloverheadcom- measures the divergence between the optimized\\nparedtooriginalDPOareprovidedonlyinAppendixI.\\n▶ policyπ andthereferencepolicyπ . Thisregu-\\nEmpiricalFindings:Evaluationson12datasetsshow ref\\nthatDPO-Kernels, particularlyHMK,achievestate-of- larization term acts as a safeguard, preventing π\\nthe-artgeneralizationinfactuality,safety,reasoning,and\\ninstruction-followingtasks. However,HMKincurs3-4× from deviating excessively from the stable base-\\nhighercomputationalcostscomparedtostandardDPO. lineprovidedbyπ . Withoutthisregularization,\\nWe outline strategies to address this challenge in the ref\\nthepolicymightbecomeoverconfidentincertainresponsesordrasticallyalteritsdistributioninun- positiveandnegativeresponses,respectively. For\\ndesirableways. Thehyperparameterαcontrolsthe ourexperiments,weutilizejina-embeddings-v3\\nstrengthofthisregularization: ahigherαkeepsthe (Sturua et al., 2024), but the framework is adapt-\\npolicyclosertoπ ,makingitmoreconservative, abletootherembeddings,enablinggeneralization\\nref\\nwhile a lower α allows greater flexibility for the acrossembeddingmodels.\\npolicytoadjustprobabilitiesbasedonpreferences. Embedding-based representations are well-\\nInthiswork,weproposethreekeyinnovations establishedinpreferencemodeling,rewarddesign,\\ntoextendthecapabilitiesofDirectPreferenceOpti- and metric learning (Bai et al., 2022b; Ouyang\\nmization(DPO).First,weenrichtherepresentation etal.,2022;PeyréandCuturi,2019),oftenrelying\\nspacebycombiningthestandardprobability-based on pairwise distances or fixed objectives (Oord\\ncontrastivelosswithsemanticembeddings,ensur- et al., 2018; Chen et al., 2020; Radford et al.,\\ningthatmodelpreferencesreflectbothstatistical 2021). Recent large language models (LLMs)\\nlikelihoodsandmeaningful,context-sensitivequal- like LaMDA (Thoppilan et al., 2022) and PaLM\\nities. Second, we enhance contrastive loss max- (Chowdhery et al., 2022) also leverage embed-\\nimization by integrating kernel-based measures, dings for preference alignment. However, exist-\\nallowingforflexiblealignmentintransformedfea- ing approaches typically treat embeddings and\\nturespacesratherthanrelyingsolelyondirectdis- probability-based signals separately, relying on\\ntributioncomparisons. Finally, wemovebeyond fixed divergence measures (e.g., KL, triplet loss\\ntheKLdivergencebyincorporatingalternativedi- (Schroffetal.,2015),orcontrastiveloss(Hadsell\\nvergence measures, such as Jensen–Shannon or etal.,2006)). Incontrast,ourworkisthefirstto\\nRényi divergences, to achieve more stable gradi- bridgeembeddingsandprobability-basedalign-\\nents, improved robustness, and better capture of ment in a unified parametric framework for\\nthetargetdistribution’sintricacies. Together,these policy learning, offering a more comprehensive\\nadvancementsformtheDPO-Kernelsframework, approachtopreferenceoptimization.\\nwhich we rigorously evaluate through empirical\\nHybridLoss: Weblendprobabilityandembed-\\nbenchmarks, demonstrating significant improve-\\ndingsignals:\\nmentsoverbaselinemethodsinstability,semantic\\nawareness,andalignmentefficacy. max E [logπ(y+|x) +γ(logπ(e y+ |e x) )]−αKL\\nπ x,y+,y− π(y−|x) π(e |e )\\ny− x\\n(cid:124) (cid:123)(cid:122) (cid:125)\\n2 RicherRepresentation: Hybrid HybridLoss\\nApproach: IntegratingProbabilityand\\nwith γ > 0 controlling the contribution of the\\nEmbeddings\\nembedding signal. When γ = 0, we recover the\\nstandardDPOloss. Increasingγ guidingthepol-\\nDPO (Rafailov et al., 2024) relies on the con-\\nicytoproduceoutputsthatarebothprobableand\\nπ(y+|x)\\ntrastiveloss log , which focusessolely on\\nπ(y−|x) semanticallypreferable.\\nprobability-based preferences. While effective,\\nthisapproachoftenneglectsdeepersemanticand Interpretation:\\nqualitativefactorsinherentinhumanpreferences.\\n• Embedding-GuidedTie-Breaking: Whenprob-\\nTo address this limitation, we introduce a hy-\\nabilities are similar, embeddings help break ties\\nbridpreferencealignmentmethodthatintegrates\\nby favoring outputs that are semantically more\\nembedding-based signals alongside probability-\\naligned or orthogonal. This alignment ensures\\nbasedcues. Ourapproachdefinesapreferencesig-\\nthat the selected output is not only probable but\\nnalasf (x,y+,y−) = e −e ,wheree\\nembed y+ y− y+ also semantically relevant, which is crucial for\\nande areembedding-basedsimilarityscoresfor\\ny− preference-drivenalignment.Figure 1: Kernel methods are techniques in machine learning that allow us to implicitly map input data into\\nahigher-dimensionalfeaturespacewithoutexplicitlyperformingthetransformation. Thisisachievedthrough\\nkernels,whicharefunctionsthatcomputetheinnerproductoftwodatapointsinthetransformedfeaturespace.\\nForbetterintutionongradientdescentdynamicsonkernel-inducedlosslandscapescf. AppendixK.\\nKernel Probability-BasedandEmbedding-BasedTermswithDescription\\nPolynomial\\nκ(cid:104) log(cid:16) π(y+|x)(cid:17)(cid:105)\\n=\\n(cid:16) logπ(y+) +c(cid:17)d\\n,\\nκ(cid:20) log(cid:18) e y+|ex(cid:19)(cid:21)\\n=\\n(cid:32)(cid:16) e⊤ x(cid:17) e y++c(cid:33)d\\nCaptureshigher-orderinterac-\\nπ(y−|x) π(y−) e y−|ex (e⊤ x)e y−+c\\ntionsusing(u⊤v+c)d.Theparameterdcontrolscomplexity.\\nRBF κ(cid:104) log(cid:16) ππ (( yy −+| |x x) )(cid:17)(cid:105) =exp\\uf8eb \\uf8ed−(cid:18) log ππ 2(( σyy −+ 2| |x x) )(cid:19)2\\uf8f6 \\uf8f8, κ(cid:20) log(cid:18) ee yy −+| |e ex x(cid:19)(cid:21) =exp\\uf8eb \\uf8ec \\uf8ec \\uf8ed−(cid:32) (( ee ⊤ x⊤ x 2)) σee 2yy −+(cid:33)2\\uf8f6 \\uf8f7 \\uf8f7 \\uf8f8Measureslocal\\nsimilaritybetweeninputsandoutputsusingtheRBFkernel.σcontrolssmoothness.\\nSpectral κ(cid:104) log(cid:16) ππ (( yy −+| |x x) )(cid:17)(cid:105) = (cid:80)p i=1exp(cid:18) −λi(cid:16) log ππ (( yy −+| |x x) )(cid:17)2(cid:19) ϕi(cid:16) log ππ (( yy −+| |x x) )(cid:17) , κ(cid:20) log(cid:18) ee yy −+| |e ex x(cid:19)(cid:21) =\\n(cid:80)p i=1exp\\uf8eb \\uf8ed−λi(cid:32)(cid:16) (ee ⊤ x⊤ x )(cid:17) ee yy −+(cid:33)2\\uf8f6 \\uf8f8ϕi(cid:32)(cid:16) (ee ⊤ x⊤ x )(cid:17) ee yy −+(cid:33) Decomposes inputs and outputs into eigenfunctions ϕ k and\\neigenvaluesλ ktocaptureglobal,frequency-baseddependencies.\\nMahalanobis κ(cid:104) log(cid:16) ππ (( yy −+| |x x) )(cid:17)(cid:105) = exp\\uf8eb \\uf8ed−(cid:18) log ππ (( yy 2−+ σ| 2|x x) )−µ(cid:19)2\\uf8f6 \\uf8f8, κ(cid:20) log(cid:18) ee yy −+| |e ex x(cid:19)(cid:21) = exp\\uf8eb \\uf8ec \\uf8ec \\uf8ed−(cid:32) (( ee ⊤ x⊤ x )) 2ee yy σ−+ ′2−µ′(cid:33)2\\uf8f6 \\uf8f7 \\uf8f7 \\uf8f8Lever-\\nagestheMahalanobisdistancetocaptureanisotropicfeaturecorrelationsusingthecovariancematrixΣ.\\nHMK κ(cid:104) log(cid:16) ππ (( yy −+| |x x) )(cid:17)(cid:105) = (cid:80)4 i=1τiλiκi(cid:16) log ππ (( yy −+| |x x) )(cid:17) , κ(cid:20) log(cid:18) ee yy −+| |e ex x(cid:19)(cid:21) =\\n(cid:18) (cid:19) (cid:18) (cid:19)\\nτ1 λλ 11 κκ RR BB FF (( ee xx ,, ee yy −+) )+ +λ λ2 2κ κP Po ol ly y( (e ex x, ,e ey y+ −)\\n)\\n+ τ2 λλ 33 κκ SS pp ee cc tt rr aa ll (( ee xx ,, ee yy −+) )+ +λ λ4 4κ κM Ma ah ha a( (e ex x, ,e ey y+ −)\\n)\\nCombines multiple\\nkernels hierarchically, balancing local kernels (RBF, Polynomial) and global kernels (Spectral, Mahalanobis).\\nK(x,x′)=τ1(λ1KRBF+λ2K Poly)+τ2(λ3K Spectral+λ4K Maha)\\nTable 1: Expansion of kernelized hybrid loss into: (a) kernelized probability-based loss and (b) kernelized\\nembedding-basedlossforPolynomial,RBF,Spectral,MahalanobiskernelsandHMK.\\n• Semantic Consistency Check: If the model nelfunction,enablingDPO-Kerneltocapturelocal,\\nstronglyprefersy+butembeddingsdonotsupport global,andhigher-orderdependencies,asdetailed\\nitssemanticquality,amoderateγ preventspurely in the next section. Appendix D formulates our\\nprobability-driven reinforcement. Instead, it en- novelhybridlosscoveringitsmathematicaldefini-\\ncouragesthemodeltorefineitsoutputdistribution tion,term-baseddecomposition,properties,impact\\ntobetteralignwithsemanticcriteria,promoting onpolicylearning,etc.\\nmoremeaningfulpreference-basedselection.\\nThehybridlossisthenembeddedwithinaker-Divergence MathematicalDefinitionandDescription\\nJensen- D JS(P∥Q) = 1 2DKL(P∥M)+ 1 2DKL(Q∥M), M = 1 2(P +Q). Asymmetrizedandsmoothedversion\\nShannon ofKLdivergence,whichmeasureshowdifferenttwoprobabilitydistributionsare. Itisboundedandalways\\nfinite,makingitmorestableforcomparingdistributions. TheDPOobjectivewithJSdivergencebecomes:\\nDivergence maxπ L KCL−αE x[D JSD(π∥p ref)]\\nHellinger H(P,Q)= √1 (cid:113) (cid:82) ((cid:112) p(x)−(cid:112) q(x))2dx.Aboundeddistancemeasure(between0and1)thatquantifies\\n2\\nDistance thesimilaritybetweentwoprobabilitydistributions.ItiswidelyusedinBayesianstatisticsandrobusttooutliers.\\nTheDPOobjectivewithHellingerdistancebecomes:maxπ L KCL−αE x[D Hellinger(π∥p ref)]\\nRényi Dα(P∥Q) = α−1 1log(cid:82) p(x)αq(x)1−αdx. AparametricgeneralizationofKLdivergencecontrolledby\\nDivergence α. ItinterpolatesbetweenKLdivergence(α → 1)andthemaximumdivergenceasα → ∞. Usefulin\\nrobustlearningwherecontroloversensitivityisrequired.TheDPOobjectivewithHellingerdistancebecomes:\\nmaxπ L KCL−αE x[Dα(π∥p ref)]\\nBhattacharyya D Bhat(P,Q) = −log(cid:82) (cid:112) p(x)q(x)dx. Measurestheamountofoverlapbetweentwoprobabilitydistri-\\nDistance butions. Itiscommonlyusedinclassificationtasks,especiallyinBayesiandecisiontheory,toquantifythe\\nseparabilityoftwodistributions.TheDPOobjectivewithBhattacharyyadistancebecomes:maxπ L KCL−\\nαE x[D Bhattacharyya(π∥p ref)]\\nWasserstein W(P,Q)=inf E [∥x−y∥].AlsoknownasEarthMover’sDistance,itquantifieshowmuch\\nγ∈Π(P,Q) (x,y)∼γ\\nDistance \"work\"isneededtomorphonedistributionintoanother.UnlikeKL,itiswell-definedfordistributionsthatdo\\nnotoverlapandiswidelyusedingenerativemodelinganddistributionalignment. TheDPOobjectivewith\\nWassersteindistancebecomes:maxπ L KCL−αE x[W(π,p ref)]\\nf-Divergence D f(P∥Q)=(cid:82) q(x)f(cid:16) p q(( xx ))(cid:17) dx. AgeneralclassofdivergencesthatsubsumesKL,Jensen-Shannon,and\\nothersasspecialcases. Itisdefinedviaaconvexfunctionf,providingaunifiedviewofmultipledivergence\\nmeasures.TheDPOobjectivewithanf-divergencebecomes:maxπ L KCL−αE x[D f(π∥p ref)]\\nTable2: Descriptionsandmathematicaldefinitionsofdivergencefunctions,includingJensen-Shannon,Hellinger,\\nRényi,Bhattacharyya,Wasserstein,andf-Divergence,andtheirapplicationstotheDPOobjective.\\n3 Kernel-IntegratedDPOFormulation ment. Polynomialkernelscapturehigher-orderin-\\nteractions,enablingcompositionalreasoning. RBF\\nStandardDPOalignsapolicyπ withhumanpref-\\nkernels emphasize local, fine-grained structure,\\nerenceswhileregularizingagainstareferencedis-\\nuseful for proximity-based alignment. Spectral\\ntributionπ viaadivergenceD(·∥·). Whileeffec-\\nref\\nkernelscaptureglobal,oscillatorypatternstohan-\\ntive,thisapproachreliesonsimpledistributional\\ndleperiodicdependencies,whileMahalanobisker-\\ndifferences, which may fail to capture deeper se-\\nnels leverage feature covariance to account for\\nmantic relationships essential for alignment. To\\nanisotropic relationships. These kernelized vari-\\naddress this, we introduce kernelized proximity\\nants preserve the core mathematical foundations\\nmeasures that enable more expressive and adap-\\nofDPOwhilesignificantlyenhancingitsabilityto\\ntivealignment. OurframeworkextendsDPOinto\\ncapturericheralignmentcriteria.\\nfourdistinctDPO-Kernelvariants: (i)Polynomial,\\n(ii)RBF,(iii)Spectral,and(iv)Mahalanobis. The Fig. 1 illustrates the effect of kernelizing the\\nresultingobjectiveisexpressedas: DPO objective with various kernels, including\\nPolynomial, RBF, Spectral, and Mahalanobis, in\\nmax E κ(cid:104) log(cid:18)π(y+|x)(cid:19) +γlog(cid:18)e y+ |e x(cid:19)(cid:105) −αKL comparisontotheVanillaDPO.Eachplotshows\\nπ x,y+,y− π(y−|x) e y− |e x how different kernels reshape the optimization\\n(cid:124) (cid:123)(cid:122) (cid:125)\\nKernelizedHybridLoss landscape by implicitly mapping input data to\\nEachkerneloffersauniqueperspectiveonalign- higher-dimensional feature spaces, allowing themodel to capture complex patterns and interac-\\ntions. Thiskernelizedtransformationenhancesthe\\nexpressiveness of the DPO objective, enabling it\\ntoadapttodiversedatadistributionsandmodeling\\nneeds.\\n4 ReplacingKLregularizerwith\\nalternatives\\nThe original DPO framework typically utilizes\\ntheKullback–Leibler(KL)divergencetoalignthe\\nlearnedpolicyπ(y | x)withthereferencedistribu-\\ntion p (y | x). While KL divergence is favored\\nref\\nfor its strong theoretical foundations, exploring\\nalternativedivergencemeasurescanleadtomore\\nrobust optimization, enhanced stability, and im-\\nprovedinterpretabilityandgeneralizability.\\n1.75\\n1.50 1.25 1.00\\n0.75\\n0.50\\n0.25\\n0.00\\n0 25 50 75 100 125 150 175 200\\nEpoch\\necnegreviD\\n.gvA\\ndelacS\\nnesohC\\nrevo\\nsriaP detcejeR\\ndna\\nKL Divergence 0.35\\nWasserstein Distance\\nHellinger 0.30 Rényi (=1.5) f-Divergence[(t-1)²] Jensen-Shannon 0.25 Bhattacharyya Dist 0.20\\n0.15\\n0.10\\n0.05\\n0.00\\necnegreviD\\n.gvA\\ndelacS\\nnesohC\\nrevo\\nriaP detcejeR\\ndna\\nshifts as training progresses, providing insights\\nintohowdivergencemeasuresrespondtoevolving\\nalignmentdynamics.\\nThe divergence equations are summarized in\\nTable2. Fordetails,pleaserefertoAppendixF.\\n5 Data-DrivenSelectionofKernelTypes\\nandDivergenceFunctions\\nChoosing the optimal kernel-divergence pair\\namong 28 combinations (4 kernels × 7 diver-\\ngences)ischallenging. Weproposeasystematic,\\ndata-drivenframeworkthatreplacesheuristicswith\\nwell-definedmetrics,ensuringadaptabilityandim-\\nprovedgeneralization.\\nDivergences Over 200 Epochs 1.0\\n(KL 15% More Oscillatory, JSD & Bhattacharyya on Right Axis)\\n0.8\\n0.6 0.4 0.2\\n0.0 0.0 2.5 5.0 7.5Sample1 0In.0dex 12.5 15.0 17.5 20.0\\nFigure2: Theplotillustratestheoscillatorybehavior\\nandtrendsofvariousdivergencemeasures,including\\nWasserstein,Jensen-Shannon,Hellinger,Rényi,Bhat-\\ntacharyya,andf-divergence,asthetrainingprogresses,\\nreflectingtheirsensitivitytotheevolvingalignmentdy-\\nnamics.\\nFig.2illustratesthetemporalevolutionofvar-\\nious divergence measures, including KL Diver-\\ngence, Wasserstein Distance, Hellinger, Rényi,\\nBhattacharyya,Jensen-Shannon,andf-divergence,\\nacrosstrainingsteps. Theoscillatorybehaviorob-\\nserved in the higher divergence measures (e.g.,\\nRényi,Bhattacharyya,andf-divergence)highlights\\ntheir sensitivity to dynamic alignment changes.\\nIn contrast, smoother trends in Wasserstein and\\nJensen-Shannondivergencesindicatetheirstability\\nandrobustnessovertime. Theoverallupwardtra-\\njectoryreflectsincreasingdistributionalalignment\\nerocS\\ntnemngilA\\nPND (Positive-Negative Divergence)\\n0.810.99 0.920.88 0.750.750.720.96 0.880.91 0.710.990.95 0.760.750.76PN 0oe .7sgi 9tai 0tvi .ev\\n8\\ne 6A Al 0ig .l 8ign 3nm 0me .7ne 9ntsts 01 .. 80\\n0.6 0.480.49 0.34 0.160.220.250.280.41 0.180.310.34 0.120.34 0.170.13 0.42 0.22 0.140.37 0.28 00 .. 24\\nPositive Negative\\nerocS\\ntnemngilA\\nPNAV (Positive-Negative Alignment Variance)\\n3.0\\n2.5\\n2.0\\n1.5\\n1.0\\n0.5\\n0.0 0.0 0.5 1.0 Dime1n.s5ion 1 2.0 2.5 3.0\\n2 noisnemiD\\nQPNoeusgeiatriy tvi evu e v v+ TAT (Triplet Alignment Tightness) 00 .. 78\\n0.6\\n0.5\\n0.4\\n0.3\\n0.2\\n0.1\\n0.0 0 1 2 3 4 5 6 7 8Sam9ple 1In0dex111213141516171819\\neulaV\\nGAN\\nNAG (Normalized Alignment Gap)\\nFigure 3: Visualization of the four proposed metrics\\nfor kernel selection in alignment tasks. (a) Positive-\\nNegativeDivergence(PND)illustratesthedivergence\\nbetweenalignmentscoresforpositiveandnegativesam-\\nples,indicatingthedegreeofseparability. (b)Positive-\\nNegative Alignment Variance (PNAV) depicts the\\nvarianceinalignmentscoresforpositiveandnegative\\nsamples,reflectingalignmentconsistency. (c)Triplet\\nAlignmentTightness(TAT)showstherelativeposi-\\ntioningofquery(x),positive(y+),andnegative(y−)\\nembeddingsinthelatentspace,highlightingalignment\\nprecision. (d) Normalized Alignment Gap (NAG)\\ntracks the evolution of alignment gaps over samples,\\nwhere smaller NAG values signify better alignment\\nquality. Thesemetricscollectivelyprovidequantitative\\nevaluationsofkernelperformanceincapturingalign-\\nmentproperties.Metric Formula Description KernelSuggestions\\nd(x,y+)\\nPos.-Neg. Diver- Indicateswhetherxis Large PND → Mahalanobis (covariance);\\nd(x,y−)\\ngence(PND) closer to y+ or y−. SmallPND→Spectral/Polynomial(nonlin-\\nA large PND implies earity)\\nstrongimbalance.\\n1(cid:88)\\nPos.-Neg. Align. (d(x,y+)−d(x,y−))2 Measures consistency HighPNAV→RBF(flexible);LowPNAV→\\nn i i i i\\nVar.(PNAV) of positive-negative Polynomial(simpler)\\nseparation.\\n1(cid:88) ∥y+−y−∥\\nTriplet Align. i i Howclosey+ andy− HighTAT→Spectral(complexpatterns);Low\\nn ∥y+−x∥+∥y−−x∥\\nTightness(TAT) i i i i arerelativetox. High TAT→RBF(separated)\\nTAT=clustertogether.\\nNorm.Align.Gap\\n1(cid:88)d(x i,y i−)−d(x i,y i+)\\nBalance in distances. NAG ≈ 0 → Polynomial (beyond linear);\\nn d(x,y−)+d(x,y+)\\n(NAG) i i i i NAGnearzero=simi- NAG̸=0→Mahalanobis(covariance)\\nlardistances.\\nTable3: ProposedMetricsforKernelSelection: Positive-NegativeDivergence(PND),Positive-NegativeAlignment\\nVariance(PNAV),TripletAlignmentTightness(TAT),andNormalizedAlignmentGap(NAG).\\n5.1 Data-DrivenKernelSelectionLogic Here,thresholdsε ,ε ,ε ,ε ,ε areempirically\\n1 2 3 4 5\\ntuned or determined through validation. Initial\\nWeproposefournovelmetrics—Positive-Negative\\nvalues such as ε = 0.5, ε = 0.3, ε = 0.2,\\nDivergence (PND), Positive-Negative Alignment 1 2 3\\nε = 0.7,andε = 0.1serveaspracticaldefaults.\\nVariance (PNAV), Triplet Alignment Tight- 4 5\\nBalanced metrics (e.g., ≈ 0) signal alignment\\nness (TAT), and Normalized Alignment Gap\\nstructures,whilelargerdeviationsrevealmorein-\\n(NAG)—thatquantifykeygeometricandrelational\\ntricaterelationshipsrequiringadvancedkernels.\\nproperties of the data, summarized in Table 3.\\nFig. 3 visualizes the four proposed metrics for\\n5.2 Data-DrivenDivergenceChoiceLogic\\nkernelselectioninalignmenttasks: thesemetrics\\ncollectively assess alignment properties, such We further propose four distributional met-\\nas separability, consistency, precision, and gap rics—Support Overlap, Drift Magnitude, Kurto-\\nquality, enabling a comprehensive evaluation of sis,andSmoothness—tosystematicallyselectthe\\nkernelperformanceinalignment. mostappropriatedivergencemeasure,summarized\\nHere,weprescribeapracticalguidelinetohelp in Table 4. Fig. 4 visualizes the four proposed\\nusers empirically select the most suitable kernel metricsfordivergenceselection: thesemetricspro-\\nforalignmenttasksbasedonkeymetrics. Bylever- videinsightsintothebehaviorofdistributionsby\\nagingthresholdsformetricssuchasPNAV,TAT, quantifyingtheiroverlap,shift,tailproperties,and\\nNAG, and PND, this framework provides an in- functionalsmoothness. Collectively,theyenable\\ntuitive yet effective approach to kernel selection, theempiricalselectionofthemostappropriatedi-\\nensuring alignment properties are well-captured vergence measure for various data scenarios, en-\\nfordiversescenarios. suringeffectivemodelingandcomparisonofdis-\\ntributions.\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f2PR oB lF ynK omer in ae ll,\\nKernel,\\ni if fP NN AA GV ≈> 0ε a1 na dn Pd NT DAT ≈< 0ε2 We provide a practical guideline to help users\\nk∗= empirically select the most suitable divergence\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f3M Spa eh ca trla an lo Kb ei rs nK ele ,rnel, i if fN TAA TG >> ε0 4a an nd dP PN NA DV << εε 53\\nmeasurebasedonkeymetrics. ThesemetricsofferProperty Computation WhentoUse BestDivergence\\nSupport Over- |p∩q|,highoverlapmeanssimilar Ifoverlap>0.6:Bhattacharyya. Bhattacharyya,KL,JS\\n|p∪q|\\nlap domains. Otherwise:KLorJS.\\nDrift Magni- 1(cid:80) (d(x,y+) − d(x,y−)), Largedrift: Wasserstein. Small Wasserstein,KL,Rényi\\nn\\ntude higher=biggershifts. drift:KLorRényi(α>1).\\nKurtosis\\nE[(x−µ)4]\\n,highvalues=heavy Kurtosis>3:Rényi.Else:JSor Rényi,JS,Hellinger\\n(E[(x−µ)2])2\\ntails. Hellinger.\\nSmoothness 1 (cid:80) W(p ,p ), lower = High smoothness: Wasserstein. Wasserstein,KL,Hellinger\\nT t t+1\\nsmoothertransitions. Low:KLorHellinger.\\nTable4: ProposedMetricsforDivergenceSelection: SupportOverlap,DriftMagnitude,Kurtosis,andSmoothness\\n012345678Distr9ibu1ti0on 1111213141516171819\\n0123456728\\nno9itub0i1rts1iD12131415161718191\\nSupport Overlap (Heatmap of Two Distributions) 3\\n2\\n1\\n0\\n1\\n0 20 40Time Steps 60 80 100\\neulaV\\nDrift Magnitude (Shift in Distribution Mean) DShriifftted Mean\\n17.5 15.0\\n12.5\\n10.0 7.5\\n5.0\\n2.5\\n0.0\\nNormal DisHteriabvuyt-iToani leTydpe Light-Tailed\\neulaV sisotruK\\nKurtosis of Different Distributions\\n18.92 4\\n3\\n2\\n1 0\\n1\\n2\\n-0.31 -1.23 43\\n0 2 4 X 6 8 10\\neulaV\\n5\\n4\\n\\uf8f1\\n23\\nD∗=\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2W RB éh\\na\\nna\\ns\\nyt st\\ne\\nia rc Dsh\\nt\\niea vir eny ry gDa\\nei\\nnvD\\nce\\nei rv ,ge er ng ce en ,ce,\\ni\\nii\\nf\\nff\\nD\\nKSu urip\\nrf\\ntp\\nt\\noo\\nM\\nsr it saO\\ng\\n>nv ie εtr\\nu\\n3l da ep >> εε 21\\n01\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3J\\nH\\nKe\\ne\\nLn ls\\nl\\nDe inn\\nig\\nv-S\\ne er\\nrh gDa en nin\\nv\\nceo ern ,geD ni cv ee ,rgence, i\\ni\\nof\\nf\\nthO\\nS\\nemv rwe or\\no\\nil sa\\nt\\nehp ni es sl so iw sla on wd aK nu drt Kos ui rs tois sil so iw\\nslow\\nSmoothness (Function and Its Derivative)\\nSDmeroivoathti vFeu n(Scmtioonothness)\\nWe recommend starting with thresholds ε = 1\\n0.6, ε = 0.3, and ε = 3, refining them based\\n2 3 ontheobservedperformance. Thissystematicap-\\nproachensuresthatdivergenceselectionisdirectly\\ntailored to the alignment complexity of the data.\\nAppendix G offers a detailed discourse for data-\\nFigure4:Visualizationofthefourkeymetricsfordiver-\\ndriven selection of kernel types and divergence\\ngenceselection: (1)SupportOverlap—Heatmaprep-\\nfunctionsbasedontheappropriatemetrics.\\nresentingtheoverlapbetweentwodistributions,high-\\nlightingsharedsupportregions;(2)DriftMagnitude\\n6 KernelMixtureApproach-Improved\\n—Illustrationoftheshiftinthemeanofadistribution\\novertime,showcasinghowdriftisdetected;(3)Kur- Generalization\\ntosis—Barplotcomparingkurtosisvaluesfornormal,\\nTheuseofasinglekerneloftenfailstocapturethe\\nheavy-tailed,andlight-taileddistributions,quantifying\\nthe\"tailedness\"ofeachdistribution;(4)Smoothness diverse relationships inherent in alignment tasks.\\n—Visualizationofasmoothfunctionanditsderivative, Different kernels are adept at modeling specific\\nwheresmootherfunctionsexhibitsmaller,lessabrupt properties,suchaslocalsimilarities,globalstruc-\\nchangesinderivatives. Thesemetricsguidetheselec-\\ntures,orhigher-orderinteractions,makingitchal-\\ntion of the most appropriate divergence measure for\\nlengingforanysinglekerneltoperformwellacross\\neachdatascenario.\\nall scenarios. A Kernel Mixture Approach ad-\\ndressesthislimitationbydynamicallycombining\\nmultiplekernels,leveragingtheircomplementary\\ninsightsintodistributionalbehavior,ensuringthe strengthstoimprovegeneralizationacrossvaried\\nchosendivergencemeasurealignswiththedata’s datasets(e.g.,diversealignmenttasksasin(Dubois\\ncharacteristics. etal.,2024b;Lvetal.,2023a),policyshifts(Kohet al., 2021a), and evolving alignment require-\\nments(Jainetal.,2024b).\\nRelatedWorks: Researchinmultiplekernellearn-\\ning (Gönen and Alpaydın, 2011), Gaussian pro-\\ncesses(Duvenaudetal.,2013),anddistributional\\nadaptation(Quinonero-Candelaetal.,2009;Koh\\netal.,2021b)highlightstheeffectivenessofcom-\\nbiningkernelstohandledatasetheterogeneityand\\ndistributionalshifts. Inspiredbytheseprinciples,\\ntheKernelMixtureApproachextendsthisflexibil-\\nitybyenablingtask-specifickernelcontributions. 0 20 40 60 80 100 120 140 160 180\\nEpochs\\nAstraightforwardformulationcouldbeexpressed\\nas:\\nκ(u,v) = λ κ (u,v)+λ κ (u,v)\\n1 poly 2 RBF\\n+λ κ (u,v)+λ κ (u,v),\\n3 spec 4 Maha\\nwhere λ ,λ ,λ ,λ ≥ 0 and\\n(cid:80)4\\nλ = 1.\\n1 2 3 4 i=1 i\\nThe weights are parameterized using a softmax:\\nλ = exp(θi) ,whereθ aretrainableparame-\\ni (cid:80)4 j=1exp(θj) i\\ntersoptimizedviagradientdescent. Thisformula-\\ntionallowsthemodeltoadaptkernelcontributions\\ndynamicallytothetaskathand.\\nHowever, a key challenge of this approach is\\nkernel collapse (Lanckriet et al., 2004, 2002;\\nRätsch and Warmuth, 2005), where one kernel\\ndisproportionatelydominates,effectivelyreducing\\nthe model to a single-kernel learner. This dimin-\\nishesdiversityandunderminestherepresentational\\npower needed to model complex data relation-\\nships. Fig.5depictstheevolutionofkernelweights\\n(λ ,λ ,λ ,λ )forPolynomial,RBF,Spectral,and\\n1 2 3 4\\nMahalanobis kernels over 200 epochs. The dy-\\nnamic adjustments showcase how the model pri-\\noritizes different kernels during training to opti-\\nmize alignment. However, the visualization also\\nhighlights the risk of kernel collapse, where one\\nor two kernels dominate, reducing diversity and\\npotentially limiting the model’s representational\\ncapacity. For detailed discussion please refer to\\nAppendixH.Addressingthisissueisessentialfor\\nfullyrealizingthepotentialofkernelmixturesin\\nalignmenttasks.\\nslenreK\\nlaimonyloP\\nFBR\\nlartcepS\\nsibonalahaM\\nKernel Mixture Evolution over 200 Epochs\\n1.0\\n0.8\\n0.6\\n0.4\\n0.2\\n0.0\\nthgieW\\nFigure5: EvolutionofKernelWeightsintheMixture\\nOver200Epochs. Theplotillustratesthedynamicad-\\njustmentofkernelweights(λ ,λ ,λ ,λ )correspond-\\n1 2 3 4\\ning to Polynomial, RBF, Spectral, and Mahalanobis\\nkernels,respectively,duringtraining. Eachcurverep-\\nresents the relative contribution of a kernel, showing\\nhowthemodeladaptsitsalignmentstrategyovertime.\\nThedominanceofoneortwokernels,asindicatedby\\nthecurves,highlightsthetendencytowardskernelcol-\\nlapse,wherecertainkernelsovershadowothers. This\\nvisualizationunderscoresthechallengesinmaintaining\\nkerneldiversitywithinthemixture.\\n6.1 HierarchicalMixtureofKernels\\nHierarchical Mixture of Kernels (HMK) over-\\ncomeskernelcollapsebyintroducingatwo-level\\ndecompositionthatbalanceslocalkernels(RBF,\\nPolynomial) (Schölkopf and Smola, 2002) and\\nglobal kernels (Spectral, Mahalanobis) (Wein-\\nberger and Saul, 2009; Ng et al., 2001). Local\\nkernels capture short-range dependencies, while\\nglobalkernelsmodelbroader,long-rangerelation-\\nships. HMK assigns learnable weights to both\\ngroups, enabling dynamic adaptation to varying\\ndatageometries:\\nK(x,x′)=τ1(λ1K RBF+λ2K Poly)+τ2(λ3K Spectral+λ4K Maha),\\nwhere τ ,τ balance local-global contributions.\\n1 2\\nBoth τ and λ are updated through backpropaga-\\ntion, allowing HMK to maintain kernel diversity\\nandadapteffectively.6.1.1 IllustrationoftheEffectiveRange • Global Kernels: Crucial for tasks like contex-\\ntual alignment or multi-hop reasoning, leverag-\\nTovisualizethekernelinfluencerange,asetof20\\ning long-range dependencies (Ng et al., 2001;\\npointswasrandomlysampledfromthe2Dspace\\nDeMaesschalcketal.,2000).\\n[−5,5] × [−5,5]. A fixed query point at (0, 0)\\nservesasthereferencepointforkernelsimilarity\\n• Generalization: HMK combines the strengths\\ncomputation for the RBF, Polynomial, Spectral,\\nof local and global kernels, reducing overfitting\\nandMahalanobiskernels. PleaserefertoFigure6.\\nwhileimprovingadaptabilityacrossdiversetasks.\\n• Purpose: Randompointsofferadataset-agnostic • DynamicAdaptation: Thehierarchicalstructure\\nviewofkernelinfluence. enablestask-awareprioritizationoflocalorglobal\\ninfluences,balancingshort-andlong-rangedepen-\\n• Why It Matters: The query point allows us to dencies(BelkinandNiyogi,2003).\\nanalyze how influence propagates, aiding in the\\nunderstandingoflocalvs. globalbehavior. • Robustness to Shifts: The Mahalanobis kernel\\naddsrobustnesstocovariancestructurechanges,\\ncomplementingtheSpectralkernel’sglobalreach\\n6 RBF Kernel (Local) 6 Spectral Kernel (Global) (DeMaesschalcketal.,2000).\\nData Points Data Points\\nQuery Point Query Point\\nEffective Range (3)\\n4 4\\n6.3 DynamicEvolutionofKernelWeights\\n2 2\\nFig. 7 shows the evolution of kernel weights\\n0 0\\n(λ ,λ ,λ ,λ )andLocal-GlobalBalanceCoeffi-\\n1 2 3 4\\n2 2\\ncients(τ ,τ )overtraining. Earlyepochshighlight\\n1 2\\n4 4\\ncompetitionbetweenlocalandglobalkernels,with\\n66 4 2 0 2 4 6 66 4 2 0 2 4 6 τ and τ stabilizing around epoch 100. Polyno-\\n6 Polynomial Kernel (Local) 6 Mahalanobis Kernel (Global) 1 2\\nD Q Efa u fet ea cr y tP\\ni\\nvo P ei on i Rt ns at\\nnge\\nD Qa ut ea r yP o Pi on it ns t mial(λ 1)andRBF(λ 2)dominateinitially,while\\n4 4\\nSpectral(λ )andMahalanobis(λ )gaininfluence\\n3 4\\n2 2 later,emphasizingglobaldependencies. Byepoch\\n0 0 200,thesystemconvergestoanoptimalbalance.\\n2 2\\n7 EmpiricalResults\\n4 4\\n66 4 2 0 2 4 6 66 4 2 0 2 4 6 Uptonow,wehavediscussedthetheoreticaland\\nFigure6: Localvs. globalkernelinfluence. RBFand mathematicalextensionsofDPO.Inthissection,\\nPolynomialkernelsexhibitlocalizedinfluence,while we empirically evaluate the effectiveness of the\\nSpectralandMahalanobiskernelscapturebroaderde- proposedDPO-Kernels. Weconductedallourex-\\npendencies. perimentsusingLlama3.3(raymondd,2024). Ap-\\npendix C details our experiments and evaluation\\nsetup.\\n6.2 KeyInsightsandAlignmentTask\\nImplications 7.1 Datasets&Tasks\\n• Local Kernels: Effective for fine-grained tasks We assess the performance of models trained\\nlikesafetyalignmentorclustering,astheirinflu- with DPO-Kernels across 12 diverse preference\\nencedecaysquicklywithdistance(Schölkopfand datasets,thoughtfullychosentoencompassawide\\nSmola,2002). spectrum of data sources. These datasets are7.2 EfficacyofHybridLoss\\nParameters The heatmap in Fig. 8 demonstrates the perfor-\\n1\\n2 mance gains from integrating hybrid loss with\\n3\\n4 various kernels (Polynomial, RBF, Spectral, Ma-\\n1.0\\nhalanobis,andKernelMixture)acrossalignment\\n0.8\\nW tasks: Factuality,Reasoning,Truthfulness,Safety,\\ne\\nig h 0.6 and Instruction Following. Hybrid loss consis-\\nt\\nV\\na tentlyoutperformsstandardDPOloss,achieving\\nlu 0.4\\ne\\nhigher F1 scores even without advanced kernels.\\n0.2\\nAmongthekernels,RBFandKernelMixturestand\\n0.0 out,particularlyexcellinginSafetyandTruthful-\\nness,highlightingtheeffectivenessofhybridloss\\n4\\nPara meters3\\n2\\n1 0 25\\n50\\n75 1 E0 p0\\noc1 h2 s5\\n150\\n175 200 a aln id gnk mer en ne tl .izedproximitymeasuresinenhancing\\nFigure 7: Dynamic evolution of kernel weights\\n(λ ,λ ,λ ,λ )andLocal-GlobalBalanceCoefficients 1 2 3 4\\n(τ ,τ ). Themodelshiftsitsrelianceonlocalorglobal 1 2\\nkernelsovertrainingepochs,achievingastablebalance.\\nDPO (Cons. Loss D) PO (Hybrid L Po os ls y) nomial (Con Ps. o lL yo ns os m) ial (Hybrid L Ro Bss F) (Cons. Loss) RBF (Hybrid Lo Sss p) ectral (Cons. L So ps es c) tral (Hybri Md aL ho as ls a) nobis (Co Mn as. h aL lo as ns o) bis (Hy Kb er ri nd eL l o Ms is x) ture (C Keo rn ns e. l L Mo is xs t) ure (Hybrid H L Mo Ks s () Cons. Loss H) MK (Hybrid Loss)\\ncategorized as follows: I. Human-Annotated\\nDatasets: HH-RLHF (Bai et al., 2022a), Help-\\nSteer (Wang et al., 2023), Chatbot Arena 2023\\n(Zhengetal.,2023),ChatbotArena2024(Chiang\\net al., 2024), AlpacaFarm Human (Dubois et al.,\\n2024c),andPRM800k(Lightmanetal.,2023). II.\\nWeb-ScrapedDatasets: SHP-2(Ethayarajhetal.,\\n2022). III. Synthetically Generated Datasets:\\nUltra-Feedback (Cui et al., 2024), Nectar (Zhu\\net al., 2023), Orca (Lv et al., 2023b), Capybara\\n(Daniele and Suphavadeeprasit, 2023a), and Al-\\npacaFarmGPT-4(DanieleandSuphavadeeprasit,\\n2023b). Collectively,thesedatasetsspanabroad\\nrangeofalignmenttasks,includingFactuality,Rea-\\nsoning,Truthfulness,Safety,andInstructionFol-\\nlowing, therebyprovidingacomprehensiveeval-\\nuationframeworkfortheDPO-Kernelsapproach.\\nAppendixBhighlightsthedetailsofdatasetsused\\ninthiswork,includinghuman-annotatedandsyn-\\ntehticallygenerateddatasets.\\nytilautcaFgninosaeRssenlufhturT\\nytefaSgniwolloF\\n.rtsnIllarevO\\n0.57 0.60 0.62 0.66 0.73 0.68 0.71 0.63 0.65 0.73 0.66 0.73 0.78 0.80\\n1.0\\n0.55 0.58 0.60 0.62 0.68 0.72 0.66 0.69 0.61 0.63 0.68 0.72 0.72 0.75\\n0.9\\n0.74 0.77 0.79 0.82 0.86 0.89 0.86 0.88 0.80 0.83 0.86 0.89 0.91 0.94 0.8\\n0.92 0.95 0.97 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.7\\n0.6\\n0.54 0.57 0.59 0.61 0.66 0.69 0.65 0.68 0.60 0.62 0.66 0.69 0.71 0.74\\n0.5\\n0.66 0.69 0.71 0.74 0.78 0.79 0.77 0.77 0.73 0.76 0.78 0.79 0.82 0.85\\nerocS\\n1F\\nFigure8: HeatmapdepictingF1scoresacrossvarious\\nkernels and loss functions for alignment tasks. The\\nyellow borders indicate the best-performing kernels\\nforeachtask,whilebluebordershighlightthesecond-\\nbestperformers. Scoresareevaluatedfortaskssuchas\\nFactuality,Reasoning,Truthfulness,Safety,andInstruc-\\ntionFollowing,withanoverallassessmentsummarized\\nin the last row. The Hierarchical Mixture of Kernels\\n(HMK)consistentlydemonstratestopperformancein\\nmultipletasks.\\n7.3 EfficacyofDivegencebasedRegularizers\\nFig.10presentsheatmapsshowcasingtheperfor-\\nmanceofkernel-divergencecombinationsacross\\nvariousalignmenttasks,includingFactuality,Rea-\\nsoning,Truthfulness,Safety,andInstructionFol-\\nlowing. Thevisualizationhighlightshowdifferent\\nkernels(DPO,Polynomial,RBF,Spectral,Maha-\\nlanobis,HMK)pairedwithdivergences(KL,JSD,\\nHellinger, Rényi, Bhattacharyya, Wasserstein, f-\\nDivergence)performonindividualtasksandover-Factuality\\nReasoning\\nTruthfulness\\nSafety\\nInstruction Following\\nOverall\\nDPO + K DL P DO P+ O JS + D Helli Dn D Pg Pe O Or + + BR hé an t Dtyi Pac O h +a ry W Dy a Pa ss O er + s ft -e di in ve Pr olg ye nnc oe m Pi oa ll P y on l+ o yK nmL i oal m ia+ l J PS + P o loD lH yye nl nl oi on mimg i ae la lr P + o l+ yBR nhé oan t mty i Pi a a oc l l h y+a n r oy Wy ma ia s as l er + s ft -e di in vergence RBF + K RL BF R B+ F JS + D Hellin RRg BBe F Fr + + BR hé an t Rtyi a Bc F h +a ry W Ry aa Bss F er + s ft -e di in verg Se pn ec ce tral S p+ e ScK ptL er ca tl ra+ l JS + D SH S pel p eli e cc tn t rg r ae la lr + + SBR phé ea cn t tty ri a ac l Sh + pa r ey cW ty a ra s as l er + s ft -e di in v Me ar hg ale anc n Me o abi h Ms a a l ha+ an lK o aL b ni os bi+ s M J M aS + a h hD aH lale al al ni n on o bg ibi Me s sr a + h + alBR ahé nan t o Mty abi a i hc s ah l+a a r ny W oy a ba s is s er + s ft -e di in vergenc He MK + K HL M HK M+ K JS + D Helli Hn H Mg Me K Kr + + BR hé an t Htyi Mac K h +a ry W Hy a Ma ss K er + s ft -e di in vergence\\nKernel Type + Divergence\\nsmoixA\\ntnemngilA\\nDPO Polynomial RBF Spectral Mahalanobis HMK 1.0\\n0.600.590.620.610.610.620.610.660.660.680.680.670.680.650.680.690.690.700.690.700.680.630.630.650.650.640.650.640.730.740.750.750.750.760.740.760.770.780.780.780.790.77 0.9\\n0.580.580.600.590.590.600.590.620.620.630.630.630.640.610.720.730.740.740.740.740.710.690.690.710.700.710.710.690.630.630.650.640.650.660.630.730.730.750.750.750.760.72\\n0.770.760.790.790.790.800.760.820.830.840.840.840.850.810.890.880.910.910.920.920.890.880.900.900.900.900.910.900.830.840.850.850.850.860.820.920.910.940.940.940.960.94 0.8\\n0.950.940.970.970.970.960.950.980.960.970.980.970.970.980.980.960.960.980.970.960.960.980.960.960.980.980.980.960.980.970.980.970.960.980.980.980.960.980.980.980.970.97 0.7\\n0.570.570.590.590.590.590.560.610.610.620.630.630.630.610.690.690.710.710.710.720.690.680.680.700.700.700.710.690.620.610.630.640.630.640.630.720.720.740.740.730.740.72\\n0.690.690.710.710.710.710.690.740.740.750.750.750.750.730.790.790.800.810.810.810.790.770.770.780.790.790.790.780.760.760.770.770.770.780.760.820.820.840.840.840.840.82 0.6\\n0.5\\nerocS\\n1F\\nFigure9: Heatmapsillustratingtheperformanceofkernel-divergencecombinationsacrossalignmenttasks. The\\nfirstheatmappresentsthecompleteview,showcasingallkernels(DPO,Polynomial,RBF,Spectral,Mahalanobis,\\nHMK)pairedwithdivergences(KL,JSD,Hellinger,Rényi,Bhattacharyya,Wasserstein,f-divergence). Thesecond\\nandthirdheatmapssplitthedataforclarity,focusingonthefirstthreekernels(DPO,Polynomial,RBF)andthe\\nlastthreekernels(Spectral,Mahalanobis,HMK),respectively. Eachrowrepresentsatask(Factuality,Reasoning,\\nTruthfulness,Safety,InstructionFollowing),whilethe\"Overall\"rowaggregatesaverageperformance. Yellowand\\nbluebordershighlightthebestandsecond-best-performingkernel-divergencecombinationsforeachtask.\\nall metrics. Yellow and blue borders indicate\\nFactuality\\nthe best and second-best combinations for each\\ntask,providingaclearcomparisonofperformance. Reasoning\\nThis comprehensive analysis helps identify opti-\\nTruthfulness\\nmalkernel-divergencecombinationsforalignment\\ntasksbasedonspecificobjectivesandscenarios. Safety\\nForbetterreadability,weseparatetheRBFker-\\nInstruction Following\\nnelfordetailedvisualization,asitemergesasthe\\nbest-performing single kernel. The heatmap in Overall\\nF n aceig rl o. w s1 si0 t th ass kh v so a :w ri Foc aa u cs s te us d ai lF v ite1 yr ,gs Rec n eo acr se e os -b nf a io nsr e gd ,t Th re re ugR tu hB l fa uF r li nzk eee sr sr s-\\n,\\nRBF + KL RBF + JSD RBF + Hellinger RBF + R Ré Bn Fy i + Bhattacharyy Ra BF + Wasserste Ri Bn F + f-divergence\\nDivergence Functions\\nSafety, and Instruction Following. Rényi and\\nBhattacharyyadivergencesexcelinTruthfulness,\\nInstruction Following, and overall performance,\\nhighlightingtheiralignmenteffectiveness. Safety\\nmaintains consistently high scores across all di-\\nvergences,reflectingtherobustnessofRBF-based\\nalignment. These results underscore the impor-\\ntanceofselectingappropriatedivergenceregulariz-\\nerstooptimizeRBFkernelsfornuancedsemantic\\nandfactualalignmenttasks.\\n7.4 MechanismofSafetyFine-Tuning: Safe\\nvs. UnsafeClusterEffects\\nJain et al. (2024a) demonstrate that safety fine-\\ntuning(alignment)minimallyadjustsMLPweights\\ninLLMstoprojectunsafeinputsintothenullspace\\nsmoixA\\ntnemngilA\\nRBF Kernel with Divergence-Based Hybrid Loss\\n0.68 0.70 0.69 0.70 0.70 0.68 0.69\\n0.72 0.73 0.74 0.73 0.73 0.72 0.72\\n1.0\\n0.89 0.91 0.90 0.92 0.89 0.88 0.89\\n0.8\\n0.98 0.98 0.98 0.98 0.98 0.98 0.98\\n0.6\\n0.69 0.68 0.68 0.70 0.71 0.68 0.68\\n0.79 0.80 0.80 0.81 0.80 0.79 0.79\\n)erocS\\n1F(\\necnamrofreP\\nFigure10:F1scoresoftheRBFkernelwithdivergence-\\nbased regularizers across key tasks. Results for all\\nkernel-divergence combinations are detailed in Ap-\\npendixJ.\\nofweightmatrices,inducingdistinctclusteringof\\ninputsbasedonsafetystatus. Weanalyzetheevo-\\nlutionoftheseclustersduringtrainingandevaluate\\ntheir separation using the Davies-Bouldin Score\\n(DBS),wherelowervaluesindicatebettercluster-\\ningwithcompactintra-clusterdistancesandlarge\\ninter-clusterseparations.\\nDefinition: For k clusters {C ,C ,...,C },\\n1 2 kFigure11: Visualizationofkernel-basedweightprojectionsover200epochsacrossdifferentkernels: Polynomial,\\nSpectral,RBF,Mahalanobis,andHMK.Greenpointsrepresenttheselectedclass,whileredpointsindicatethe\\nrejectedclass,showcasinghoweachkerneladaptstoandseparatesthedataeffectively.\\nDBS(DaviesandBouldin,1979)isdefinedas: demonstrate strong separation between selected\\nand rejected samples, highlighting their superior\\nk (cid:18) (cid:19)\\n1 (cid:88) S i+S j alignment performance. In contrast, the Polyno-\\nDBS = max ,\\nk j̸=i D ij mialandMahalanobiskernelsexhibitlessdistinct\\ni=1\\nseparation.\\nwhere:\\n• S = 1 (cid:80) ∥x−µ ∥: Averageintra-cluster\\ni |Ci| x∈Ci i\\ndistanceforclusterC ,withµ asitscentroid.\\ni i\\nLlama 3.3-70B-Instruct\\nLLM + DPO\\nPolynomial DPO\\n• D ij = ∥µ i−µ j∥: Distancebetweencentroidsof 3.31 3.58 0.5 R S MpB aeF hc aD t lr aP a nO l oD bP isO DPO\\nclustersC andC . 4.62 4.05 0.4 H GM enK e D raP liO zation Threshold\\ni j\\n4.82 5.15\\n6.19\\n0.3\\nOv Densityerfitting Threshold\\nLower DBS values in alignment learning indi- 0.2\\ncate: 0.1\\n0.0\\n• ClearerDecisionBoundaries: Betterseparation\\nof safe and unsafe clusters for precise behavior 0 2 4 RBFS Dpe PM c Ota rh aa l l Da Pn OoH bM isK D D POPO\\n6 Polynomial DPO\\ncontrol. Alpha 8\\n10Llama\\n3.3-7L 0L BM\\n-I\\nn+\\ns\\ntD ruP cO\\nt\\n• Improved Generalization: Enhanced perfor-\\nFigure12: Generalizationvs. overfittingtrade-offfor\\nmanceonunseendatathroughwell-separatedclus-\\nvariousDPO-kernels,groundedinHeavy-TailedSelf-\\nters.\\nRegularization(HTSR)theory. Smallerαvaluesindi-\\ncatestrongerself-regularizationandbettergeneraliza-\\n• Increased Robustness: Compact clusters with\\ntion,whilelargerαvaluessignaloverfittingorunder-\\nstrongseparationreducesensitivitytonoiseand\\noptimized layers. This plot highlights how different\\noutliers. cf. sec:appendix:safe_unsafe_cluster. DPO-kernels impact the balance between generaliza-\\ntionandoverfitting.\\nFig.11visualizesthekernelembeddingsafter\\n200epochsacrossdifferentkernels: Polynomial,\\n7.5 Generalizationvs. Overfitting: Which\\nSpectral, RBF, Mahalanobis, and HMK. Green\\nKernelExcels?\\npointsrepresentselectedsamples,whileredpoints\\nindicaterejectedsamples,illustratinghoweachker- TheWeightedAlphametric(Martinetal.,2021a)\\nnelprocessesthedata. TheRBFandHMKkernels offers a novel way to assess generalization andoverfitting in LLMs without requiring training nelized representations and divergence-based\\nor test data. Rooted in Heavy-Tailed Self- regularization. By leveraging a Hierarchical\\nRegularization (HT-SR) theory, it analyzes the Mixture of Kernels (HMK) and data-driven se-\\neigenvalue distribution of weight matrices, mod- lection, our approach systematically addresses\\neling the Empirical Spectral Density (ESD) as a the challenges of robust generalization and scal-\\npower-law ρ(λ) ∝ λ−α. Smaller α values indi- able alignment. A significant challenge in align-\\ncate stronger self-regularization and better gen- ment is selecting the optimal kernel-divergence\\neralization, while larger α values signal overfit- pair from 28 possible combinations (4 kernels\\nting. The Weighted Alpha αˆ is computed as: × 7 divergences). To tackle this, we proposed\\nαˆ = 1 (cid:80)L α logλ , where α and λ a data-driven framework that replaces heuristics\\nL l=1 l max,l l max,l\\narethepower-lawexponentandlargesteigenvalue with well-defined metrics, ensuring adaptability\\nof the l-th layer, respectively. This formulation and enhanced performance across tasks. Our\\nhighlightslayerswithlargereigenvalues,providing frameworkwasrigorouslyevaluatedon12diverse\\napracticalmetrictodiagnosegeneralizationand datasets, demonstratingstate-of-the-artgeneral-\\noverfittingtendencies. ResultsreportedinFig.12. izationacrosstasks,includingfactuality,reason-\\ning, safety, and instruction following. While\\nResearchQuestionsandKeyInsights\\nHMK achieves superior performance, it incurs\\n1. RQ1: Do aligned LLMs lose generalizability\\ncomputational costs 3x-4x higher than baseline\\nandbecomeoverfitted? Alignmentprocedures\\nDPOmethods. Toaddressthis,futureworkcould\\nslightlyincreaseoverfitting,withageneralization\\nexplore approximation strategies like Random\\nerrordrift|∆E |≤ 0.1(within±10%),whichis\\ngen FourierFeatures(RFF)andNyströmmethods\\nconsideredacceptable.\\ntoreducecomputationalcomplexity.\\nLookingahead,DPO-Kernelspresentstransfor-\\n2. RQ2: Whichkernelanddivergencefunctions\\nmative potential across domains such as multi-\\nofferthebestgeneralizability? RBFandSpec-\\nmodal alignment (e.g., text-image or text-video\\ntralkernelsachievethelowestgeneralizationgap,\\ntasks),fairness-sensitiveAI,andpersonalizeded-\\nwhilePolynomialkernelsincreaseoverfittingby\\nucation systems. We encourage the community\\n15%. Mahalanobiskernelsperformcomparablyto\\ntoexploreitscapabilitiesinexpandingalignment\\nRBFandSpectralbutincurhighercomputational\\nbeyondtexttomultimodalandreal-worldapplica-\\ncosts. Among divergences, Bhattacharyya and\\ntions.\\nWassersteinshowthestrongestgeneralization,out-\\nperforming others like KL and Jensen-Shannon.\\nRényi divergence is effective for specific tasks\\nbutrequirescarefultuningofαtobalancealign-\\nmentstrengthandoverfittingrisks. AppendixM\\ndetailsthetheoryandimplicationsoftheHeavy-\\nTailedSelf-Regularization(HT-SR)theorywhich\\nprovidesastatisticalmechanicsframeworktoana-\\nlyzetheweightmatricesofDeepNeuralNetworks\\n(DNNs).\\n8 Conclusion\\nWeintroducedDPO-Kernels,anovelframework\\ndesignedtoadvancealignmentbycombiningker-9 DiscussionandLimitations andcertifiedrobustness(WongandKolter,2018)\\nWhile DPO-Kernels demonstrate significant ad- toenforcebalancedkernelcontributions.\\nvancementsinalignmentandgeneralization,sev- 3. Adversarial Robustness: HMK’s sensitiv-\\nerallimitationswarrantfurtherattention. ity to adversarial preference perturbations is cur-\\nrentlyuntested. Smallinputchangescanresultin\\nKernel Vulnerabilities Across Limitations RBF Kernel\\nKernel Collapse Polynomial Kernel significantalignmentshifts. Approachessuchas\\nSpectral Kernel\\nMahalanobis Kernel adversarialtraining(Madryetal.,2018)androbust\\nHMK\\nkernellearning(Xuetal.,2009)couldstrengthen\\nAdversarial Robustness\\nresilience.\\n4. HyperparameterSensitivity: Performance\\ndepends on sensitive parameters like the RBF\\n1 2 3 Co4mputat5ional Overhead bandwidth(σ),Polynomialdegree(d),andMaha-\\nlanobiscovariance(Σ). Techniquessuchasmeta-\\nlearning (Finn et al., 2017a) and adaptive tuning\\n(Hazanetal.,2007)canstreamlinehyperparameter\\nHyperparameter Sensitivity\\noptimization.\\n5. Multimodal Alignment: Extending HMK\\nMultimodal Alignment to multimodal tasks (e.g., text-image alignment)\\nFigure13: Radarchartillustratingthevulnerabilities involves computationally expensive cross-modal\\nof different kernels (RBF, Polynomial, Spectral, Ma-\\nkernelcomputations. Techniqueslikecross-modal\\nhalanobis) and the HMK framework across key lim-\\ncontrastive learning (Radford et al., 2021) and\\nitations: Computational Overhead, Kernel Collapse,\\ncross-modalRFFapproximationscouldimprove\\nAdversarial Robustness, Hyperparameter Sensitivity,\\nandMultimodalAlignment. Eachaxisrepresentsalimi- efficiency.\\ntation,andtheplottedvaluesindicatethevulnerability Addressing these limitations through the sug-\\nseverityonascaleof1(lowvulnerability)to5(high gestedmitigationswillnotonlyenhancethescal-\\nvulnerability). ability and robustness of DPO-Kernels but also\\nbroadentheirapplicabilitytodynamic,multimodal\\n1. ComputationalOverhead: TheHierarchical alignmenttasks. RefertoTable5andFig.13fora\\nMixtureofKernels(HMK)incursacomputational detailedoverviewoflimitationsandsolutions.\\ncost 3-4x higher than baseline methods, primar-\\nily due to dynamic kernel balancing and hierar- 10 EthicalConsiderations\\nchicaldecomposition. Approximationtechniques\\nlikeRandomFourierFeatures(RFF)(Rahimiand TheDPO-Kernelsframeworkofferssignificantpo-\\nRecht, 2007), Nyström methods (Williams and tentialforalignmenttasks,yetitsapplicationde-\\nSeeger, 2001), and sparse Gaussian processes mandscarefulattentiontoethicalconcerns. Below,\\n(SnelsonandGhahramani,2006)canalleviatethis we highlight key considerations and propose ac-\\noverhead,makingtheframeworkmorescalablefor tionablestrategiestoaddressthem.\\nlarge-scaledatasets. HMK’scomputationalcostis\\n10.1 FairnessandBias\\njustifiedbysuperioralignmentcapabilities.\\n2. KernelCollapse: Thedominanceofasingle Kernel methods, including those employed in\\nkernelduringtraining,knownaskernelcollapse, HMK,caninadvertentlypropagatebiasespresent\\nlimits the diversity of kernel contributions. Miti- in training data. For instance, an imbalanced co-\\ngationsincludeentropy-basedregularization(Ne- variance matrix in the Mahalanobis kernel may\\nmirovskietal.,2009)topromotekerneldiversity lead to disparate impacts on underrepresentedTable5: SummaryofLimitationsandMitigationStrategies. Thistableprovidesanoverviewofthekeylimitations\\nidentified in the DPO-Kernels framework and suggests potential mitigation strategies to address them. Each\\nlimitation,suchascomputationaloverhead,kernelcollapse,oradversarialperturbations,isdescribedindetail,\\nalongwithreferencestostate-of-the-artsolutionslikeRandomFourierFeatures(RFF),entropy-basedregularization,\\nandadversarialtraining. Thesemitigationsaimtoenhancethescalability, robustness, andapplicabilityofthe\\nframeworkacrossdiversealignmenttasksandmultimodaldatasets.\\nLimitation Description SuggestedMitigation\\nComputational 3-4x computational cost increase for Use Random Fourier Features (RFF)\\nOverhead HMK due to dynamic kernel balancing (RahimiandRecht,2007),Nyströmmeth-\\nandhierarchicaldecomposition. ods(WilliamsandSeeger,2001),orsparse\\nGaussianprocesses(SnelsonandGhahra-\\nmani,2006).\\nKernelCollapse Dominanceofasinglekernelduringtrain- Applyentropy-basedregularization(Ne-\\ning, reducing kernel diversity and effec- mirovskietal.,2009)orcertifiedrobust-\\ntiveness. ness(WongandKolter,2018).\\nAdversarialPertur- Smallinputchangescancausesignificant Adoptadversarialtraining(Madryetal.,\\nbations shiftsinpreferences,impactingalignment 2018)orrobustkernellearningtechniques\\nstability. (Xuetal.,2009).\\nHyperparameter Performancedependsonsensitiveparam- Employmeta-learningapproaches(Finn\\nSensitivity eterslikeRBFbandwidth(σ),Polynomial etal.,2017a)oradaptivetuningstrategies\\ndegree (d), and Mahalanobis covariance (Hazanetal.,2007).\\n(Σ).\\nMultimodal Align- Cross-modal kernel computations are Leveragecross-modalcontrastivelearning\\nment computationallyexpensive,limitingscala- (Radfordetal.,2021)orcross-modalRFF\\nbilityformultimodaltasks. approximations.\\ngroups. To mitigate these risks, we recommend lationships. Techniquessuchasprivatekernelem-\\nemployingfairness-awarecovarianceregulariza- beddings (Abadi et al., 2016) can enhance data\\ntion(Gordalizaetal.,2021)andentropy-basedad- protectionbyminimizingprivacyleakagesduring\\njustmentstoensurebalancedkernelcontributions. kernelcomputation.\\nIncorporatingfairnessconstraintsintokernelopti-\\nmizationcanfurtheraddressthesebiases(Kamiran 10.3 InterpretabilityandTrust\\nandCalders,2012).\\nThehierarchicalnatureofHMKintroducescom-\\nplexity,makingitchallengingtointerpretthecon-\\n10.2 PrivacyRisks\\ntributions of individual kernels. Transparent vi-\\nTheMahalanobiskernel’srelianceoncovariance sualizations of kernel weights and the evolution\\nstructures poses privacy risks, as it may encode of local-global balance parameters (τ ,τ ) over\\n1 2\\nsensitivecorrelationswithinthedata. Thisconcern trainingcanbuildusertrust(Doshi-VelezandKim,\\nisparticularlyrelevantforpersonalorhealthcare 2017). Interactive tools enabling stakeholders to\\ndatasets. IncorporatingDifferentialPrivacy(DP) explore kernel influences at different stages of\\nmechanismsduringcovarianceestimation(Jayara- trainingwouldfurtherenhancemodelaccountabil-\\nmanandEvans,2021)cansafeguardsensitivere- ity.Table6: SummaryofEthicalConsiderationsandCorrespondingMitigationStrategies. Thistableoutlinesfive\\nkeyethicalconcernsassociatedwiththeDPO-Kernelsframework: fairnessandbias,privacyrisks,interpretability\\nandtrust,environmentalimpact,andpotentialmisuse. Eachconcernisaccompaniedbyabriefdescriptionofthe\\nissueandsuggestedmitigationstrategies,includingstate-of-the-arttechniquessuchasfairness-awarecovariance\\nregularization,differentialprivacymechanisms,efficientkernelapproximations,androbustdocumentationpractices.\\nThesestrategiesaimtoensuretheresponsibleandequitabledeploymentofDPO-Kernelsinalignmenttasksacross\\ndiversedomains.\\nEthicalConcern Description SuggestedMitigation\\nFairnessandBias Kernel methods may propagate bi- Use fairness-aware covariance reg-\\nasespresentintrainingdata,leading ularization (Gordaliza et al., 2021)\\ntounfairoutcomes. and entropy-based adjustments to\\nbalancekernelcontributions.\\nPrivacyRisks Covariance structures in Maha- IncorporateDifferentialPrivacy(DP)\\nlanobis kernel may encode sensi- mechanismsduringcovarianceesti-\\ntivedatacorrelations,riskingprivacy mation(JayaramanandEvans,2021)\\nbreaches. anduseprivatekernelembeddings.\\nInterpretability and Hierarchical kernel design intro- Provide transparent visualizations\\nTrust ducescomplexity,makingitdifficult of kernel weights and parameters\\ntointerpretindividualkernelcontri- (τ ,τ );developinteractivetoolsfor\\n1 2\\nbutions. stakeholders.\\nEnvironmentalImpact ThecomputationaldemandsofHMK Leverage efficient kernel approx-\\nraise concerns about energy effi- imations (e.g., Nyström methods\\nciency and environmental sustain- (Williams and Seeger, 2001)) and\\nability. energy-efficient hardware. Report\\nenergy usage in research publica-\\ntions.\\nPotentialMisuse Theframework’sflexibilitymaylead Adoptrobustdocumentationofmis-\\ntodual-useconcerns,suchasprofil- usescenariosandimplementethical\\ningormanipulativepersonalization. deploymentpractices.\\n10.4 EnvironmentalImpact (Hendersonetal.,2020).\\nThecomputationaldemandsofHMK,stemming\\n10.5 PotentialMisuse\\nfrom hierarchical kernel computation and opti-\\nmization, raise concerns about energy efficiency TheversatilityofDPO-Kernels,especiallyincap-\\n(Strubelletal.,2019). Toaddressthis,weadvocate turing local and global dependencies, presents\\nforefficientkernelapproximationtechniques,such dual-use concerns. For instance, while benefi-\\nasNyströmmethods(WilliamsandSeeger,2001), cialforalignmenttasks, theframeworkcouldbe\\nandencouragetheuseofenergy-efficienthardware. misusedforprofilingormanipulativepersonaliza-\\nReportingenergyusageinresearchpublicationsis tion(Zarsky,2016). Mitigationstrategiesinclude\\nanothersteptowardresponsibleAIdevelopment, robustdocumentationofpotentialmisusescenar-\\npromotingtransparencyinenvironmentalimpact iosandadherencetoethicaldeploymentpractices,Kernel Vulnerabilities Across Ethical Considerations RBF Kernel References\\nPolynomial Kernel\\nPrivacy Risks Spectral Kernel\\nM HMah Kalanobis Kernel MartinAbadietal.2016. Deeplearningwithdif-\\nferential privacy. In Proceedings of the ACM\\nInterpretability and Trust\\nSIGSACConferenceonComputerandCommu-\\nnicationsSecurity,pages308–318.\\nJina AI. 2023. Jina embeddings: A high-\\n1 2 3 4Fairne5ss and Bias\\nperformance embedding library. https://\\ngithub.com/jina-ai/embeddings.Accessed:\\nDecember24,2024.\\nEnvironmental Impact\\nFrancisBach.2017. Breakingthecurseofdimen-\\nsionalitywithconvexneuralnetworks. Journal\\nPotential Misuse\\nofMachineLearningResearch,18(19):1–53.\\nFigure14: Radarchartillustratingthevulnerabilities\\nofdifferentkernels(RBF,Polynomial,Spectral,Maha- FrancisRBach,GertRGLanckriet,andMichaelI\\nlanobis) and the HMK framework across key ethical Jordan. 2004. Multiple kernel learning, conic\\nconsiderations: FairnessandBias, PrivacyRisks, In-\\nduality,andthesmoalgorithm. InICML.\\nterpretability and Trust, Environmental Impact, and\\nPotentialMisuse. Higherscoresindicategreatervulner- YuntaoBai,AndyJones,KamalNdousse,Amanda\\nabilities,withHMKshowcasingheightenedsusceptibil-\\nAskell, Anna Chen, Nova DasSarma, Dawn\\nityinareassuchasEnvironmentalImpactandPotential\\nDrain, Stanislav Fort, Deep Ganguli, Tom\\nMisuse.\\nHenighan, Nicholas Joseph, Saurav Kadavath,\\nJacksonKernion,TomConerly,SheerEl-Showk,\\nsuchasmodelauditing(Binns,2018). NelsonElhage,ZacHatfield-Dodds,DannyHer-\\nDPO-Kernels demonstrate the transformative nandez,TristanHume,ScottJohnston,Shauna\\npotential of advanced machine learning in align- Kravec, Liane Lovitt, Neel Nanda, Cather-\\nmenttasks. Theirdeploymentmustprioritizefair- ine Olsson, Dario Amodei, Tom Brown, Jack\\nness,transparency,andsustainabilitytobenefitall Clark, Sam McCandlish, Chris Olah, Ben\\nstakeholders. Proactive measures and continued Mann, and Jared Kaplan. 2022a. Training a\\nresearchareessentialtoaddressethicalchallenges helpful and harmless assistant with reinforce-\\n(summarizedinTable6andinFig.14)andensure mentlearningfromhumanfeedback. Preprint,\\nresponsibleapplicationacrossdiversedomains. arXiv:2204.05862.\\nYuntao Bai, Saurav Kadavath, Amanda Askell,\\nand et al. 2022b. Training a helpful and\\nharmless assistant with rlhf. arXiv preprint\\narXiv:2204.05862.\\nMikhailBelkinandParthaNiyogi.2003.Laplacian\\neigenmapsfordimensionalityreductionanddata\\nrepresentation.Neuralcomputation,15(6):1373–\\n1396.\\nJamesBergstraandYoshuaBengio.2012.Random\\nsearchforhyper-parameteroptimization. Jour-nalofMachineLearningResearch,13(2):281– K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen,\\n305. H. Jun, L. Kaiser, M. Plappert, J. Tworek,\\nJ.Hilton,R.Nakano,C.Hesse,andJ.Schulman.\\nReuben Binns. 2018. Fairness auditing: Under- 2021. Training verifiers to solve math word\\nstandingtheimpactofbiasinmachinelearning problems. arXivpreprintarXiv:2110.14168.\\nsystems. InProceedingsoftheACMConference\\nonFairness,Accountability,andTransparency, Imre Csiszar. 2004. Information geometry and\\npages1–15. alternatingminimizationprocedures. Statistics\\n&Decisions.\\nChristopherM.Bishop.2006. PatternRecognition\\nandMachineLearning. Springer.\\nGanqu Cui, Lifan Yuan, Ning Ding, Guanming\\nYao,BingxiangHe,WeiZhu,YuanNi,Guotong\\nStephen Boyd and Lieven Vandenberghe. 2004.\\nXie, Ruobing Xie, Yankai Lin, Zhiyuan Liu,\\nConvex optimization. Cambridge University\\nandMaosongSun.2024. Ultrafeedback: Boost-\\nPress.\\ning language models with scaled ai feedback.\\nPreprint,arXiv:2310.01377.\\nJohn S Bridle. 1990. Training stochastic model\\nrecognitionalgorithmsasnetworkscanleadto\\nL.DanieleandSuphavadeeprasit.2023a. Amplify-\\nmaximummutualinformationestimationofpa-\\ninstruct: Synthetically generated diverse\\nrameters. In Neural Computation, volume 2,\\nmulti-turn conversations for efficient llm\\npages68–75.MITPress.\\ntraining. arXiv preprint arXiv:(coming\\nsoon). https://huggingface.co/datasets/\\nTingChen,SimonKornblith,MohammadNorouzi,\\nLDJnr/Capybara.\\nandGeoffreyHinton.2020.Asimpleframework\\nforcontrastivelearningofvisualrepresentations.\\nL.DanieleandSuphavadeeprasit.2023b. Amplify-\\nIn International conference on machine learn-\\ninstruct: Syntheticallygenerateddiversemulti-\\ning,pages1597–1607.PMLR.\\nturn conversations for efficient llm training.\\narXivpreprint,arXiv:(comingsoon).\\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng,\\nAnastasios Nikolas Angelopoulos, Tianle Li,\\nDavidLDaviesandDonaldWBouldin.1979. A\\nDachengLi,HaoZhang,BanghuaZhu,Michael\\nclusterseparationmeasure. IEEEtransactions\\nJordan, Joseph E. Gonzalez, and Ion Stoica.\\non pattern analysis and machine intelligence,\\n2024. Chatbot arena: An open platform for\\n1(2):224–227.\\nevaluatingllmsbyhumanpreference. Preprint,\\narXiv:2403.04132.\\nRoy De Maesschalck, Delphine Jouan-Rimbaud,\\nAakanksha Chowdhery et al. 2022. Palm: Scal- andDesireLMassart.2000. Themahalanobis\\ning language models with pathways. In arXiv distance. Chemometricsandintelligentlabora-\\npreprintarXiv:2204.02311. torysystems,50(1):1–18.\\nPaulFChristiano,JanLeike,TomBBrown,Miljan Jane Doe and Michael Lee. 2019. Advanced\\nMartic,ShaneLegg,andDarioAmodei.2017. weightedkernelmixturesforrobustmodelalign-\\nDeepreinforcementlearningfromhumanpref- ment. InProceedingsofthe36thInternational\\nerences. In Advances in Neural Information Conference on Machine Learning, pages 456–\\nProcessingSystems,volume30. 465.PMLR.FinaleDoshi-VelezandBeenKim.2017. Towards the34thInternationalConferenceonMachine\\na rigorous science of interpretable machine Learning(ICML),pages1126–1135.\\nlearning. arXivpreprintarXiv:1702.08608.\\nMehmetGönenandEthemAlpaydın.2011. Multi-\\nYann Dubois, Balázs Galambosi, Percy Liang, plekernellearningalgorithms. JournalofMa-\\nand Tatsunori B. Hashimoto. 2024a. Length- chineLearningResearch,12:2211–2268.\\ncontrolled alpacaeval: A simple way to\\ndebias automatic evaluators. Preprint, Ian Goodfellow, Yoshua Bengio, and Aaron\\narXiv:2404.04475. Courville.2016. DeepLearning. MITPress.\\nYann Dubois, Xuechen Li, Rohan Taori, Tianyi Pedro Gordaliza et al. 2021. A fairness-aware\\nZhang, Ishaan Gulrajani, Jimmy Ba, Car- frameworkforcovariance-basedclustering.Neu-\\nlos Guestrin, Percy Liang, and Tatsunori B. rocomputing,462:357–372.\\nHashimoto.2024b. Alpacafarm: Asimulation\\nframeworkformethodsthatlearnfromhuman Raia Hadsell, Sumit Chopra, and Yann LeCun.\\nfeedback. Preprint,arXiv. 2006. Dimensionalityreductionbylearningan\\ninvariantmapping. InIEEEConferenceonCom-\\nYann Dubois, Xuechen Li, Rohan Taori, Tianyi puter Vision and Pattern Recognition (CVPR),\\nZhang, Ishaan Gulrajani, Jimmy Ba, Car-\\npages1735–1742.\\nlos Guestrin, Percy Liang, and Tatsunori B.\\nHashimoto.2024c. Alpacafarm: Asimulation T. Hartvigsen, S. Gabriel, H. Palangi, M. Sap,\\nframeworkformethodsthatlearnfromhuman D.Ray,andE.Kamar.2022. Toxigen: Alarge-\\nfeedback. Preprint,arXiv:2305.14387. scalemachine-generateddatasetforadversarial\\nandimplicithatespeechdetection. InProceed-\\nDavid Duvenaud. 2014. Automatic Model Con-\\ningsofthe60thAnnualMeetingoftheAssoci-\\nstructionwithGaussianProcesses. Ph.D.thesis,\\nationforComputationalLinguistics(Volume1:\\nUniversityofCambridge.\\nLongPapers),pages3309–3326.\\nDavidDuvenaud,HannesNickisch,andCarlEd-\\nElad Hazan, Alekh Agarwal, and Satyen Kale.\\nwardRasmussen.2013. Additivegaussianpro-\\n2007. Adaptive online gradient descent. Pro-\\ncesses. InAdvancesinNeuralInformationPro-\\nceedings of the 20th Annual Conference on\\ncessingSystems(NeurIPS),pages226–234.\\nLearningTheory(COLT),pages528–543.\\nKawin Ethayarajh, Yejin Choi, and Swabha\\nPeterHendersonetal.2020. Towardstransparent\\nSwayamdipta.2022. Understandingdatasetdif-\\nandreproducibleairesearch: Aprotocolfordoc-\\nficulty with V-usable information. Preprint,\\numentenergyconsumption. JournalofMachine\\narXiv:2110.08420.\\nLearningResearch,21(248):1–43.\\nChelsea Finn, Pieter Abbeel, and Sergey Levine.\\n2017a. Model-agnostic meta-learning for fast D. Hendrycks, C. Burns, S. Basart, A. Zou,\\nadaptationofdeepnetworks. InProceedingsof M.Mazeika,D.Song,andJ.Steinhardt.2020.\\nthe34thInternationalConferenceonMachine Measuring massive multitask language under-\\nLearning(ICML),pages1126–1135. standing. InInternationalConferenceonLearn-\\ningRepresentations(ICLR).\\nChelsea Finn, Pieter Abbeel, and Sergey Levine.\\n2017b. Model-agnostic meta-learning for fast HamishIvison,YizhongWang,JiachengLiu,Ze-\\nadaptationofdeepnetworks. InProceedingsof qiu Wu, Valentina Pyatkin, Nathan Lambert,NoahA.Smith,YejinChoi,andHannanehHa- Gert R. G. Lanckriet, Nello Cristianini, Peter\\njishirzi.2024. Unpackingdpoandppo: Disen- Bartlett,LaurentElGhaoui,andMichaelI.Jor-\\ntanglingbestpracticesforlearningfromprefer- dan.2004. Multiplekernellearningforsupport\\nencefeedback. Preprint,arXiv:2406.09279. vectormachines. JournalofMachineLearning\\nResearch,5:27–72.\\nSamyakJain,EkdeepSinghLubana,KemalOksuz,\\nTomJoy,PhilipHSTorr,AmartyaSanyal,and\\nGert R. G. Lanckriet, Laurent El Ghaoui, Nello\\nPuneet K Dokania. 2024a. What makes and\\nCristianini,andMichaelI.Jordan.2002. Learn-\\nbreakssafetyfine-tuning? amechanisticstudy.\\ning the kernel matrix with semi-definite pro-\\narXivpreprintarXiv:2407.10264.\\ngramming. InProceedingsoftheInternational\\nConferenceonMachineLearning(ICML),pages\\nSamyakJain,EkdeepSinghLubana,KemalOksuz,\\n323–330.\\nTomJoy,PhilipHSTorr,AmartyaSanyal,and\\nPuneet K. Dokania. 2024b. What makes and\\nSergeyLevine,AviralKumar,GeorgeTucker,and\\nbreakssafetyfine-tuning? amechanisticstudy.\\nJustin Fu. 2020. Offline reinforcement learn-\\nPreprint,arXiv.\\ning: Tutorial,review,andperspectivesonopen\\nB. Jayaraman and David Evans. 2021. Privacy- problems. arXivpreprintarXiv:2005.01643.\\npreservingmachinelearning: Threatmodelsand\\nLisha Li, Kevin Jamieson, Giulia DeSalvo, Af-\\nsolutions. IEEESecurity&Privacy,19(2):49–\\nshinRostamizadeh,andAmeetTalwalkar.2018.\\n54.\\nHyperband: A novel bandit-based approach\\nEdwinTJaynes.1957. Informationtheoryandsta- to hyperparameter optimization. In Interna-\\ntisticalmechanics.PhysicalReview,106(4):620– tionalConferenceonLearningRepresentations\\n630. (ICLR).\\nFaisal Kamiran and Toon Calders. 2012. Data\\nX. Li, T. Zhang, Y. Dubois, R. Taori, I. Gulra-\\npreprocessingtechniquesforclassificationwith-\\njani,C.Guestrin,P.Liang,andT.B.Hashimoto.\\noutdiscrimination. KnowledgeandInformation\\n2023. Alpacaeval: An automatic evaluator of\\nSystems,33(1):1–33.\\ninstruction-following models. GitHub reposi-\\ntory.\\nHassanK.Khalil.2002. Nonlinearsystems. Pren-\\nticeHall.\\nHunter Lightman, Vineet Kosaraju, Yura Burda,\\nPangWeiKoh,ShioriSagawa,HakonMarklund, Harri Edwards, Bowen Baker, Teddy Lee, Jan\\nSangMichaelXie,MarvinZhang,AkshayBal- Leike,JohnSchulman,IlyaSutskever,andKarl\\nasubramani, Weihua Hu, Michihiro Yasunaga, Cobbe.2023. Let’sverifystepbystep. Preprint,\\nLisa Phillips, Irena Gao, et al. 2021a. Wilds: arXiv:2305.20050.\\nAbenchmarkofin-the-wilddistributionshifts.\\nPreprint,arXiv. Zachary C Lipton. 2016. The mythos of model\\ninterpretability. InProceedingsoftheInterna-\\nPangWeiKoh,ShioriSagawa,HakonMarklund, tionalConferenceonMachineLearning(ICML),\\nSangMichaelXie,MarvinZhang,AkshayBal- pages96–100.\\nsubramani, Weihua Hu, Michihiro Yasunaga,\\nLisa Phillips, Irena Gao, et al. 2021b. Wilds: ZiyuLiu,YuhangZang,XiaoyiDong,PanZhang,\\nAbenchmarkofin-the-wilddistributionshifts. YuhangCao,HaodongDuan,ConghuiHe,Yuan-\\narXivpreprintarXiv:2012.07421. jun Xiong, Dahua Lin, and Jiaqi Wang. 2024.Mia-dpo: Multi-image augmented direct pref- Sebastian Nowozin, Botond Cseke, and Ryota\\nerence optimization for large vision-language Tomioka.2016. f-gan: Traininggenerativeneu-\\nmodels. Preprint,arXiv:2410.17637. ral samplers using variational divergence min-\\nimization. In Proceedings of the 30th Interna-\\nK.Lv,W.Zhang,andH.Shen.2023a. Supervised tional Conference on Neural Information Pro-\\nfine-tuninganddirectpreferenceoptimization. cessingSystems(NeurIPS),pages271–279.Cur-\\nPreprint. ranAssociates,Inc.\\nK. Lv, W. Zhang, and H. Shen. 2023b. Super- Aaron van den Oord, Yazhe Li, and Oriol\\nvisedfine-tuninganddirectpreferenceoptimiza- Vinyals. 2018. Representation learning with\\ntion on intel gaudi2. https://medium.com/ contrastive predictive coding. arXiv preprint\\nintel-analytics-software/a1197d8a3cd3. arXiv:1807.03748.\\nAleksanderMadry,AleksandarMakelov,Ludwig Long Ouyang, Jeffrey Wu, Xu Jiang, and et al.\\nSchmidt, Dimitris Tsipras, and Adrian Vladu. 2022. Training language models to follow in-\\n2018. Towardsdeeplearningmodelsresistantto structionswithhumanfeedback. arXivpreprint\\nadversarialattacks. InInternationalConference arXiv:2203.02155.\\nonLearningRepresentations(ICLR).\\nGabrielPeyréandMarcoCuturi.2019. Computa-\\nCharles H Martin, Tongsu (Serena) Peng, and tionalOptimalTransport: WithApplicationsto\\nMichaelWMahoney.2021a. Predictingtrends DataScience. NowPublishersInc.\\ninthequalityofstate-of-the-artneuralnetworks\\nwithoutaccesstotrainingortestingdata. Nature LutzPrechelt.1998. Earlystopping—butwhen?\\nCommunications,12(1):4237. Neural Networks: Tricks of the Trade, pages\\n55–69.\\nCharles H. Martin, Tongsu (Serena) Peng, and\\nMichaelW.Mahoney.2021b. Predictingtrends JoaquinQuinonero-Candela,MasashiSugiyama,\\ninthequalityofstate-of-the-artneuralnetworks Anton Schwaighofer, and Neil D Lawrence.\\nwithoutaccesstotrainingortestingdata. Nature 2009. Dataset shift in machine learning. The\\nCommunications,12(1):4122. MITPress.\\nArkadi Nemirovski, Anatoli Juditsky, Guanghui Alec Radford, Jong Wook Kim, Chris Hallacy,\\nLan, and Alexander Shapiro. 2009. Robust AdityaRamesh,GabrielGoh,SandhiniAgarwal,\\nstochasticapproximationapproachtostochastic GirishSastry,AmandaAskell,PamelaMishkin,\\nprogramming. SIAMJournalonOptimization, JackClark,etal.2021. Learningtransferablevi-\\n19(4):1574–1609. sualmodelsfromnaturallanguagesupervision.\\nIn Proceedings of the 38th International Con-\\nYurii Nesterov. 2003. Introductory lectures on ference on Machine Learning (ICML), pages\\nconvexoptimization: Abasiccourse,volume87. 8748–8763.\\nSpringerScience&BusinessMedia.\\nRafael Rafailov, Archit Sharma, Eric Mitchell,\\nAndrewYNg,MichaelIJordan,andYairWeiss. Stefano Ermon, Christopher D. Manning, and\\n2001. Onspectralclustering: Analysisandan ChelseaFinn.2024. Directpreferenceoptimiza-\\nalgorithm. InAdvancesinNeuralInformation tion: Yourlanguagemodelissecretlyareward\\nProcessingSystems(NeurIPS),pages849–856. model. Preprint,arXiv:2305.18290.Raphael Rafailov, Orion Redwood, et al. 2023. John Shawe-Taylor and Nello Cristianini. 2004.\\nDirect preference optimization: You don’t Kernel Methods for Pattern Analysis. Cam-\\nneed rewards to finish rlhf. arXiv preprint bridgeuniversitypress.\\narXiv:2305.11517. Preprint,arXiv:2305.11517.\\nJohn Smith and Emily Davis. 2020. Hierarchi-\\nAli Rahimi and Benjamin Recht. 2007. Ran-\\ncal mixture models for enhanced semantic un-\\ndom features for large-scale kernel machines.\\nderstanding. JournalofMachineLearningRe-\\nNeurIPS.\\nsearch,21(123):1–25.\\nCarl Edward Rasmussen and Christopher K. I.\\nEdward Snelson and Zoubin Ghahramani. 2006.\\nWilliams. 2006. Gaussian Processes for Ma-\\nSparsegaussianprocessesusingpseudo-inputs.\\nchineLearning. MITpress.\\nInAdvancesinNeuralInformationProcessing\\nGunnar Rätsch and Manfred K. Warmuth. 2005. Systems(NeurIPS),pages1257–1264.\\nGeneralizedrepresentertheoremandkernelcol-\\nJasper Snoek, Hugo Larochelle, and Ryan P\\nlapse in regularized learning. In Proceedings\\nAdams. 2012. Practical bayesian optimiza-\\noftheConferenceonLearningTheory(COLT),\\ntion of machine learning algorithms. In Ad-\\npages104–118.Springer.\\nvances in Neural Information Processing Sys-\\nraymondd.2024. Llama-3.3-70b-instruct_gguf. tems(NeurIPS),pages2951–2959.\\nPaul Röttger, Hannah Kirk, Bertie Vidgen,\\nAarohi Srivastava and Colleagues. 2023. Be-\\nGiuseppeAttanasio,FedericoBianchi,andDirk\\nyond the imitation game: Quantifying and ex-\\nHovy.2024. XSTest: Atestsuiteforidentifying\\ntrapolatingthecapabilitiesoflanguagemodels.\\nexaggeratedsafetybehavioursinlargelanguage\\nPreprint,arXiv:2206.04615.\\nmodels. InProceedingsofthe2024Conference\\nof the North American Chapter of the Associ-\\nIngo Steinwart and Andreas Christmann. 2008.\\nation for Computational Linguistics: Human\\nSupportVectorMachines. SpringerScience&\\nLanguage Technologies (Volume 1: Long Pa-\\nBusinessMedia.\\npers),pages5377–5400,MexicoCity,Mexico.\\nAssociationforComputationalLinguistics. EmmaStrubell,AnanyaGanesh,andAndrewMc-\\nCallum.2019. Energyandpolicyconsiderations\\nBernhardSchölkopfandAlexanderJSmola.2002.\\nfordeeplearninginnlp. ProceedingsoftheAs-\\nLearning with Kernels: Support Vector Ma-\\nsociationforComputationalLinguistics(ACL).\\nchines, Regularization, Optimization, and Be-\\nyond. MITpress.\\nSaba Sturua, Isabelle Mohr, Mohammad Kalim\\nAkram, Michael Günther, Bo Wang, Markus\\nFlorianSchroff,DmitryKalenichenko,andJames\\nKrimmel, Feng Wang, Georgios Mastrapas,\\nPhilbin. 2015. Facenet: A unified embedding\\nAndreas Koukounas, Nan Wang, and Han\\nforfacerecognitionandclustering. Proceedings\\nXiao. 2024. jina-embeddings-v3: Multilin-\\noftheIEEEconferenceoncomputervisionand\\ngual embeddings with task lora. Preprint,\\npatternrecognition(CVPR),pages815–823.\\narXiv:2409.10173.\\nOzanSenerandVladlenKoltun.2018. Multi-task\\nlearningasmulti-objectiveoptimization. InAd- MiracSuzgun,NathanScales,NathanaelSchärli,\\nvances in Neural Information Processing Sys- Sebastian Gehrmann, Yi Tay, Hyung Won\\ntems(NeurIPS),pages527–538. Chung, Aakanksha Chowdhery, Quoc Le,EdChi,DennyZhou,andJasonWei.2023.Chal- J. Wei, X. Wang, D. Schuurmans, M. Bosma,\\nlengingBIG-benchtasksandwhetherchain-of- E. Chi, Q. Le, and D. Zhou. 2022. Chain\\nthoughtcansolvethem. InFindingsoftheAs- of thought prompting elicits reasoning in\\nsociationforComputationalLinguistics: ACL large language models. arXiv preprint\\n2023,pages13003–13051,Toronto,Canada.As- arXiv:2201.11903.\\nsociationforComputationalLinguistics.\\nKilianQWeinbergerandLawrenceKSaul.2009.\\nRami Thoppilan, Daniel De Freitas, Jamie Hall, Distancemetriclearningforlargemarginnear-\\nNoamShazeer,etal.2022. Lamda: Language estneighborclassification.InProceedingsofthe\\nmodelsfordialogapplications. InNeurIPS. InternationalConferenceonMachineLearning\\n(ICML).\\nRobertTibshirani.1996. Regressionshrinkageand\\nChristopher KI Williams and Matthias Seeger.\\nselection via the lasso. Journal of the Royal\\n2001. Using the Nyström method to speed up\\nStatisticalSociety: SeriesB(Methodological),\\nkernelmachines. AdvancesinNeuralInforma-\\n58(1):267–288.\\ntionProcessingSystems.\\nH. Touvron, L. Martin, K. Stone, P. Albert,\\nRonaldJWilliams.1991. Functionoptimization\\nA.Almahairi, Y.Babaei, N.Bashlykov, S.Ba-\\nusingconnectionistreinforcementlearningalgo-\\ntra,P.Bhargava,S.Bhosale,etal.2023. Llama\\nrithms. InConnectionistModels: Proceedings\\n2: Openfoundationandfine-tunedchatmodels.\\nofthe1990SummerSchool,pages229–255.El-\\narXivpreprintarXiv:2307.09288.\\nsevier.\\nLaurens van der Maaten and Geoffrey Hinton.\\nEricWongandJZicoKolter.2018. Provablede-\\n2008. Visualizingdatausingt-sne. Journalof\\nfensesagainstadversarialexamplesviathecon-\\nmachinelearningresearch,9(11):2579–2605.\\nvexouteradversarialpolytope. InInternational\\nConferenceonMachineLearning(ICML),pages\\nBram Wallace, Meihua Dang, Rafael Rafailov,\\n5283–5292.\\nLinqiZhou,AaronLou,SenthilPurushwalkam,\\nStefano Ermon, Caiming Xiong, Shafiq Joty,\\nZenglinXu,RongJin,HuanYang,andIrwinKing.\\nand Nikhil Naik. 2023. Diffusion model\\n2009. Robust multiple kernel learning. In In-\\nalignmentusingdirectpreferenceoptimization.\\nternational Conference on Machine Learning\\nPreprint,arXiv:2311.12908.\\n(ICML),pages1145–1152.\\nChenglong Wang, Yang Gan, Yifu Huo, Yongyu JaehongYoon,ShoubinYu,VaidehiPatil,Huaxiu\\nMu,MurunYang,QiaozhiHe,TongXiao,Chun- Yao, and Mohit Bansal. 2024. Safree:\\nliangZhang, TongranLiu, QuanDu, Di Yang, Training-free and adaptive guard for safe text-\\nandJingboZhu.2024. Rovrm: Arobustvisual to-image and video generation. Preprint,\\nreward model optimized via auxiliary textual arXiv:2410.12761.\\npreferencedata. Preprint,arXiv:2408.12109.\\nTianyuYu,YuanYao,HaoyeZhang,TaiwenHe,\\nZhilinWang,YiDong,JiaqiZeng,VirginiaAdams, Yifeng Han, Ganqu Cui, Jinyi Hu, Zhiyuan\\nMakesh Narsimhan Sreedhar, Daniel Egert, Liu, Hai-Tao Zheng, Maosong Sun, and Tat-\\nOlivierDelalleau,JanePolakScowcroft,Neel Seng Chua. 2024. Rlhf-v: Towards trustwor-\\nKant,AidanSwope,andOleksiiKuchaiev.2023. thy mllms via behavior alignment from fine-\\nHelpsteer: Multi-attribute helpfulness dataset grainedcorrectionalhumanfeedback. Preprint,\\nforsteerlm. Preprint,arXiv:2311.09528. arXiv:2312.00849.Tal Z Zarsky. 2016. Informed consent: Lessons\\nfromtheecj. FordhamInternationalLawJour-\\nnal,39:1171–1202.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng,\\nSiyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li,\\nEric P. Xing, Hao Zhang, Joseph E. Gonzalez,\\nand Ion Stoica. 2023. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. Preprint,\\narXiv:2306.05685.\\nJeffreyZhou,TianjianLu,SwaroopMishra,Sid-\\ndharthaBrahma, Sujoy Basu, YiLuan, Denny\\nZhou,andLeHou.2023. Instruction-following\\nevaluationforlargelanguagemodels. Preprint,\\narXiv:2311.07911.\\nBanghua Zhu, Evan Frick, Tianhao Wu, Hanlin\\nZhu, and Jiantao Jiao. 2023. Starling-7b: Im-\\nproving llm helpfulness & harmlessness with\\nrlaif.11 FrequentlyAskedQuestions(FAQs)\\n✽ What problem does DPO-Kernels address in Direct Preference Optimization (DPO)?\\n➠ DPO-KernelsaddressesthelimitationsofstandardDirectPreferenceOptimization,whichprimarily\\nrelies on fixed divergence measures (e.g., KL divergence) and simple transformations. These\\nlimitationsoftenresultininsufficientalignmentwithcomplexhumanpreferences. Byintroducing\\nkernelmethods,DPO-Kernelsenhancesthefeaturerepresentationandenablesaricher,moreadaptive\\noptimizationprocess. Theframeworkalsoincorporatesdiversedivergencemeasures(e.g.,Jensen-\\nShannon,Wasserstein)toimprovestabilityandrobustnessduringalignment,makingitsuitablefora\\nbroaderrangeoftasks.\\n✽ How do kernel methods improve preference optimization?\\n➠ Kernel methods map input data into higher-dimensional spaces where complex patterns and\\nrelationshipsaremoreeasilycaptured. InDPO-Kernels,thiscapabilityallowsfor:\\n– EnhancedRepresentationalPower: KernelslikeRBFfocusonlocalrelationships,whilespectral\\nkernelscaptureglobaldependencies.\\n– Flexible Feature Transformations: Instead of relying on raw distributions, kernel methods use\\ntransformedfeaturespacestobetterdifferentiatepreferredandless-preferredoutputs.\\n– Adaptability: Thehierarchicalmixtureofkernels(HMK)ensuresthemodelcandynamicallyadjust\\ntodiversealignmenttasksbybalancinglocalandglobalkernels.\\n✽ What is the purpose of the hybrid loss in DPO-Kernels?\\n➠ Thehybridlosscombinestwocomplementarycomponents:\\n– Probability-BasedContrastiveLoss: Thisensuresthatpreferredoutputsarerankedhigherbasedon\\nlikelihood.\\n– Embedding-Based Signals: These provide semantic context, helping resolve ambiguities when\\nprobabilitiesaloneareinsufficient. Forexample, embedding-basedlosscandistinguishbetween\\nsemanticallyrelevantoutputseveniftheirprobabilitiesaresimilar. Thisdual-objectivelossmech-\\nanism aligns the model’s output with both statistical and semantic expectations, leading to more\\nmeaningfulpreferenceoptimization.\\n✽ How are kernels and divergence measures selected in DPO-Kernels?\\n➠ DPO-Kernelsemploysdata-drivenmetricstoautomateselection:\\n– KernelSelection: MetricslikePositive-NegativeDivergence(PND)andTripletAlignmentTightness\\n(TAT)evaluatetheseparationandclusteringofalignedpreferences,helpingidentifythemostsuitable\\nkernelforagiventask.\\n– DivergenceSelection: MetricssuchasSupportOverlapandDriftMagnitudeassessthedistributional\\ncharacteristicsofthedata,guidingthechoiceofdivergencemeasures. Forexample,Wasserstein\\ndivergence is preferred for distributions with significant shifts, while Bhattacharyya divergence\\nworkswellwithoverlappingdistributions.\\n✽ What is the Hierarchical Mixture of Kernels (HMK), and why is it needed?\\n➠ The Hierarchical Mixture of Kernels (HMK) dynamically combines local kernels (e.g., RBF,\\nPolynomial)andglobalkernels(e.g.,Spectral,Mahalanobis). Thisdesign:– Balancesshort-andlong-rangedependencies.\\n– Preventskernelcollapse,whereonekerneldominates,reducingdiversity.\\n– Adaptstovaryingdatageometries,ensuringrobustalignmentacrossdiversetasks. HMK’shierarchi-\\ncalstructureimprovesgeneralizationbyleveragingthecomplementarystrengthsofdifferentkernel\\ntypes.\\n✽ How does DPO-Kernels ensure generalization and prevent overfitting?\\n➠ DPO-KernelsusestheWeightedAlphametric,basedonHeavy-TailedSelf-Regularization(HT-\\nSR)theory,tomonitorandmitigateoverfitting. Byanalyzingtheeigenvaluedistributionofweight\\nmatrices,theframeworkidentifieslayerspronetooverfitting. KernelslikeRBFandspectral,paired\\nwithdivergencessuchasBhattacharyyaandWasserstein,achievelowgeneralizationgaps,ensuring\\nrobustness. Thisapproachminimizesoverfittingwhilemaintaininghighalignmentfidelity.\\n✽ What are the computational trade-offs of DPO-Kernels?\\n➠ DPO-Kernels,particularlytheHMKframework,incurshighercomputationalcosts(3-4xcompared\\ntostandardDPO).Thisisduetotheincreasedcomplexityofkernelcomputationsandthehybridloss\\nfunction. However,theframework’ssignificantgainsinalignmentperformanceandgeneralization\\njustifythesecostsforhigh-stakesapplications. Futureworkaimstooptimizecomputationalefficiency\\nwhilepreservingthesebenefits.\\n✽ What datasets were used to validate DPO-Kernels?\\n➠ DPO-Kernels was tested on 12 datasets, covering tasks like factuality, reasoning, safety, and\\ninstructionfollowing. Thesedatasetsincludehuman-annotatedsources(e.g.,HH-RLHF,Chatbot\\nArena),web-scrapeddatasets(e.g.,SHP-2),andsyntheticallygenerateddatasets(e.g.,Ultra-Feedback,\\nAlpacaFarm GPT-4). This diverse evaluation ensures that the framework is robust across various\\nreal-worldalignmentchallenges.\\n✽ What is the primary motivation for the local-global split in the Hierarchical Mixture of\\nKernels (HMK)?\\n➠ Thelocal-globalsplitaddressestheneedtocapturebothshort-range,fine-graineddependencies\\nandlong-range,structuralrelationshipsinthedata. Localkernels(e.g.,RBF,Polynomial)havebeen\\nshowntobeeffectiveincapturingneighborhood-levelrelationships(Shawe-TaylorandCristianini,\\n2004),whileglobalkernels(e.g.,Spectral,Mahalanobis)modelthebroaderstructureofthedata,as\\nseeninLaplacianeigenmaps(BelkinandNiyogi,2003)andcovariance-baseddistances(DeMaess-\\nchalcketal.,2000). Byintegratinglocalandglobalviews, HMKoffersimprovedgeneralization,\\nreducingoverfittingtospuriouspatterns(RasmussenandWilliams,2006).\\n✽ How are kernels classified as local or global? Why is Polynomial considered local and\\nSpectral considered global?\\n➠ Kernelsareclassifiedaslocalorglobalbasedontheireffectiverange(Shawe-TaylorandCristianini,\\n2004). RBFkernelshaveafiniteeffectiverangeofr ≈ 2.15σ (RasmussenandWilliams,2006),and\\nPolynomialkernelscaptureinteractionsatshortdistancesforsmalldegrees. Incontrast,Spectral\\nkernelsspantheeigenspectrum,capturingtheglobalmanifoldstructure(BelkinandNiyogi,2003),\\nwhileMahalanobiskernelsaregovernedbytheglobalcovarianceofthedata(DeMaesschalcketal.,\\n2000).✽ How does the Local-Global Balance Parameter (τ) influence generalization and kernel\\ndominance?\\n➠ TheLocal-GlobalBalanceParameter(τ)allowsadaptivecontrolbetweenlocalandglobalcon-\\ntributions,followingprinciplesestablishedinmulti-scalemodeling(Duvenaud,2014). Ahigherτ\\nencouragesemphasisonlocalkernels,whilealowerτ highlightsglobalkernels. Thisdecomposition\\nprevents the model from overfitting to either extreme. Studies on Gaussian Processes with multi-\\nlevelkernelcombinationssupportthisapproach,enablingdynamicadaptationtotaskcomplexity\\n(RasmussenandWilliams,2006;Duvenaud,2014).\\n✽ What role do the kernel weights λ ,λ ,λ ,λ play in kernel selection, and how are they\\n1 2 3 4\\nlearned?\\n➠ Theweightsλ ,λ ,λ ,λ controltherelativecontributionsofeachkernel. Similartopriorwork\\n1 2 3 4\\nonmixturemodels(SteinwartandChristmann,2008),theseweightsarelearnedviagradientdescent\\nandparameterizedusingasoftmaxtransformation. Thisensuresthattheweightsremainnon-negative\\nandsumto1,enablingsmoothadjustmentsduringtraining(Shawe-TaylorandCristianini,2004).\\nSuchadaptiveweightlearninghasbeenlinkedtoimprovedmodelrobustness(Duvenaud,2014).\\n✽ What prevents HMK from collapsing to a single dominant kernel?\\n➠ HMK avoids kernel collapse through two strategies: (1) hierarchical decomposition using the\\nLocal-GlobalBalanceParameter(τ),whichensuresbothlocalandglobalcomponentsremainactive,\\nand(2)entropyregularization,whichencouragesnon-uniformkernelweights. Similarapproachesto\\npreventcollapseinkernel-basedlearninghavebeenexploredinconvexneuralnetworks(Bach,2017)\\nandkernelmixtures(Shawe-TaylorandCristianini,2004).\\n✽ Why are RBF, Polynomial, Spectral, and Mahalanobis kernels chosen for HMK?\\n➠ Thesefourkernelsarechosenfortheirdiverseandcomplementarycharacteristics. RBFkernelsare\\npopularfortheirsmoothlocalinteractions(Shawe-TaylorandCristianini,2004),whilePolynomial\\nkernelsmodelhigher-orderlocaldependencies(SteinwartandChristmann,2008). Spectralkernels\\naremotivatedbygraph-basedapproacheslikeLaplacianeigenmaps(BelkinandNiyogi,2003),and\\nMahalanobiskernelsexploitcovariance-baseddistances(DeMaesschalcketal.,2000). Thisselection\\nprovidescomprehensivecoverageoflocalandglobalproperties.\\n✽ How does HMK improve generalization over flat kernel mixtures?\\n➠ Unlikeflatkernelmixtures,whichcancollapsetoasingledominantkernel(Shawe-Taylorand\\nCristianini, 2004), HMK uses hierarchical decomposition. The Local-Global Balance Parameter\\n(τ) dynamically shifts between local and global contributions, thereby enhancing generalization.\\nSimilar strategies have been shown to improve performance in Gaussian Processes with multiple\\nkernellearning(RasmussenandWilliams,2006;Duvenaud,2014).\\n✽ What is the role of entropy regularization in HMK?\\n➠ Entropy regularization prevents collapse to a single dominant kernel by encouraging diversity\\nin the kernel weights λ ,λ ,λ ,λ . This approach follows principles used in Bayesian learning\\n1 2 3 4\\nandkernelmixturemodels(Shawe-TaylorandCristianini,2004;RasmussenandWilliams,2006).\\nThe entropy term\\n−(cid:80)4\\nλ log(λ ) ensures that at least two kernels maintain significant weight\\ni=1 i i\\ncontributionsthroughouttraining.✽ How do the alignment metrics (PND, PNAV, TAT, NAG) influence kernel selection?\\n➠ Themetricsofferinsightsintokerneleffectiveness. PND(Positive-NegativeDivergence)ensures\\nalignmentseparability,PNAV(Positive-NegativeAlignmentVariance)selectsstablekernels,TAT\\n(Triplet Alignment Tightness) promotes tight clusters, and NAG (Normalized Alignment Gap)\\nemphasizesgeneralization. Similarmetricsareusedinkernelalignmentstudies(Shawe-Taylorand\\nCristianini,2004;SteinwartandChristmann,2008)andhavebeenshowntoguidetheselectionof\\ntask-appropriatekernels.\\n✽ Can HMK support more complex kernel hierarchies or additional kernels?\\n➠ Yes, HMK can be extended to support deeper hierarchies or new kernel types. For instance,\\nLaplacian, Wasserstein, or graph-based kernels can be added to the local or global groups. Prior\\nworkonhierarchicalGaussianProcesses(Duvenaud,2014)andmulti-scalemodels(Rasmussenand\\nWilliams,2006)suggeststhatdeeperhierarchiescanofferfinercontroloverdependenciesatmultiple\\nscales.\\n✽ HMKissimplyanother\"weightedkernelmixture\"withamorecomplexparameterization.\\n➠ WhileHMKmayinitiallyresembletraditionalweightedkernelmixtures, itfundamentallydis-\\ntinguishesitselfthroughitshierarchicalarchitectureandadaptiveparameterization,asdetailedin\\nSection6.1. Unlikeflatmixturesthatassignstaticweightstoeachkernel,HMKorganizeskernels\\nintomultiplehierarchicallayers,enablingdynamicinteractionsandcontext-dependentweighting\\nduringtraining(SmithandDavis,2020). ThishierarchicalstructureallowsHMKtocapturemore\\ncomplex semantic relationships and enhances scalability, addressing limitations inherent in stan-\\ndardmixtures. Additionally,HMKincorporatesanautomatickernelselectionmechanism,which\\navoidsdata-drivenmetricstooptimizekernelchoicethatdemandsmanualtuning. Theseinnovations\\ncollectivelyprovidesuperiorflexibilityandgeneralizationcapabilities,distinguishingHMKfrom\\nconventionalweightedkernelapproaches(DoeandLee,2019).\\n✽ Abstract is too long\\n➠ The abstract is intentionally detailed to provide reviewers with comprehensive insights into\\nourmethodology,keycontributions,andempiricalresults. Thisthoroughnessfacilitatesadeeper\\nunderstanding and more informed evaluation of our DPO-Kernels framework during the review\\nprocess. Upon acceptance, we will produce a more concise version of the abstract for public\\ndisseminationandbroaderaudiences,highlightingthemainaspectsofourworksuccinctly.A Appendix Complexity, and Overhead: Appendix Ap-\\npendixIdetailsgradientderivationsforvarious\\nTheAppendixservesasacomprehensivesupple- kernelsanddivergences,alongwithcomplexity\\nmenttothemaincontent,providingdetailedtech- analysis and computational overhead. These\\nnicaljustifications,theoreticalinsights,andexperi- aspects, omitted from the main paper due to\\nmentalevidencethatcouldnotbeincludedinthe spaceconstraints,arecrucialfortheoreticalun-\\nmainbodyduetospaceconstraints. Itaimstoen- derstandingandreplicability.\\nhancetheclarity,reproducibility,andtransparency ✽ EmpiricalFindings: Resultsfrom12datasets\\noftheresearch. Theappendixisdesignedtopro- aresummarizedinSec.7andexpandedupon\\nvide a complete, transparent, and accessible ref- inAppendixJ.\\nerence for the reader. We encourage readers to ✽ Gradient Descent Dynamics on Kernel-\\nreview this material, as it offers deeper insights Induced Loss Landscapes: In Appendix K,\\nintothetheoreticalandempiricalcontributionsof we analyze gradient descent dynamics on\\nourwork. Thisappendixisorganizedintoseveral losslandscapesinducedbyRBF,Polynomial,\\nkeysections: Spectral, Mahalanobis kernels, and HMK,\\n✽ Richer Representation: Hybrid Loss: Key brieflymentionedinthemainbodyinFig.1.\\npointsareoutlinedinSec.2,whileAppendix ✽ Safe vs. Unsafe Cluster Effects: Kernel-\\nAppendixDprovidesdetailedderivationsand induced clustering during safety fine-tuning\\ntheoreticalunderpinningsoftheHybridLoss. projects unsafe inputs into null spaces (Jain\\n✽ Kernel-Integrated DPO Formulation: Key etal.,2024a),formingdistinctclustersforsafe\\npoints are covered in Sec. 3, with Appendix andunsafedata. Separationandcohesionare\\nAppendixEdetailingHybridLossderivations quantifiedusingDavies-BouldinScore(DBS)\\nusingspecifickernels: RBF,Polynomial,Spec- and qualitative assessments of different ker-\\ntral,andMahalanobis. nels. Discussed in Sec. 7.4 and detailed in\\n✽ Alternative Divergence Functions: Beyond AppendixL.\\nKL divergence, we explore Jensen-Shannon, ✽ Heavy-Tailed Self-Regularization (HT-SR)\\nHellinger,Rényi,Bhattacharyya,Wasserstein, - Generalization: Using the Weighted Al-\\nand f-divergences, outlined in Sec. 4 and de- phametricproposedin(Martinetal.,2021a),\\ntailedinAppendixF. grounded in HT-SR theory, we investigate\\n✽ Data-DrivenSelectionofKernel-Divergence: whetheralignedmodels,particularlyHMK,ex-\\nChoosing the optimal kernel-divergence pair hibit overfitting and quantify its extent. The-\\nfrom 28 combinations (4 kernels × 7 diver- oretical bounds for all kernels and HMK are\\ngences) is complex. To address this, we in- analyzed,withanoverviewinSec.7.5andde-\\ntroduce4 metricsforkernelselection—PND, tailedfindingsinAppendixM.\\nPNAV, TAT, and NAG—and 4 for divergence ✽ Hyperparameters and Best Practices: Key\\nselection: Support Overlap, Drift Magnitude, hyperparameter settings and practical guide-\\nKurtosis, and Smoothness, outlined in Sec. 5 linesforoptimizingDPO-Kernelperformance\\nandextendedinAppendixG). across tasks are detailed in Appendix N, as\\n✽ WehighlighttheadvantagesoftheKernelMix- spaceconstraintsnoscopeofdiscussioninthe\\ntureapproachoversingle-kernellearningand mainpaper.\\nintroduce the Hierarchical Mixture of Ker-\\nnels(HMK)inSec.6,withdetaileddiscussion\\ninAppendixH.\\n✽ Gradient Computation, ComputationalB DatasetDetails – PRM800k (Lightman et al., 2023): Data from\\nthesecondphaseofcollectionisemployed. We\\nThissectionprovidesanoverviewofthedatasets\\nselectpromptswheremodelgenerationsinclude\\nutilized in this study, categorized into Human-\\nonecorrectandoneincorrectanswer,randomly\\nAnnotated,Web-Scraped,andSyntheticallyGen-\\ndesignatingthemas\"chosen\"and\"rejected,\"re-\\nerateddatasets. Eachdataset’ssources,licensing\\nspectively. This dataset is distributed under the\\ninformation,andpreprocessingstepsareoutlined\\nMIT license. More information is available at\\nbelow.\\nhttps://github.com/openai/prm800k.\\n• Human-AnnotatedDatasets: • Web-ScrapedDatasets:\\n– HH-RLHF(Baietal.,2022a): Thetrainingsplit – SHP-2(Ethayarajhetal.,2022): Weutilizethe\\nis accessed via Hugging Face. This dataset fol- publicly available training split from Hugging\\nlows the MIT license. https://huggingface. Face, downsampled to 500,000 samples for ef-\\nco/datasets/Anthropic/hh-rlhf. ficiency. This dataset comprises content from\\nStackExchange, licensed under the CC BY-SA\\n– HelpSteer (Wang et al., 2023): Available\\nlicense, and Reddit, adhering to Reddit’s API\\non Hugging Face, we average fine-grained\\ntermsofuse. Formoredetails,refertothedataset\\nscores (excluding verbosity) to determine cho-\\ncard at https://huggingface.co/datasets/\\nsen and rejected pairs. Licensed under CC\\nstanfordnlp/SHP-2.\\nBY-4.0. https://huggingface.co/datasets/\\nnvidia/HelpSteer.\\n• SyntheticallyGeneratedDatasets:\\n– Chatbot Arena Conversations (Chat-\\n– Ultra-Feedback(Cuietal.,2024): Asynthetic\\nbot Arena 2023) (Zheng et al., 2023):\\ndataset designed to amplify fine-grained align-\\nSourced from Hugging Face’s training split at\\nment signals across diverse tasks. Licensing\\nhttps://huggingface.co/datasets/lmsys/\\ndetailsarespecifiedinthecorrespondingdataset\\nchatbot_arena_conversations. We exclude\\ncard https://huggingface.co/datasets/\\nmulti-turnsamplesandfilterouttiestomaintain\\nHuggingFaceH4/ultrafeedback_binarized.\\ndataconsistency. PromptsarelicensedunderCC\\nBY-4.0,andoutputsunderCCBY-NC-4.0. – Nectar (Zhu et al., 2023): A synthetically gen-\\nerated dataset aimed at task-specific alignment\\n– Chatbot Arena Preferences (Chat-\\nevaluations. Detailsandlicensingcanbefound\\nbot Arena 2024) (Chiang et al.,\\nhttps://starling.cs.berkeley.edu/.\\n2024): Obtained from Hugging Face at\\nhttps://huggingface.co/datasets/lmsys/ – Orca (Lv et al., 2023b): This dataset is\\nlmsys-arena-human-preference-55k. Sim- synthesized for improving alignment across\\nilar preprocessing is applied as with the 2023 multiple alignment domains. It is avail-\\ndataset. This dataset is available under the able under a custom license from https:\\nApache2.0license. //huggingface.co/datasets/argilla/\\ndistilabel-intel-orca-dpo-pairs.\\n– AlpacaFarmHumanPreferences(Duboisetal.,\\n2024c): We use the ’preference’ splits from – Capybara 7k (Daniele and Suphavadeepra-\\nHugging Face. The dataset is licensed under sit, 2023a): Provided by Argilla on Hugging\\nCC BY-NC-4.0. https://huggingface.co/ Face at https://huggingface.co/datasets/\\ndatasets/tatsu-lab/alpaca_farm/viewer/ argilla/. Licensingdetailsareavailableonthe\\nalpaca_human_preference. datasetpage.– AlpacaFarmGPT-4Preferences(Danieleand 2022). The classifier implementation is avail-\\nSuphavadeeprasit, 2023b): A synthetic dataset able at https://github.com/paul-rottger/\\ngenerated using GPT-4, utilized for preference exaggerated-safety. Wereportthepercentage\\nfine-tuning tasks. The dataset is licensed un- of model generations classified as toxic by the\\nder CC BY-NC-4.0. https://huggingface. detector.\\nco/datasets/tatsu-lab/alpaca_farm\\n• XSTest(Röttgeretal.,2024): XSTestevaluatesa\\nmodel’s ability to refuse malicious instructions\\nC EvaluationDetails\\nwhile correctly following similar but safe\\nones. We use the official set of test prompts\\nWe evaluate our models across multiple tasks,\\nprovided in their repository (https://github.\\ngroupedintothefollowingcategories: Factuality,\\ncom/paul-rottger/exaggerated-safety),\\nSafety, Reasoning, and Instruction Following.\\ncomprising 200 unsafe prompts and 250 safe\\nThe benchmarks and methodologies are detailed\\nprompts.\\nbelow. We close follow evaluation setup as pro-\\nposedin(Ivisonetal.,2024). Followingtheoriginalsetup,wetestedbothGPT-\\n4andheuristic-basedrulestodetectwhetherthe\\nFactuality\\nmodel’sresponsesconstitutedrefusals. Ouranaly-\\n• MMLU:Usingtheofficialevaluationscriptand sisfoundGPT-4tobemorereliable,asitsbroader\\nprompts from Hendrycks et al. (Hendrycks interpretative capabilities effectively handle the\\net al., 2020) https://github.com/hendrycks/ varied response patterns exhibited by modern\\ntest, wetestwith0-shotexamples, adheringto models,whichoftenexceedthecoverageofpre-\\nthe original setup. Average accuracy across test definedheuristicrules.\\nsamplesisreported.\\nInthisstudy,wereporttheF1metric,whichbal-\\nances precision and recall, as a comprehensive\\nSafety\\nmeasureofthemodel’srefusalaccuracy.\\n• ToxiGen(Hartvigsenetal.,2022): Weadhereto\\ntheevaluationsetupdescribedin(Touvronetal.,\\nReasoning\\n2023)butusetheoriginalsetofpromptsprovided\\nin(Hartvigsenetal.,2022),specificallydesigned • GSM8k (Cobbe et al., 2021): Following Wei et\\nto elicit toxic language for certain demographic al. (Wei et al., 2022), we evaluate on the test\\ngroups. Tominimizeevaluationcosts,weuse500 setusingchain-of-thoughtpromptingwith8-shot\\n\"hateful\"promptspergroup. examples. Finalnumericalanswersareextracted,\\nandaccuracyiscalculated.\\nForbaselanguagemodels,theoriginalToxiGen\\nprompts are used without modification, and re-\\n• Big Bench Hard (BBH) (Srivastava and Col-\\nsponsesaregreedilydecodeduptothefirstnew-\\nleagues, 2023; Suzgun et al., 2023): We adopt\\nline or a maximum of 512 tokens. For aligned\\nthe setup outlined in the original paper, using\\nmodels,promptsareincorporatedintothecorre-\\nthechain-of-thought(CoT)reasoningframework.\\nspondingtemplate,andthemodelispromptedto\\nThe evaluation employs the officially provided\\ncompletethetaskuntilastoptokenisgenerated\\nprompts,whichincludethreefew-shotin-context\\noramaximumof512tokensisreached.\\nexamples. FortheCoTsetup,weextractthefirst\\nThegeneratedoutputsareanalyzedusingafine- word following the phrase \"So the answer is,\"\\ntuned roberta-large model trained to detect or the entire response if this substring is absent.\\ntoxic content, as detailed in (Hartvigsen et al., PerformanceisreportedastheaverageaccuracyProbabilityPath Probability-basedAlignment\\nInput(x,y+,y−) π(y+|x)\\nπ(y−|x)\\nEmbedding-basedAlignment\\nHybridLossLhybrid =E x,y+,y−(cid:104) ππ (( yy −+| |x x)\\n)\\n+γlog(cid:16) ee yy −+| |e ex x(cid:17)(cid:105)\\nEmbeddingPath\\nγlog(cid:16) ee yy −+| |e ex x(cid:17)\\nFigure 15: The input (x,y+,y−) is processed through two parallel paths: (1) probability-based alignment,\\nwhich computes\\nπ(y+|x),\\nand (2) embedding-based alignment, which computes\\nγlog(cid:16)e y+|ex(cid:17)\\n. Both signals\\nπ(y−|x) e y−|ex\\narecombinedtoformtheHybridLossL ,capturingprobabilisticandsemanticalignmentinasingleunified\\nhybrid\\nframework.\\nacrossallsub-tasks,eachofwhichusesaccuracy semanticalignment. Thisunifiedapproachyields\\nastheprimaryevaluationmetric. richer,morecomprehensivepreferencemodeling,\\ndepictedinFig.15.\\nInstructionFollowing\\nD.1 MathematicalDefinition\\n• AlpacaEval(Lietal.,2023;Duboisetal.,2024a):\\nUtilizing the framework by Li et al. (Li et al., TheHybridLossobjectivecombinesprobability-\\n2023), we evaluate both AlpacaEval 1 and 2 based and embedding-based preference informa-\\nwithdefaultsettings,allowingmodelstogenerate tionintoasingleloss:\\nup to 8192 tokens. Performance is reported un-\\ndertheseconfigurations. https://github.com/\\n(cid:104)π(y+ | x) (cid:16)e | e (cid:17)(cid:105)\\ntatsu-lab/alpaca_eval. E + γlog y+ x ,\\nx,y+,y− π(y− | x) e | e\\ny− x\\n• IFEval (Zhou et al., 2023): IFEval evaluates a\\nwhere:\\nmodel’sabilitytofollowinstructionscontaining\\nverifiableconstraints,suchas\"writeinmorethan\\n• xistheinputorquery.\\n400 words.\" We utilize the official evaluation\\ncodeprovidedwiththeoriginalpaperandreport • y+ andy− arethepositive(preferred)andnega-\\nthe \"Loose Accuracy\" metric at the prompt tive(non-preferred)responses,respectively.\\nlevel. Aresponseisconsideredcorrectonlyifall\\n• π(y+ | x) and π(y− | x) denote the model’s\\nconstraints specified in the prompt are satisfied\\npredictedprobabilitiesfory+ andy−.\\nafter normalizing the output. https://github.\\ncom/google-research/google-research/ • e ande representembedding-basedsimilarity\\ny+ y−\\ntree/master/instruction_following_eval. scoresofy+ andy− withrespecttox.\\nD HybridLossFormulation • γ > 0 controls the relative importance of the\\nembedding-basedcomponent.\\nDPO(Rafailovetal.,2023)optimizesthelog-ratio\\nbetween the probabilities of preferred and non- • αandβ arehyperparametersforaregularization\\npreferredresponses. Whileitiseffectiveformany termensuringπ remainsclosetoareferencepol-\\nθ\\nalignment tasks, it focuses only on probability- icyπ .\\nref\\nbasedsignalsanddoesnotcapturenuancedseman-\\nD.2 DecompositionoftheHybridLoss\\ntic alignment. To address this gap, we propose a\\nnovelHybridLossthatintegratesbothprobability- Thehybridlosscanbeviewedasthesumofthree\\nbasedpreferencealignmentandembedding-based mainparts:1. Probability-Based Preference Alignment: 3. Interpretable Embedding Signal: The dif-\\nmultline* ference(e −e )intheembeddingspaceacts\\ny+ y−\\nlikea“semanticmargin”separatingpositivefrom\\n(cid:104) π(y+ | x)(cid:105) negative responses. This helps improve general-\\nL = E log\\nDPO x,y+,y− π(y− | x) izationandmaintainsemanticconsistencyinthe\\nmodel’soutputs.\\nThisisthestandardDPOloss,ensuringthemodel\\nassignshigherprobabilitytothepositiveresponse D.4 ImpactoftheHybridLossonPolicy\\ny+ overthenegativeresponsey−. Itprovidesthe Learning\\ncorepreferencealignmentsignalcommonlyused\\n• Semantic-AwarePreferenceModeling: Byin-\\nin reinforcement learning from human feedback\\ncorporatingembedding-basedsignals,thehybrid\\n(RLHF)(Christianoetal.,2017).\\nlossensuresthathigh-probabilityresponsesalso\\nremainsemanticallyalignedwiththeinput. This\\n2. Embedding-BasedSemanticAlignment:\\nis especially advantageous for tasks where se-\\nmanticcoherenceiscrucial(e.g.,summarization,\\nL = E (cid:104) γlog(cid:16)e y+| e x(cid:17)(cid:105) question-answering).\\nembed x,y+,y−\\ne | e\\ny− x\\n• DynamicEmphasisonProbabilityandEmbed-\\nThis term leverages embedding-based similarity dings: Theparameterγ canbetunedthroughout\\nscores e and e . The factor γ determines training. Early in training, a larger γ might be\\ny+ y−\\nhow much the model should focus on aligning usedtoguidesemanticcoherencemorestrongly.\\nresponsessemantically. Whenγ ishigher,seman- Astrainingprogresses,γ canbereducedtofine-\\ntic alignment plays a larger role relative to the tunetheprobabilityalignment.\\nprobability-basedterm.\\n• GeneralizationAcrossEmbeddingModels: Al-\\nD.3 PropertiesoftheHybridLoss thoughtheembeddingsimilarityscorese and\\ny+\\ne arederivedusingJinaEmbeddings(AI,2023),\\n1. Adaptive Control via γ: γ balances y−\\nthe approach is compatible with other models,\\nprobability-basedandembedding-basedalignment\\nmaking the framework flexible across different\\nsignals:\\nembeddingecosystems.\\n• γ = 0: Thehybridlosssimplifiestothestandard\\nD.5 HowDoesHybridLossDifferfrom\\nDPOloss,usingonlyprobability-basedalignment.\\nRLHF’sUseofEmbeddings?\\n• γ > 0: Embedding-basedalignmentisincluded, Reinforcement Learning from Human Feed-\\nencouraging the model to consider semantic co- back(RLHF)(Christianoetal.,2017)isawidely\\nherencealongsideprobabilityalignment. adopted mechanism for aligning language mod-\\nels with human preferences. The RLHF process\\n2. Soft Constraint on Semantic Consistency: involvestwomainsteps:\\nTheembedding-basedtermensuresthemodeldoes\\nnotrewardmisalignmentsify+ andy− areseman- 1. Reward Model Training: A reward model is\\nticallysimilar. Thishelpsthemodelavoidreinforc- trainedtopredicthumanpreferencesbylearning\\ningincorrectpreferenceswhenprobability-based from comparison data where human annotators\\nsignalsareuncertain. rankdifferentresponses.2. PolicyOptimization: Thelanguagemodel(pol- • Reward Model Dependency: RLHF relies on\\nicy)isthenoptimizedusingreinforcementlearn- a pre-trained reward model to guide the policy\\ningalgorithms,suchasProximalPolicyOptimiza- optimization. Thisintroducesanadditionalcom-\\ntion(PPO),tomaximizetheexpectedrewardas ponentthatmustbetrainedandmaintained. Hy-\\ndefinedbythetrainedrewardmodel. brid Loss removes this dependency by directly\\nintegratingembedding-basedpreferencesintothe\\nThe objective in RLHF can be formalized as\\noptimization procedure, simplifying the overall\\nmaximizingtheexpectedcumulativereward:\\nframework.\\n(cid:34) T (cid:35) • Stability: RLHF often employs reinforcement\\n(cid:88)\\nJ(θ) = E γtr(τ ) , (1) learning algorithms like PPO, which can suffer\\nτ∼π t\\nθ\\nt=0 frominstabilityduetofactorsliketrajectorysam-\\nplingandexploration-exploitationtrade-offs. Hy-\\nwhere:\\nbridLossleveragesdirectpairwiseoptimization\\n• θ representsthepolicyparameters. foreach(y+,y−)pair,resultinginamorestable\\nandpredictabletrainingprocess.\\n• τ denotesatrajectoryofstatesandactions.\\n• r(τ ) is the reward at timestep t as predicted by • Pipeline Complexity: The RLHF approach in-\\nt\\ntherewardmodel. volves a two-stage pipeline: (1) training the re-\\nward model based on human feedback, and (2)\\n• γ isthediscountfactor.\\noptimizingthepolicyusingreinforcementlearn-\\ning. HybridLosssimplifiesthisintoasingle-stage\\nAsnotedbyChristianoetal.,\"therewardmodel\\noptimizationframeworkbycombiningbothpref-\\nserves as a learned proxy for human judgment,\\nerence alignment signals into one loss function,\\nguidingthepolicytogeneratemoredesirableout-\\nreducingcomputationaloverheadandsimplifying\\nputs\"(Christianoetal.,2017,Section3).\\nimplementation. Allthepointsaresummarizedin\\nKey Differences Between Hybrid Loss and\\nTable7.\\nRLHF:\\n• Role of Embeddings: RLHF utilizes embed- WhyItMatters: TheHybridLossunifiesprob-\\ndings within a separate reward model to evalu- abilistic and embedding-based alignment into a\\nate and score responses. These embeddings are single objective, removing the need for a sepa-\\nnot directly part of the policy optimization loss. rate reward model and avoiding the instabilities\\nIn contrast, Hybrid Loss directly incorporates inherentinRL-basedmethods. Bydirectlyincor-\\nembedding-based signals e y+,e y− into the uni- porating semantic signals, it offers more robust,\\nfiedlossfunction,integratingsemanticalignment interpretable,andflexiblepolicylearning.\\nalongsideprobability-basedpreferencealignment.\\nE Kernel-IntegratedDPOFormulation\\n• Signal Integration: In RLHF, embeddings are\\nprocessedbytherewardmodeltoproducescalar In this section, we introduce four kernel-based\\nrewardsignals,whicharethenusedbyreinforce- extensionstotheDirectPreferenceOptimization\\nment learning algorithms to optimize the policy. (DPO)objective. StandardDPOalignsalearned\\nHybridLoss,however,mergesprobability-based policy π with human preferences and simultane-\\nandembedding-basedsignalswithinasingleloss ouslyregularizesitagainstareferencedistribution\\nfunction,streamliningtheprocessbyeliminating p using KL divergence. Hybrid loss is defined\\nref\\ntheneedforseparaterewardsignalcomputation. as:Table 7: Comparative Analysis of Reinforcement Learning from Human Feedback (RLHF) and Hybrid Loss\\nApproachesAcrossKeyAspectsintheDirectPreferenceOptimization(DPO)Framework\\nAspect RLHF HybridLoss\\nEmbeddingUsage Indirect(rewardmodelonly) Directinlossfunction\\nSignalIntegration Separaterewardsignals Unified(probabilities+embeddings)\\nPipelineComplexity Twostages(rewardmodeltraining+RL) Single-stageoptimization\\nStability PotentialRLinstability(PPO,etc.) Directpairwiseoptimization,morestable\\nOptimizationObjective Maximizecumulativereward Combinelikelihoodandsemanticalignment\\nEmbeddingAdaptability Fixedduringrewardmodeltraining Dynamicallyadaptedinpolicytraining\\nas:\\nκ (u,v) = (u⊤v+c)d,\\nπ(y+ | x) π(e | e ) poly\\nmax E [log +γ(log y+ x )]\\nπ x,y+,y− π(y− | x) π(e y− | e x) where:\\n(cid:124) (cid:123)(cid:122) (cid:125) • c ∈ R is a bias term that allows for shifting the\\nHybridLoss\\n(2) kernel function, providing greater flexibility in\\nmodelingdata.\\nByincorporatingkernels,weprovidericherno-\\n• d ∈ Nisthepolynomialdegreethatcontrolsthe\\ntionsofdistributionalproximity. Wepresentfour\\ncomplexity of the mapping. Higher values of d\\nkernelvariants: i)polynomial,ii)RBF,iii)spectral,\\nenable the kernel to capture more intricate rela-\\nandiv)mahalanobis.\\ntionships.\\nE.1 PolynomialKernel\\nThiskernelimplicitlymapstheinputvectorsintoa\\nIntegrating a polynomial kernel into the Direct higher-dimensionalfeaturespace,wherecomplex,\\nPreferenceOptimization(DPO)frameworksignifi- higher-orderinteractionsbecomelinearlysepara-\\ncantlyenhancesthealignmentbetweenthepolicy ble. Thisimplicitprojectionnegatestheneedfor\\nπ(y | x)andthereferencedistributionp (y | x). explicit feature expansion, making the computa-\\nref\\nThisintegrationsurpassesthecapabilitiesofalign- tion more efficient while maintaining expressive\\ning distributions based solely on raw probability power.\\noutputsbyenablingagreementacrosshigher-order IncorporatingHigher-OrderInteractions:\\ninteractions. Consequently, the learned policy π Toeffectivelyintegratehigher-orderinteractions\\ncancapturemoreintricateandnonlinearstructures withintheDPOframework,weredefinethepref-\\ninherent in p , which might remain undetected erenceratiosusingthepolynomialkernel. Specifi-\\nref\\nwhen relying exclusively on simpler divergence cally,forthepreferenceratiosofthepolicyoutputs\\nmeasures. andtheircorrespondingembeddings,weapplythe\\nDefinitionandPropertiesofthePolynomial polynomialkernelasfollows:\\nKernel:\\n(cid:18) π(y+ | x)(cid:19) (cid:18) π(y+ | x) (cid:19)d\\nThe polynomial kernel transforms the conven- κ log = log +c ,\\nπ(y− | x) π(y− | x)\\ntionaldot-product-basedsimilaritymeasureintoa\\nmore expressive form, facilitating the capture of\\n(cid:32) e⊤ e (cid:33) (cid:32) e⊤ e +c(cid:33)d\\ncomplexinteractionsbetweenvectors. Fortwovec- y+ x y+ x\\nκ log = .\\ntorsu,v ∈ Rm, thepolynomial kernelisdefined e⊤ e e⊤ e +c\\ny− x y− xThese formulations leverage the polynomial ker- ImplementationConsiderations:\\nnel’s ability to model complex dependencies, Modern hardware accelerators, such as GPUs,\\nthereby capturing higher-order interactions. The canefficientlyhandletheadditionalcomputational\\nparameterdservesasacriticalcontrolforthecom- operations introduced by the polynomial kernel.\\nplexity of these interactions, allowing the model This capability ensures that the polynomial ker-\\nto adjust the degree of nonlinearity based on the nel extension is feasible for large-scale training\\nspecificrequirementsofthetask. scenarios. Byleveragingtheenhancedexpressive-\\nRedefinitionoftheHybridLosswiththePoly- ness of the polynomial kernel, the DPO frame-\\nnomialKernel: work achieves finer-grained alignment, enabling\\nTo incorporate the polynomial kernel into the the model to capture more nuanced patterns and\\nembedding similarity terms, let e , e , and e complexdependenciespresentinthereferencepol-\\nx y+ y−\\ndenote the embeddings for the input x, the pre- icy.\\nferredoutcomey+,andthelesspreferredoutcome Summary:\\ny−,respectively. Thehybridlossfunctionisrede- IncorporatingapolynomialkernelintotheDPO\\nfinedas: frameworkallowsforthemodelingofhigher-order\\ninteractionsbetweenembeddings,therebyenhanc-\\nHybridLoss=(cid:18) logπ(y+|x) +c(cid:19)d +γ(cid:32) e⊤ y+e x+c(cid:33)d\\n,\\ningthepolicy’sabilitytoalignwithcomplexref-\\nπ(y−|x) e⊤ e +c erence distributions. The parameter d provides\\ny− x\\ncontroloverthecomplexityoftheseinteractions,\\nwhere γ > 0 is a tunable hyperparameter that enablingtheframeworktoadapttovaryinglevels\\ncontrolstheweightoftheembedding-basedcom- of data intricacy. This integration not only im-\\nponentinthelossfunction. provesthesemanticalignmentbetweenthepolicy\\nComplete DPO Objective with the Polyno- andreferencedistributionbutalsomaintainscom-\\nmialKernel: putationalefficiency,makingitarobustchoicefor\\nThefullDPOobjective,integratingthepolyno- preferenceoptimizationtasks.\\nmialkernel,isformulatedas:\\nE.2 RadialBasisFunction(RBF)Kernel\\nmaxE\\n(cid:34) (cid:18)\\nlog\\nπ(y+ | x) +c(cid:19)d +γ(cid:32) e⊤ y+e xI n+n et lce ig(cid:33) nr tad ot(cid:35)i tn hg eDa irR ea cd ti Pa rl efB ea res nis ceF Oun pc tit mio in za( tR ioB nF (D) Pk Oer )-\\nπ x,y+,y− π(y− | x) e⊤ e +c\\ny− xframework significantly enhances the alignment\\n(cid:34) (cid:35)\\nπ (y | x) between the policy π(y | x) and the reference\\n−αE βlog θ ,\\nx distribution p (y | x). Unlike approaches that\\nπ (y | x) ref\\nref\\naligndistributionssolelybasedonrawprobability\\noutputs, the RBF kernel facilitates agreement by\\nwhere:\\ncapturinglocalandnon-linearinteractionswithin\\nthedata. Thisintegrationenablesthelearnedpol-\\n• α and β are hyperparameters that control the\\nicy π to model more intricate and nuanced struc-\\nstrengthoftheKullback-Leibler(KL)regulariza-\\nturesinherentinp ,whichmightremainobscured\\ntionterm. ref\\nwhen relying exclusively on simpler divergence\\n• γ isahyperparametercontrollingthecontribution measures.\\noftheembeddingsignal. DefinitionandPropertiesoftheRBFKernel:\\nThe Radial Basis Function (RBF) kernel, also\\n• π (y | x) denotes the reference distribution knownastheGaussiankernel,transformsthecon-\\nref\\nagainstwhichthepolicyπ(y | x)isaligned. ventionalsimilaritymeasurebasedonthedotprod-uctintoonethatemphasizesthedistancebetween RedefinitionoftheHybridLosswiththeRBF\\nfeature vectors. For two vectors u,v ∈ Rm, the Kernel:\\nRBFkernelisdefinedas: ToincorporatetheRBFkernelintotheembed-\\ndingsimilarityterms,lete ,e ,ande denote\\n(cid:18) ∥u−v∥2(cid:19) x y+ y−\\nκ (u,v) = exp − , theembeddingsfortheinputx,thepreferredout-\\nRBF 2σ2 come y+, and the less preferred outcome y−, re-\\nspectively. The hybrid loss function is redefined\\nwhere:\\nas:\\n• σ the> w0 idi ts ht oh fe tb ha en kd ew ri nd et lh\\n,\\ndp ea tr ea rm me it ne ir ngtha ht owcon mtr uo cl hs\\nHybridLoss=exp\\uf8eb \\uf8ec−(cid:16) log ππ (( yy −+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7+γexp\\uf8eb\\n\\uf8ec\\n\\uf8ec−(cid:18)\\nee ⊤ x⊤ x ee yy\\n−+(cid:19)2\\uf8f6\\n\\uf8f7\\n\\uf8f7,\\ninfluenceasingletrainingexamplehas. \\uf8ed 2σ2 \\uf8f8 \\uf8ec \\uf8ed 2σ2 \\uf8f7 \\uf8f8\\nTheRBFkernelimplicitlymapsinputvectorsinto\\nwhere γ > 0 is a tunable hyperparameter that\\naninfinite-dimensionalfeaturespace,allowingthe\\ncontrolstheweightoftheembedding-basedcom-\\nmodeltocapturecomplex,non-linearrelationships\\nponentinthelossfunction.\\nwithout the need for explicit feature expansion.\\nCompleteDPOObjectivewiththeRBFKer-\\nThispropertymakestheRBFkernelhighlyeffec-\\nnel:\\ntive in modeling local structures within the data,\\nThe full DPO objective, integrating the RBF\\nenablingfiner-grainedpreferencealignment.\\nkernel,isformulatedas:\\nIncorporatingHigher-OrderInteractions:\\nToeffectivelyintegratehigher-orderinteractions\\n(cid:34)\\n\\uf8eb (cid:16)\\nlog\\nπ(y+|x)(cid:17)2\\uf8f6\\nwithintheDPOframeworkusingtheRBFkernel,\\nmaxE exp\\uf8ec−\\nπ(y−|x)\\n\\uf8f7\\nweredefinethepreferenceratiosbyapplyingthe π x,y+,y− \\uf8ed 2σ2 \\uf8f8\\nkerneltoboththeprobabilityratiosandtheembed-\\ndingsimilarities. Specifically,wedefine: \\uf8eb (cid:18) (cid:19)2\\uf8f6\\ne⊤ xe y+ (cid:35)\\nκ(cid:34) log(cid:18) π(y+ |x)(cid:19)(cid:35) =exp\\uf8eb \\uf8ec−(cid:16) log ππ (( yy −+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7,\\n+γexp\\uf8ec \\uf8ec \\uf8ec \\uf8ed− e⊤ x 2e σy− 2 \\uf8f7 \\uf8f7 \\uf8f7\\n\\uf8f8\\nπ(y− |x) \\uf8ed 2σ2 \\uf8f8\\n(cid:34) (cid:35)\\nπ (y | x)\\n−αE βlog θ ,\\n\\uf8eb (cid:18) (cid:19)2\\uf8f6 x π (y | x)\\n(cid:34) (cid:35) e⊤ xe y+ ref\\nκ log(cid:18)e y+ | e x(cid:19) = exp\\uf8ec \\uf8ec− e⊤ xe y− \\uf8f7 \\uf8f7 where:\\ne | e \\uf8ec 2σ2 \\uf8f7\\ny− x \\uf8ed \\uf8f8\\n• α and β are hyperparameters that control the\\nstrengthoftheKullback-Leibler(KL)regulariza-\\nTheseformulationsleveragetheRBFkernel’sabil-\\ntionterm.\\nitytomodelnon-lineardependenciesbyemphasiz-\\ning the similarity based on the distance between\\n• π (y | x) denotes the reference distribution\\nref\\nthetransformedpreferenceratiosandembedding\\nagainstwhichthepolicyπ(y | x)isaligned.\\nsimilarities. The parameter σ serves as a critical\\ncontrol for the sensitivity of the kernel to differ- ImplementationConsiderations:\\nencesintheseratios,allowingthemodeltoadjust IntegratingtheRBFkernelintotheDPOframe-\\nthe degree of nonlinearity based on the specific work introduces additional computational opera-\\nrequirementsofthetask. tions,primarilyduetothecalculationofEuclideandistancesandtheexponentialfunction. However, SpectralKernelisdefinedas:\\nmodernhardwareaccelerators,suchasGPUs,are\\nwell-equipped to handle these computations effi-\\np\\nciently, ensuring that the RBF kernel extension κ (u,v)=(cid:88) exp(cid:0) −λ ∥u−v∥2(cid:1) ϕ (u)ϕ (v),\\nspectral i i i\\nremainsfeasibleforlarge-scaletrainingscenarios.\\ni=1\\nItisessentialtocarefullyselectthebandwidthpa-\\nwhere:\\nrameterσtobalancethetrade-offbetweensensitiv-\\nityandgeneralization. Cross-validationtechniques • λ > 0 are the eigenvalues corresponding to the\\ni\\ncanbeemployedtotuneσ effectively. principalcomponentsofthedatacovariancema-\\nSummary: trix.\\nIncorporating the RBF kernel into the DPO\\nframeworkenablesthemodelingoflocalandnon- • ϕ i(u) and ϕ i(v) are the projections of vectors u\\nlinear interactions between embeddings, thereby andv ontothei-theigenvector,respectively.\\nenhancing the policy’s ability to align with com-\\n• p denotes the number of principal components\\nplex reference distributions. The bandwidth pa-\\nconsidered,typicallychosenbasedonthedesired\\nrameterσ providescontroloverthesensitivityof\\nlevelofapproximation.\\nthe kernel to differences in preference ratios and\\nembedding similarities, allowing the framework This kernel implicitly maps input vectors into a\\nto adapt to varying levels of data intricacy. This featurespacedefinedbytheprincipalcomponents,\\nintegrationnotonlyimprovesthesemanticalign- emphasizing the global structure of the data. By\\nmentbetweenthepolicyandreferencedistribution weightingthecontributionsofeachprincipalcom-\\nbutalsomaintainscomputationalefficiency,mak-\\nponentwithexp(cid:0)\\n−λ\\n∥u−v∥2(cid:1)\\n,theSpectralKer-\\ni\\ningitarobustandversatilechoiceforpreference nelbalancestheinfluenceofdifferentspectralcom-\\noptimizationtasks. ponents,allowingthemodeltoprioritizedominant\\nglobalpatternswhilemitigatingtheimpactofnoise\\nE.3 SpectralKernel\\nandlesssignificantvariations.\\nIntegratingaSpectralKernelintotheDPOframe- IncorporatingHigher-OrderInteractions:\\nworksignificantlyenhancesthealignmentbetween Toeffectivelyintegratehigher-orderinteractions\\nthepolicyπ(y | x)andthereferencedistribution withintheDPOframeworkusingtheSpectralKer-\\np ref(y | x). Unlike traditional kernels that pri- nel,weredefinethepreferenceratiosbyapplying\\nmarilycapturelocalornon-linearinteractions,the the kernel to both the probability ratios and the\\nSpectralKernelleveragestheglobalspectralprop- embeddingsimilarities. Specifically,wedefine:\\nerties of the data, facilitating a deeper and more\\ncomprehensivealignment. Thisintegrationenables\\nthelearnedpolicyπtomodelintricateglobalstruc- κ(cid:34) log(cid:18)π π( (y y+ −| |x x) )(cid:19)(cid:35) =(cid:88)p exp(cid:32) −λi(cid:18) logπ π( (y y+ −| |x x) )(cid:19)2(cid:33) ϕi(cid:18) logπ π( (y y+ −| |x x) )(cid:19) ,\\nturesinherentinp ,whichmayremainobscured i=1\\nref\\nwhen relying solely on simpler divergence mea-\\nsur Des e. finitionandPropertiesoftheSpectralKer- κ(cid:34) log(cid:18) ee yy −+| |e ex x(cid:19)(cid:35) =(cid:88) i=p 1exp\\uf8eb \\uf8ed−λi(cid:32) ee\\n⊤\\nx⊤ x ee yy −+(cid:33)2\\uf8f6 \\uf8f8ϕi(cid:32) ee\\n⊤\\nx⊤ x ee yy −+(cid:33) .\\nnel:\\nThe Spectral Kernel is designed to capture TheseformulationsleveragetheSpectralKernel’s\\nglobal relationships within the data by utilizing abilitytomodelcomplexglobaldependenciesby\\nthespectral(eigenvalue)decompositionofthedata decomposingthepreferenceratiosandembedding\\ncovariancematrix. Fortwovectorsu,v ∈ Rm,the similarities into their spectral components. Theeigenvaluesλ controltheinfluenceofeachspec- • α and β are hyperparameters that control the\\ni\\ntralcomponent,allowingthemodeltoadjustthe strengthoftheKullback-Leibler(KL)regulariza-\\ndegree of emphasis on different global patterns tionterm.\\nbasedonthespecificrequirementsofthetask.\\n• π (y | x) denotes the reference distribution\\nRedefinitionoftheHybridLosswiththeSpec- ref\\nagainstwhichthepolicyπ(y | x)isaligned.\\ntralKernel:\\nToincorporatetheSpectralKernelintotheem-\\nThisobjectivefunctionintegratestheSpectralKer-\\nbeddingsimilarityterms,lete ,e ,ande de-\\nx y+ y− nelintotheDPOframework,allowingthemodel\\nnotetheembeddingsfortheinputx,thepreferred\\ntoleverageglobalspectralpropertiesforenhanced\\noutcome y+, and the less preferred outcome y−,\\npreferencealignmentwhilemaintainingregulariza-\\nrespectively. Thehybridlossfunctionisredefined\\ntionagainstthereferencedistribution.\\nas:\\nImplementationConsiderations:\\nIntegrating the Spectral Kernel into the DPO\\n(cid:88)p (cid:32) (cid:18) π(y+ | x)(cid:19)2(cid:33)fra (cid:18)mewo πrk (yi +nt |ro xd )u (cid:19)ces additional computational\\nHybridLoss = exp −λ log ϕoverhloegadduetothenecessityofperformingspec-\\ni π(y− | x) i π(y− | x)\\ntral (eigenvalue) decompositions and managing\\ni=1\\n+γ(cid:88)p exp\\uf8eb\\n\\uf8ed−λ\\ni(cid:32) ee ⊤⊤\\nx\\nee y+(cid:33)2\\uf8f6\\n\\uf8f8ϕ\\ni(cid:32) ee ⊤⊤\\nx\\nee y+(cid:33)\\n,\\nm hau rdlt wip ale resp ae cc ct er la el rac to om rsp ,o sn ue cn hts a. sH Gow PUev se ,r, am reo wde er ln\\nl-\\ni=1 x y− x y− equippedtohandlethesecomputationsefficiently,\\nespeciallywhenleveragingoptimizedlinearalge-\\nwhere γ > 0 is a tunable hyperparameter that\\nbralibraries.\\ncontrolstheweightoftheembedding-basedcom-\\nKeyconsiderationsforimplementationinclude:\\nponent in the loss function. This redefinition al-\\nlowsthehybridlosstoincorporateboththetrans- • EigenvalueDecomposition: Efficientcomputa-\\nformedprobabilityratiosandembeddingsimilari- tionoftheeigenvaluesλ i andeigenvectorsϕ i(u)\\nties,weightedbytheirrespectivespectralcompo- is crucial. Utilizing optimized libraries like LA-\\nnents,therebycapturinghigher-orderglobalinter- PACK or GPU-accelerated routines can signifi-\\nactions. cantlyreducecomputationtime.\\nComplete DPO Objective with the Spectral\\n• Selection of Principal Components (p): The\\nKernel:\\nnumberofprincipalcomponentspshouldbecho-\\nThefullDPOobjective,integratingtheSpectral\\nsen based on a balance between computational\\nKernel,isformulatedas:\\nfeasibilityandthelevelofdetailrequiredtocap-\\nturethedata’sglobalstructure. Techniquessuch\\n(cid:34) (cid:88)p (cid:32) (cid:18) π(y+ | x)(cid:19)2(cid:33)as(cid:18)explai πne (yd +va |r xia )n(cid:19)cecanguidetheselectionofp.\\nmaxE exp −λ log ϕ log\\nπ x,y+,y− i π(y− | x) • Hi yperpaπr(aym− e|txer)Tuning(λ ): Theeigenvalues\\ni=1 i\\n(cid:88)p \\uf8eb (cid:32) e⊤ xe y+(cid:33)2\\uf8f6 (cid:32) e⊤ xe y+(cid:33)(cid:35) λ nei nc to .nt Pr ro ol pt eh re ti un nfl iu ne gn ,c pe oo tef ne ta iac lh lysp thec rotr ua gl hco cm rop so s--\\n+γ i=1exp\\uf8ed−λ\\ni e⊤ xe y−\\n\\uf8f8ϕ\\ni e⊤ xe y− validation, is essential to ensure that the kernel\\n(cid:34) (cid:35) appropriatelyemphasizesrelevantglobalpatterns\\nπ (y | x)\\n−αE βlog θ , withoutoverfitting.\\nx\\nπ (y | x)\\nref\\n• Scalability:**Forveryhigh-dimensionaldata,\\nwhere: dimensionality reduction techniques (e.g.,PCA)maybeemployedpriortoapplyingthe\\nSpectralKerneltomanagecomputationalcom-\\n(cid:18) (u−v)⊤Σ−1(u−v)(cid:19)\\nplexityeffectively. κ (u,v)=exp − ,\\nMahalanobis\\n2\\nSummary: Incorporating the Spectral Kernel where:\\nintotheDPOframeworkenablesthemodelingof\\n• Σ ∈ Rm×m is thecovariance matrixof thedata,\\nglobal and complex interactions within the data,\\ncapturing the variance and covariance between\\ntherebyenhancingthepolicy’sabilitytoalignwith\\ndifferentfeatures.\\nintricatereferencedistributions. Byleveragingthe\\nspectralpropertiesofthedata,theSpectralKernel\\nThiskernelimplicitlymapsinputvectorsintoa\\nfacilitatesadeeperunderstandingofglobalstruc-\\nfeaturespacewherethedistancemetricaccounts\\ntures, allowing for more nuanced and effective\\nforthedata’scovariance,allowingthemodeltoem-\\npreferencealignment. Theparameterλ provides\\ni phasizedirectionswithhighervarianceanddeem-\\ncontrolovertheinfluenceofdifferentspectralcom-\\nphasizethosewithlowervariance. Bydoingso,the\\nponents,enablingtheframeworktoadapttovary-\\nMahalanobiskerneleffectivelymodelsanisotropic\\ninglevelsofdatacomplexity. Thisintegrationnot\\nrelationships, making it particularly suitable for\\nonlyimprovesthesemanticalignmentbetweenthe\\ndatawithcorrelatedfeatures.\\npolicyandreferencedistributionbutalsomaintains\\nIncorporatingHigher-OrderInteractions:\\ncomputationalefficiencythroughoptimizedspec-\\nToeffectivelyintegratehigher-orderinteractions\\ntralcomputations,makingitarobustandcompre-\\nwithintheDPOframeworkusingtheMahalanobis\\nhensivechoiceforpreferenceoptimizationtasks.\\nkernel,weredefinethepreferenceratiosbyapply-\\ningthekerneltoboththeprobabilityratiosandthe\\nE.4 MahalanobisKernel\\nembeddingsimilarities. Specifically,wedefine:\\nIntegrating a Mahalanobis kernel into the Direct\\nP nir fief ce ar ne tn lyce eO nhp at nim ceiz sa tt hio en a( lD igP nO m) enfr ta bm ee twwo eerk\\nn\\ns ti hg e-\\nκ(cid:34) log(cid:18) π(y+ |x)(cid:19)(cid:35)\\n=exp\\uf8eb \\uf8ec−(cid:16)\\nlog ππ (( yy −+| |x x) )\\n−µ(cid:17)2\\uf8f6\\n\\uf8f7,\\npolicy π(y | x) and the reference distribution π(y− |x) \\uf8ed 2σ2 \\uf8f8\\np (y | x). Unlike traditional kernels that pri-\\nref\\nmarilycaptureisotropicorlocalrelationships,the\\nMahalanobis kernel accounts for the underlying \\uf8eb (cid:18) (cid:19)2\\uf8f6\\nc ino fv oa rr mia en dce as nt druc nt uu ar ne co ef dth ae lid ga nt ma, ef nac t.ili Tta hti in sg ina tm ego rr ae\\n-\\nκ(cid:34) log(cid:18) ee\\nyy −+\\n| |e\\nex\\nx(cid:19)(cid:35) =exp\\uf8ec\\n\\uf8ec \\uf8ec \\uf8ed−\\nee ⊤ x⊤ x ee yy 2−+ σ′−\\n2\\nµ′ \\uf8f7\\n\\uf8f7 \\uf8f7 \\uf8f8.\\ntionenablesthelearnedpolicyπtomodelintricate\\ndependenciesandfeaturecorrelationsinherentin\\np ref, which might remain obscured when relying Here, µ and µ′ are mean parameters, and σ2 and\\nexclusivelyonsimplerdivergencemeasures. σ′2\\nare variance parameters that control the sen-\\nDefinitionandPropertiesoftheMahalanobis sitivityofthekerneltodeviationsfromthemean.\\nKernel: TheseformulationsleveragetheMahalanobisker-\\nThe Mahalanobis kernel leverages the covari- nel’sabilitytomodelanisotropicdependenciesby\\nance structure of the data to measure similarity, emphasizingdifferencesalongcorrelatedfeature\\nincorporatingfeaturecorrelationsandscalevaria- dimensions. The parameters Σ, µ, and µ′ serve\\ntions. Fortwovectorsu,v ∈ Rm,theMahalanobis as critical controls for the kernel’s behavior, al-\\nkernelisdefinedas: lowingthemodeltoadjustthedegreeandnatureofsimilaritymeasurementsbasedonthespecific\\nrequirementsofthetask.\\n(cid:34)\\n\\uf8eb (cid:16)\\nlog π(y+|x)\\n−µ(cid:17)2\\uf8f6\\nRedefinitionoftheHybridLosswiththeMa- m πaxE x,y+,y− exp\\uf8ec \\uf8ed− π(y 2− σ|x 2) \\uf8f7 \\uf8f8\\nhalanobisKernel:\\n\\uf8eb (cid:18) (cid:19)2\\uf8f6\\nToincorporatetheMahalanobiskernelintothe e⊤ xe y+ −µ′ (cid:35)\\nembedding similarity terms, let e x, e y+, and e y− +γexp\\uf8ec \\uf8ec \\uf8ec− e⊤ xe y 2− σ′2 \\uf8f7 \\uf8f7 \\uf8f7\\ndenote the embeddings for the input x, the pre- \\uf8ed \\uf8f8\\nferredoutcomey+,andthelesspreferredoutcome\\ny−,respectively. Thehybridlossfunctionisrede- (cid:34) (cid:35)\\nπ (y | x)\\nfinedas: −αE x βlog θ ,\\nπ (y | x)\\nref\\nwhere:\\n• α and β are hyperparameters that control the\\nstrengthoftheKullback-Leibler(KL)regulariza-\\ntionterm.\\n\\uf8eb (cid:16)\\nπ(y+|x)\\n(cid:17)2\\uf8f6\\nlog −µ • π (y | x) denotes the reference distribution\\nπ(y−|x) ref\\nHybridLoss = exp\\uf8ec− \\uf8f7\\n\\uf8ed 2σ2 \\uf8f8 againstwhichthepolicyπ(y | x)isaligned.\\nThisobjectivefunctionintegratestheMahalanobis\\n\\uf8eb (cid:18) (cid:19)2\\uf8f6\\ne⊤ xe y+ −µ′ kernel into the DPO framework, allowing the\\n+γexp\\uf8ec\\n\\uf8ec−\\ne⊤ xe y− \\uf8f7\\n\\uf8f7,\\nmodeltoleveragethecovariancestructureofthe\\n\\uf8ec 2σ′2 \\uf8f7 data for enhanced preference alignment while\\n\\uf8ed \\uf8f8\\nmaintaining regularization against the reference\\ndistribution.\\nImplementationConsiderations:\\nIntegratingtheMahalanobiskernelintotheDPO\\nframework introduces additional computational\\nconsiderations due to the necessity of handling\\nwhere γ > 0 is a tunable hyperparameter that\\nthecovariancematrixΣandperformingmatrixin-\\ncontrolstheweightoftheembedding-basedcom-\\nversions. However,modernhardwareaccelerators,\\nponent in the loss function. This redefinition al-\\nsuchasGPUs,arewell-equippedtohandlethese\\nlowsthehybridlosstoincorporateboththetrans-\\ncomputationsefficiently,especiallywhenleverag-\\nformedprobabilityratiosandembeddingsimilar-\\ningoptimizedlinearalgebralibraries.\\nities, weighted by their respective Mahalanobis\\nKeyconsiderationsforimplementationinclude:\\nkerneltransformations,therebycapturinghigher-\\norderanisotropicinteractions. • CovarianceMatrixEstimation(Σ): Thecovari-\\nance matrix Σ must be estimated from the data.\\nComplete DPO Objective with the Maha- This can be done using empirical covariance es-\\nlanobisKernel: timation techniques. For high-dimensional data,\\nregularizationmethods(e.g.,addingasmallmulti-\\nThe full DPO objective, integrating the Maha- pleoftheidentitymatrixtoΣ)maybenecessary\\nlanobiskernel,isformulatedas: toensurenumericalstabilityandinvertibility.• Matrix Inversion Efficiency: Computing Σ−1 is commonly employed to regularize the learned\\ncanbecomputationallyintensiveforlargem. Uti- policy π(y | x) against a reference distribution\\nlizing efficient matrix inversion algorithms and p (y | x). Specifically, the KL divergence term\\nref\\nleveraging hardware-accelerated libraries (e.g., intheDPOobjectiveisdefinedas:\\ncuBLAS for GPUs) can mitigate computational (cid:20) (cid:21)\\nπ(y | x)\\noverhead. αE β log ,\\nx\\nπ (y | x)\\nref\\n•\\nParameterTuning(µ,µ′,σ2,σ′2\\n):\\nwhereαandβ arehyperparameterscontrollingthe\\nSelectingappropriatevaluesforthemeanandvari- strengthoftheregularization.\\nanceparametersiscrucialforthekernel’sperfor- However,alternativedivergencemeasurescan\\nmance. Cross-validation techniques can be em- offerdistinctadvantagesdependingonthespecific\\nployedtotunethesehyperparameterseffectively, requirements of the task. In this section, we ex-\\nbalancingsensitivityandgeneralization. ploreseveralalternativedivergencefunctionsthat\\ncanbeintegratedintotheDPOframeworktopo-\\n• Scalability: For very high-dimensional embed- tentiallyenhanceperformanceandstability.\\ndings,dimensionalityreductiontechniques(e.g.,\\nPrincipalComponentAnalysis)maybeemployed F.1 Jensen-ShannonDivergence(JSD)\\npriortoapplyingtheMahalanobiskerneltoman- MathematicalDefinition:\\nagecomputationalcomplexityeffectively.\\n1 1 1\\nD (P∥Q)= D (P∥M)+ D (Q∥M), M = (P+Q)\\nJS 2 KL 2 KL 2\\nSummary:\\nwhereD (P∥Q)istheKLdivergencebetween\\nIncorporating the Mahalanobis kernel into KL\\ndistributionsP andQ.\\nthe DPO framework enables the modeling of\\nUsageinDPO:IntheDPOsetting,theJensen-\\nanisotropicandcorrelatedinteractionsbetweenem-\\nShannon Divergence compares the policy distri-\\nbeddings, thereby enhancing the policy’s ability\\nbutionπ(y | x)againstthereferencedistribution\\ntoalignwithcomplexreferencedistributions. By\\nπ (y | x). Thesymmetricalandboundednature\\nleveragingthecovariancestructureofthedata,the ref\\nof JSD (0 ≤ D ≤ log2) ensures more stable\\nMahalanobis kernel facilitates a more informed JS\\noptimizationcomparedtotheasymmetricKLdi-\\nandnuancedpreferencealignment,accountingfor\\nvergence:\\nfeaturecorrelationsandscalevariations. Thepa-\\nrameters Σ, µ, and σ2 provide control over the maxL −αE [D (π(· | x)∥π (· | x))]\\nKCL x JS ref\\nkernel’ssensitivityandemphasisondifferentdata π\\ndimensions, allowing the framework to adapt to F.2 HellingerDistance\\nvaryinglevelsofdatacomplexity. Thisintegration\\nMathematicalDefinition:\\nnotonlyimprovesthesemanticalignmentbetween\\n(cid:115)\\nthepolicyandreferencedistributionbutalsomain- 1 (cid:90) (cid:16)(cid:112) (cid:112) (cid:17)2\\nH(P,Q) = √ P(x)− Q(x) dx\\ntainscomputationalefficiencythroughoptimized 2\\ncovariancecomputations, makingitarobustand\\nUsage in DPO: The Hellinger Distance mea-\\ncomprehensivechoiceforpreferenceoptimization\\nsures the similarity between the policy π(y | x)\\ntasks.\\nand the reference distribution π (y | x). It is\\nref\\nF AlternativeDivergenceFunctions robust to noise and provides a bounded metric\\n(0 ≤ H ≤ 1):\\nIn the Direct Preference Optimization (DPO)\\nframework,theKullback-Leibler(KL)divergence maxL KCL−αE x[H(π(· | x),π ref(· | x))]\\nπF.3 RényiDivergence F.6 f-Divergence\\nMathematicalDefinition: MathematicalDefinition:\\n1 (cid:90) (cid:90) (cid:18) P(x)(cid:19)\\nD α(P∥Q)= α−1log P(x)αQ(x)1−αdx, α>0,α̸=1 D f(P∥Q) = Q(x)f\\nQ(x)\\ndx\\nwhereαistheorderofthedivergence.\\nwheref : (0,∞) → Risaconvexfunctionwith\\nUsageinDPO:RényiDivergencegeneralizes\\nf(1) = 0.\\nseveraldivergencemeasures,allowingcontrolover\\nUsageinDPO:Thef-Divergenceencompasses\\nsensitivity to differences between π and π via\\nref a broad class of divergence measures, including\\ntheparameterα. TheDPOobjectiveincorporating\\nKL,JSD,andothers,byselectingappropriatefunc-\\nRényiDivergenceis:\\ntionsf. ThisflexibilityallowstheDPOobjective\\nmaxL −αE [D (π(· | x)∥π (· | x))] tobetailoredtospecifictaskrequirements:\\nKCL x α ref\\nπ\\nmaxL −αE [D (π(· | x)∥π (· | x))]\\nKCL x f ref\\nChoosingdifferentvaluesofαcanprioritizevari- π\\nousaspectsofthedistributionaldifferences,such\\nBy designing the function f, one can emphasize\\nasfocusingmoreonthetailsorthemodes.\\nparticularaspectsofthedistributionaldifferences,\\nsuchaspenalizingunderestimationoroverestima-\\nF.4 BhattacharyyaDistance\\ntionofcertainprobabilities.\\nMathematicalDefinition:\\n(cid:90) Summary\\n(cid:112)\\nD (P∥Q) = −log P(x)Q(x)dx\\nBhat\\nIntheDPOframework,divergencefunctionsplay\\nacrucialroleinregularizingthepolicydistribution\\nUsage in DPO: The Bhattacharyya Distance\\nπ(y | x)withrespecttothereferencedistribution\\nquantifies the overlap between the policy π(y |\\nπ (y | x). Eachdivergencemeasureoffersunique\\nx) and the reference distribution π (y | x). It ref\\nref\\nbenefits:\\nencourages the model to maximize the overlap,\\ntherebypromotingalignment:\\n• Jensen-ShannonDivergence(JSD):Providesa\\nsymmetricalandboundedmeasure,ensuringsta-\\nmaxL −αE [D (π(· | x)∥π (· | x))]\\nKCL x Bhat ref\\nπ ble and balanced comparisons between distribu-\\ntions.\\nF.5 WassersteinDistance\\nMathematicalDefinition: • Hellinger Distance: Offers robustness against\\nnoisy data by measuring the similarity between\\n(cid:90)\\nW(P,Q) = inf ∥x−y∥dγ(x,y) distributionsbasedontheirsquareroots.\\nγ∈Π(P,Q)\\n• Rényi Divergence: Allows tunable sensitivity\\nwhereΠ(P,Q)denotesthesetofallcouplingsof\\ntodistributionaldifferencesthroughitsorderpa-\\nP andQ.\\nrameterα,enablingcustomizationbasedontask-\\nUsageinDPO:TheWassersteinDistancemea-\\nspecificneeds.\\nsurestheminimalcostoftransportingmassfrom\\nπ(y | x) to π (y | x), making it effective for • BhattacharyyaDistance: Quantifiestheoverlap\\nref\\ndistributionswithdisjointsupports: betweendistributions,encouragingthepolicyto\\nmaximizealignmentwith thereferencedistribu-\\nmaxL KCL−αE x[W(π(· | x),π ref(· | x))] tion.\\nπ• WassersteinDistance: Effectivefordistributions selection,weassessSupportOverlap,DriftMag-\\nwithdisjointsupportsbymeasuringtheminimal nitude,Kurtosis,andSmoothness. Thesemetrics\\ntransportationcostbetweenthem,capturingmean- provide quantitative insights that inform the op-\\ningfulgeometricdifferences. timalchoiceofkernelsanddivergencefunctions,\\ntherebyenhancingthealignmentperformanceof\\n• f-Divergence: Providesaflexibleframeworkthat theDPOframework.\\nunifiesvariousdivergencemeasures,allowingtai-\\nloredregularizationbyselectingappropriatefunc- G.1 MetricsforData-DrivenKernelSelection\\ntionsf.\\nWeproposefourkeymetricstofacilitatethedata-\\ndrivenselectionofkernels. Thesemetricsevaluate\\nSelecting the appropriate divergence function\\nhowwellaparticularkernelfitsthealignmenttask\\ndependsonthespecificcharacteristicsofthetask\\nbyassessingitsabilitytoseparateandgeneralize\\nand the nature of the distributions involved. By\\noversafeandunsafeclusters.\\nleveragingthesealternativedivergencemeasures,\\nthe DPO framework can achieve more nuanced 1. Positive-Negative Divergence (PND) The\\nandeffectivepreferencealignment,enhancingthe Positive-NegativeDivergence(PND)measuresthe\\noverall performance and stability of the learned difference in alignment scores between positive\\npolicy. andnegativesamples. Itisdefinedas:\\nG Data-DrivenSelectionofKernelTypes PND = d(x,y+)−d(x,y−)\\nandDivergenceFunctions\\nwhered(x,y+)andd(x,y−)denotethedistances\\nSelecting the most appropriate kernel and diver-\\nfromxtothepositiveandnegativeresponses,re-\\ngence functions is pivotal for achieving effec-\\nspectively. Larger PND values indicate stronger\\ntive alignment in preference-based learning sys-\\nseparability between positive and negative sam-\\ntems. The variety of available kernels—such as\\nples, which typically favors the use of RBF or\\nRadial Basis Function (RBF), Polynomial, Ma-\\nMahalanobiskernelsduetotheirabilitytomodel\\nhalanobis, and Spectral—and divergence mea-\\ncomplex,non-linearrelationships.\\nsures—includingKullback-Leibler(KL),Jensen-\\nShannon(JSD),Hellinger,Wasserstein,andBhat-\\n2. Positive-Negative Alignment Variance\\ntacharyya—necessitatesaprincipledapproachto\\n(PNAV) ThePositive-NegativeAlignmentVari-\\ntheirselection. Whilepreviousresearchhasprimar-\\nance(PNAV)capturesthevariabilityinalignment\\nilyfocusedonfixedkernelselection(Shawe-Taylor\\nscores between positive and negative responses\\nandCristianini,2004;SchölkopfandSmola,2002)\\nacrossmultiplesamples:\\nor manual divergence selection (Csiszar, 2004),\\nour approach introduces a dynamic, data-driven\\nn\\nmechanism that adapts to specific alignment re- PNAV = 1 (cid:88)(cid:0) d(x ,y+)−d(x ,y−)(cid:1)2\\nquirements. n i i i i\\ni=1\\nWeachievethisadaptabilitybyemployingaset\\nofcarefullydesignedmetrics. Forkernelselection, HighPNAVvaluesindicateinconsistentalignment,\\nweutilizePositive-NegativeDivergence(PND), suggesting a need for more flexible kernels like\\nPositive-NegativeAlignmentVariance(PNAV), RBForPolynomial. Conversely,lowPNAVvalues\\nTriplet Alignment Tightness (TAT), and Nor- implystablealignment, favoringsimplerkernels\\nmalizedAlignmentGap(NAG).Fordivergence suchasMahalanobisorSpectral.1.0\\n0.8\\n0.6\\n0.4\\n0.2\\n0.0\\n0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0\\nSample Index\\nerocS\\ntnemngilA\\nPND (Positive-Negative Divergence)\\n0.99 0.96 0.99 0.95 Positive Alignments 1.0\\n0.92 0.91 Negative Alignments\\n0.88 0.88 0.86\\n0.81 0.79 0.83 0.79 0.750.75 0.72 0.71 0.760.750.76 0.8\\n0.6\\n0.480.49\\n0.41 0.42\\n0.37\\n0.34\\n0.28\\n0.310.34 0.34\\n0.28\\n0.4\\n0.25 0.22 0.22\\n0.16 0.18 0.12 0.17 0.13 0.14 0.2\\nPositive Negative\\nerocS\\ntnemngilA\\nPNAV (Positive-Negative Alignment Variance)\\n3.0\\n2.5\\n2.0\\n1.5\\n1.0\\n0.5\\n0.0\\n0.0 0.5 1.0 1.5 2.0 2.5 3.0\\nDimension 1\\n2 noisnemiD\\nTAT (Triplet Alignment Tightness)\\n0.8\\nQuery u\\nPositive v+\\nNegative v 0.7\\n0.6\\n0.5\\n0.4\\n0.3\\n0.2\\n0.1\\n0.0\\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\\nSample Index\\neulaV\\nGAN\\nNAG (Normalized Alignment Gap)\\nFigure16: Visualizationofthefourproposedmetricsforkernelselectioninalignmenttasks. (a)Positive-Negative\\nDivergence(PND)illustratesthedivergencebetweenalignmentscoresforpositiveandnegativesamples,indicating\\nthedegreeofseparability. (b)Positive-NegativeAlignmentVariance(PNAV)depictsthevarianceinalignment\\nscores for positive and negative samples, reflecting alignment consistency. (c) Triplet Alignment Tightness\\n(TAT)showstherelativepositioningofquery(x),positive(y+),andnegative(y−)embeddingsinthelatentspace,\\nhighlightingalignmentprecision. (d)NormalizedAlignmentGap(NAG)trackstheevolutionofalignmentgaps\\nover samples, where smaller NAG values signify better alignment quality. These metrics collectively provide\\nquantitativeevaluationsofkernelperformanceincapturingalignmentproperties.\\n3. TripletAlignmentTightness(TAT) Triplet 4. NormalizedAlignmentGap(NAG) TheNor-\\nAlignment Tightness (TAT) assesses the relative malizedAlignmentGap(NAG)quantifiestherel-\\ntightnessofthequery,positive,andnegativetriplet ativedifferenceindistancesbetweenpositiveand\\nintheembeddingspace: negativesamples:\\n∥y+−y−∥ d(x,y−)−d(x,y+)\\nTAT = NAG =\\n∥y+−x∥+∥y−−x∥ d(x,y−)+d(x,y+)\\nHigher TAT values signify tighter clustering of WhenNAGisclosetozero,itindicatessimilardis-\\npositive and negative samples around the query, tancesforpositiveandnegativesamples,favoring\\nindicatingthatSpectralkernelsmaybebeneficial PolynomialorMahalanobiskernels. Largerdevi-\\ninmaintainingprecisealignment. ationsinNAGsuggestthesuitabilityofRBFandSpectralkernelstohandletheincreasedseparation. handle extreme values. Lower kurtosis, indicat-\\ning lighter tails, is better managed by Hellinger\\nG.2 MetricsforData-DrivenDivergence\\ndivergence, which measures similarity based on\\nSelection\\nthesquarerootsofprobabilities.\\nWeintroducefourkeymetricstoguidetheselec-\\n4. Smoothness Smoothnessassessesthevariabil-\\ntionofdivergencefunctions. Thesemetricsevalu-\\nity in the change of distribution parameters over\\natewhetherKL,JSD,Rényi,Wasserstein,orBhat-\\ntime:\\ntacharyyadivergencesaremostsuitablebasedon\\nthestructureandbehaviorofthealignmenttask.\\nT\\n1 (cid:88)\\nSmoothness = |p −p |\\n1. SupportOverlap SupportOverlapquantifies T t t−1\\nt=1\\ntheextenttowhichtwodistributionsP andQshare\\ncommonsupportregions: Lowersmoothnessvaluesindicategradualchanges,\\nfavoring Wasserstein divergence, which can ef-\\n|P ∩Q|\\nSupportOverlap = fectively capture gradual shifts. Higher smooth-\\n|P ∪Q|\\nness, with abrupt changes, suggests using KL or\\nHellinger divergence for more responsive align-\\nHigh overlap suggests that Bhattacharyya diver-\\nment.\\ngence is appropriate, as it effectively measures\\ndistributionsimilaritywhensupportsoverlapsig-\\nG.3 AnalysisofFigures\\nnificantly. Low overlap, on the other hand, indi-\\ncatesthatKLorJensen-Shannondivergencemay Figures 16 and 17 illustrate the eight proposed\\nbemoresuitableforcapturingthedifferencesbe- metrics,organizedasfollows:\\ntweendistributionswithdistinctsupports.\\n• KernelSelectionMetrics(Figure16):\\n2. DriftMagnitude DriftMagnitudemeasures\\nthe shift in the mean of a distribution over time, – (a) Positive-Negative Divergence (PND):\\nwhichisusefulfordetectingchangesduringtrain- Demonstrates the divergence between align-\\ning: ment scores for positive and negative samples,\\nindicatingthedegreeofseparability.\\nn\\nDriftMagnitude= n1 (cid:88)(cid:0) d(x i,y i+)−d(x i,y i−)(cid:1) – (b) Positive-Negative Alignment Variance\\ni=1 (PNAV): Measures the variance in alignment\\nscoresforpositiveandnegativesamples,reflect-\\nLargedriftmagnitudesfavortheuseofWasserstein\\ningalignmentconsistency.\\ndivergence, which is robust to distribution shifts,\\nwhilesmallerdriftmagnitudessuggestthatKLor – (c)TripletAlignmentTightness(TAT):Tracks\\nRényidivergencemaysuffice. the relative positioning of query (x), positive\\n(y+),andnegative(y−)embeddingsinthelatent\\n3. Kurtosis Kurtosiscapturesthe\"tailedness\"of\\nspace,highlightingalignmentprecision.\\nadistributionandisdefinedas:\\n– (d) Normalized Alignment Gap (NAG): Re-\\nE(cid:2) (x−µ)4(cid:3)\\nflectsthealignmentqualityofpositiveandneg-\\nKurtosis =\\n(E[(x−µ)2])2 ative responses by tracking the normalized gap\\noversamples.\\nHighkurtosisindicatesheavytails,makingRényi\\ndivergence more appropriate due to its ability to • DivergenceSelectionMetrics(Figure17):0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\\nDistribution 1\\n2 noitubirtsiD\\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n01112131415161718191\\nSupport Overlap (Heatmap of Two Distributions)\\n3\\n2\\n1\\n0\\n1\\n0 20 40 60 80 100\\nTime Steps\\neulaV\\nDrift Magnitude (Shift in Distribution Mean)\\nDrift\\nShifted Mean\\n17.5\\n15.0\\n12.5\\n10.0\\n7.5\\n5.0\\n2.5\\n0.0\\nNormal Heavy-Tailed Light-Tailed\\nDistribution Type\\neulaV\\nsisotruK\\nKurtosis of Different Distributions\\n18.92\\n4\\n3\\n2\\n1\\n0\\n1\\n2\\n3\\n-0.31\\n-1.23\\n4\\n0 2 4 6 8 10\\nX\\neulaV\\n5\\n4\\n3\\n2\\n1\\n0\\nSmoothness (Function and Its Derivative)\\nSmooth Function\\nDerivative (Smoothness)\\nFigure 17: Visualization of the four key metrics for divergence selection: (1) Support Overlap — Heatmap\\nrepresentingtheoverlapbetweentwodistributions,highlightingsharedsupportregions;(2)DriftMagnitude—\\nIllustrationoftheshiftinthemeanofadistributionovertime,showcasinghowdriftisdetected; (3)Kurtosis\\n— Bar plot comparing kurtosis values for normal, heavy-tailed, and light-tailed distributions, quantifying the\\n\"tailedness\"ofeachdistribution;(4)Smoothness—Visualizationofasmoothfunctionanditsderivative,where\\nsmootherfunctionsexhibitsmaller,lessabruptchangesinderivatives. Thesemetricsguidetheselectionofthe\\nmostappropriatedivergencemeasureforeachdatascenario.\\n– (1)SupportOverlap: Illustratestheoverlapbe- tionderivatives.\\ntween positive and negative distributions, high-\\nThesevisualizationssupportourdata-drivenap-\\nlightingsharedsupportregions.\\nproachbydemonstratinghoweachmetricevolves\\n– (2)DriftMagnitude: Showstheshiftinthemean\\nduringthealignmentprocess. Thekernelselection\\nof alignment distributions over time, indicating\\nmetrics indicate the suitability of RBF, Polyno-\\ndriftdetection.\\nmial,Mahalanobis,andSpectralkernelsatdiffer-\\n– (3)Kurtosis: Comparesthe\"tailedness\"ofalign-\\nent training stages. Similarly, divergence selec-\\nmentdistributions,quantifyingtheirkurtosis.\\ntionmetricsillustratehowWassersteinandBhat-\\n– (4)Smoothness: Depictsthesmoothnessofdiver- tacharyyadivergencesbecomemoreprominentin\\ngencefunctionsbyvisualizingchangesinfunc- laterepochs,especiallyinsafety-criticalalignmenttasks. tiple kernels. This adaptability facilitates richer\\nrepresentations and improved responsiveness to\\nG.4 RelatedWork varyingdistributions,whichiscrucialinscenarios\\ninvolvingpolicyshifts,datasetshifts,orevolving\\nOur approach to metric-driven kernel and diver-\\nalignmentcriteria. Consequently,theKernelMix-\\ngence selection builds upon existing research in\\ntureApproachoffersenhancedgeneralizabilityand\\nkernellearning(Bachetal.,2004;Schölkopfand\\nrobustnessinpreference-basedlearningsystems.\\nSmola,2002)anddivergence-basedlossfunctions\\n(Csiszar, 2004; Nowozin et al., 2016). Multi-\\nH.1 MotivationandBackground\\nple Kernel Learning (MKL) (Bach et al., 2004)\\nintroduced the concept of learning optimal ker- Previous research in multiple kernel learning\\nnelweights,whileinformation-theoreticmeasures (MKL) (Gönen and Alpaydın, 2011) and addi-\\nhavedriventhedevelopmentofdivergence-based tive Gaussian processes (Duvenaud et al., 2013)\\nalignment methods (Csiszar, 2004). Our contri- has demonstrated the utility of combining multi-\\nbution extends these ideas by introducing a con- ple kernels to improve generalization. Addition-\\ncretesetofinterpretablemetricsandanend-to-end ally,studiesondatasetshift(Quinonero-Candela\\nframeworkforthedynamicselectionofkernelsand etal.,2009;Kohetal.,2021b)andofflinereinforce-\\ndivergencefunctionsbasedondata-drivenevalua- ment learning (Levine et al., 2020) highlight the\\ntions. necessityforadaptivemechanismscapableofre-\\nOur framework for Data-Driven Selection of spondingtodistributionalchanges. Buildingupon\\nKernelTypesandDivergenceFunctionsprovides these principles, we propose the Kernel Mixture\\na systematic and principled approach to optimiz- Approachtodynamicallyselectandweightmulti-\\ning kernel and divergence choices in alignment plekernels,therebyaddressingthelimitationsof\\ntasks. ByleveragingmetricssuchasPND,PNAV, fixed-kernelmodelsinevolvingenvironments.\\nTAT, and NAG for kernel selection, and Support\\nOverlap,DriftMagnitude,Kurtosis,andSmooth- H.2 FormalDefinition\\nnessfordivergenceselection,weenabletheDPO\\nWedefinethecombinedkernelasaweightedsum\\nframework to adapt dynamically to varying data\\nofindividualkernels:\\ncharacteristics and alignment requirements. Em-\\npiricalevaluationsdemonstratethatthisapproach\\nenhances generalization, robustness, and safety\\nκ(u,v) = λ κ (u,v)+λ κ (u,v)+\\ninalignmenttasks. Futureworkmayextendthis 1 Poly 2 RBF\\nλ κ (u,v)+λ κ (u,v),\\nframeworktomultimodalsettingsandlarge-scale 3 Spectral 4 Mahalanobis\\nalignmentsystems,furtherbroadeningitsapplica-\\nbilityandeffectiveness. where:\\nH KernelMixtureApproach • κ Poly,κ RBF,κ Spectral,andκ Mahalanobisrepresentthe\\nPolynomial,RadialBasisFunction(RBF),Spec-\\nTheKernelMixtureApproachintroducesaflex- tral,andMahalanobiskernels,respectively.\\nibleandadaptivemechanismforcombiningmul-\\ntiplekernels,therebyenhancingthemodel’sabil- • λ ,λ ,λ ,λ ≥ 0 are the non-negative coeffi-\\n1 2 3 4\\nity to generalize across diverse alignment tasks. cientscontrollingthecontributionofeachkernel.\\nUnliketraditionalDirectPreferenceOptimization\\n(DPO), which relies on a fixed kernel, this ap- • λ +λ +λ +λ = 1ensuresthatthecoefficients\\n1 2 3 4\\nproachdynamicallyadjuststheinfluenceofmul- formaconvexcombination.Toenforcenon-negativityandensurethattheco-\\nefficientssumtoone,weparameterizethemusing\\nasoftmaxtransformation:\\nexp(θ )\\ni\\nλ = , fori = 1,2,3,4,\\ni (cid:80)4 exp(θ ) j=1 j\\nwhere θ are learnable parameters updated\\ni\\nthroughgradientdescent. Thisformulationallows\\nthemodeltoautomaticallyadjustthekernelmix- 0 20 40 60 80 100 120 140 160 180\\nEpochs\\nture in response to changes in task dynamics or\\ndistributionalshifts,maintainingadaptabilityand\\nrobustness.\\nDespitetheinitialpromiseoftheKernelMixture\\nApproach, a fundamental limitation becomes ap-\\nparentduringtraining. AsshowninFigure18,the\\ndynamicevolutionofkernelweightsoftenleadsto\\nthedominanceofonekernel,effectivelyreducing\\nthemixturetoanear-single-kernelsolution. While\\nthisbehaviormayoptimizeperformanceforspe-\\ncifictasks,itunderminestheprimaryadvantageof\\nthemixturemodel—leveragingdiversekernelsto\\ncapturevarieddatacharacteristics. Theoretically\\nwell-grounded,butinpractice,theKernelMixture\\nApproachfacesthekernelcollapsephenomenon,\\nwhere the mixture tends to favor one or two ker-\\nnels while suppressing the others. This behavior\\nreducesthediversityandeffectivenessoftheker-\\nnelmixture,limitingitsabilitytogeneralizeacross\\ndifferenttasks.\\nH.3 WhatisKernelCollapse?\\nKernel Collapse refers to aphenomenon in ker-\\nnel mixture models where, during training, the\\nsystem increasingly relies on a single dominant\\nkernelwhiletheotherkernelsbecomeirrelevant\\n(i.e.,theirweightsreducetozero). Formally,sup-\\nposeamixtureofkernelsisdefinedas:\\nκ(u,v) = λ κ (u,v)+λ κ (u,v)\\n1 RBF 2 Poly\\n+λ κ (u,v)+λ κ (u,v),\\n3 Spectral 4 Mahalanobis\\nslenreK\\nlaimonyloP\\nFBR\\nlartcepS\\nsibonalahaM\\nKernel Mixture Evolution over 200 Epochs\\n1.0\\n0.8\\n0.6\\n0.4\\n0.2\\n0.0\\nthgieW\\nFigure18: EvolutionofKernelWeightsintheMixture\\nOver200Epochs. Theplotillustratesthedynamicad-\\njustmentofkernelweights(λ ,λ ,λ ,λ )correspond-\\n1 2 3 4\\ning to Polynomial, RBF, Spectral, and Mahalanobis\\nkernels,respectively,duringtraining. Eachcurverep-\\nresents the relative contribution of a kernel, showing\\nhowthemodeladaptsitsalignmentstrategyovertime.\\nThedominanceofoneortwokernels,asindicatedby\\nthecurves,highlightsthetendencytowardskernelcol-\\nlapse,wherecertainkernelsovershadowothers. This\\nvisualizationunderscoresthechallengesinmaintaining\\nkerneldiversitywithinthemixture.\\nwhereλ ,λ ,λ ,λ ∈ [0,1]andλ +λ +λ + 1 2 3 4 1 2 3\\nλ = 1. Kernelcollapseoccurswhenoneofthe 4\\nweights (e.g., λ ) approaches 1 while the others 1\\n(λ ,λ ,λ → 0). This behavior is visualized in 2 3 4\\nFigure18,whereasinglekerneldominateswhile\\nothersbecomeirrelevant.\\nH.4 IntuitiveExplanationofKernelCollapse\\nTounderstandkernelcollapseintuitively,imagine\\nhiringateamoffourexpertstosolveatask:\\n• Alice(RBFkernel)specializesinsolvinglocal,\\nneighborhood-levelproblems.\\n• Bob (Polynomial kernel) excels at identifying\\ncomplex,nonlinearpatterns.\\n• Carol (Spectral kernel) understands global\\ngraph-basedrelationships.\\n• Dave(Mahalanobiskernel)capturestheoverallshapeofthedatabyconsideringdatadistribution 1996),wherenon-zerocoefficientsarepenalized.\\nandcorrelations. Similarly,withoutadiversity-promotingpenalty\\n(likeentropymaximization),thesystemnaturally\\nInitially,youconsultallfourequally. However,\\neliminates\"weaker\"kernelstominimizethetrain-\\nifAlice(RBF)consistentlyproducesbetterresults\\ningobjective.\\nintheearlystages,youbegintorelymoreonher\\nexpertise. AsAlice’sinfluencegrows,Bob,Carol, • ImbalancedTaskContributions: Differenttasks\\nandDave’scontributionsdiminish. Eventually,the favor different kernels. For example, reasoning\\nteamreliespredominantlyonAlice,effectivelyig- tasks may rely on Spectral kernels for graph-\\nnoring the others. This scenario mirrors kernel like dependencies, while local decision bound-\\ncollapse, where the mixture focuses on the RBF ariesmayfavorRBFkernels. Ifthetrainingdata\\nkernel while the others are suppressed. Conse- emphasizeslocalalignment(likeshort-termrea-\\nquently,thesystemlosesitsdiverseperspectives soning),RBFkernelswilldominate,andthesys-\\nandbecomeslimitedinitsreasoningandgeneral- tem will collapse to RBF. This task imbalance\\nizationcapabilities. hasbeenobservedinmulti-objectiveoptimization\\n(SenerandKoltun,2018).\\nH.5 CausesofKernelCollapse\\nKernelcollapsearisesfromseveralfactorsrelated H.6 WhyShouldWeCareAboutKernel\\ntooptimizationdynamicsandregularization: Collapse?\\nKernelcollapseiscriticaltoalignmentlearning\\n• Positive Feedback Loop: During training, if andgeneralization. Here’swhyitmatters:\\nonekernel(e.g.,RBF)initiallyperformswell,its\\nweightλ 1 increasesduetogradientdescent. As • LossofKernelDiversity: Theprimaryadvantage\\nλ 1 increases, the contributions of other kernels of a kernel mixture lies in its ability to combine\\n(Polynomial, Spectral, Mahalanobis) decrease, local,nonlinear,andglobalrelationships. Kernel\\nwhich further amplifies RBF’s influence. This collapse reduces the mixture to a single-kernel\\npositive feedback loop forces the system into model,diminishingitsabilitytogeneralizeacross\\na winner-takes-all situation, as also observed multipleformsofreasoning. Forinstance,amodel\\nin multiple kernel learning (MKL) (Bach et al., dominated by an RBF kernel may struggle with\\n2004). multi-hopreasoning,whichrequiresglobalker-\\nnelslikeSpectralorMahalanobiskernels(Ng\\n• OptimizationBiasTowardSimplicity: Gradient-\\netal.,2001).\\nbasedoptimizationfavorssimplersolutionswith\\nfeweractivedegreesoffreedom. Insteadofmain- • ReducedGeneralization: Withonlyonekernel\\ntainingabalancedmixtureofkernels,thesystem active,themodel’sgeneralizationcapabilitiesare\\nfinds it easier to \"drop out\" less useful kernels. limited to the specific strengths of that kernel.\\nThis behavior aligns with Occam’s razor and is This is particularly problematic in scenarios re-\\nwell-knowninconicduality-basedMKL(Bach quiring both local alignment (e.g., step-by-step\\netal.,2004). logical reasoning) and global alignment (e.g.,\\ncontextualalignment).\\n• LackofRegularizationforDiversity: Without\\nanexplicitpenaltytoenforcekerneldiversity,the • Reduced Interpretability: Tracking the contri-\\nsystemhasnoincentivetokeepmultiplekernels butions of different kernels over time provides\\nactive. This behavior is analogous to sparsity- insightsintowhichkernel(localorglobal)isguid-\\ninducingnormssuchastheℓ -norm(Tibshirani, ing alignment learning. If collapse occurs, only\\n1onekernelguidesthealignment,andinterpretabil- • GlobalKernels(e.g.,Spectral,Mahalanobis)cap-\\nityislost. ThisisakeyproblemforExplainable turelarger-scalestructuresandrelationships,par-\\nAI(XAI)(Lipton,2016). ticularlywhendataexhibitsnonlinearglobalde-\\npendencies. TheMahalanobiskernelisinspired\\nH.7 WeNeedaBetterKernelMixingStrategy bymetriclearning(WeinbergerandSaul,2009),\\nwhileSpectralkernelshaverootsingraphLapla-\\nTo address the issue of kernel collapse, we in-\\nciansandspectralclustering(Ngetal.,2001).\\ntroduce the Hierarchical Mixture of Kernels\\n(HMK) in the next section. Unlike the flat Ker- WhyHMK?Naivekernelcombinations,such\\nnelMixtureApproach,HMKmaintainsdiversity asthoseusedinMultipleKernelLearning(MKL),\\nbylearningahierarchicaldecompositionoflocal fail to capture hierarchical dependencies. HMK\\nand global kernels. By structuring the mixture resolves this by allowing local kernels to model\\nintolocal(e.g.,RBF,Polynomial)andglobal(e.g., fine-grainedinformationwhileglobalkernelscap-\\nSpectral,Mahalanobis)subspaces,HMKprevents turelarger-scaledependencies. Thisdesigndraws\\nthedominanceofasinglekernel. Thishierarchy parallelswiththehierarchicalfeaturelearningob-\\nallows for a more balanced integration of kernel servedindeeplearningmodels(Goodfellowetal.,\\ntypes,enablingbettergeneralizationandalignment 2016).\\nlearningacrossdifferenttasks. Hierarchical Structure: Unlike linear kernel\\nmixtures, HMK imposes a hierarchical structure\\nH.8 HierarchicalMixtureofKernels(HMK)\\nwherelocalkernelsoperateonsmall,localregions,\\nMotivationandDesignPrinciples: TheHierar- andglobalkernelscapturelarger-scaledependen-\\nchical Mixture of Kernels (HMK) framework cies. Thisstructureisformalizedas:\\naddresses the limitations of conventional kernel\\nmethodsbyleveragingbothlocalandglobalfea-\\ntureinteractionswithinaunifiedstructure. Unlike K(x,x′) = τ 1(cid:0) λ 1K RBF(x,x′)+λ 2K Poly(x,x′)(cid:1)\\nsimple linear combinations of kernels, HMK in- +τ (cid:0) λ K (x,x′)+λ K (x,x′)(cid:1)\\n2 3 Spectral 4 Mahalanobis\\ntroduces a hierarchical decomposition, enabling\\nadynamicbalancebetweenlocalandglobalper- where:\\nspectives. This approach draws inspiration from\\n• λ ,λ ,λ ,λ arethekernelmixtureweights.\\n1 2 3 4\\nhierarchical learning models (Goodfellow et al.,\\n2016),multiplekernellearning(Bachetal.,2004), • τ ,τ arecoefficientsbalancingthecontribution\\n1 2\\nandgraph-basedkernels(Ngetal.,2001). oflocalandglobalkernels.\\nThe motivation behind HMK is rooted in the\\nBothsetsofweightsarelearnedusingbackprop-\\nobservationthatdifferenttypesofkernelsexcelat\\nagation,allowingthemodeltodynamicallyadjust\\ncapturing distinct forms of relationships in data.\\nthebalancebetweenlocalandglobalkernelsbased\\nForinstance:\\nonthedataandtaskrequirements.\\n• LocalKernels(e.g.,RBF,Polynomial)areeffec- H.9 EffectiveRangeofaKernel\\ntiveatcapturingfine-grained,localpatternsinthe\\nTheeffectiverangeofakernelκ(u,v)isthedis-\\ndata. RBFkernels,widelyusedinsupportvector\\ntancer atwhichthekerneldecaystoasmallfrac-\\nmachines(SVMs)(SchölkopfandSmola,2002),\\ntion(e.g.,0.01)ofitsmaximumvalue.\\ndefine local decision boundaries, while Polyno-\\nMathematicalDefinition:\\nmialkernelscapturenonlinearfeatureinteractions\\nwithinaboundedrange. κ(u,v) ≈ 0.01×κ(u,u) when ∥u−v∥= rForspecifickernels,theeffectiverangecanbe 6 RBF Kernel (Local) 6 Spectral Kernel (Global)\\nData Points Data Points\\nQuery Point Query Point\\ncomputedasfollows: Effective Range (3)\\n4 4\\n2 2\\n• RBFKernel:\\n0 0\\n(cid:115)\\n(cid:18) (cid:19)\\nκ(u,u) 2 2\\nr = 2σ2ln\\n0.01 4 4\\n66 4 2 0 2 4 6 66 4 2 0 2 4 6\\n• PolynomialKernel: 6 Polynomial Kernel (Local) 6 Mahalanobis Kernel (Global)\\nData Points Data Points\\nQuery Point Query Point\\nEffective Range\\n4 4\\n(cid:18)\\n0.01\\n(cid:19)1/d\\nr = 2 2\\nκ(u,u)\\n0 0\\n• SpectralKernel: 2 2\\n4 4\\nr = min{d (u,v)|d (u,v) > 0}\\nconnect connect 66 4 2 0 2 4 6 66 4 2 0 2 4 6\\nFigure 19: Illustration of local vs. global kernel in-\\n• MahalanobisKernel:\\nfluence. Thetoprowshowslocalandglobalbehavior\\n(cid:112) (cid:112) (cid:112) (cid:112) fortheRBFandSpectralkernels,respectively,while\\nr major= λmax× 2ln(100), r minor= λmin× 2ln(100)\\nthebottomrowillustratesthePolynomial(local)and\\nMahalanobis(global)kernels.\\nH.9.1 IllustrationoftheEffectiveRange\\nTop-left(RBFKernel): Demonstrateslocalinfluence\\nTovisualizethekernelinfluencerange,asetof20 withinacirculareffectiverange,beyondwhichsimilar-\\npointswasrandomlysampledfromthe2Dspace itydecaysrapidly.\\n[−5,5] × [−5,5]. A fixed query point at (0, 0) Top-right(SpectralKernel): Capturesglobalrelation-\\nshipsviagraph-basedconnectivity,withlong-distance\\nservesasthereferencepointforkernelsimilarity\\nconnectionsbetweendistantpoints.\\ncomputation for the RBF, Polynomial, Spectral,\\nBottom-left(PolynomialKernel): Exhibitslocalinflu-\\nand Mahalanobis kernels. Please refer to Figure\\nencebutallowsnonlineartransformations,illustrated\\n19.\\nbydotted,non-linearconnections.\\nBottom-right(MahalanobisKernel): Showsglobalin-\\n• Purpose: Randompointsofferadataset-agnostic\\nfluence,withellipsoidalregionsdeterminedbythedata\\nviewofkernelinfluence. covariancematrix,highlightinganisotropicsimilarity.\\n• Why It Matters: The query point allows us to\\nanalyze how influence propagates, aiding in the in alignment tasks. Fig. 20 illustrates the decay\\nunderstandingoflocalvs. globalbehavior. patternsforRBF,Polynomial,Spectral,andMaha-\\nlanobiskernels,providinginsightsintotheirlocal\\nH.10 AlternativeAnalysisoftheEffective andglobalproperties.\\nRangeofKernels\\nH.11 KeyObservationsandInsights\\nThissectionprovidesyetanotherviewofselecting\\nglobal and local kernels. The effective range of • LocalKernels(RBFandPolynomial): TheRBF\\nakernelquantifiesthedistance∥u−v∥atwhich kernelexhibitssharpexponentialdecay,making\\nitsinfluencediminishestoanegligiblevalue,typi- it effective for modeling fine-grained, localized\\ncally1%ofitsmaximum. Understandingtheeffec- relationships(SchölkopfandSmola,2002). Sim-\\ntiverangeispivotalforanalyzingkernelbehavior ilarly, the Polynomial kernel, influenced by itsdegreed,demonstratesalimitedeffectiverange, FortheMahalanobiskernel:\\nemphasizinglocalinteractions(GönenandAlpay-\\ndın,2011).\\n(cid:18) (u−v)⊤Σ−1(u−v)(cid:19)\\nκ (u,v)=exp − .\\nMahalanobis\\n2\\n• Global Kernels (Spectral and Mahalanobis):\\nTheMahalanobiskernel’sdecayratedependson\\nTheSpectralkernel’srangedependsonitseigen-\\ntheconditioningofthecovariancematrixΣ,allow-\\nvaluesλ andbasisfunctionsϕ :\\ni i\\ningittomodelanisotropic,long-rangedependen-\\ncies(WeinbergerandSaul,2009). Incontrast,the\\nm\\n(cid:88)\\nSpectralkernelsustainsinfluenceoverthelongest κ (u,v) = λ ϕ (u)ϕ (v).\\nSpectral i i i\\nrangeduetoitsrelianceoneigenfunctionsofthe\\ni=1\\ndata’sgraphLaplacian(Ngetal.,2001).\\nFig.20underscoresthetrade-offsbetweenlocal\\n• 1% Decay Threshold: The dashed red line in\\nand global kernels. Local kernels excel at cap-\\nFig.20highlightsthe1%decaythreshold. RBF\\nturingfine-graineddetailsbutlacklong-rangein-\\nandPolynomialkernelscrossthisthresholdwithin\\nfluence, whereas global kernels provide broader\\nashortdistance(r ≈ 2),whileMahalanobisand\\ncoverage at the cost of precision. These insights\\nSpectralkernelsmaintaininfluencebeyondr > 5,\\nemphasizethenecessityofcombiningtheseprop-\\nunderliningtheir\"global\"characteristics.\\nertiesinhierarchicalframeworkslikeHMK,which\\noptimallybalanceslocalandglobalinteractionsto\\nH.12 AlignmentTaskImplications\\naddressdiversealignmentchallenges.\\n• LocalKernels: Providesharperdecisionbound-\\naries, making them ideal for tasks like safety\\nalignmentandfine-grainedclustering(Bachetal.,\\n1.0\\n2004).\\n0.8\\n• Global Kernels: Excel in capturing broader re-\\n0.6\\nlationships,crucialforcontextualalignmentand\\nmulti-hop reasoning (Quinonero-Candela et al.,\\n0.4\\n2009).\\n0.2\\n• Hierarchical Mixture of Kernels (HMK):\\nHMK’s hierarchical structure combines these 0.0\\n0 2 4 6 8 10\\nstrengths, achieving robust performance across Distance ||u - v||\\ndiversetasks(Levineetal.,2020).\\nH.13 MathematicalFormulation\\nThe effective range r of a kernel can be derived\\nanalytically. FortheRBFkernel:\\n(cid:115)\\n(cid:18) (cid:19)\\nκ(u,u)\\nr = 2σ2ln ,\\n0.01\\nwhereσ isthebandwidthparameter.\\n)v\\n,u(\\neulaV\\nlenreK\\nEffective Range of Local and Global Kernels\\nRBF (Local)\\nPolynomial (Global)\\nMahalanobis (Local)\\nSpectral (Global)\\n1% Decay Threshold\\nEffective Range for Mahalanobis\\nEffective Range for RBF\\nFigure20: Visualizationofkerneldecayasafunction\\nofdistance∥u−v∥. Theeffectiverangeforeachker-\\nnelisshown,wherekernelvaluesdropto1%oftheir\\nmaximum. TheRBFandPolynomialkernelsexhibit\\nrapiddecay,characterizingthemas\"local\"kernels. In\\ncontrast,theMahalanobisandSpectralkernelsshowa\\nslowerdecay,reflectingtheirroleas\"global\"kernels.\\nThe1%decaythreshold,markedasadashedredline,\\nhighlightsthedistanceatwhichtheRBFandPolyno-\\nmialkernelseffectivelybecomenegligible.H.13.1 ObservationsfromtheEffective • Dynamic Adaptation: HMK enables task-\\nRange specific adaptation through the learnable coef-\\n1. LocalKernels(RBF,Polynomial): Influence ficients τ 1 and τ 2. Unlike fixed kernel combi-\\nis confined to a neighborhood. The RBF kernel nations, the hierarchical design allows HMK to\\nexhibits isotropic influence (circular), while the dynamicallyadjustthecontributionsoflocaland\\nPolynomial kernel allows nonlinear, bounded in- globalkernelsbasedonthespecificrequirements\\nfluence. of a task. During training, backpropagation up-\\n2. Global Kernels (Spectral, Mahalanobis): datestheseweightstobestfitthealignmentobjec-\\nInfluenceextendsacrossthefeaturespace. Spec- tive,facilitatingatask-awaremixtureofkernels.\\ntralkernelsconnectdistantpointsbasedoncluster Thispropertydrawsinspirationfromconceptsin\\nmembership,andMahalanobiskernelsexhibitel- MultipleKernelLearning(MKL)(Bachetal.,\\nlipsoidal,anisotropicinfluence,aligningwiththe 2004)andadaptivegraph-basedmodels(Ngetal.,\\ncovarianceofthedata. 2001).\\nH.14 IntuitiveExplanationofLocalvs. • Unified Kernel Framework: HMK serves as a\\nGlobalKernels unifiedframeworkforintegratinglocalandglobal\\nkernels. Traditionalapproaches,suchasMultiple\\nLocal Kernels act like navigating a city on foot.\\nKernelLearning(MKL),utilizelinearcombina-\\nYouseelocalobjects(e.g.,streetsigns),focusing\\ntionsofkernelsbutdonotincorporateahierarchi-\\nonnearbyinteractions.\\ncal decomposition as HMK does. By explicitly\\nGlobalKernelsofferabird’s-eyeviewfroman\\nstructuringkernelsintolocal(RBF,Polynomial)\\nairplane,revealinglarge-scalestructureslikeparks\\nand global (Spectral, Mahalanobis) subspaces,\\nandroads. Bycombiningtheseperspectives,HMK\\nHMKachievesamoreinterpretableandeffective\\nmodelsbothlocaldetailsandglobalstructures.\\nalignment mechanism. This decomposition pro-\\nH.15 KeyTakeawaysforHMK videsaprincipledapproachtounifykernelsfrom\\ngraph-based,metric-learning,andlocality-based\\nThe Hierarchical Mixture of Kernels (HMK)\\nperspectives (Bach et al., 2004; Ng et al., 2001;\\nframeworkoffersseveralconceptualandempirical\\nWeinbergerandSaul,2009).\\nbenefits. Thissubsectionhighlightsthemostim-\\nportanttakeaways,supportedbyrelevantcitations\\n• ImprovedGeneralization: Bylearningamixture\\ntosubstantiatetheclaims.\\noflocalandglobalkernels,HMKenhancesgener-\\nalizationcapabilitiesbeyondwhatsimplekernel\\n• Bias-VarianceTrade-off: HMKfacilitatesanat-\\nmixturesoffer. Empiricalstudieshaveshownthat\\nuraltrade-offbetweenbiasandvariance. Local\\nhybridkernelscanreduceoverfittingwhilemain-\\nkernels, such as RBF and Polynomial, capture\\ntainingpredictiveaccuracy(SchölkopfandSmola,\\nfine-grainedpatternswithinsmallneighborhoods,\\n2002;Bachetal.,2004). Byleveragingbothlocal\\nthereby reducing variance but potentially intro-\\ndecisionboundariesandglobalstructures,HMK\\nducingbias. Conversely,globalkernels,likeSpec-\\nprovidesageneralizationadvantageinlarge-scale\\ntralandMahalanobis,generalizeoverlargerstruc-\\nalignmenttasks.\\ntures,reducingbiaswhilepotentiallyincreasing\\nvariance. Bybalancingthesetwoforcesthrough • HierarchicalInterpretability: Thehierarchical\\nthe learnable weights τ and τ , HMK achieves decompositionoflocalandglobalkernelsinHMK\\n1 2\\nimprovedgeneralization, asdemonstratedinhy- offers interpretability to the alignment process.\\nbridmodelsforkernelalignment(Schölkopfand Unlikeblack-boxkernelcombinations,HMKpro-\\nSmola,2002;Bachetal.,2004). videsinsightsintowhichkernel(localorglobal)isbeingemphasized. Forexample,therelativemag- including language models and AI systems, and\\nnitudes of τ and τ indicate whether the align- encompassesdifferentcategoriessuchas:\\n1 2\\nment process relies more on fine-grained local\\nfeaturesoronglobalstructuralfeatures. Suchin- • InstructionFollowing: Localkernels(RBF,Poly-\\nterpretabilityiscrucialinapplicationslikeexplain- nomial) enable the model to align with task-\\nable AI (XAI) (Goodfellow et al., 2016; Wein- specificinstructionsbyfocusingonfine-grained\\nbergerandSaul,2009). local features. For example, if an instruction\\nrequires immediate changes in behavior (e.g.,\\n\"stop execution if X is true\"), the RBF kernel\\ncan swiftly adjust to this directive. Simultane-\\nParameters\\nously,globalkernels(Spectral,Mahalanobis)cap-\\n1\\n2 turebroadersemanticconceptsfrominstruction-\\n3\\n4\\n1.0 following datasets. As illustrated in Figure 21,\\nduringtheearlyepochs,localkernels(RBF,Poly-\\n0.8\\nW nomial)dominatetheinfluence. Astrainingpro-\\ne\\nig\\nh 0.6 gresses and broader instruction semantics are\\nt\\nV\\na lu 0.4 learned,thecontributionsofglobalkernels(Spec-\\ne\\ntral,Mahalanobis)graduallyincrease,enhancing\\n0.2\\nthemodel’sabilitytounderstandandexecutecom-\\n0.0 plexinstructions.\\n4\\nPara meters3\\n2\\n1 0 25\\n50\\n75 1 E0 p0 oc1 h2 s5\\n150\\n175 200 • R\\nq\\ntuue\\nri\\nea\\nr\\nses .o\\ns\\nHn thi Mn eg\\nKin\\n’A\\nt\\nsel hgig\\nir\\nen\\na\\nrtm\\naio\\nre cnn\\nho\\nit c:\\nf as\\nlE\\nt\\ndeff epe c-c\\nw\\not mi iv\\ns\\npe\\ne\\nor\\nl\\nsoe ia\\ng\\ntis\\ni\\noco nan li an\\nls\\nlg\\nt oru\\nwr ce s--\\nlocalkernelstocapturelocallogicaltransitions,\\nsuch as intermediate steps in multi-step reason-\\nFigure21: EvolutionoftheHierarchicalMixtureof\\nKernels(HMK)parametersover200epochs. The ing tasks. Concurrently, global kernels capture\\nplotvisualizestheweightdynamicsforthelocalkernel multi-hopdependenciesandrelationshipsacross\\ncomponents λ 1 (Polynomial) and λ 2 (RBF), as well extensive contexts, as evidenced in graph-based\\nastheglobalkernelcomponentsλ (Spectral)andλ\\n3 4 reasoning(Ngetal.,2001). InFigure21,thein-\\n(Mahalanobis).Additionally,theevolutionoftheLocal-\\ncreasingweightoftheSpectralkernel(λ )reflects\\n3\\nGlobalBalanceParameterτ isshown,illustratinghow\\nthemodel’sattempttointegratemulti-hopdepen-\\nthemodeladaptivelybalancescontributionsfromlocal\\ndencies. Meanwhile,Polynomialkernels(λ )ex-\\nandglobalmixtures. Thetrajectoryofeachparameter 1\\nreveals how kernel dominance shifts during training, perienceatemporaryincreasewhenstep-by-step\\noftenconvergingtoastablebalance. logicaltransitionsareemphasized,demonstrating\\nHMK’sabilitytobalancedifferentaspectsofrea-\\nsoning.\\nH.16 HowHMKSupportsAlignment\\nLearning\\n• Safety and Robustness Alignment: Ensuring\\nThe Hierarchical Mixture of Kernels (HMK) predictablebehaviorinsafety-criticalapplications\\nframework leverages both local and global ker- necessitatesmodelingbothlocalconstraints(fine-\\nnelswithinahierarchicalstructure,offeringunique grained decision boundaries) and global struc-\\nbenefitsforvariousformsofalignmentlearning. tures (macro-level behavior constraints). Lo-\\nAlignmentisacriticaltaskinlarge-scalemodels, calkernelscanmodelstrictdecisionboundariesfor sensitive instructions, ensuring that out-of- bothtypesofkernelscompetefordominance,as\\ndistribution (OOD) inputs are quickly rejected. reflectedbytheconvergenceofτ andτ around\\n1 2\\nGlobalkernelscapturebroadersafetyconstraints, epoch100. ThisstabilizationindicatesthatHMK\\nmaintainingsystemrobustnessagainstlargercon- has learned an optimal balance tailored to the\\ntextualshifts. AsshowninFigure21,duringthe specificalignmenttask,allowingittoeffectively\\nearlyepochs,RBF(local)kernelsdominate,effec- leveragebothlocalandglobalfeatures.\\ntivelycapturinglocalizeddecisionboundaries. As\\ntrainingprogresses,theSpectralkernel(λ )rises, • KernelWeightEvolution(λ): Eachkernelcom-\\n3\\nreflecting the emergence of global connectivity- ponent(λ Polynomial,λ RBF,λ Spectral,and\\n1 2 3\\nbasedsafetyconstraintsthatenhancethemodel’s λ Mahalanobis)followsadistincttrajectorydur-\\n4\\noverallrobustness. ing training. In the early stages, local kernels\\n(Polynomial λ and RBF λ ) exhibit high influ-\\n1 2\\n• ContextualAlignment: Inretrieval-augmented\\nence, aligning with their role in capturing fine-\\nsystems,aligningcontextfromretrievedinforma-\\ngrained, local patterns. As training progresses,\\ntionwithtaskqueriesisessential. Localkernels\\nglobalkernels(Spectralλ andMahalanobisλ )\\n3 4\\nidentify similarities within smaller local neigh-\\ngradually increase their weights, reflecting the\\nborhoods,ensuringthatcloselyrelatedretrievals\\nmodel’s shift towards capturing broader, long-\\nare appropriately weighted. Conversely, global\\nrangedependencies. Forexample, incontextual\\nkernelsassessalignmentatthecontext-document\\nalignment tasks, the Mahalanobis kernel weight\\nlevel, ensuring that large-scale relationships be-\\n(λ )notablyincreasesbetweenepochs50and150,\\n4\\ntweenmultipleretrieveddocumentsareaccurately\\nindicatingthegrowingimportanceofglobalcon-\\nmodeled. In Figure 21, the Mahalanobis kernel\\ntext.\\n(λ )becomesprominentinlaterepochs,highlight-\\n4\\ningthesystem’sefforttomodelanisotropicinflu-\\n• Localvs. GlobalAdaptation: Theinterplaybe-\\nenceacrosscontextspaces. Initially,theRBFker-\\ntween local and global kernels is evident in the\\nnel(λ )dominates,effectivelyidentifyingclose-\\n2 behavior of τ and τ . Initially, both local and\\n1 2\\nbydocumentsimilarities.\\nglobalkernelsareweightedequally,butovertime,\\nHMKprioritizesoneovertheotherbasedonthe\\nH.17 HowtoInterpretFigure21\\ntask’srequirements. InFigure21,τ (local)gradu-\\n1\\nFigure 21 illustrates the dynamic evolution of allydecreaseswhileτ (global)increases,demon-\\n2\\nHMK parameters over 200 training epochs. stratingHMK’sadaptivemechanismtoemphasize\\nSpecifically,itdepictstheweightdynamicsforthe globalinfluenceasalignmentlearningprogresses.\\nlocalkernelcomponentsλ (Polynomial)andλ\\n1 2\\n(RBF),theglobalkernelcomponentsλ (Spectral) • ConvergenceBehavior: Overthecourseof200\\n3\\nandλ (Mahalanobis),aswellastheLocal-Global epochs,thekernelweights(λ)andbalancecoef-\\n4\\nBalanceCoefficientsτ andτ . Thisvisualization ficients(τ)convergetowardsstablevalues. This\\n1 2\\nprovidesvaluableinsightsintohowHMKbalances convergencesignifiesthatHMKhassuccessfully\\nthecontributionsoflocalandglobalkernelsduring learnedanoptimalmixtureoflocalandglobalker-\\nthe training process. The key observations from nels tailored to the alignment task. Specifically,\\nthisplotareasfollows: thesteadyincreaseoftheMahalanobiskernel(λ )\\n4\\ninlaterepochsunderscoresitsroleinestablishing\\n• AdaptiveBalancingofLocalandGlobalKer- long-term global dependencies, while the stabi-\\nnels: Thecoefficientsτ andτ regulatethebal- lizationofτ andτ indicatesabalancedintegra-\\n1 2 1 2\\nance between local and global kernels. Initially, tionoflocalandglobalcontributions.H.18 TheoreticalGuarantee: HMKAvoids H.19.2 2. RoleofEntropyRegularization\\nKernelCollapse Weintroduceanentropyregularizationtermtothe\\nTheorem (Stochastic Stability of HMK) Let lossfunction:\\nλ 1,λ 2,λ 3,λ 4 denote the kernel mixture weights 4\\n(cid:88)\\nof the Hierarchical Mixture of Kernels (HMK) R(λ) = − λ logλ\\ni i\\nframework,optimizedusinggradientdescentwith i=1\\na learning rate η > 0. Suppose that the ker-\\nThistermencouragesdiversityamongthekernel\\nnelweightsarereparameterizedusingasoftmax\\nweights,preventinganysinglekernelfromdomi-\\ntransformation, and the total loss function in-\\nnatingthemixtureexcessively. Thepartialderiva-\\ncludes an entropy regularization term R(λ) =\\ntiveofR(λ)withrespecttoλ is:\\n−(cid:80)4\\nλ logλ . Then, for any training epoch\\ni\\ni=1 i i\\n∂R(λ)\\nt, the kernel weights satisfy λ (t) > 0 for all\\ni = −logλ −1\\ni\\ni ∈ {1,2,3,4}. Moreover, the coefficients τ 1(t) ∂λ i\\nandτ (t),whichcontrolthebalancebetweenlocal\\n2 As λ → 0, logλ → −∞, causing the gradi-\\ni i\\nandglobalkernels,arealsoguaranteedtoremain ent ∂R to become significantly negative. This\\nstrictlypositiveforallt.\\n∂λi\\nresultsinastrongupwardpushonλ ,preventing\\ni\\nit from reaching zero. Thus, the entropy regular-\\nH.19 ProofofTheorem\\nizationactsasarepulsionforce,ensuringthatall\\nThe proof consists of four key components: 1. kernelweightsremainstrictlypositiveanddiverse\\nPropertiesofSoftmaxReparameterization2. Role (Williams,1991;Jaynes,1957).\\nof Entropy Regularization 3. Impact of Local-\\nH.19.3 3. ImpactofLocal-Global\\nGlobal Decomposition via τ and τ , and 4.\\n1 2\\nDecompositionviaτ andτ\\nStochasticStabilityviaGradientDescent. 1 2\\nThehierarchicaldecompositionofkernelsinHMK\\nH.19.1 1. PropertiesofSoftmax\\nisdefinedas:\\nReparameterization\\nWe parameterize the kernel weights λ\\ni\\nusing the K(x,x′) = τ 1(cid:0) λ 1K RBF(x,x′)+λ 2K Polynomial(x,x′)(cid:1)\\nsoftmaxfunction: +τ (cid:0) λ K (x,x′)+λ K (x,x′)(cid:1)\\n2 3 Spectral 4 Mahalanobis\\nλ =\\nexp(θ i)\\nfor i ∈ {1,2,3,4}\\nHere,τ\\n1\\nandτ\\n2\\nbalancethecontributionsfrom\\ni (cid:80)4 exp(θ ) local kernels (RBF, Polynomial) and global ker-\\nj=1 j\\nnels(Spectral,Mahalanobis),respectively. These\\nSincetheexponentialfunctionsatisfiesexp(θ ) > coefficientsarealsoparameterizedusingasoftmax\\ni\\n0 for all θ ∈ R, it follows that λ > 0 for all i transformation:\\ni i\\nand at all times t. This ensures that none of the\\nexp(ψ )\\ni\\nλ i cancollapsetozero. Additionally,thesoftmax τ i = (cid:80)2\\nexp(ψ )\\nfor i ∈ {1,2}\\ntransformationguaranteesthat: j=1 j\\nSimilar to the kernel weights λ , this parameter-\\ni\\n4\\n(cid:88) ization ensures that τ > 0 and τ > 0 for all t,\\nλ = 1 1 2\\ni\\nguaranteeingthatbothlocalandglobalkernelcom-\\ni=1\\nponentsremainactive. Thishierarchicalstructure\\nThisnormalizationensuresboundednessandnon- facilitatestheintegrationofbothfine-grainedlocal\\ndegeneracy of the kernel weights (Bridle, 1990; patternsandbroadglobaldependencies(Goodfel-\\nBishop,2006). lowetal.,2016;Bachetal.,2004;Ngetal.,2001).H.19.4 4. StochasticStabilityviaGradient thatbothlocalandglobalkernelscontributeeffec-\\nDescent tivelytothealignmentprocess. Thecombination\\nTodemonstratethattheweightsλ andcoefficients ofentropyregularization,hierarchicaldecomposi-\\ni\\nτ ,τ converge to non-zero stable points, we an- tion,andstochasticstabilitythroughgradientde-\\n1 2\\nalyzethegradientdescentupdatesunderentropy scentformsarobustfoundationforHMK’sperfor-\\nregularization. manceindiversealignmenttasks.\\nTheparametersθ andψ areupdatedusinggra-\\ni i\\nI GradientComputation,Computational\\ndientdescentasfollows:\\nComplexity,andOverhead\\n∂L\\n(t+1) (t)\\nθ = θ −η\\ni i ∂θ Since this paper introduces several concepts and\\ni\\nnew formulation, for better resproducability and\\n(t+1) (t) ∂L andbetterreadweprovidedetailedmathematical\\nψ = ψ −η\\ni i ∂ψ i derivationofgradientcalculationsforDPOHybrid\\nwhereListhetotalloss,includingthealignment Lossandgradientcalculationforallthekernels.\\nobjectiveandentropyregularization.\\nI.1 GradientofHybridLoss\\nUsing the chain rule, the gradients can be ex-\\npressedas: In this subsection, we derive the gradient of the\\nHybridLosswithrespecttothemodelparameters\\n∂L ∂L\\n= ·λ (1−λ ) θ. TheHybridLossisdefinedas:\\ni i\\n∂θ ∂λ\\ni i\\n∂L\\n=\\n∂L\\n·τ i(1−τ i)\\nm πax E x,y+,y−(cid:20) log ππ (( yy −+ || xx )) +γ(cid:18) log ππ (( ee yy −+ | |e ex x) )(cid:19)(cid:21)\\n∂ψ i ∂τ i (cid:124) (cid:123)(cid:122) (cid:125)\\nHybridLoss\\nSince λ > 0 and τ > 0, the gradients ∂L and\\n∂L\\narei\\nnon-zero.\\ni ∂θi\\nwhere:\\n∂ψi\\nTheentropyregularizationensuresthatifanyλ\\ni\\n• xrepresentstheinputdata.\\napproaches zero, the gradient ∂L becomes large\\n∂λi\\nandpositiveduetothe−logλ term,forcingλ to\\ni i • y+ andy− denotethepositiveandnegativesam-\\nincrease. Similarly,thesoftmaxparameterization\\nples,respectively.\\npreventsτ fromcollapsingtozero.\\ni\\nApplyingLyapunov’sstabilitytheorem(Khalil,\\n• π(y | x)istheprobabilityofy givenx,modeled\\n2002),weconcludethatthesystemreachesastable\\nusingasoftmaxfunction.\\nequilibriumwhereallλ > 0andτ > 0forallt.\\ni i\\nThisguaranteesthatHMKavoidskernelcollapse, • e ande aretheembeddingsofy andx,respec-\\ny x\\nmaintaining active contributions from both local\\ntively.\\nandglobalkernelsthroughouttraining.\\nWehaveestablishedthatundergradientdescent • γ isahyperparametercontrollingtheinfluenceof\\noptimizationwithentropyregularizationandsoft- theembedding-basedterm.\\nmax parameterization, the Hierarchical Mixture\\nofKernels(HMK)frameworkensuresthatallker- Our goal is to compute the gradient\\nnelweightsλ andbalancecoefficientsτ remain ∇ HybridLoss(x,y+,y−), which involves\\ni i θ\\nstrictlypositivethroughouttraining. Thistheoret- differentiating each term of the loss function\\nicalguaranteepreventskernelcollapse, ensuring separately.GradientoftheLogProbabilityRatio CombinedGradient\\nThefirstcomponentoftheHybridLossisthelog Byintegratingthegradientsofboththelogprob-\\nprobabilityratiobetweenthepositiveandnegative ability ratio and the embedding-based term, we\\nsamples: obtaintheoverallgradientoftheHybridLosswith\\nπ(y+ | x) respect to the model parameters θ. The Hybrid\\nlog\\nπ(y− | x) Lossisdefinedas:\\nThegradientofthistermwithrespecttoθ is: HybridLoss(x,y+,y−)=logπ(y+|x) +γ(cid:18) logπ(e y+ |e x)(cid:19)\\nπ(y−|x) π(e |e )\\ny− x\\n∂ π(y+ | x) whereγ isahyperparametercontrollingtheinflu-\\nlog = ∇ logπ(y+ | x)\\n∂θ π(y− | x) θ enceoftheembedding-basedterm.\\n−∇ logπ(y− | x) The gradient of the Hybrid Loss with respect\\nθ\\nto θ is obtained by summing the gradients of its\\nThisfollowsfromthepropertiesoflogarithmsand individualcomponents:\\nthechainruleindifferentiation.\\nGradientoftheEmbedding-BasedTerm\\n∇θHybridLoss(x,y+,y−)=∇θlog ππ (( yy+ −| |xx )) +γ∇θlog ππ (( ee yy −+| |e ex x)\\n)\\nSubstitutingthegradientsderivedintheprevi-\\nThesecondcomponentinvolvesthelogprobability\\noussections,wehave:\\nratiooftheembeddings:\\nπ(e\\ny+\\n| e x) ∇ θHybridLoss(x,y+,y−) =\\nγlog π(e\\ny−\\n| e x) (cid:2) ∇ θlogπ(y+ | x)−∇ θlogπ(y− | x)(cid:3)\\n(cid:2) (cid:3)\\n+γ ∇ logπ(e | e )−∇ logπ(e | e )\\nθ y+ x θ y− x\\nThegradientofthistermwithrespecttoθ is:\\nExpandingeachtermbasedonthegradientcom-\\n∂ (cid:18) π(e | e )(cid:19) putationsfromtheindividualcomponents,thefinal\\ny+ x\\nγ log =\\n∂θ π(e | e ) expressionforthegradientoftheHybridLossis:\\ny− x\\n(cid:0) (cid:1)\\nγ ∇ logπ(e | e )−∇ logπ(e | e )\\nθ y+ x θ y− x ∇ HybridLoss(x,y+,y−) =\\nθ\\n\\uf8ee \\uf8f9\\nGradientoftheEmbedding-BasedTerm\\n(cid:88)\\nThesecondcomponentinvolvesthelogprobability\\n\\uf8f0∇ θf θ(x,y+)− π θ(y′ | x)∇ θf θ(x,y′)\\uf8fb\\ny′\\nratiooftheembeddings:\\n\\uf8ee \\uf8f9\\n(cid:88)\\nπ(e\\ny+\\n| e x) −\\uf8f0∇ θf θ(x,y−)− π θ(y′ | x)∇ θf θ(x,y′)\\uf8fb\\nγlog\\nπ(e | e ) y′\\ny− x\\n(cid:0) (cid:1)\\n+γ ∇ s (e ,e )−∇ s (e ,e )\\nθ θ x y+ θ θ x y−\\nThegradientofthistermwithrespecttoθ is:\\nSimplifiedGradientExpression Aftersimpli-\\n∂ (cid:18) π(e | e )(cid:19) fying the above expression, the gradient of the\\ny+ x\\nγ log =\\n∂θ π(e | e ) HybridLosscanbesuccinctlywrittenas:\\ny− x\\n(cid:0) (cid:1)\\nγ ∇ logπ(e | e )−∇ logπ(e | e )\\nθ y+ x θ y− x ∇ HybridLoss(x,y+,y−) =\\nθ\\n∇ logπ(y+ | x)−∇ logπ(y− | x)\\nThis derivation also employs the chain rule and θ θ\\n(cid:0) (cid:1)\\npropertiesoflogarithms. +γ ∇ s (e ,e )−∇ s (e ,e )\\nθ θ x y+ θ θ x y−Interpretation 2. Embedding-BasedTerm\\nCalculatings+ ands− involves:\\n• ∇ logπ(y+ | x): Encourages the model to in-\\nθ\\ncrease the probability of the positive sample y+ • Evaluating the scoring function s (x,y) for the\\nθ\\ngiventheinputx. positiveandnegativesamples.\\n• −∇ logπ(y− | x): Encourages the model to • Typically depends on the embedding dimension\\nθ\\ndecrease the probability of the negative sample d.\\ny− giventheinputx.\\nTimeComplexity: O(d).\\n(cid:0) (cid:1)\\n• γ ∇ s (e ,e )−∇ s (e ,e ) : Incorpo-\\nθ θ x y+ θ θ x y− OverallComputationalComplexity\\nratesthegradientfromtheembedding-basedsim-\\nCombining both components, the total computa-\\nilarity,adjustingthemodeltofavorembeddings\\ntionalcomplexityoftheHybridLossis:\\nthat better capture the desired relationships be-\\ntweene ande .\\nx y O(C +d)\\nThe combined gradient effectively integrates\\nwhere C is the number of classes and d is the\\nboththediscriminativeaspect(logprobabilityra-\\nembeddingdimension.\\ntio) and the semantic aspect (embedding-based\\nterm) of the loss function. The hyperparameter ComparisonwithStandardLossFunctions\\nγ allowsfortuningtherelativeimportanceofthese • Cross-EntropyLoss: Hasatimecomplexityof\\ntwo components, enabling the model to balance O(C),similartothelogprobabilityratiocompo-\\nbetweenaccuratelyclassifyingpositiveandnega- nentoftheHybridLoss.\\ntivesamplesandcapturingmeaningfulembedding\\nrelationships. • ContrastiveLoss: Typicallyoperateswithacom-\\nplexity of O(d), aligning with the embedding-\\nI.2 ComputationalComplexityAnalysisof basedterm.\\nHybridLoss\\nThus,theHybridLosscombinesthesecomplexi-\\nThecomputationalcomplexityoftheHybridLoss\\ntieslinearly,maintainingefficiencywhileenhanc-\\narisesfromtwoprimarycomponents:\\ningfunctionalitybyintegratingbothdiscriminative\\n1. LogProbabilityRatio andembedding-basedcomponents.\\nModelingπ (y | x)withasoftmaxfunction:\\nθ I.3 EfficiencyofHybridLoss\\nef θ(x,y) The Hybrid Loss achieves a balanced trade-off\\nπ (y | x) =\\nθ (cid:80) y′ef θ(x,y′) betweendiscriminativepowerandcomputational\\nefficiencyby:\\nComputingthelogprobabilityratioinvolves:\\n• Scalability: Scalinglinearlywithboththenumber\\n• CalculatingexponentialsforeachoftheC classes. ofclassesC andembeddingdimensionsd,allow-\\ningittohandlelarge-scaledatasetseffectively.\\n• Computingthelogarithmoftheratiobetweenthe\\n• Parallel Computation: Enabling parallel com-\\npositiveandnegativeclassprobabilities.\\nputationoflosscomponents,leveragingmodern\\nTimeComplexity: O(C),whereC isthenumber hardwareacceleratorssuchasGPUstoexpedite\\nofclasses. training.• Rich Semantic Information: Incorporating I.5 GradientofPolynomialKernelized\\nembedding-based similarities without introduc- HybridLoss\\ning significant computational overhead, thereby\\nThe Polynomial Kernelized Hybrid Loss is de-\\nenhancingthemodel’sabilitytocapturecomplex\\nfinedas:\\nrelationships.\\n(cid:34)\\n(cid:18) π(y+ | x) (cid:19)d\\nL = E log +c\\nx,y+,y− π(y− | x)\\nI.4 PracticalConsiderations\\n(cid:32) e⊤ e +c(cid:33)d(cid:35)\\ny+ x\\n+γ\\nWhile the theoretical complexity of the Hybrid e⊤ e +c\\ny− x\\nLoss is O(C + d), several practical factors con-\\ntributetoitsefficientimplementation: where:\\n• xrepresentstheinputdata.\\n• GPUParallelism: LeveragingGPUparallelism • y+ andy− denotethepositiveandnegativesam-\\nmitigatesthelinearscalingwithC andd,allowing ples,respectively.\\nsimultaneouscomputationsandreducingoverall\\ntrainingtime. • π(y | x)istheprobabilityofy givenx,modeled\\nusingasoftmaxfunction.\\n• e ande aretheembeddingsofy andx,respec-\\ny x\\n• Optimized Libraries: Utilizing optimized li-\\ntively.\\nbrariessuchasBLASandcuDNNenhancescom-\\nputational performance through highly efficient • cisaconstanttoensurenumericalstabilityandto\\nmatrixoperations. shiftthepolynomialkernel.\\n• disthedegreeofthepolynomialkernel.\\n• BatchSizing: Appropriatelyselectingbatchsizes\\n• γ isahyperparametercontrollingtheinfluenceof\\nmaximizes hardware utilization, ensuring that\\ntheembedding-basedterm.\\ncomputations are performed efficiently without\\nbottlenecks. Ourobjectiveistocomputethegradientofthe\\nHybrid Loss ∇ L with respect to the model pa-\\nθ\\nrametersθ. Thisinvolvesdifferentiatingeachterm\\n• Sparse Representations: In scenarios with a ofthelossfunctionseparatelyandthencombining\\nlargenumberofclasses,employingsparserepre- them.\\nsentationscanfurtherreducecomputationalover-\\nGradientoftheLogProbabilityRatioTerm\\nheadbyfocusingcomputationsonlyonrelevant\\nThefirstcomponentoftheHybridLossinvolves\\nclasses.\\nthelogprobabilityratiobetweenthepositiveand\\nnegativesamples:\\nByconsideringthesepracticalaspects,theHy- (cid:18) π(y+ | x) (cid:19)d\\nbridLossnotonlyremainstheoreticallyefficient log +c\\nπ(y− | x)\\nbut also performs effectively in real-world appli-\\ncations,ensuringrobustandscalabletrainingpro- Tocomputeitsgradientwithrespecttoθ,weapply\\ncesses. thechainrule:Simplifyingthegradientoftheratio:\\n∇\\nθ(cid:18)\\nlog\\nπ π( (y y+\\n−\\n|\\n|\\nx x)\\n)\\n+c(cid:19)d ∇θ(cid:32) ee\\n⊤\\ny⊤ y −+e ex x+ +c c(cid:33) =(e⊤ y−ex+c)∇θ(e⊤ y (+ ee\\n⊤\\nyx −) e− x+(e c⊤ y )+ 2ex+c)∇θ(e⊤ y−ex)\\n(cid:18) π(y+ | x) (cid:19)d−1 π(y+ | x) Assuminge ande aredifferentiablewithre-\\nx y\\n= d log +c ∇ log\\nπ(y− | x) θ π(y− | x) specttoθ,wehave:\\nExpanding the gradient of the log probability ∇ (e⊤e ) = (∇ e )⊤e +e⊤(∇ e )\\nθ x y θ x y x θ y\\nratio:\\nThus,thegradientofthepolynomialkernelterm\\nπ(y+ |x)\\n∇ θlog\\nπ(y− |x)\\n=∇ θlogπ(y+ |x)−∇ θlogπ(y− |x) becomes:\\nAssumingπ θ(y | x)ismodeledusingasoftmax\\n∇θγ(cid:32) ee\\n⊤\\ny⊤ y −+e ex x+ +c c(cid:33)d =γd(cid:32) ee\\n⊤\\ny⊤ y −+e ex x+ +c c(cid:33)d−1\\nfunction:\\n·(cid:34)(e⊤ y−ex+c)∇θ(e⊤ y+ex)−(e⊤ y+ex+c)∇θ(e⊤ y−ex)(cid:35)\\n(e⊤ y−ex+c)2\\nπ (y | x) =\\nef θ(x,y)\\n,\\n=γd(cid:32)e⊤ y+ex+c(cid:33)d−1\\nthegradientoθ\\nflogπ(y\\n|(cid:80)\\nx)y\\nw′e itf hθ( rx e,y s′ p)\\necttoθ is:\\n·(cid:34)∇\\ne⊤\\nyθ\\n−e (⊤ y\\ne\\ne−\\n⊤ y\\nx+e +x ex+ c)c\\n− (ee\\n⊤\\ny⊤ y −+ ee xx ++ cc )2∇θ(e⊤ y−ex)(cid:35) .\\nCombinedGradient\\n(cid:88)\\n∇ logπ(y|x)=∇ f (x,y)− π (y′|x)∇ f (x,y′)\\nθ θ θ θ θ θ Combining the gradients of both components,\\ny′\\nthe overall gradient of the Polynomial Ker-\\nSubstitutingback,weobtain:\\nnelized Hybrid Loss with respect to θ is:\\n∇ \\uf8eeθlog π π( (y y+\\n−\\n|\\n|\\nx x)\\n)\\n=\\n\\uf8f9\\n∇θL= =∇ d(cid:18)θ l(cid:18) ol gog\\nπ π(\\n(π π\\ny\\ny( (\\n+\\n−y y+ −\\n| |x\\nx| |\\n)\\n)x x +) )+ c(cid:19)c d(cid:19) −d 1+ (cid:2)∇∇ θθ lγ og(cid:32) πee (⊤ y⊤ y y−+ +e ex x |x+ + )c c −(cid:33) ∇d\\nθlogπ(y−|x)(cid:3)\\n\\uf8f0∇ θf θ(x,y+)−(cid:88)\\ny′\\nπ θ(y′ | x)∇ θf θ(x,y′)\\uf8fb +γd(cid:32) ee\\n⊤\\ny⊤ y −+e ex x+ +c c(cid:33)d−1(cid:34)∇\\ne⊤\\nyθ −(e e⊤ y x+ +ex c) − (ee\\n⊤\\ny⊤ y −+ ee xx ++ cc )2∇θ(e⊤ y−ex)(cid:35) .\\n\\uf8ee \\uf8f9 Simplified Gradient Expression For\\n−\\uf8f0∇ θf θ(x,y−)−(cid:88) π θ(y′ | x)∇ θf θ(x,y′)\\uf8fb ease of implementation and readabil-\\nity, the gradient can be expressed as:\\ny′\\nGradientofthePolynomialKernelTerm\\n∇θL=d(cid:18) logπ π( (y y+ −| |x x) )+c(cid:19)d−1 (cid:2)∇θfθ(x,y+)−∇θfθ(x,y−)(cid:3)\\nThe second component involves the polynomial +γd(cid:32) ee\\n⊤\\ny⊤ y −+e ex x+ +c c(cid:33)d−1(cid:34) ∇\\ne⊤\\nyθ −(e e⊤ x xe +y+ c) − (ee\\n⊤\\ny⊤ y −+ ee xx ++ cc )2∇θ(e⊤ xe y−)(cid:35) .\\nkernelappliedtotheembeddings:\\nInterpretationoftheGradient\\n(cid:32) e⊤ e +c(cid:33)d\\ny+ x • LogProbabilityRatioTerm:\\nγ\\ne⊤ e +c\\ny− x\\n– ∇ f (x,y+): Encouragesthemodeltoincrease\\nθ θ\\nTocomputeitsgradientwithrespecttoθ,weagain thescore(andhencetheprobability)oftheposi-\\napplythechainrule: tivesampley+.\\n– −∇ f (x,y−): Encourages the model to de-\\nθ θ\\n(cid:32) e⊤ e +c(cid:33)d (cid:32) e⊤ e +c(cid:33)d−1 (cid:32) e⊤ e +c(cid:33) crease the score (and hence the probability) of\\n∇ θγ\\ne⊤y+ ex\\n+c\\n=γd\\ne⊤y+ ex\\n+c\\n∇ θ\\ne⊤y+ ex\\n+c\\nthenegativesampley−.\\ny− x y− x y− x• PolynomialKernelTerm: TimeComplexity: O(C),whereC isthenum-\\nber of classes. This complexity arises from the\\n– ∇ (e⊤e ): Adjuststhemodeltobetteralignthe\\nθ x y+ softmax computation, which requires evaluating\\nembeddingsofxandy+.\\nf (x,y)andnormalizingoverallC classes.\\nθ\\n– −∇ (e⊤e ): Adjusts the model to reduce the\\nθ x y− 2. PolynomialKernelTerm\\nalignmentbetweentheembeddingsofxandy−.\\nThepolynomialkerneltermisdefinedas:\\n– The hyperparameter γ controls the influence of\\ntheembedding-basedtermrelativetothelogprob- (cid:32) e⊤ e +c(cid:33)d\\ny+ x\\nabilityratioterm. γ\\ne⊤ e +c\\ny− x\\nI.6 ComputationalComplexityAnalysisof\\nStepsInvolved:\\nPolynomialKernelizedHybridLoss\\n• Dot Product Computation: Calculate the dot\\nToevaluatetheefficiencyofthePolynomialKer-\\nproductse⊤e ande⊤e ,wheree ,e ,e ∈\\nnelizedHybridLoss,weanalyzethecomputational x y+ x y− x y+ y−\\nRd.\\ncomplexityofitstwoprimarycomponents: thelog\\nprobability ratio term and the polynomial kernel\\n• AdditionofConstant: Addtheconstantctoeach\\nterm.\\ndotproducttoensurenumericalstability.\\n1. LogProbabilityRatioTerm\\n• RatioCalculation: Computetheratioofthead-\\nThelogprobabilityratiotermisdefinedas: justeddotproducts.\\n(cid:18) π(y+ | x) (cid:19)d • Exponentiation: Raise the ratio to the power d\\nlog +c\\nπ(y− | x) andmultiplybythehyperparameterγ.\\nTime Complexity: O(d), where d is the di-\\nwhereπ (y | x)ismodeledusingasoftmaxfunc-\\nθ\\nmensionoftheembeddings. Thisarisesfromthe\\ntion:\\nef θ(x,y) computationofthedotproductbetweene x ande y,\\nπ θ(y | x) = (cid:80) y′ef θ(x,y′) whichscaleslinearlywithd.\\nOverallComputationalComplexity\\nStepsInvolved:\\nCombining both components, the total computa-\\n• ScoreComputation: Calculatef (x,y)foreach tionalcomplexityofthePolynomialKernelized\\nθ\\nclass y, which involves a dot product between HybridLossis:\\ninputfeaturesandmodelparameters.\\nO(C)+O(d) = O(C +d)\\n• SoftmaxCalculation: Computetheexponential\\nef θ(x,y) foreachclassandnormalizebythesum where:\\noverallclasses.\\n• C isthenumberofclasses.\\n• LogProbabilityRatio: Computethelogarithmof • distheembeddingdimension.\\ntheratiobetweentheprobabilitiesofthepositive\\nThis linear complexity ensures scalability\\nandnegativeclasses.\\nfor large-scale applications involving high-\\n• Exponentiation: Raise the log probability ratio dimensional embeddings and extensive class la-\\ntothepowerd. bels.ComparisonwithStandardLossFunctions • ParallelComputation: Boththelogprobability\\nratiotermandthepolynomialkerneltermcanbe\\n• Cross-EntropyLoss:\\ncomputedinparallel. Modernhardwareaccelera-\\n– TimeComplexity: O(C). tors,suchasGPUs,canleveragethisparallelism\\ntosignificantlyspeeduptrainingprocesses.\\n– Description: Involves computing the softmax\\noverC classesandcalculatingthenegativelog-\\n• IntegratedSemanticInformation: Bycombin-\\nlikelihood.\\ning probability-based and embedding-based ob-\\njectives, the loss function enriches the model’s\\n• ContrastiveLoss:\\nlearningwithoutincurringsubstantialadditional\\ncomputationaloverhead.\\n– TimeComplexity: O(d).\\n– Description: Focuses on the distance between • Hyperparameter Control: The hyperparame-\\nembeddings,typicallyrequiringcomputationof ter γ allows for fine-tuning the influence of the\\npairwisedistances. embedding-based term relative to the log proba-\\nbilityratioterm,providingflexibilityinbalancing\\n• PolynomialKernelizedHybridLoss: performanceandcomputationalcost.\\n– TimeComplexity: O(C +d).\\nI.8 PracticalConsiderations\\n– Description: Combinesboththediscriminative While the theoretical complexity of the Polyno-\\npower of the log probability ratio (similar to mialKernelizedHybridLossisO(C +d),sev-\\nCross-Entropy Loss) and the semantic richness eral practical factors can influence its real-world\\nofthepolynomialkernel(similartoContrastive performance:\\nLoss),therebyintegratingbothaspectsintoasin-\\nglelossfunction. • GPUParallelism: LeveragingGPUparallelism\\ncan mitigate the linear scaling with C and d, al-\\nThePolynomialKernelizedHybridLossthus lowingforefficientcomputationevenwithlarge\\noffers a balanced combination of the compu- numbersofclassesandhigh-dimensionalembed-\\ntational efficiencies of Cross-Entropy and Con- dings.\\ntrastiveLosseswhileenhancingthemodel’sability\\nto capture both discriminative and semantic rela- • Optimized Implementations: Utilizing opti-\\ntionships. mizedlibraries(e.g.,BLAS,cuDNN)formatrix\\noperationsandgradientcomputationscanenhance\\nI.7 EfficiencyofPolynomialKernelized performance, reducing the actual computation\\nHybridLoss time.\\nThe Polynomial Kernelized Hybrid Loss\\n• Batch Sizing: Selecting appropriate batch sizes\\nachieves a balanced trade-off between discrimi-\\ncan maximize hardware utilization. Larger\\nnativepowerandcomputationalefficiencythrough\\nbatchesmayimprovecomputationalefficiencybut\\nthefollowingmechanisms:\\nrequiremorememory,whilesmallerbatchesmay\\nbe more memory-efficient but less computation-\\n• Linear Scaling: The loss scales linearly with\\nallyoptimal.\\nboththenumberofclassesC andtheembedding\\ndimensiond,ensuringscalabilityforlarge-scale • HyperparameterTuning: Carefultuningofthe\\ndatasetsandhigh-dimensionalembeddingspaces. hyperparameterγ andthepolynomialdegreedisessential. Higherdegreesdcancapturemorecom- GradientoftheLogProbabilityRatioTerm\\nplexrelationshipsbutmayincreasecomputational\\nThefirstcomponentoftheHybridLossinvolves\\ncostandriskoverfitting.\\ntheexponentialofthesquaredlogprobabilityra-\\ntio:\\n• Numerical Stability: Adding the constant c en- \\uf8eb (cid:16) π(y+|x)(cid:17)2\\uf8f6\\nlog\\nsuresnumericalstability,especiallywhendealing π(y−|x)\\nexp\\uf8ec− \\uf8f7.\\nwithsmallorzerodotproducts. Properlychoos- \\uf8ed 2σ2 \\uf8f8\\ningciscrucialtopreventnumericalissuesduring\\ntraining.\\nTocomputeitsgradientwithrespecttoθ,weapply\\nthechainrule:\\nByconsideringthesepracticalaspects,thePoly-\\nnomial Kernelized Hybrid Loss can be effec-\\ntivelyintegratedintolarge-scalemachinelearning \\uf8eb (cid:16) logπ(y+|x)(cid:17)2\\uf8f6 \\uf8eb (cid:16) logπ(y+|x)(cid:17)2\\uf8f6\\nmodels,providingenhancedperformancewithout ∇θexp\\uf8ec \\uf8ed− π 2( σy 2−|x) \\uf8f7 \\uf8f8=exp\\uf8ec \\uf8ed− π 2( σy 2−|x) \\uf8f7 \\uf8f8\\ncompromisingcomputationalefficiency.\\n·\\uf8eb \\uf8ed−2log 2ππ σ(( 2yy −+| |x x) )\\uf8f6 \\uf8f8·∇θlogπ π( (y y+ −| |x x)\\n).\\nI.9 GradientofRBFKernelizedHybridLoss\\nTheRBFKernelizedHybridLossisdefinedas:\\nSimplifying,weobtain:\\nL=E x,y+,y−(cid:34) exp\\uf8eb \\uf8ec \\uf8ed−(cid:16) log ππ 2(( σyy 2−+| |x x) )(cid:17)2\\uf8f6 \\uf8f7\\n\\uf8f8+γexp\\uf8eb\\n\\uf8ec \\uf8ec \\uf8ec\\n\\uf8ed−(cid:18)\\nee ⊤x⊤ x 2ee σyy −+\\n2(cid:19)2\\uf8f6\\n\\uf8f7 \\uf8f7 \\uf8f7 \\uf8f8(cid:35) , ∇θexp\\uf8eb\\n\\uf8ec\\n\\uf8ed−(cid:16) log ππ 2(( σyy 2−+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7 \\uf8f8=−\\nσ1 2logπ π( (y y+ −| |x x) )·exp\\uf8eb\\n\\uf8ec\\n\\uf8ed−(cid:16) log ππ 2(( σyy 2−+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7\\n\\uf8f8\\nπ(y+|x)\\nwhere: ·∇θlog π(y−|x).\\n• xrepresentstheinputdata. GradientoftheRBFKernelTerm\\nThesecondcomponentinvolvestheexponentialof\\n• y+ andy− denotethepositiveandnegativesam-\\nthesquaredratioofembeddingdotproducts:\\nples,respectively.\\n\\uf8eb (cid:18) (cid:19)2\\uf8f6\\n• π(y | x)istheprobabilityofy givenx,modeled e⊤ xe y+\\nusingasoftmaxfunction.\\nγexp\\uf8ec\\n\\uf8ec−\\ne⊤ xe y− \\uf8f7\\n\\uf8f7.\\n\\uf8ec 2σ2 \\uf8f7\\n\\uf8ed \\uf8f8\\n• e ande aretheembeddingsofy andx,respec-\\ny x\\ntively.\\nTocomputeitsgradientwithrespecttoθ,weagain\\n• σ isthebandwidthparameteroftheRBFkernel. applythechainrule:\\n• γ isahyperparametercontrollingtheinfluenceof\\nth Oee um rob be jd ed ci tn ivg e-b ia ss te od ct oe mrm p.\\nutethegradientofthe\\n∇θγexp\\uf8eb\\n\\uf8ec\\n\\uf8ec\\n\\uf8ec\\n\\uf8ed−(cid:18) ee ⊤x⊤ x 2ee σyy −+ 2(cid:19)2\\uf8f6\\n\\uf8f7\\n\\uf8f7\\n\\uf8f7\\n\\uf8f8=γexp\\uf8eb\\n\\uf8ec\\n\\uf8ec\\n\\uf8ec\\n\\uf8ed−(cid:18) ee ⊤x⊤ x 2ee σyy −+ 2(cid:19)2\\uf8f6\\n\\uf8f7\\n\\uf8f7\\n\\uf8f7\\n\\uf8f8·\\uf8eb\\n\\uf8ec\\n\\uf8ed−2· 2ee σ⊤x⊤ x 2ee yy −+\\uf8f6\\n\\uf8f7\\n\\uf8f8\\nH ray mb er ti ed rsL θo .s Ts h∇ isθ iL nvw oli vth esr de is fp fee rc et nt to iatt ih ne gm eao cd he tl ep rma- ·∇θ(cid:32) ee\\n⊤\\nx⊤\\nx\\nee\\nyy\\n−+(cid:33)\\nofthelossfunctionseparatelyandthencombining\\nthem. Simplifying,weobtain:∇θL=E\\nx,y+,y−(cid:34)\\n−\\nσ1 2logπ π( (y y+ −| |x x) )·exp\\uf8eb\\n\\uf8ec\\n\\uf8ed−(cid:16) log ππ 2(( σyy 2−+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n∇\\nθγexp\\uf8eb\\n\\uf8ec \\uf8ec\\n\\uf8ec\\n\\uf8ed−(cid:18)\\nee ⊤ x⊤ x 2ee σyy −+\\n2(cid:19)2\\uf8f6\\n\\uf8f7 \\uf8f7\\n\\uf8f7\\n\\uf8f8=− σγ 2· ee\\n⊤\\nx⊤ x ee yy −+\\n·exp\\uf8eb\\n\\uf8ec \\uf8ec\\n\\uf8ec\\n\\uf8ed−(cid:18)\\nee ⊤ x⊤ x 2ee σyy −+\\n2(cid:19)2\\uf8f6\\n\\uf8f7 \\uf8f7\\n\\uf8f7\\n\\uf8f8\\n· −(cid:0)∇ γθf ·θ e(x\\n⊤\\nx, ey y+ +) ·− ex∇ pθ \\uf8eb\\n\\uf8ec\\n\\uf8ecfθ −(x (cid:18), eey ⊤x⊤x− ee) yy(cid:1) −+(cid:19)2\\uf8f6\\n\\uf8f7\\n\\uf8f7\\n(cid:32) (cid:33) σ2 e⊤ xey− \\uf8ec \\uf8ed 2σ2 \\uf8f7 \\uf8f8\\n·∇ θ ee ⊤ x⊤ x ee yy −+ ·(cid:34) (e⊤ xey−)(∇θex)⊤ey++(e⊤ xey−)e⊤ x(∇θey+)\\n(e⊤ xey−)2\\nTocompute∇\\nθ(cid:18) ee\\n⊤\\nx⊤\\nx\\nee\\nyy\\n−+(cid:19)\\n,weusethequotient\\n−(e⊤ xey++c)(∇θex)⊤ (e ey\\n⊤\\nx− e+ y−( )e 2⊤ xey++c)e⊤ x(∇θey−)(cid:35)(cid:35)\\nrule: InterpretationoftheGradient\\n• LogProbabilityRatioTerm:\\n(cid:32) (cid:33)\\ne⊤e (e⊤e )∇ (e⊤e )−(e⊤e )∇ (e⊤e )\\n∇ x y+ = x y− θ x y+ x y+ θ x y−\\nθ e⊤ xe y− (e⊤ xe y−)2 – − 1 log π(y+|x) : Scalestheinfluenceofthelog\\nσ2 π(y−|x)\\nprobabilityratiobasedonitsmagnitudeandthe\\nAssuminge ande aredifferentiablewithre-\\nx y\\nbandwidthparameterσ.\\nspecttoθ,wehave:\\n– ∇ logπ(y+ | x): Encourages the model to in-\\nθ\\ncreasetheprobabilityofthepositivesampley+.\\n∇ (e⊤e ) = (∇ e )⊤e +e⊤(∇ e )\\nθ x y θ x y x θ y – −∇ logπ(y− | x): Encourages the model to\\nθ\\ndecrease the probability of the negative sample\\nThus, the gradient of the RBF kernel term be-\\ny−.\\ncomes:\\n\\uf8eb (cid:18) e⊤ xey+(cid:19)2\\uf8f6 \\uf8eb (cid:18) e⊤ xey+(cid:19)2\\uf8f6\\n∇θγexp\\uf8ec \\uf8ec\\n\\uf8ec\\n\\uf8ed− e⊤x 2e σy−\\n2\\n\\uf8f7 \\uf8f7\\n\\uf8f7\\n\\uf8f8=− σγ 2· ee\\n⊤\\nx⊤ x ee yy −+·exp\\uf8ec \\uf8ec\\n\\uf8ec\\n\\uf8ed− e⊤x 2e σy−\\n2\\n\\uf8f7 \\uf8f7\\n\\uf8f7\\n\\uf8f8\\n• RBFKernelTerm:\\n·(cid:34) (e⊤ xey−)∇θ(e⊤ xey (+\\ne⊤\\nx) e− y−(e )⊤ x 2ey+)∇θ(e⊤ xey−)(cid:35) .– − emσγ b2 ed· diee n⊤ x⊤ x gee -yy b−+ a: sedS tc ea rmles bat sh ee doin nfl thu een rc ae tioo of feth me\\n-\\nCombinedGradient beddingsandthebandwidthparameterσ.\\nCombining the gradients of both compo- – ∇ (e⊤e ): Adjuststhemodeltobetteralignthe\\nθ x y+\\nnents, the overall gradient of the RBF Ker- embeddingsofxandy+.\\nnelized Hybrid Loss with respect to θ is:\\n∇ θL=E\\nx,y+,y−(cid:34)\\n−\\nσ1 2logπ π( (y y+ −| |x x) )·exp\\uf8eb\\n\\uf8ec\\n\\uf8ed−(cid:16) log ππ 2(( σyy 2−+| |x x) )(cid:17)2\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n– − ali∇ gnθ m(e e⊤ x ne ty b− e) t: wA eed nju thst es et mhe bem do dd ine gl sto ofre xd au nc de yth −e\\n.\\n(cid:16) (·)2(cid:17)\\n·(cid:0) ∇ θlogπ(y+|x)−∇ θlogπ(y−|x)(cid:1) – The exponential terms exp − 2σ2 ensure that\\n\\uf8eb (cid:18)\\ne⊤ xe\\ny+(cid:19)2\\uf8f6 the influence diminishes as the squared ratios\\n− γ ·e⊤ xe y+ ·exp\\uf8ec \\uf8ec− e⊤ xe y− \\uf8f7 \\uf8f7 increase,promotingsmoothergradients.\\nσ2 e⊤ xe y− \\uf8ec \\uf8ed 2σ2 \\uf8f7 \\uf8f8\\n• Hyperparameterγ: Controlstherelativeimpor-\\n(cid:34) (cid:35)(cid:35)\\n·\\n(e⊤ xe y−)∇ θ(e⊤ xe y+)−(e⊤ xe y+)∇ θ(e⊤ xe y−)\\ntanceoftheembedding-basedtermcomparedto\\n(e⊤ xe y−)2\\nthe log probability ratio term. A higher γ em-\\nSimplifiedGradientExpression Foreaseofim- phasizes the alignment in the embedding space,\\nplementationandreadability,thegradientcanbe whilealowerγ prioritizestheprobability-based\\nexpressedas: alignment.I.10 ComputationalComplexityAnalysisof StepsInvolved:\\nRBFKernelizedHybridLoss\\n• Dot Product Computation: Calculate the dot\\nToevaluatetheefficiencyoftheRBFKernelized productse⊤e ande⊤e ,wheree ,e ,e ∈\\nx y+ x y− x y+ y−\\nHybridLoss,weanalyzethecomputationalcom- Rd.\\nplexity of its two primary components: the log\\nprobabilityratiotermandtheRBFkernelterm. • RatioCalculation: Computetheratio e⊤ xe y+.\\ne⊤ xe y−\\n1. LogProbabilityRatioTerm\\n• Exponentiation: Squaretheratio,scaleby− 1 ,\\nThelogprobabilityratiotermisdefinedas: 2σ2\\nandcomputetheexponential.\\n\\uf8eb (cid:16) π(y+|x)(cid:17)2\\uf8f6\\nlog π(y−|x) • Scaling: Multiplybythehyperparameterγ.\\nexp\\uf8ec− \\uf8f7.\\n\\uf8ed 2σ2 \\uf8f8\\nTime Complexity: O(d), where d is the di-\\nmensionoftheembeddings. Thisarisesfromthe\\nwhereπ θ(y | x)ismodeledusingasoftmaxfunc-\\ncomputation of the dot products between e and\\nx\\ntion: e ,whichscaleslinearlywithd.\\nef θ(x,y) y\\nπ (y | x) = .\\nθ (cid:80) y′ef θ(x,y′) OverallComputationalComplexity\\nCombining both components, the total computa-\\nStepsInvolved:\\ntionalcomplexityoftheRBFKernelizedHybrid\\n• ScoreComputation: Calculatef θ(x,y)foreach Lossis:\\nclass y, which involves a dot product between\\ninputfeaturesandmodelparameters. O(C)+O(d) = O(C +d),\\n• SoftmaxCalculation: Computetheexponential where:\\nef θ(x,y) foreachclassandnormalizebythesum\\n• C isthenumberofclasses(softmaxcomputation).\\noverallclasses.\\n• LogProbabilityRatio: Computethelogarithmof • d is the embedding dimension (kernel computa-\\ntheratiobetweentheprobabilitiesofthepositive tion).\\nandnegativeclasses.\\nThis linear complexity ensures scalability\\n• Exponentiation: Squarethelogprobabilityratio, for large-scale applications involving high-\\nscaleby− 1 ,andcomputetheexponential. dimensional embeddings and extensive class la-\\n2σ2\\nbels.\\nTimeComplexity: O(C),whereC isthenum-\\nber of classes. This complexity arises from the ComparisonwithStandardLossFunctions\\nsoftmax computation, which requires evaluating • Cross-EntropyLoss:\\nf (x,y)andnormalizingoverallC classes.\\nθ\\n– TimeComplexity: O(C).\\n2. RBFKernelTerm\\n– Description: Involves computing the softmax\\nTheRBFkerneltermisdefinedas:\\noverC classesandcalculatingthenegativelog-\\n\\uf8eb (cid:18) e⊤ xe y+(cid:19)2\\uf8f6 likelihood.\\nγexp\\uf8ec\\n\\uf8ec−\\ne⊤ xe y− \\uf8f7\\n\\uf8f7 • ContrastiveLoss:\\n\\uf8ec 2σ2 \\uf8f7\\n\\uf8ed \\uf8f8\\n– TimeComplexity: O(d).– Description: Focuses on the distance between embedding-based term relative to the log proba-\\nembeddings,typicallyrequiringcomputationof bilityratioterm,providingflexibilityinbalancing\\npairwisedistances. performanceandcomputationalcost.\\n• RBFKernelizedHybridLoss: I.12 PracticalConsiderations\\n– TimeComplexity: O(C +d).\\nWhilethetheoreticalcomplexityoftheRBFKer-\\nnelizedHybridLossisO(C+d),severalpractical\\n– Description: Combinesboththediscriminative\\nfactorscaninfluenceitsreal-worldperformance:\\npower of the log probability ratio (similar to\\nCross-Entropy Loss) and the semantic richness\\n• GPUParallelism: LeveragingGPUparallelism\\noftheRBFkernel(similartoContrastiveLoss),\\ncan mitigate the linear scaling with C and d, al-\\ntherebyintegratingbothaspectsintoasingleloss\\nlowingforefficientcomputationevenwithlarge\\nfunction.\\nnumbersofclassesandhigh-dimensionalembed-\\ndings.\\nTheRBFKernelizedHybridLossthusoffers\\nabalancedcombinationofthecomputationaleffi- • Optimized Implementations: Utilizing opti-\\ncienciesofCross-EntropyandContrastiveLosses mizedlibraries(e.g.,BLAS,cuDNN)formatrix\\nwhileenhancingthemodel’sabilitytocaptureboth operationsandgradientcomputationscanenhance\\ndiscriminativeandsemanticrelationships. performance, reducing the actual computation\\ntime.\\nI.11 EfficiencyofRBFKernelizedHybrid\\nLoss • Batch Sizing: Selecting appropriate batch sizes\\ncan maximize hardware utilization. Larger\\nThe RBF Kernelized Hybrid Loss achieves a\\nbatchesmayimprovecomputationalefficiencybut\\nbalancedtrade-offbetweendiscriminativepower\\nrequiremorememory,whilesmallerbatchesmay\\nandcomputationalefficiencythroughthefollowing\\nbe more memory-efficient but less computation-\\nmechanisms:\\nallyoptimal.\\n• Linear Scaling: The loss scales linearly with\\n• HyperparameterTuning: Carefultuningofthe\\nboththenumberofclassesC andtheembedding\\nhyperparameterγ andthebandwidthparameterσ\\ndimensiond,ensuringscalabilityforlarge-scale\\nisessential. Higherdegreesofinfluence(through\\ndatasetsandhigh-dimensionalembeddingspaces.\\nγ and lower σ) can capture more complex rela-\\n• ParallelComputation: Boththelogprobability tionshipsbutmayincreasecomputationalcostand\\nratio term and the RBF kernel term can be com- riskoverfitting.\\nputedinparallel. Modernhardwareaccelerators,\\n• NumericalStability: Theconstantcensuresnu-\\nsuch as GPUs, can leverage this parallelism to\\nmerical stability, especially when dealing with\\nsignificantlyspeeduptrainingprocesses.\\nsmallorzerodotproductratios. Properlychoos-\\n• IntegratedSemanticInformation: Bycombin- ingciscrucialtopreventnumericalissuesduring\\ning probability-based and embedding-based ob- training.\\njectives, the loss function enriches the model’s\\nByconsideringthesepracticalaspects,theRBF\\nlearningwithoutincurringsubstantialadditional\\nKernelizedHybridLosscanbeeffectivelyinte-\\ncomputationaloverhead.\\ngrated into large-scale machine learning models,\\n• Hyperparameter Control: The hyperparame- providingenhancedperformancewithoutcompro-\\nter γ allows for fine-tuning the influence of the misingcomputationalefficiency.I.13 GradientofSpectralKernelizedHybrid Tocomputeitsgradientwithrespecttoθ,weapply\\nLoss thechainruletoeachterminthesum:\\nThe Spectral Kernelized Hybrid Loss is defined\\nas: p p\\n∇\\n(cid:88) exp(cid:0) −λz2(cid:1) ϕ(z)=(cid:88)(cid:2)\\n∇\\nexp(cid:0) −λz2(cid:1)\\n·ϕ(z)\\nθ i i θ i i\\nL=E\\nx,y+,y−(cid:34) (cid:88)p exp(cid:32) −λi(cid:18)\\nlog\\nππ( (y y+ −| |x x) )(cid:19)2(cid:33) ϕi(cid:18) logπ π( (y y+ −| |x x) )(cid:19) i=1 +i= e1\\nxp(cid:0) −λ iz2(cid:1) ·∇ θϕ i(z)(cid:3) ,\\ni=1\\n+γ(cid:88) i=p 1exp\\uf8eb \\uf8ed−λi(cid:32) ee\\n⊤\\nx⊤ x ee yy −+(cid:33)2\\uf8f6 \\uf8f8ϕi(cid:32) ee\\n⊤\\nx⊤ x ee yy −+(cid:33)(cid:35) , wherez = log ππ (( yy −+| |x x)\\n)\\n1. GradientoftheExponentialTerm\\nwhere:\\n∇\\nexp(cid:0)\\n−λ\\nz2(cid:1) =exp(cid:0)\\n−λ\\nz2(cid:1)\\n·(−2λ z)·∇ z.\\nθ i i i θ\\n• xrepresentstheinputdata.\\n2. Gradient of the Feature Transformation\\n• y+ andy− denotethepositiveandnegativesam- Term Assumingϕ i(z)isdifferentiablewithre-\\nples,respectively. specttoz:\\n• π(y | x)istheprobabilityofy givenx,modeled ∇ θϕ i(z) = ϕ′ i(z)·∇ θz\\nusingasoftmaxfunction.\\n3. Gradientofz\\n• e ande aretheembeddingsofy andx,respec- π(y+ | x)\\ny x\\nz = log ,\\ntively. π(y− | x)\\n• λ iarethespectralkernelparametersforeachcom- ∇ z = ∇ logπ(y+ | x)−∇ logπ(y− | x)\\nθ θ θ\\nponenti.\\nCombinedGradientforEachi\\n• ϕ (·)arefeaturetransformationfunctionsassoci-\\ni\\n∇\\n(cid:2) exp(cid:0) −λz2(cid:1) ϕ(z)(cid:3) =exp(cid:0) −λz2(cid:1)\\n·(−2λz)·∇ z·ϕ(z)\\natedwitheachspectralkernelcomponenti. θ i i i i θ i\\n+exp(cid:0) −λz2(cid:1) ·ϕ′(z)·∇ z.\\ni i θ\\n• γ isahyperparametercontrollingtheinfluenceof GradientoftheSpectralKernelTerm\\ntheembedding-basedterm.\\nThesecondcomponentinvolvesasumoverspec-\\ntralkernelcomponentsappliedtotheembedding-\\n• pisthenumberofspectralkernelcomponents.\\nbasedratio:\\nOurobjectiveistocomputethegradientofthe p\\nSpectralKernelizedHybridLoss∇ θLwithrespect\\nγ(cid:88) exp(cid:0)\\n−λ\\nir2(cid:1)\\nϕ i(r),\\ntothemodelparametersθ. Thisinvolvesdifferenti- i=1\\natingeachtermofthelossfunctionseparatelyand wherer = e⊤ xe y+.\\nthencombiningthem. e⊤ xe y−\\nTo compute its gradient with respect to θ, we\\nGradientoftheLogProbabilityRatioTerm\\napplythechainruletoeachterminthesum:\\nThe first component of the Spectral Kernelized\\np p\\nHybrid Loss involves a sum over spectral kernel ∇ γ(cid:88) exp(cid:0) −λr2(cid:1) ϕ(r)=γ(cid:88)(cid:2) ∇ exp(cid:0) −λr2(cid:1) ·ϕ(r)\\nθ i i θ i i\\ncomponentsappliedtothelogprobabilityratio: i=1 i=1\\n+exp(cid:0) −λr2(cid:1)\\n·∇\\nϕ(r)(cid:3)\\n,\\ni θ i\\n(cid:88) i=p 1exp(cid:32) −λ i(cid:18) logπ π( (y y+ − | |x x) )(cid:19)2(cid:33) ϕ i(cid:18) logπ π(( yy −+ || xx ))(cid:19) wherer = ee\\n⊤\\nx⊤ x ee yy −+.1. GradientoftheExponentialTerm InterpretationoftheGradient\\n∇\\nexp(cid:0)\\n−λ\\nr2(cid:1)\\n=\\nexp(cid:0)\\n−λ\\nr2(cid:1)\\n·(−2λ r)·∇ r.\\nθ i i i θ • LogProbabilityRatioTerm:\\n2. Gradient of the Feature Transformation\\n– −2λizϕ (z): Scalestheinfluenceofthelogprob-\\nTerm Assumingϕ (r)isdifferentiablewithre- σ2 i\\ni\\nabilityratiobasedonitsmagnitude,thespectral\\nspecttor:\\nkernelparameterλ ,andthebandwidthparameter\\ni\\n∇ ϕ (r) = ϕ′(r)·∇ r σ.\\nθ i i θ\\n– ϕ′(z): Incorporatesthederivativeofthefeature\\n3. Gradientofr i\\ntransformation function, allowing for more nu-\\ne⊤ xe y+ ancedadjustmentsbasedonthetransformedlog\\nr = ,\\ne⊤e probabilityratio.\\nx y−\\n– ∇ z = ∇ logπ(y+ | x) − ∇ logπ(y− | x):\\n(e⊤e )∇ (e⊤e )−(e⊤e )∇ (e⊤e ) θ θ θ\\n∇ r = x y− θ x y+ x y+ θ x y− . Encourages the model to increase the probabil-\\nθ (e⊤e )2\\nx y− ity of the positive sample y+ and decrease the\\nAssuminge\\nx\\nande\\ny\\naredifferentiablewithre- probabilityofthenegativesampley−.\\nspecttoθ:\\n• SpectralKernelTerm:\\n∇ (e⊤e ) = (∇ e )⊤e +e⊤(∇ e )\\nθ x y θ x y x θ y\\nCombinedGradientforEachi\\n– −2 σλ 2irϕ i(r): Scales the influence of the\\nembedding-based ratio based on its magnitude,\\n∇\\n(cid:2) exp(cid:0) −λr2(cid:1) ϕ(r)(cid:3) =exp(cid:0) −λr2(cid:1)\\n·(−2λr)·∇ r·ϕ(r)\\nθ i i i i θ i the spectral kernel parameter λ , and the band-\\n+exp(cid:0) −λr2(cid:1) ·ϕ′(r)·∇ r. i\\ni i θ widthparameterσ.\\nCombinedGradient – ϕ′(r): Incorporatesthederivativeofthefeature\\ni\\nCombiningthegradientsofbothcomponents,the transformation function, allowing for more nu-\\noverallgradientoftheSpectralKernelizedHybrid ancedadjustmentsbasedonthetransformedem-\\nLosswithrespecttoθ is: beddingratio.\\n∇θL=E x,y+,y−(cid:34) (cid:88) i=p 1(cid:18) −2 σλ 2iz exp(cid:0)−λiz2(cid:1)ϕi(z)+exp(cid:0)−λiz2(cid:1)ϕ′ i(z)(cid:19) ∇θz – ∇ θr = (e⊤ xe y−)∇ θ(e⊤ xe (y e+\\n⊤\\nx) e− y( −e )⊤ x 2e y+)∇ θ(e⊤ xe y−) :\\n+γ(cid:88)p (cid:18) −2 σλ 2ir exp(cid:0)−λir2(cid:1)ϕi(r)+exp(cid:0)−λir2(cid:1)ϕ′ i(r)(cid:19) ∇θr(cid:35) A ofd xju wsts ithth ye +m wod he il leto dib se ct ote ur raa gli ig nn gt ah le ige nm mb ee nd td win ig ths\\ni=1\\ny−.\\nwhere:\\nπ(y+ | x) e⊤ xe y+ • Hyperparameters:\\nz = log , r = .\\nπ(y− | x) e⊤e\\nx y−\\n– λ : Controlstheinfluenceofeachspectralkernel\\ni\\nSimplifiedGradientExpression Foreaseofim-\\ncomponent.\\nplementationandreadability,thegradientcanbe\\n– γ: Balancestheinfluencebetweenthelogproba-\\nexpressedas:\\nbilityratiotermandtheembedding-basedterm.\\n∇θL=E x,y+,y−(cid:34) (cid:88)p exp(cid:0)−λiz2(cid:1)(cid:18) −2 σλ 2iz ϕi(z)+ϕ′ i(z)(cid:19) (cid:0)∇θfθ(x,y+)−∇θfθ(x,y−)(cid:1)\\n– σ: Determines the bandwidth of the RBF ker-\\ni=1\\n+γ(cid:88)p exp(cid:0)−λir2(cid:1)(cid:18) −2 σλ 2ir ϕi(r)+ϕ′ i(r)(cid:19) nel,affectinghowsharplytheexponentialterms\\ni=1\\n×(cid:32)(e⊤ xey−)(∇θex)⊤ey++(e⊤ xey−)e⊤ x(∇θey+)−(e⊤ xey+)(∇θex)⊤ey−−(e⊤ xey+)e⊤ x(∇θey−)(cid:33)(cid:35) decay.\\n(e⊤xey−)2I.14 ComputationalComplexityAnalysisof • Dot Product Computation: Calculate the dot\\nSpectralKernelizedHybridLoss productse⊤e ande⊤e ,wheree ,e ,e ∈\\nx y+ x y− x y+ y−\\nRd.\\nToevaluatetheefficiencyoftheSpectralKernel-\\nized Hybrid Loss, we analyze the computational • RatioCalculation: Computetheratio e⊤ xe y+.\\ncomplexityofitstwoprimarycomponents: thelog e⊤ xe y−\\nprobabilityratiotermandthespectralkernelterm.\\n• Exponentiation and Feature Transformation:\\n1. LogProbabilityRatioTerm Foreachspectralkernelcomponenti,computethe\\nexponentialandapplythefeaturetransformation\\nThelogprobabilityratiotermisdefinedas:\\nfunctionϕ (r).\\np i\\n(cid:88) exp(cid:0)\\n−λ\\nz2(cid:1)\\nϕ (z),\\ni i Time Complexity: O(p · d), where p is the\\ni=1 numberofspectralkernelcomponentsanddisthe\\nwherez = log π(y+|x) . dimension of the embeddings. This arises from\\nπ(y−|x)\\niteratingovereachspectralkernelcomponentand\\nStepsInvolved:\\nperformingcomputationsthatscalewithd.\\n• ScoreComputation: Calculatef (x,y)foreach\\nθ\\nclass y, which involves a dot product between OverallComputationalComplexity\\ninputfeaturesandmodelparameters. Combining both components, the total computa-\\ntionalcomplexityoftheSpectralKernelizedHy-\\n• SoftmaxCalculation: Computetheexponential\\nbridLossis:\\nef θ(x,y) foreachclassandnormalizebythesum\\noverallC classes.\\nO(p·C +p·d) = O(p(C +d)),\\n• LogProbabilityRatio: Computethelogarithmof\\nwhere:\\ntheratiobetweentheprobabilitiesofthepositive\\nandnegativeclasses.\\n• pisthenumberofspectralkernelcomponents.\\n• Exponentiation and Feature Transformation:\\n• C isthenumberofclasses.\\nForeachspectralkernelcomponenti,computethe\\nexponentialandapplythefeaturetransformation • distheembeddingdimension.\\nfunctionϕ (z).\\ni\\nThis linear complexity in p, C, and d en-\\nTime Complexity: O(p · C), where p is the\\nsures scalability for large-scale applications in-\\nnumberofspectralkernelcomponentsandC isthe\\nvolvingmultiplespectralkernelcomponents,high-\\nnumber of classes. This complexity arises from\\ndimensional embeddings, and extensive class la-\\niteratingovereachspectralkernelcomponentand\\nbels.\\nperformingcomputationsthatscalewithC.\\nComparisonwithStandardLossFunctions\\n2. SpectralKernelTerm\\n• Cross-EntropyLoss:\\nThespectralkerneltermisdefinedas:\\np – TimeComplexity: O(C).\\nγ(cid:88) exp(cid:0)\\n−λ\\nr2(cid:1)\\nϕ (r),\\ni i – Description: Involves computing the softmax\\ni=1 overC classesandcalculatingthenegativelog-\\nwherer = e⊤ xe y+. likelihood.\\ne⊤ xe y−\\nStepsInvolved: • ContrastiveLoss:– TimeComplexity: O(d). • IntegratedFeatureTransformations: Theuse\\nof feature transformation functions ϕ (·) allows\\n– Description: Focuses on the distance between i\\nforsophisticatedtransformationsofthelogproba-\\nembeddings,typicallyrequiringcomputationof\\nbilityratiosandembeddingratios,enrichingthe\\npairwisedistances.\\nmodel’slearningcapacitywithoutincurringsub-\\n• SpectralKernelizedHybridLoss: stantialadditionalcomputationaloverhead.\\n– TimeComplexity: O(p(C +d)). • HyperparameterFlexibility: Thehyperparame-\\n– Description: Extends both Cross-Entropy and tersλ i,γ,andσ provideflexibilityincontrolling\\nContrastive Losses by incorporating multiple the influence of each spectral kernel component\\nspectral kernel components, enhancing the andtheoverallbalancebetweenprobability-based\\nmodel’sabilitytocapturecomplexrelationships andembedding-basedterms. Thisallowsforfine-\\nwhilemaintainingcomputationalefficiency. tuning to achieve optimal performance without\\nsignificantcomputationalpenalties.\\nTheSpectralKernelizedHybridLossthusof-\\nfersacomprehensiveapproachbyintegratingmul- I.16 PracticalConsiderations\\ntiplespectralkernelsintothelossfunction,provid-\\nWhilethetheoreticalcomplexityoftheSpectral\\ning enhanced modeling capabilities at a manage-\\nKernelizedHybridLossisO(p(C +d)),several\\nablecomputationalcost.\\npractical factors can influence its real-world per-\\nI.15 EfficiencyofSpectralKernelizedHybrid formance:\\nLoss\\n• GPUParallelism: LeveragingGPUparallelism\\nTheSpectralKernelizedHybridLossachievesa\\ncan mitigate the linear scaling with p, C, and d,\\nbalancedtrade-offbetweendiscriminativepower\\nallowingforefficientcomputationevenwithlarge\\nandcomputationalefficiencythroughthefollowing\\nnumbersofspectral kernelcomponents, classes,\\nmechanisms:\\nandhigh-dimensionalembeddings.\\n• Scalability with Spectral Components: By al-\\n• Optimized Implementations: Utilizing opti-\\nlowing multiple spectral kernel components (p),\\nmizedlibraries(e.g.,BLAS,cuDNN)formatrix\\nthelossfunctioncancaptureavarietyofcomplex\\noperationsandgradientcomputationscanenhance\\npatterns and relationships in the data without a\\nperformance, reducing the actual computation\\ndisproportionateincreaseincomputationalcost.\\ntime.\\n• LinearScaling: Thelossscaleslinearlywiththe\\nnumberofspectralkernelcomponentsp,thenum- • Batch Sizing: Selecting appropriate batch sizes\\nber of classes C, and the embedding dimension can maximize hardware utilization. Larger\\nd,ensuringthatitremainsefficientevenasthese batchesmayimprovecomputationalefficiencybut\\nparametersgrow. requiremorememory,whilesmallerbatchesmay\\nbe more memory-efficient but less computation-\\n• ParallelComputation: Boththelogprobability allyoptimal.\\nratio term and the spectral kernel term involve\\noperations that can be parallelized across spec- • HyperparameterTuning: Carefultuningofthe\\ntralkernelcomponents. Leveragingmodernhard- hyperparametersγ,λ ,andσ isessential. Higher\\ni\\nwareaccelerators,suchasGPUs,cansignificantly values of p can capture more complex relation-\\nspeedupthesecomputations. ships but may increase computational cost andriskoverfitting. Similarly,thebandwidthparam- • µ and µ′ are means for the log probability ratio\\neterσ affectshowsharplytheexponentialterms andembeddingratioterms,respectively.\\ndecay,influencingthegradientmagnitudes.\\n• σ andσ′ arebandwidthparametersfortheMaha-\\n• Numerical Stability: The constants c and σ en- lanobiskernelsappliedtothelogprobabilityratio\\nsurenumericalstability,especiallywhendealing andembeddingratioterms,respectively.\\nwith small or large ratios in the log probability\\n• γ isahyperparametercontrollingtheinfluenceof\\nand embedding terms. Properly choosing these\\ntheembedding-basedterm.\\nconstants is crucial to prevent numerical issues\\nduringtraining.\\nOurobjectiveistocomputethegradientofthe\\nMahalanobis Kernelized Hybrid Loss ∇ L with\\nθ\\n• MemoryConsumption: Asp,C,anddincrease,\\nrespecttothemodelparametersθ. Thisinvolves\\nmemory consumption can become a bottleneck.\\ndifferentiatingeachtermofthelossfunctionsepa-\\nEfficientmemorymanagementandpossiblyreduc-\\nratelyandthencombiningthem.\\ning the number of spectral kernel components p\\nwithoutsignificantlycompromisingperformance GradientoftheLogProbabilityRatioTerm\\ncanhelpmitigatethisissue. The first component of the Mahalanobis Kernel-\\nizedHybridLossinvolvestheexponentialofthe\\nByconsideringthesepracticalaspects,theSpec- squaredandshiftedlogprobabilityratio:\\ntral Kernelized Hybrid Loss can be effectively\\nintegratedintolarge-scalemachinelearningmod-\\n\\uf8eb (cid:16)\\nπ(y+|x)\\n(cid:17)2\\uf8f6\\nlog −µ\\nπ(y−|x)\\nels,providingenhancedperformancethroughso- exp\\uf8ec− \\uf8f7.\\n\\uf8ed 2σ2 \\uf8f8\\nphisticatedspectralkerneltransformationswhile\\nmaintainingcomputationalefficiency.\\nTocomputeitsgradientwithrespecttoθ,weapply\\nI.17 GradientofMahalanobisKernelized\\nthechainrule:\\nHybridLoss\\n(cid:32) (z−µ)2(cid:33) (cid:32) (z−µ)2(cid:33) (cid:18) 2(z−µ)(cid:19)\\nTheMahalanobisKernelizedHybridLossisde- ∇θexp −\\n2σ2\\n=exp −\\n2σ2\\n· −\\n2σ2\\n·∇θz,\\nfinedas:\\nπ(y+|x)\\nL=E x,y+,y−(cid:34) exp\\uf8eb \\uf8ec \\uf8ed−(cid:16) log ππ (( yy 2−+ σ| |x x 2) )−µ(cid:17)2\\uf8f6 \\uf8f7 \\uf8f8+γexp\\uf8eb \\uf8ec \\uf8ec\\n\\uf8ec\\n\\uf8ed−(cid:18) ee ⊤x⊤x ee yy 2−+ σ′− 2µ′(cid:19)2\\uf8f6 \\uf8f7 \\uf8f7\\n\\uf8f7\\n\\uf8f8(cid:35) , wh Se ir me pz li= fyl io ng g,π w(y e− o|x b) t. ain:\\n(cid:32) (cid:33) (cid:32) (cid:33)\\n(z−µ)2 (z−µ) (z−µ)2\\n∇ exp − =− exp − ·∇ z.\\nwhere: θ 2σ2 σ2 2σ2 θ\\nExpanding the gradient of the log probability\\n• xrepresentstheinputdata.\\nratio:\\n• y+ andy− denotethepositiveandnegativesam-\\nπ(y+|x)\\nples,respectively. ∇ θz=∇ θlog\\nπ(y−|x)\\n=∇ θlogπ(y+|x)−∇ θlogπ(y−|x).\\n• π(y | x)istheprobabilityofy givenx,modeled Assumingπ (y | x)ismodeledusingasoftmax\\nθ\\nusingasoftmaxfunction. function:\\n• e ande aretheembeddingsofy andx,respec- ef θ(x,y)\\ny x π (y | x) = ,\\ntively. θ (cid:80) y′ef θ(x,y′)thegradientoflogπ(y | x)withrespecttoθ is: Assuminge ande aredifferentiablewithre-\\nx y\\nspecttoθ,wehave:\\n(cid:88)\\n∇ logπ(y|x)=∇ f (x,y)− π (y′|x)∇ f (x,y′).\\nθ θ θ θ θ θ\\n∇ (e⊤e ) = (∇ e )⊤e +e⊤(∇ e ).\\ny′ θ x y θ x y x θ y\\nSubstitutingback,weobtain: Substituting back, the gradient of the Maha-\\nlanobiskerneltermbecomes:\\n\\uf8ee \\uf8f9\\n(cid:88)\\n∇ θz = \\uf8f0∇ θf θ(x,y+)− π θ(y′ | x)∇ θf θ(x,y′)\\uf8fb\\n(cid:32) (cid:33)\\n(r−µ′)2\\ny′\\n∇ γexp − =\\n\\uf8ee \\uf8f9 θ 2σ′2\\n(cid:88)\\n−\\uf8f0∇ θf θ(x,y−)− π θ(y′ | x)∇ θf θ(x,y′)\\uf8fb γ(r−µ′) (cid:32) (r−µ′)2(cid:33) (e⊤e )∇ (e⊤e )−(e⊤e )∇ (e⊤e )\\nx y− θ x y+ x y+ θ x y−\\ny′ −\\nσ′2\\nexp −\\n2σ′2\\n·\\n(e⊤e )2\\n.\\nx y−\\n= ∇ f (x,y+)−∇ f (x,y−).\\nθ θ θ θ\\nCombinedGradient\\nTherefore, the gradient of the log probability\\nCombiningthegradientsofbothcomponents,the\\nratiotermis:\\noverall gradient of the Mahalanobis Kernelized\\nHybridLosswithrespecttoθ is:\\n∇θexp(cid:32)\\n−(z 2−\\nσ2µ)2(cid:33)\\n=−(z σ− 2µ)\\nexp(cid:32)\\n−(z 2−\\nσ2µ)2(cid:33)\\n(cid:0)∇θfθ(x,y+)−∇θfθ(x,y−)(cid:1).\\n∇θL=E x,y+,y−(cid:34) −(z σ− 2µ) exp(cid:18) −(z 2− σ2µ)2(cid:19) (cid:0)∇θfθ(x,y+)−∇θfθ(x,y−)(cid:1)\\nGradientoftheMahalanobisKernelTerm\\nT thh ee ss qe uc ao rn ed dc ao nm dp so hn ife tn edti en mvo bl ev de ds it nh ge -e bx ap seo dne rn at ti ia ol :of −γ(r σ− ′2µ′) exp(cid:18) −(r 2− σµ ′2′)2(cid:19) ·(e⊤ xey−)∇θ(e⊤ xey (+\\ne⊤\\nx) e− y−(e )⊤ x 2ey+)∇θ(e⊤ xey−)(cid:35) .\\n(cid:32) (cid:33) SimplifiedGradientExpression Foreaseofim-\\n(r−µ′)2\\nγexp − , plementationandreadability,thegradientcanbe\\n2σ′2\\nexpressedas:\\nwherer = ee\\n⊤\\nx⊤ x ee yy −+. ∇θL=E x,y+,y−(cid:34) −(z σ− 2µ) exp(cid:18) −(z 2− σ2µ)2(cid:19) (cid:0)∇θfθ(x,y+)−∇θfθ(x,y−)(cid:1)\\nTo compute its gradient with respect to θ, we\\napplythechainrule: −γ(r σ− ′2µ′) exp(cid:18) −(r 2− σµ ′2′)2(cid:19) ·(e⊤xey−)(cid:0)(∇θex)⊤ey++e⊤x(∇θey+ (e)(cid:1) ⊤xe− y−(e )⊤x 2ey+)(cid:0)(∇θex)⊤ey−+e⊤x(∇θey−)(cid:1)(cid:35)\\n.\\n(cid:32) (r−µ′)2(cid:33) (cid:32) (r−µ′)2(cid:33) (cid:18) 2(r−µ′)(cid:19) InterpretationoftheGradient\\n∇θγexp −\\n2σ′2\\n=γexp −\\n2σ′2\\n· −\\n2σ′2\\n·∇θr,\\n• LogProbabilityRatioTerm:\\nwherer = ee\\n⊤\\nx⊤ x ee yy −+.\\n–\\n−(z σ− 2µ) exp(cid:16) −(z 2− σµ 2)2(cid:17)\\n: Scalestheinfluenceof\\nSimplifying,weobtain: the log probability ratio based on its deviation\\nfromthemeanµandthebandwidthparameterσ.\\n(cid:32) (r−µ′)2(cid:33)\\nγ(r−µ′)\\n(cid:32) (r−µ′)2(cid:33) – ∇ θf θ(x,y+): Encouragesthemodeltoincrease\\n∇ γexp − =− exp − ·∇ r.\\nθ 2σ′2 σ′2 2σ′2 θ thescore(andhencetheprobability)oftheposi-\\ntivesampley+.\\nTocompute∇ r,weusethequotientrule:\\nθ – −∇ f (x,y−): Encourages the model to de-\\nθ θ\\n(cid:32) (cid:33) crease the score (and hence the probability) of\\n∇θr=∇θ ee\\n⊤\\nx⊤ x ee yy −+ =(e⊤ xe y−)∇θ(e⊤ xe y (+\\ne⊤\\nx) e− y−(e )⊤ x 2e y+)∇θ(e⊤ xe y−) . thenegativesampley−.• MahalanobisKernelTerm: andz = log\\nπ(y+|x)\\n.\\nπ(y−|x)\\nγ(r−µ′) (cid:16) (r−µ′)2(cid:17) StepsInvolved:\\n– − exp − : Scales the influence\\nσ′2 2σ′2\\noftheembedding-basedratiobasedonitsdevia- • ScoreComputation: Calculatef (x,y)foreach\\nθ\\ntionfromthemeanµ′ andthebandwidthparame- class y, which involves a dot product between\\nterσ′,adjustedbythehyperparameterγ.\\ninputfeaturesandmodelparameters.\\n–\\n(e⊤ xe y−)∇ θ(e⊤ xe y+)−(e⊤ xe y+)∇ θ(e⊤ xe y−)\\n: Adjuststhe\\n(e⊤ xe y−)2 • SoftmaxCalculation: Computetheexponential\\nmodel to better align the embeddings of x with ef θ(x,y) foreachclassandnormalizebythesum\\ny+ whilediscouragingalignmentwithy−. overallC classes.\\n(cid:16) (cid:17)\\n(r−µ′)2\\n– The exponential term exp − ensures\\n2(σ′)2 • LogProbabilityRatio: Computethelogarithmof\\nthattheinfluencediminishesasthesquaredratios\\ntheratiobetweentheprobabilitiesofthepositive\\ndeviate from the mean µ′, promoting smoother\\nandnegativeclasses.\\ngradients.\\n• ExponentiationandScaling: Subtractthemean\\n• Hyperparameters:\\nµ,squaretheresult,scaleby− 1 ,andcompute\\n2σ2\\n– µandµ′: ControlthecenteroftheMahalanobis theexponential.\\nkernels for the log probability ratio and embed-\\nTimeComplexity: O(C),whereC isthenum-\\ndingratioterms,respectively.\\nber of classes. This complexity arises from the\\n– σ andσ′: DeterminethebandwidthoftheMaha-\\nsoftmax computation, which requires evaluating\\nlanobiskernels,affectinghowsharplytheexpo-\\nf (x,y)andnormalizingoverallC classes.\\nθ\\nnentialtermsdecay.\\n– γ: Balancestheinfluencebetweentheprobability- 2. MahalanobisKernelTerm\\nbasedtermandtheembedding-basedterm,allow- TheMahalanobiskerneltermisdefinedas:\\ningforfine-tuningoftheirrelativeimportance.\\n\\uf8eb (cid:18) (cid:19)2\\uf8f6\\ne⊤ xe y+ −µ′\\nI.18 ComputationalComplexityAnalysisof γexp\\uf8ec\\n\\uf8ec−\\ne⊤ xe y− \\uf8f7\\n\\uf8f7\\nMahalanobisKernelizedHybridLoss \\uf8ec 2σ′2 \\uf8f7\\n\\uf8ed \\uf8f8\\nToevaluatetheefficiencyoftheMahalanobisKer-\\nnelizedHybridLoss,weanalyzethecomputational\\ncomplexityofitstwoprimarycomponents: thelog wherer = e⊤ xe y+.\\nprobabilityratiotermandtheMahalanobiskernel e⊤ xe y−\\nStepsInvolved:\\nterm.\\n1. LogProbabilityRatioTerm • Dot Product Computation: Calculate the dot\\nproductse⊤e ande⊤e ,wheree ,e ,e ∈\\nThelogprobabilityratiotermisdefinedas: x y+ x y− x y+ y−\\nRd.\\n\\uf8eb (cid:16)\\nπ(y+|x)\\n(cid:17)2\\uf8f6\\nlog −µ\\nexp\\uf8ec− π(y−|x) \\uf8f7 • RatioCalculation: Computetheratio e⊤ xe y+.\\n\\uf8ed 2σ2 \\uf8f8 e⊤ xe y−\\n• MeanSubtractionandSquaring: Subtractthe\\nwhereπ θ(y | x)ismodeledusingasoftmaxfunc- meanµ′,squaretheresult,andscaleby− 1 .\\n2σ′2\\ntion:\\nef θ(x,y) • ExponentiationandScaling: Computetheexpo-\\nπ (y | x) = ,\\nθ (cid:80) y′ef θ(x,y′) nentialandmultiplybythehyperparameterγ.Time Complexity: O(d), where d is the di- The Mahalanobis Kernelized Hybrid Loss\\nmensionoftheembeddings. Thisarisesfromthe thus offers a balanced combination of the com-\\ncomputation of the dot products between e and putationalefficienciesofCross-EntropyandCon-\\nx\\ne ,whichscaleslinearlywithd. trastiveLosseswhileenhancingthemodel’sability\\ny\\nto capture both discriminative and semantic rela-\\nOverallComputationalComplexity\\ntionships.\\nCombining both components, the total computa-\\ntionalcomplexityoftheMahalanobisKernelized I.19 EfficiencyofMahalanobisKernelized\\nHybridLossis: HybridLoss\\nO(C)+O(d) = O(C +d), The Mahalanobis Kernelized Hybrid Loss\\nachieves a balanced trade-off between discrimi-\\nwhere:\\nnativepowerandcomputationalefficiencythrough\\n• C isthenumberofclasses(softmaxcomputation). thefollowingmechanisms:\\n• d is the embedding dimension (kernel computa-\\n• Linear Scaling: The loss scales linearly with\\ntion).\\nboththenumberofclassesC andtheembedding\\nThis linear complexity ensures scalability dimensiond,ensuringscalabilityforlarge-scale\\nfor large-scale applications involving high- datasetsandhigh-dimensionalembeddingspaces.\\ndimensional embeddings and extensive class la-\\nbels. • ParallelComputation: Boththelogprobability\\nratiotermandtheMahalanobiskerneltermcanbe\\nComparisonwithStandardLossFunctions\\ncomputedinparallel. Modernhardwareaccelera-\\n• Cross-EntropyLoss: tors,suchasGPUs,canleveragethisparallelism\\ntosignificantlyspeeduptrainingprocesses.\\n– TimeComplexity: O(C).\\n– Description: Involves computing the softmax\\n• IntegratedSemanticInformation: Bycombin-\\noverC classesandcalculatingthenegativelog-\\ning probability-based and embedding-based ob-\\nlikelihood.\\njectives, the loss function enriches the model’s\\nlearningwithoutincurringsubstantialadditional\\n• ContrastiveLoss:\\ncomputationaloverhead.\\n– TimeComplexity: O(d).\\n– Description: Focuses on the distance between • HyperparameterControl: Thehyperparameters\\nembeddings,typicallyrequiringcomputationof µ,µ′,σ,σ′,andγ allowforfine-tuningtheinflu-\\npairwisedistances. ence of each component, enabling the model to\\nbalance between accurately classifying positive\\n• MahalanobisKernelizedHybridLoss: and negative samples and capturing meaningful\\nembeddingrelationships.\\n– TimeComplexity: O(C +d).\\n– Description: Combinesboththediscriminative\\nI.20 PracticalConsiderations\\npower of the log probability ratio (similar to\\nCross-Entropy Loss) and the semantic richness While the theoretical complexity of the Maha-\\noftheMahalanobiskernel(similartoContrastive lanobisKernelizedHybridLossisO(C +d),sev-\\nLoss),therebyintegratingbothaspectsintoasin- eral practical factors can influence its real-world\\nglelossfunction. performance:• GPUParallelism: LeveragingGPUparallelism sophisticated kernel transformations while main-\\ncan mitigate the linear scaling with C and d, al- tainingcomputationalefficiency.\\nlowingforefficientcomputationevenwithlarge\\nI.21 GradientofHierarchicalMixtureof\\nnumbersofclassesandhigh-dimensionalembed-\\nKernels(HMK)\\ndings.\\nHierarchicalMixtureofKernels(HMK)imposesa\\n• Optimized Implementations: Utilizing opti-\\nhierarchicalstructurewherelocalkernelsoperate\\nmizedlibraries(e.g.,BLAS,cuDNN)formatrix\\non small, local regions, and global kernels cap-\\noperationsandgradientcomputationscanenhance\\nture larger-scale dependencies. This structure is\\nperformance, reducing the actual computation\\nformalizedas:\\ntime.\\n• Batch Sizing: Selecting appropriate batch sizes K(x,x′)=τ 1(cid:0) λ 1K RBF(x,x′)+λ 2K Poly(x,x′)(cid:1)\\ncan maximize hardware utilization. Larger +τ 2(cid:0) λ 3K Spectral(x,x′)+λ 4K Mahalanobis(x,x′)(cid:1)\\nbatchesmayimprovecomputationalefficiencybut\\nwhere:\\nrequiremorememory,whilesmallerbatchesmay\\n• x,x′ areinputdatapoints.\\nbe more memory-efficient but less computation-\\nallyoptimal. • K (x,x′), K (x,x′), K (x,x′), and\\nRBF Poly Spectral\\nK (x,x′)aretheRadialBasisFunction,\\n• HyperparameterTuning: Carefultuningofthe Mahalanobis\\nhyperparameters µ, µ′, σ, σ′, and γ is essential. Polynomial, Spectral, and Mahalanobis kernels,\\nThemeansµandµ′ determinethecentersofthe respectively.\\nMahalanobiskernels,whilethebandwidthparam-\\n• λ ,λ ,λ ,λ areweightingcoefficientsforeach\\n1 2 3 4\\neters σ and σ′ affect how sharply the exponen-\\nkerneltype.\\ntialtermsdecay. Thehyperparameterγ balances\\ntheinfluencebetweentheprobability-basedand • τ 1 andτ 2 arescalingfactorsthatbalancethecon-\\nembedding-basedterms. tributionoflocalandglobalkernels.\\nOurobjectiveistocomputethegradientofthe\\n• Numerical Stability: The constants µ, µ′, σ,\\nHMKK(x,x′)withrespecttothemodelparame-\\nandσ′ ensurenumericalstability,especiallywhen\\ntersθ. Thisgradientisessentialforoptimizingthe\\ndealingwithsmallorlargeratiosinthelogprob-\\nmodel parameters during training, ensuring that\\nabilityandembeddingterms. Properlychoosing\\nboth local and global dependencies are appropri-\\ntheseconstantsiscrucialtopreventnumericalis-\\natelycaptured.\\nsuesduringtraining.\\nGradientComputationofHMK\\n• Memory Consumption: As C and d increase,\\nThegradientoftheHMKwithrespecttoθ isde-\\nmemory consumption can become a bottleneck.\\nrivedbydifferentiatingeachcomponentkernelin-\\nEfficient memory management and possibly re-\\ndividuallyandthencombiningthemaccordingto\\nducing the number of classes or embedding di-\\ntheirhierarchicalstructure. Formally,thegradient\\nmensionswithoutsignificantlycompromisingper-\\nisexpressedas:\\nformancecanhelpmitigatethisissue.\\nByconsideringthesepracticalaspects,theMa-\\n∇θK(x,x′)=τ1(cid:0)λ1∇θKRBF(x,x′)+λ2∇θKPoly(x,x′)(cid:1)+τ2(cid:0)λ3∇θKSpectral(x,x′)+λ4∇θKMahalanobis(x,x′)(cid:1).\\nhalanobisKernelizedHybridLosscanbeeffec- Eachgradientterm∇ K (x,x′)corresponds\\nθ Type\\ntivelyintegratedintolarge-scalemachinelearning tothegradientoftherespectivekernelwithrespect\\nmodels,providingenhancedperformancethrough toθ,asderivedintheirindividualsections.1. GradientoftheRBFKernel SimplifiedGradientExpression Foreaseofim-\\nplementationandreadability,thegradientcanbe\\n∇θKRBF(x,x′)=∇θexp(cid:18) −∥x 2− σx 2′∥2(cid:19) =exp(cid:18) −∥x 2− σx 2′∥2(cid:19) ·(cid:18)(x′ σ− 2x)(cid:19)\\n·∇θx, succinctlywrittenas:\\nwhereσ isthebandwidthparameter. ∇θK(x,x′)=τ1λ1exp(cid:18) −∥x 2− σx 2′∥2(cid:19) ·(x′ σ− 2x) ·∇θx+τ1λ2d(x⊤x′+c)d−1·(cid:0)x′∇θx+x∇θx′(cid:1)\\n2. GradientofthePolynomialKernel\\n∇θKPoly(x,x′)=∇θ(x⊤x′+c)d=d(x⊤x′+c)d−1·(cid:0)x′∇θx+x∇θx′(cid:1), +τ2λ3(cid:88) i=p 1exp(cid:0)−λizi2(cid:1)(cid:0)−2λiziϕi(zi)+ϕ′i(zi)(cid:1)∇θzi+τ2λ4(cid:88) i=p 1exp(cid:0)−λi(ri−µi)2(cid:1)(cid:18) −2λi(r σi i2−µi)ϕi(ri)+ϕ′i(ri)(cid:19) ∇θri.\\nInterpretationoftheGradient\\nwhere c is a constant and d is the degree of the\\npolynomial. • RBFKernelGradient(τ λ ):\\n1 1\\n3. GradientoftheSpectralKernel (cid:16) ∥x−x′∥2(cid:17)\\n– exp − : Measures the similarity be-\\n2σ2\\n∇θKSpectral(x,x′)=(cid:88)p\\n(cid:2) exp(cid:0) −λiz i2(cid:1)(cid:0) −2λiziϕi(zi)+ϕ′ i(zi)(cid:1) ∇θzi(cid:3) ,\\ntweenxandx′.\\ni=1 –\\n(x′−x)\\n: Directsthegradienttoincreasesimilarity\\nσ2\\nπ(y+|x) ifxandx′ aresimilar,ordecreaseotherwise.\\nwherez = log andϕ (·)arefeaturetrans-\\ni π(y−|x) i\\nformationfunctions. – ∇ θx: Adjuststhemodelparameterstooptimize\\ntherepresentationofx.\\n4. GradientoftheMahalanobisKernel\\n• PolynomialKernelGradient(τ λ ):\\n1 2\\n∇θKMahalanobis(x,x′)=(cid:88) i=p 1(cid:20) exp(cid:0)−λi(ri−µi)2(cid:1)(cid:18) −2λi(r σi i2−µi) ϕi(ri)+ϕ′ i(ri)(cid:19) ∇θri(cid:21) ,\\n– d(x⊤x′ +c)d−1: Scales the influence based on\\nwherer = e⊤ xe y+,µ aremeanparameters,andσ the degree of the polynomial and the similarity\\ni e⊤ xe y− i i betweenxandx′.\\narebandwidthparametersforeachspectralcompo-\\n– (x′∇ x+x∇ x′): Updates the model parame-\\nθ θ\\nnent.\\nterstoenhanceorreducethepolynomialsimilar-\\nCombinedGradientExpression ity.\\nCombiningthegradientsofallkernelcomponents,\\n• SpectralKernelGradient(τ λ ):\\n2 3\\ntheoverallgradientoftheHMKwithrespecttoθ\\nis: –\\nexp(cid:0)\\n−λ\\nz2(cid:1)\\n: Appliesaspectraltransformation\\ni i\\nbasedonthelogprobabilityratio.\\n∇θK(x,x′)=τ1(cid:0)λ1∇θKRBF(x,x′)+λ2∇θKPoly(x,x′)(cid:1)+τ2(cid:0)λ3∇θKSpectral(x,x′)+λ4∇θKMahalanobis(x,x′)(cid:1).\\n– (−2λ z ϕ (z )+ϕ′(z )): Modulates the gradi-\\ni i i i i i\\nSubstitutingthegradientsofindividualkernels: entbasedonthespectralfeaturetransformations.\\n– ∇ z : Encouragesthemodeltoadjustprobabili-\\nθ i\\n∇ K(x,x′) = τ\\n(cid:18)\\nλ\\nexp(cid:18) −∥x−x′∥2(cid:19)\\n·\\n(x′−xt)ie\\n·s ∇to xoptimizethespectralfeatures.\\nθ 1 1 2σ2 σ2 θ\\n+λ d(x⊤x′+c)d−1·(cid:0) x′∇ x+x∇\\nx′(cid:1)(cid:17) • MahalanobisKernelGradient(τ 2λ 4):\\n2 θ θ\\n(cid:32) p –\\nexp(cid:0)\\n−λ i(r i−µ\\ni)2(cid:1)\\n: Applies a Mahalanobis\\n+τ λ (cid:88) exp(cid:0) −λ z2(cid:1)(cid:0) −2λ z ϕ (z )+ϕ′(z )(cid:1) ∇trzansformationbasedontheembeddingratio.\\n2 3 i i i i i i i i θ i\\n(cid:16) (cid:17)\\ni=1 – −2λi(ri−µi) ϕ (r )+ϕ′(r ) : Modulates the\\n+λ\\n(cid:88)p\\nexp(cid:0)\\n−λ (r −µ\\n)2(cid:1)(cid:18)\\n−2λ i(r i−µ i)\\nϕ (r\\n)+gra ϕd′i (e\\nrnσ )ti(cid:19)2\\nba ∇sed\\nri o(cid:33) ni .theMi ahai\\nlanobisfeaturetrans-\\n4 i i i σ2 i i formi atii ons. θ i\\ni=1 i– ∇ r : Adjusts the embeddings to optimize the 2. GlobalKernels\\nθ i\\nMahalanobisdistance. a. SpectralKernel\\np\\n• Hyperparametersτ 1,τ 2,λ 1,λ 2,λ 3,λ 4: K (x,x′) = (cid:88) exp(cid:0) −λ z2(cid:1) ϕ (z ),\\nSpectral i i i i\\n– τ ,τ : Balance the contributions of local and i=1\\n1 2\\nglobalkernels. π(y+|x)\\nwherez = log .\\ni π(y−|x)\\n– λ ,λ ,λ ,λ : Controltheinfluenceofeachker- StepsInvolved:\\n1 2 3 4\\nneltypewithintheirrespectivehierarchies.\\n• Compute the log probability ratio z , which in-\\ni\\nvolvesO(C)operationsduetothesoftmax.\\nComputationalComplexityAnalysisofHMK\\nToevaluatetheefficiencyoftheHierarchicalMix- • Foreachofthepspectralcomponents:\\ntureofKernels(HMK),weanalyzethecomputa-\\n–\\nComputeexp(cid:0)\\n−λ\\nz2(cid:1)\\n,whichisaconstant-time\\ntionalcomplexityofitsprimarycomponents: the i i\\noperation.\\nlocalkernels(RBFandPolynomial)andtheglobal\\n– Applythefeaturetransformationϕ (z ),assumed\\nkernels(SpectralandMahalanobis). i i\\ntobeconstant-time.\\n1. LocalKernels\\nTimeComplexity: O(p·C)\\na. RBFKernel\\nb. MahalanobisKernel\\n(cid:18) ∥x−x′∥2(cid:19)\\nK RBF(x,x′) = exp −\\n2σ2 K\\n(x,x′)=(cid:88)p\\nexp(cid:0)\\n−λ (r −µ\\n)2(cid:1)\\nϕ (r ),\\nMahalanobis i i i i i\\ni=1\\nStepsInvolved:\\nwherer = e⊤ xe y+.\\n• ComputetheEuclideandistance∥x−x′∥,which i e⊤ xe y−\\nStepsInvolved:\\ninvolves O(d) operations, where d is the dimen-\\n• Computetheembeddingratiosr ,whichinvolves\\nsionoftheinput. i\\nO(d)operationsforthedotproducts.\\n• Exponentiation, which is a constant-time opera-\\n• ForeachofthepMahalanobiscomponents:\\ntion.\\n– Compute\\nexp(cid:0)\\n−λ (r −µ\\n)2(cid:1)\\n, which is a\\ni i i\\nTimeComplexity: O(d)\\nconstant-timeoperation.\\nb. PolynomialKernel – Applythefeaturetransformationϕ i(r i),assumed\\ntobeconstant-time.\\nK (x,x′) = (x⊤x′+c)d\\nPoly TimeComplexity: O(p·d)\\nStepsInvolved: OverallComputationalComplexity\\nCombiningthecomplexitiesofallkernelcompo-\\n• Compute the dot product x⊤x′, which involves\\nnents, the total computational complexity of the\\nO(d)operations.\\nHMKis:\\n• Addconstantcandraisetothepowerd,bothof\\nO(d)+O(d)+O(p·C)+O(p·d)=O(p·(C+d)+d).\\nwhichareconstant-timeoperations.\\nSincedistypicallymuchsmallerthanp·(C +d),\\nTimeComplexity: O(d) thedominanttermisO(p·(C +d)).ComparisonwithStandardLossFunctions globalkernels(SpectralandMahalanobis)capture\\n• Cross-EntropyLoss: broaderdependencies.\\n• ParallelComputation: Thecomputationsfordif-\\n– TimeComplexity: O(C).\\nferentkernelcomponentsareindependentandcan\\n– Description: Involves computing the softmax\\nbeparallelized. Leveragingmodernhardwareac-\\noverC classesandcalculatingthenegativelog-\\ncelerators,suchasGPUs,cansignificantlyreduce\\nlikelihood.\\ntrainingtimes.\\n• ContrastiveLoss:\\n• Scalability with Spectral Components: Al-\\nthoughthecomplexityscaleswiththenumberof\\n– TimeComplexity: O(d).\\nspectralcomponentsp,carefulselectionofpcan\\n– Description: Focuses on the distance between\\nbalance expressiveness with computational cost.\\nembeddings,typicallyrequiringcomputationof\\nTechniques such as dimensionality reduction or\\npairwisedistances.\\nkernelapproximationcanbeemployedtomanage\\nlargep.\\n• HierarchicalMixtureofKernels(HMK):\\n• HyperparameterTuning: Thehyperparameters\\n– TimeComplexity: O(p·(C +d)).\\nτ ,τ ,λ ,λ ,λ ,λ allow for fine-tuning the in-\\n1 2 1 2 3 4\\n– Description: Combinesmultiplekernelswithhi- fluence of each kernel component, enabling the\\nerarchicalweighting,integratingbothlocal(RBF modeltoprioritizecertainrelationshipsoveroth-\\nand Polynomial) and global (Spectral and Ma- erswithoutrequiringextensivecomputationalre-\\nhalanobis) dependencies. This allows HMK to sources.\\ncapturecomplexpatternsandrelationshipsinthe\\n• Optimized Implementations: Utilizing opti-\\ndata,leveragingthestrengthsofeachkerneltype.\\nmizedlibraries(e.g.,BLAS,cuDNN)formatrix\\nThe HMK offers a more expressive and flexi- operationsandkernelcomputationscanenhance\\nblemodelingapproachcomparedtostandardloss performance,ensuringthatthetheoreticalcompu-\\nfunctions by incorporating multiple kernel types tationalcomplexitiestranslateintopracticaleffi-\\nandhierarchicalweighting. However,thisexpres- ciencygains.\\nsivenesscomesatthecostofincreasedcomputa-\\nPracticalConsiderations\\ntionalcomplexity,especiallywithhighernumbers\\nWhile the theoretical complexity of the HMK is\\nofspectralcomponentsp, classesC, andembed-\\nO(p·(C +d)),severalpracticalfactorscaninflu-\\ndingdimensionsd.\\nenceitsreal-worldperformance:\\nEfficiencyofHMK\\n• GPUParallelism: LeveragingGPUparallelism\\nThe Hierarchical Mixture of Kernels (HMK)\\ncan mitigate the linear scaling with p, C, and d,\\nachieves a balanced trade-off between modeling\\nallowingforefficientcomputationevenwithlarge\\ncomplexityandcomputationalefficiencythrough\\nnumbersofspectral kernelcomponents, classes,\\nthefollowingmechanisms:\\nandhigh-dimensionalembeddings.\\n• Modular Kernel Design: By decomposing the • Optimized Implementations: Utilizing opti-\\nkernel into local and global components, HMK mizedlibraries(e.g.,BLAS,cuDNN)formatrix\\nallows for targeted optimization of different as- operationsandgradientcomputationscanenhance\\npects of the data. Local kernels (RBF and Poly- performance, reducing the actual computation\\nnomial)focusonfine-grainedsimilarities,while time.• Batch Sizing: Selecting appropriate batch sizes I.22 AnalysisofGradientConvergencefor\\ncan maximize hardware utilization. Larger FourKernelsandHMK\\nbatchesmayimprovecomputationalefficiencybut\\nInthissection,weinvestigatetheconvergencebe-\\nrequiremorememory,whilesmallerbatchesmay\\nhavior of gradient descent when applied to four\\nbe more memory-efficient but less computation-\\ndistinctkernels: Polynomial,RBF(RadialBasis\\nallyoptimal.\\nFunction), Spectral, and Mahalanobis. Addi-\\ntionally,weanalyzetheHierarchicalMixtureof\\n• HyperparameterTuning: Carefultuningofthe Kernels(HMK),whichcombinesthesekernelsto\\nhyperparametersτ 1,τ 2,λ 1,λ 2,λ 3,λ 4 isessential. leveragebothlocalandglobaldependencies. The\\nThevaluesoftheseparametersdeterminetherela- convergencepropertiesareevaluatedbasedonkey\\ntiveimportanceofeachkernelcomponent,affect- factorssuchassmoothness, Lipschitzcontinuity,\\ning both the model’s performance and computa- gradientsimplicity,androbustnesstoinitialization.\\ntionalcost. Understandingthesepropertiesiscrucialforeffec-\\ntivealignmentlearningandoptimization.\\n• MemoryConsumption: Asthenumberofspec-\\nI.23 LipschitzContinuity: Intuitionand\\ntralcomponentsp,classesC,andembeddingdi-\\nImportance\\nmensions d increase, memory consumption can\\nbecomeabottleneck. Efficientmemorymanage- Definition: Afunctionf : Rn → Rissaidtobe\\nmentstrategies,suchasgradientcheckpointingor LipschitzcontinuouswithconstantL > 0if,for\\ndimensionality reduction, can help mitigate this allx,y ∈ Rn,\\nissue.\\n|f(x)−f(y)|≤ L∥x−y∥.\\n• NumericalStability: Ensuringnumericalstabil- Here,ListheLipschitzconstantandservesasan\\nity during kernel computations is crucial, espe- upperboundontherateatwhichthefunctionf can\\ncially when dealing with exponential functions change. Intuitively, Lipschitz continuity ensures\\nthat can lead to very large or very small values. thatthefunctiondoesnotexhibitabruptchanges,\\nTechniquessuchasnormalizationoraddingsmall whichisessentialforthestabilityandconvergence\\nconstantstodenominatorscanpreventnumerical ofgradient-basedoptimizationmethods.\\noverfloworunderflow.\\nWhyLipschitzContinuityMatters\\n• ConvergenceStability: Ifthegradientofaloss\\n• KernelSelection: Thechoiceofkerneltypesand\\nfunctionisLipschitzcontinuous,gradientdescent\\ntheir respective parameters (σ, c, d, λ , µ , σ′)\\ni i i is guaranteed to converge at a stable rate (Nes-\\nshouldbeinformedbythespecificcharacteristics\\nterov,2003).\\nof the data and the problem domain. Empirical\\nvalidationandcross-validationcanaidinselecting • PreventionofExplodingGradients: Lipschitz\\noptimalkernelconfigurations. continuity bounds the gradients, preventing ex-\\ncessively large updates that can destabilize the\\noptimizationprocess,particularlyindeeplearning\\nByconsideringthesepracticalaspects,theHier-\\nmodels(Goodfellowetal.,2016).\\narchicalMixtureofKernels(HMK)canbeeffec-\\ntivelyintegratedintolarge-scalemachinelearning • SmoothOptimizationLandscape: ALipschitz\\nmodels,providingenhancedperformancethrough continuous gradient implies a smooth loss land-\\nsophisticatedkernelcombinationswhilemaintain- scape, facilitating efficient and predictable opti-\\ningcomputationalefficiency. mization(BoydandVandenberghe,2004).IllustrativeExamples I.25 ConvergencePropertiesofEachKernel\\n• LipschitzContinuousFunction: Thelinearfunc- 1. RBFKernel\\ntion f(x) = 2x is Lipschitz continuous with\\n• Smoothness: TheRBFkernelinducesasmooth\\nL = 2. Regardless of the input difference, the\\nandconvexlosslandscape,whichisconduciveto\\nfunction’srateofchangeremainsconstant,ensur-\\nfastandstableconvergence(Bishop,2006).\\ningboundedgradientupdates.\\n• LipschitzContinuity: ThegradientoftheRBF\\n• Non-LipschitzFunction: Thequadraticfunction\\nkernelisLipschitzcontinuousduetoitsexponen-\\nf(x) = x2 isnotLipschitzcontinuouson[0,∞)\\ntial decay property. This ensures that gradient\\nbecause its slope becomes unbounded as x in-\\nupdateschangegradually,enhancingconvergence\\ncreases. Thiscanleadtounstablegradientupdates\\nstability.\\nduringoptimization.\\n• Gradient Simplicity: The gradient of the RBF\\nRelevanceinKernelMethods kernelisstraightforwardandlinearwithrespect\\ntotheinput:\\nThe convergence behavior of different kernels is\\ninfluencedbywhethertheirgradientsareLipschitz (y′−y)\\ncontinuous. Below,weexplorehowLipschitzcon- ∇ yK RBF(y,y′) = K RBF(y,y′)·\\nσ2\\n,\\ntinuity impacts gradient descent for each of the\\nfourkernelsunderconsideration. whereσ isthebandwidthparameter.\\n• RobustnesstoInitialization: Duetoitsconvex\\nI.24 KeyFactorsInfluencingGradient\\nlosssurface,theRBFkernelisrobusttorandom\\nConvergence\\ninitializations, minimizing the risk of converg-\\nToanalyzetheconvergenceofgradientdescentfor\\ningtopoorlocalminima(SchölkopfandSmola,\\neachkernel,weconsiderthefollowingcriteria:\\n2002).\\n• SmoothnessoftheLossLandscape: Asmoother 2. PolynomialKernel\\nloss landscape facilitates faster and more stable\\n• Smoothness: ThesmoothnessofthePolynomial\\nconvergencebyavoidingabruptchangesingradi-\\nkerneldependsonitsdegreed. Higherdegreesin-\\nents.\\ntroducenon-convexity,resultinginamorerugged\\n• LipschitzContinuityoftheGradient: Asmaller loss landscape with multiple local minima and\\nLipschitz constant ensures that gradients do not saddlepoints.\\nchange abruptly, promoting stable convergence\\n• LipschitzContinuity: Lipschitzcontinuitydete-\\n(Nesterov,2003).\\nrioratesasthedegreedincreases. Higherdegrees\\nleadtosteepergradients,makingtheoptimization\\n• Gradient Simplicity: Simpler gradient expres-\\nprocessmoresusceptibletoinstability.\\nsionsenhancecomputationalefficiencyandaccel-\\nerateconvergence.\\n• Gradient Simplicity: The gradient complexity\\nincreaseswiththedegreed:\\n• RobustnesstoInitialization: Kernelsthatexhibit\\nlesssensitivitytoinitialparametervaluesleadto ∇ K (y,y′) = d(y⊤y′+c)d−1·y′,\\ny Poly\\nmore reliable convergence from diverse starting\\npoints. wherecisaconstant.• Robustness to Initialization: The Polynomial smoothandstablegradients,whileapoorlycondi-\\nkernel is highly sensitive to initialization, espe- tionedΣresultsinrapidlychanginggradientsin\\ncially for higher degrees, due to its non-convex certaindirections.\\nloss landscape. This can lead to convergence to\\n• GradientSimplicity: ThegradientoftheMaha-\\nsuboptimallocalminima.\\nlanobis kernel incorporates the precision matrix\\n3. SpectralKernel Σ−1:\\n• Smoothness: ThesmoothnessoftheSpectralker- ∇ K (y,y′)=K (y,y′)·Σ−1(y′−y).\\ny Mahalanobis Mahalanobis\\nnelisinfluencedbythechoiceofbasisfunctions\\nThisintroducesadditionalcomplexitycompared\\nϕ . Orthonormalbasisfunctions,suchaswavelets,\\ni totheRBFkernel.\\ncanintroduceoscillatorybehaviorinthelossland-\\nscape(Ngetal.,2001). • Robustness to Initialization: When Σ is well-\\nconditioned,theMahalanobiskernelexhibitsro-\\n• LipschitzContinuity: Lipschitzcontinuityiscon-\\nbust convergence properties similar to the RBF\\ntingent on the eigenvalues λ of the underlying\\ni kernel. However,apoorlyconditionedΣcanlead\\nLaplacian. Large eigenvalues can cause rapid\\ntoslowconvergenceandsensitivitytoinitializa-\\noscillations in the gradients, leading to abrupt\\ntionduetounevengradientmagnitudes.\\nchangesandpotentialinstability.\\nI.26 ConvergencePropertiesofHMK\\n• GradientSimplicity: ThegradientoftheSpectral\\nHierarchicalMixtureofKernels(HMK) The\\nkernel depends on the complexity of the basis\\nHierarchical Mixture of Kernels (HMK) inte-\\nfunctions:\\ngratesthefouraforementionedkernelsintoahier-\\n∇yKSpectral(y,y′)=(cid:88)p\\n(cid:2)exp(cid:0)−λiz i2(cid:1)(cid:0)−2λiziϕi(zi)+ϕ′ i(zi)(cid:1)∇yzi(cid:3),\\narchicalstructuretocapturebothlocalandglobal\\ndependencies. HMKisdefinedas:\\ni=1\\nwherez\\ni\\n= log ππ (( yy −+| |x x) ). K(x,x′)=τ1(cid:0)λ1KRBF(x,x′)+λ2KPoly(x,x′)(cid:1)+τ2(cid:0)λ3KSpectral(x,x′)+λ4KMahalanobis(x,x′)(cid:1),\\nwhere:\\n• Robustness to Initialization: The convergence\\noftheSpectralkernelissensitivetothealignment • K (x,x′), K (x,x′), K (x,x′), and\\nRBF Poly Spectral\\nbetweendataandthechosenbasisfunctions. Poor K (x,x′)aretherespectivekernelfunc-\\nMahalanobis\\nalignment can lead to oscillatory gradients, re- tions.\\nquiringcarefulinitializationstrategies(Ngetal.,\\n• λ ,λ ,λ ,λ areweightingcoefficientsforeach\\n2001). 1 2 3 4\\nkerneltype.\\n4. MahalanobisKernel\\n• τ andτ arescalingfactorsthatbalancethecon-\\n1 2\\n• Smoothness: The Mahalanobis kernel behaves tributionoflocalandglobalkernels.\\nsimilarlytotheRBFkernelwhenthecovariance\\n• Smoothness: HMKexhibitspiecewisesmooth-\\nmatrixΣistheidentitymatrix. IfΣispoorlycon-\\nness due to its hierarchical decomposition. The\\nditioned,thelosslandscapebecomesanisotropic,\\nlocal kernels (RBF and Polynomial) contribute\\nleadingtounevensmoothnessacrossdifferentdi-\\ntofine-grainedsimilarities,whiletheglobalker-\\nmensions(WeinbergerandSaul,2009).\\nnels(SpectralandMahalanobis)capturebroader\\n• LipschitzContinuity: TheLipschitzcontinuity dependencies. ThiscombinationallowsHMKto\\noftheMahalanobiskerneldependsonthecondi- adaptively smooth different regions of the loss\\ntionnumberofΣ. Awell-conditionedΣensures landscape.• LipschitzContinuity: TheLipschitzcontinuity grees. Thecomplexityofitsgradientsandsensitiv-\\nof HMK is influenced by the individual Lips- itytoinitializationcanhinderstableconvergence,\\nchitzpropertiesofitscomponentkernels. Since especiallyforlarged.\\nRBF and Mahalanobis kernels typically have\\n• SpectralKernel: Introducesoscillatorybehavior\\nLipschitz continuous gradients (when Σ is well-\\ndependingonthebasisfunctionsandeigenvalues.\\nconditioned),andSpectralkernelshavemedium\\nWhileitcancaptureintricatepatterns,thepoten-\\nLipschitz continuity depending on eigenvalues,\\ntial for abrupt gradient changes requires careful\\nHMK inherits a balanced Lipschitz continuity.\\ndesignandinitializationtoensurestableconver-\\nThePolynomialkernel’sLipschitzpropertiescan\\ngence.\\nbecontrolledthroughthedegreed,allowingHMK\\ntomaintainoverallstability.\\n• MahalanobisKernel: BalancesbetweentheRBF\\nand Spectral kernels. With a well-conditioned\\n• Gradient Simplicity: The gradient of HMK is\\ncovariancematrixΣ,itmaintainssmoothandLip-\\naweightedsumofthegradientsofitsindividual\\nschitzcontinuousgradients,ensuringrobustcon-\\nkernels:\\nvergence. However, apoorly conditionedΣcan\\ncompromiseconvergencestability.\\n∇θK(x,x′)=τ1(cid:0)λ1∇θKRBF(x,x′)+λ2∇θKPoly(x,x′)(cid:1)+τ2(cid:0)λ3∇θKSpectral(x,x′)+λ4∇θKMahalanobis(x,x′)(cid:1).\\nThismodularityallowsHMKtobalancethesim- • HierarchicalMixtureofKernels(HMK):Com-\\nplicityofRBFandMahalanobisgradientswith binesthestrengthsofallfourkernels,achieving\\nthecomplexityofPolynomialandSpectralgra- abalancedconvergencebehavior. HMKbenefits\\ndients,ensuringmanageablegradientexpressions. fromthesmoothnessandstabilityofRBFandMa-\\nhalanobiskernelswhileincorporatingtheexpres-\\n• RobustnesstoInitialization: HMKenhancesro- sivepowerofPolynomialandSpectralkernels.\\nbustnesstoinitializationbyleveragingthestable ThishierarchicalstructureensuresthatHMKcan\\nconvergencepropertiesofRBFandMahalanobis adapt to various data characteristics, promoting\\nkernels alongside the expressive power of Poly- bothrobustandefficientconvergence.\\nnomial and Spectral kernels. The hierarchical\\nweighting factors τ and τ allow HMK to dy-\\n1 2\\nKeyTakeaways\\nnamicallyadjusttheinfluenceofeachkerneltype,\\nreducingsensitivitytopoorinitializations.\\n• RBFKernel: Idealforscenariosrequiringstable\\nandrapidconvergence. Itsconvexityandsmooth\\nI.27 SummaryofConvergenceProperties\\ngradients make it a dependable choice for many\\nTheanalysisrevealsthateachkernelexhibitsdis- optimizationtasks.\\ntinct convergence behaviors influenced by their\\ninherentproperties: • Polynomial Kernel: Best suited for problems\\nwherecapturinghigh-degreeinteractionsisessen-\\n• RBFKernel: Offersthesmoothestandmoststa- tial. However, care must be taken to manage its\\nbleconvergenceduetoitsconvexandLipschitz non-convexity and gradient complexity, particu-\\ncontinuous gradient. Its simplicity in gradient larlywithhigherdegrees.\\ncomputationandrobustnesstoinitializationmake\\n• SpectralKernel: Effectiveincapturingcomplex,\\nithighlyreliableforgradient-basedoptimization.\\noscillatorypatternswithinthedata. Requirescare-\\n• PolynomialKernel: Suffersfromnon-convexity fulselectionofbasisfunctionsandinitialization\\nandincreasingLipschitzconstantswithhigherde- strategiestomaintainconvergencestability.Table8: ComparisonofGradientConvergencePropertiesforFourKernelsandHMK\\nKernel Smoothness LipschitzGradient GradientSimplicity RobustnesstoInitialization\\nRBF Smooth,Convex High Simple Robust\\nPolynomial Non-Convex(Higherd) Low(Higherd) Complex Sensitive\\nSpectral Oscillatory(Basis-Dependent) Medium Complex(Basis-Dependent) Moderate\\nMahalanobis Smooth(ifΣWell-Conditioned) High(ifΣWell-Conditioned) SimilartoRBF Robust(ifΣWell-Conditioned)\\nHMK PiecewiseSmooth High CompositeofSimpleandComplex HighlyRobust\\n• MahalanobisKernel: Providesflexibilityinmod- kernels: RBF(RadialBasisFunction), Polyno-\\neling by incorporating covariance structure. En- mial,Spectral,andMahalanobis. Foreachkernel\\nsuring that Σ is well-conditioned is crucial for anddivergencemeasure,thefollowingkeyaspects\\nmaintainingsmoothandstableconvergence. areevaluated:\\n• HierarchicalMixtureofKernels(HMK):Com- • Smoothness: Characterizesthelandscapeofthe\\nbines the strengths of all four kernels, offer- losssurfaceinducedbyeachkernelunderthere-\\ningabalancedandrobustconvergencebehavior. spectivedivergencemeasure.\\nHMK’shierarchicalstructureallowsittoadaptto\\n• LipschitzContinuity: Assessesthesmoothness\\nvariousdatacomplexities,ensuringbothstability\\nofgradientchanges,wherehigherLipschitzconti-\\nand expressiveness in gradient-based optimiza-\\nnuityisdesirableforstablegradientdescent.\\ntion.\\n• Gradient Simplicity: Evaluates the complexity\\nDesigningkernelswithfavorableconvergence ofthegradientfunction,impactingcomputation\\npropertiesisessentialforrobustandefficientopti- timeandconvergencespeed.\\nmizationinalignmentlearning. Selectingtheap-\\npropriatekernelbasedonthespecificrequirements • RobustnesstoInitialization: Measuresthesen-\\nof the task and the nature of the data can signifi- sitivity of convergence to the initial weights or\\ncantlyenhancetheperformanceandreliabilityof parameters.\\ngradient-basedlearningalgorithms.\\nFor practical alignment tasks, the choice of KeyObservationsfromTable9:\\nkernelshouldbalancecomputationalcomplexity,\\n• RBFKernel: TheRBFkernelexhibitsthemost\\nconvergence speed, and robustness. Hybrid ap-\\nstablepropertiesacrossalldivergencemeasures.\\nproaches, such as the **Hierarchical Mixture of\\nIt maintains a smooth, convex loss landscape,\\nKernels (HMK)** (Bach et al., 2004), leverage\\nhighLipschitzcontinuity,andsimplelineargra-\\nthestrengthsofmultiplekernelstoachievemore\\ndients. Thesefeaturescontributetorobustcon-\\nstableandgeneralizablelearningoutcomes.\\nvergence,makingitapreferredchoiceinpractical\\nI.28 AnalysisofKernelPropertiesAcross applications.\\nDivergenceMeasures\\n• Polynomial Kernel: The Polynomial kernel’s\\nThis subsection provides a comprehensive anal- propertiesarehighlysensitivetoitsdegreed. For\\nysis of kernel properties across various diver- larged,itbecomesnon-convex,withsharptransi-\\ngence measures, including Kullback–Leibler tionsinitsgradient. Thisincreasesitssusceptibil-\\n(KL), Jensen–Shannon (JS), Hellinger, Rényi itytopoorinitializationandslowerconvergence.\\nDivergence, Bhattacharyya, Wasserstein, and Additionally, its complexity increases as the de-\\nf-Divergence. The focus is on four widely used greedincreases.Table9:ComparisonofKernelsacrossDivergenceMeasures:KL,JS,Hellinger,Rényi,Bhattacharyya,Wasserstein,\\nandf-Divergence\\nKernel Kullback–Leibler(KL) Jensen–Shannon(JS) Hellinger RényiDivergence Bhattacharyya Wasserstein f-Divergence\\nSmoothandConvex SmoothandConvex SmoothandConvex SmoothandConvex SmoothandConvex SmoothandConvex SmoothandConvex\\nRBF H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy H Si ig mh pL lei ,p Lsc inh eit az rC Go rn at di in eu ni tt sy\\nRobustandFastConvergence RobustandFastConvergence RobustandFastConvergence RobustandFastConvergence RobustandFastConvergence RobustandFastConvergence RobustandFastConvergence\\nComplexandNon-Convex ComplexandNon-Convex ComplexandNon-Convex ComplexandNon-Convex ComplexandNon-Convex ComplexandNon-Convex ComplexandNon-Convex\\nPolynomial LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd) LowL Nip os nch -Lit iz nC eao rn Gti rn au di it ey n( tH sighd)\\nSensitivetoInitialization SensitivetoInitialization SensitivetoInitialization SensitivetoInitialization SensitivetoInitialization SensitivetoInitialization SensitivetoInitialization\\nOscillatory Oscillatory Oscillatory Oscillatory Oscillatory Oscillatory Oscillatory\\nSpectral MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent) MediumLipsch Ci otz mC po len xti Gnu ri at dy ie(B nta ssis-Dependent)\\nModerateSensitivity ModerateSensitivity ModerateSensitivity ModerateSensitivity ModerateSensitivity ModerateSensitivity ModerateSensitivity\\nSmooth(likeRBF) Smooth(likeRBF) Smooth(likeRBF) Smooth(likeRBF) Smooth(likeRBF) Smooth(likeRBF) Smooth(likeRBF)\\nMahalanobis HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF) HighL Si ip ms ic lh ai rtz toC Ro Bnt Fin Gui rt ay d( ieli nk te sRBF)\\nRobust(Well-ConditionedΣ) Robust(Well-ConditionedΣ) Robust(Well-ConditionedΣ) Robust(Well-ConditionedΣ) Robust(Well-ConditionedΣ) Robust(Well-ConditionedΣ) Robust(Well-ConditionedΣ)\\nPiecewiseSmooth PiecewiseSmooth PiecewiseSmooth PiecewiseSmooth PiecewiseSmooth PiecewiseSmooth PiecewiseSmooth\\nHMK Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity Hig Ch omLi pp os sc ih teitz GC rao dn ieti nn tu sity\\nHighlyRobust HighlyRobust HighlyRobust HighlyRobust HighlyRobust HighlyRobust HighlyRobust\\n• SpectralKernel: TheSpectralkernel’sbehavior it well-suited for graph-based data, whereas the\\nis highly dependent on the choice of basis func- Mahalanobiskerneloffersflexibilityinmodeling\\ntions ϕ (y). For certain bases, such as wavelets, anisotropic similarities, provided that the covari-\\ni\\nthelosslandscapebecomesoscillatory,andcon- ancematrixΣiswell-conditioned.\\nvergencedependsonthealignmentoftheinitial- TheHMKstandsoutbyintegratingmultipleker-\\nizationwiththebasisfunctions. nelstobalancetheirrespectivestrengthsandmiti-\\ngatetheirweaknesses. Thishierarchicalapproach\\n• Mahalanobis Kernel: The Mahalanobis kernel\\nensuresthattheoptimizationprocessremainsro-\\nbehaves similarly to the RBF kernel when Σ =\\nbustandefficientacrossdiversedatadistributions\\nI. Forwell-conditionedΣ,itspropertiesremain\\nanddivergencemeasures.\\nstable and akin to the RBF kernel. However, if\\nΣisill-conditioned,thelosslandscapebecomes RecommendationsforKernelSelection:\\nanisotropic,leadingtoconvergenceslowdowns\\n• RBF Kernel: Use when stability and simplic-\\ninspecificdirections.\\nityareparamount,andthedataexhibitssmooth,\\n• HierarchicalMixtureofKernels(HMK):HMK isotropicpatterns.\\ncombinesthestrengthsofallfourkernels,achiev-\\n• PolynomialKernel: Optforwhenmodelinghigh-\\ningabalancedconvergencebehavior. Itbenefits\\ndegreeinteractionsisessential,keepinginmind\\nfrom the smoothness and stability of the RBF\\ntheneedforcarefulparametertuning.\\nandMahalanobiskernelswhileincorporatingthe\\nexpressivepowerofthePolynomialandSpectral\\n• SpectralKernel: Chooseforapplicationsinvolv-\\nkernels. ThishierarchicalstructureallowsHMK\\ning graph-based data or scenarios requiring the\\ntoadapttovariousdatacharacteristics,promoting\\ncaptureofoscillatoryrelationships.\\nbothrobustandefficientconvergence.\\n• Mahalanobis Kernel: Select when anisotropic\\nImplicationsforKernelSelection: Thechoice\\nsimilarity measures are necessary, ensuring that\\nofkernelinalignmenttaskssignificantlyimpacts\\nthecovariancematrixiswell-conditioned.\\ntheoptimizationprocess. TheRBFkernelisideal\\nfor scenarios requiring stable and rapid conver-\\n• HMK:Employwhenleveragingthestrengthsof\\ngence due to its smooth and convex properties.\\nmultiplekernelsisadvantageous,providingabal-\\nIn contrast, the Polynomial kernel is suitable for\\nanced approach to handle both local and global\\nmodelingcomplex,high-degreeinteractionsbutde-\\ndependenciesinthedata.\\nmandscarefultuningtomanageitsnon-convexity\\nand gradient complexity. The Spectral kernel Designing kernels with favorable properties\\nexcels in capturing oscillatory patterns, making across different divergence measures is essentialforrobustandefficientoptimizationinalignment stemsfromtheinversionofthecovariancematrix.\\nlearning. Selectingtheappropriatekernelbasedon Its 3-5× relative cost is offset by robust general-\\nthespecificrequirementsofthetaskandthenature izationintasksinvolvinghighlycorrelateddata.\\nof the data can significantly enhance the perfor-\\n• HierarchicalMixtureofKernels(HMK):HMK\\nmance and reliability of gradient-based learning\\ndynamically combines local and global kernels,\\nalgorithms.\\naccumulating the individual costs of its compo-\\nI.29 ComputationalOverheadof nents. While offering the best generalization,\\nDPO-Kernels itscomputationaldemandsare3–4×higherthan\\nDPO for simple configurations, with costs esca-\\nThe computational complexity of DPO-Kernels\\nlatingfurtherdependingonthenumberofkernels\\nstemsfromtheintegrationofdiversekernelsand\\nused.\\ndivergencemeasures,eachintroducinguniquebot-\\ntlenecksandcomputationaldemands. Thissection Divergence Measures: Stability vs. Complex-\\nprovidesananalysisofthesecostsbasedonkernel ity The divergence regularizers integrated into\\nanddivergencecharacteristics,assummarizedin DPO-Kernelsintroduceadditionalcomputational\\nTables10and11. overhead,buttheyaregenerallylessintensivethan\\nkerneloperations:\\nKernels: BalancingFlexibilityandCost The\\nuseofkernelizedrepresentationssignificantlyen-\\n• Low-CostDivergences: KLdivergence,Jensen-\\nhancesalignmentflexibilitybutincursvaryingde-\\nShannon,Bhattacharyya,Rényi,andHellingerdi-\\ngreesofcomputationalandmemoryoverhead: vergencesexhibitlineartimecomplexity(O(m)),\\nwithrelativecostsrangingfrom1×to1.5×.These\\n• RBF Kernel: With a linear time and memory\\nmeasures are efficient and versatile, suitable for\\ncomplexityofO(m),theRBFkernelisefficient\\nmostalignmenttasks.\\nandwidelyapplicable. Itincursarelativecostof\\n1.3×comparedtostandardDPOwhilemaintain-\\n• High-CostDivergences: Wassersteindivergence,\\ninghighgeneralization. Thismakesitthedefault requiringO(m3)timeandO(m2)memorycom-\\nchoicefortasksrequiringfine-grained,localalign-\\nplexity,isthemostcomputationallyintensivedue\\nment.\\ntooptimaltransportcalculations. Despiteitsrel-\\nativecostof3–4×,itishighlyeffectivefortasks\\n• Polynomial Kernel: The computational cost of\\ninvolvingsignificantdistributionalshifts.\\nthis kernel increases with its degree d, resulting\\nin O(md) complexity. While its relative cost KeyInsightsandRecommendations\\nrangesfrom1.2–1.5×,itssusceptibilitytooverfit-\\n• BalancingCostandPerformance: Forresource-\\ntinglimitsitsgeneralizability,makingitsuitable\\nconstrainedsettings,RBFandPolynomialkernels\\nfordatasetswithnonlineardependencies.\\ncombined with low-cost divergences like KL or\\n• Spectral Kernel: Leveraging eigen decomposi- Jensen-Shannon offer a pragmatic trade-off be-\\ntionortheNyströmmethod,thiskernelachieves tweencomputationalefficiencyandalignmentper-\\nglobal structural alignment at the expense of formance.\\nO(m2)timeandmemorycomplexity. Witharel-\\n• ScalabilityofHMK:Thesignificantoverheadof\\native cost of 2–3×, it is ideal for tasks requiring\\nHMKnecessitatesexplorationofapproximation\\nbroad,globalrelationships.\\ntechniques like Random Fourier Features (RFF)\\n• MahalanobisKernel: Themostcomputationally orNyströmmethodstoreducecomputationalde-\\nexpensive kernel, with O(m3) time complexity, mandswhilepreservingperformance.Kernel TimeComplexity MemoryComplexity KeyBottleneck RelativeCost(vs.DPO) Generalization UseCase\\nRBF O(m) O(m) Euclideandistancecomputation Low(1.3x) High DefaultChoice\\nPolynomial O(md) O(m) Computationof(u⊤v+c)d Low(1.2-1.5x) RiskofOverfitting NonlinearDatasets\\nSpectral O(m2) O(m2) Eigendecomposition(orNyström) Medium(2-3x) High GlobalStructure\\nMahalanobis O(m3) O(m2) InvertingΣandprojection High(3-5x) High CorrelatedData\\nHMK Dependson#ofKernels Sumofeachkernel’scost Linearcombinationofkernels VeryHigh(3-4x) Best GeneralPurpose\\nTable10: SummaryofKernelCharacteristics: TimeComplexity,MemoryComplexity,Bottleneck,Computational\\nCost,Generalization,andUseCases.\\nDivergence TimeComplexity Memory Com- KeyBottleneck RelativeCost\\nplexity\\nKLDivergence O(m) O(m) Logarithmanddivisionon Low(1x)\\nelements.\\nJensen-Shannon O(m) O(m) Computeaveragedistribu- Low(1.2x)\\ntionandKL.\\nWasserstein O(m3) O(m2) Optimal transport High(3-4x)\\n(Sinkhorn) computa-\\ntion.\\nRényi O(m) O(m) Powersanddivisionsfor Low(1.5x)\\neachelement.\\nBhattacharyya O(m) O(m) Logarithmiccomputation Low(1.3x)\\nofcoefficient.\\nHellinger O(m) O(m) Squarerootonprobability Low(1.3x)\\nelements.\\nf-Divergence O(m) O(m) Apply any convex func- Low(1.2x)\\ntionftotheratiop.\\nq\\nTable11: ComputationalCostAnalysisforDivergenceFunctions.\\n• Task-Specific Optimization: Divergence selec- J.1 EfficacyofHybridLoss\\ntion should align with task complexity, leverag-\\nMotivationandDesign: TheHybridLossisde-\\ningefficientmeasureslikeHellingerforstandard\\nsignedtocombinethebenefitsofprobability-based\\nalignmentandWassersteinforcomplexdistribu-\\nloss(whichfocusesonprobabilityalignment)and\\ntionalshifts.\\nembedding-basedloss(whichcapturesstructural\\nalignment). Byleveragingbothperspectives,the\\nAddressing these computational challenges is\\nHybridLossaimstoachievebettergeneralization,\\ncritical for scaling DPO-Kernels to real-world,\\nespeciallyintaskswherealignmentrequiresmulti-\\nmultimodal, and large-scale alignment tasks (Ta-\\nscaleadaptation.\\nbles10and11).\\nTheoretical Justification: The Hybrid Loss\\nL isdefinedas:\\nJ Results&Analysis Hybrid\\nL = αL +(1−α)L\\nThissectionprovidesadetailedanalysisoftheper- Hybrid Probability Embedding\\nformanceofourproposedapproach,focusingon whereα ∈ [0,1]isalearnablecoefficientthatcon-\\ntheefficacyofHybridLoss,theroleofDivergence- trolsthebalancebetweenthetwocomponents. The\\nbasedregularizers,andtheimpactofSafetyFine- probability-basedlossiseffectiveforfine-grained\\nTuning. Eachsubsectiondelvesintothequantita- preference alignment, while the embedding loss\\ntiveandqualitativeaspectsoftheproposedmeth- capturessemanticstructure.\\nods,supportedbytheoreticalanalysisandempiri- EmpiricalEvidence: Weconductexperiments\\ncalresults. across13datasetswithvaryinglevelsofcomplex-Epoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nDPO-Probability DPO-Probability DPO-Probability DPO-Probability DPO-Probability DPO-Probability\\n2 1 12 1 1 2\\n0 0 0 0 0 0\\n1 1 1 1\\n1 0 1 2 0 2 1 0 1 1 0 1 2 0 2 1 0 1 2 1 0 1 1 0 1 2 0 2 2 0 2 1 0 1 1 0 1\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nDPO-Hybrid DPO-Hybrid DPO-Hybrid DPO-Hybrid DPO-Hybrid DPO-Hybrid\\n2 1 1 1 1 1\\n0 0 0 0 0 0\\n1 1 1 1\\n1 0 1 2 0 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 1 0 1 0 2 1 0 1 0 1 2 1 0 2 1 0\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nDPO-Hybrid (RBF Kernel) DPO-Hybrid (RBF Kernel) DPO-Hybrid (RBF Kernel) DPO-Hybrid (RBF Kernel) DPO-Hybrid (RBF Kernel) DPO-Hybrid (RBF Kernel)\\n2 1 1 1 1 1\\n0 0 0 0 0 0\\n1 1 1 1\\n1 0 1 2 0 2 2 1 0 1 2 1 0 2 0 2 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\\nFigure22: EvolutionofLLMLogitsAcrossEpochsforDPO-ProbabilityLoss,DPO-HybridLoss,andDPO-\\nHybrid(RBFKernel)Loss. Thisfigurepresentstheevolutionoflogits,treatedasembeddings,atsixkeyepochs\\n(0,40,80,120,160,200)forthreealignmentmethoRedjesc:teDd PO-PSreolebctaebdilityLoss,DPO-HybridLoss,andDPO-Hybrid\\n(RBFKernel)Loss. Thelogitsareprojectedintoa3Dspaceusingt-SNE(vanderMaatenandHinton,2008)\\nappliedtothealignmentspace,whereredpointsrepresentrejectedsamplesandgreenpointsrepresentselected\\nsamples. Atepoch0,allmethodsshareidenticalembeddings. Astrainingprogresses,DPO-ProbabilityLossshows\\nmodestclusteringimprovements. Incontrast,DPO-HybridLossachievesbetterseparationbetweenselectedand\\nrejectedsamples,withnotableimprovementsafterepoch80. TheDPO-Hybrid(RBFKernel)Lossachievesthe\\nmostpronouncedclustering,withsignificantlytighterandmoredistinctgroupingsofredandgreenpointsdueto\\ntheenhancedcapacityofRBFkernelstomodelnonlinearseparations. Thisvisualizationhighlightsthesuperior\\nalignmentcapabilitiesofDPO-Hybrid(RBFKernel)LosscomparedtoDPO-HybridLossandDPO-Probability\\nLoss.ity(e.g.,factuality,reasoning,andsafety). Fig.23 Mahalanobis. Using gradient vector fields and\\nshowstheperformanceofHybridLosscompared contourplots,wehighlightthekeyoptimizationbe-\\ntobaselinemethods. TheHybridLossconsistently haviorsassociatedwitheachkernel. Theseinsights\\noutperformsbothstandaloneprobabilityandem- elucidate why certain kernels are more effective\\nbeddinglosses,withanaveragerelativeimprove- for stable and efficient optimization in machine\\nmentof9.2%. Thisdemonstratesthecomplemen- learningtasks.\\ntarynatureofthetwolosscomponents.\\nK.1 VisualizationofGradientFieldsand\\nJ.2 EfficacyofDivergence-Based ContourPlots\\nRegularizers\\nFigure25illustratesthegradientfieldsoverlaidon\\nOverview: Divergence-basedregularizersarecru- thecontourplotsforthelosslandscapesinduced\\ncialinaligningmodel-generateddistributionswith by the four kernels. The following observations\\nhuman-preferreddistributions. Weexploreseveral provideinsightsintothebehaviorofeachkernel:\\ndivergencemeasures,includingKullback-Leibler\\n(KL),Jensen-Shannon(JS),Hellinger,Rényi,Bhat- • RBFKernel:\\ntacharyya,andWassersteindivergences.\\nMathematicalFormulation: Giventwodistri- – Smoothness: Thecontoursareisotropic,forming\\nbutionsP andQ,thedivergence-basedregulariza- circularbasinsofattraction.\\ntiontermR Divergence isdefinedas: – GradientBehavior: Gradientsguidetheparame-\\nterssteadilytowardtheglobalminimum,promot-\\nn\\n(cid:88)\\nR = D(P ∥Q ) ingstableandfastconvergence.\\nDivergence i i\\ni=1 – Suitability: Idealfortaskswithsmoothandcon-\\nvex loss landscapes, as supported by theoreti-\\nwhereD(P∥Q)canbeanyoftheaforementioned\\ncal guarantees for convergence (Schölkopf and\\ndivergencemeasures.\\nSmola,2002).\\nEmpiricalAnalysis: Toevaluatetheefficacyof\\neachdivergence,wemeasurethealignmentscore\\n• PolynomialKernel:\\n(AS)onmultipledatasets. Fig.24illustratesthat\\nWasserstein divergence achieves the best perfor- – Non-Convexity: Thecontoursexhibitsharptran-\\nmance due to its ability to consider distance in sitions and irregular regions, creating multiple\\ntheprobabilityspace,unlikeKLorJSwhichmay localminima.\\nsufferfromzero-probabilityissues.\\n– Gradient Behavior: Gradients are chaotic in\\nTakeaway: Wasserstein divergence offers the\\nregions with high curvature, causing sensitivity\\nmostconsistentperformancegainsacrossdatasets.\\ntoinitialization.\\nThissupportstheclaimthatWasserstein’sabilityto\\nmodelthe\"distance\"betweendistributionsmakes – Suitability: Effective for problems requiring\\nitmoresuitableforalignmenttasksthantheKLor higher-orderfeatureinteractions,thoughsensitive\\nJSdivergences. tohyperparameterchoiceslikedegreed(Shawe-\\nTaylorandCristianini,2004).\\nK GradientDescentDynamicson\\nKernel-InducedLossLandscapes • SpectralKernel:\\nInthissection,weanalyzethegradientdescentdy- – OscillatoryNature: Thecontoursarehighlyde-\\nnamicsonlosslandscapesinducedbyfourwidely- pendent on the choice of basis functions ϕ , re-\\ni\\nused kernels: RBF, Polynomial, Spectral, and sultinginoscillations.DPO (Cons. Loss D) PO (Hybrid L Po os ls y) nomial (Con Ps.\\no\\nlL yo ns os m) ial (Hybrid L Ro Bss F) (Cons. Loss) RBF (Hybrid Lo Sss p) ectral (Cons. L So ps es c) tral (Hybri Md aL ho as ls a) nobis (Co Mn as.\\nh\\naL lo as ns o) bis (Hy Kb er ri nd eL\\nl\\no Ms is x) ture (C Keo rn ns e.\\nl\\nL Mo is xs t) ure (Hybrid H L Mo Ks s () Cons. Loss H) MK (Hybrid Loss)\\nytilautcaF\\ngninosaeRssenlufhturT\\nytefaS\\ngniwolloF\\n.rtsnI\\nllarevO\\n0.57 0.60 0.62 0.66 0.73 0.68 0.71 0.63 0.65 0.73 0.66 0.73 0.78 0.80\\n1.0\\n0.55 0.58 0.60 0.62 0.68 0.72 0.66 0.69 0.61 0.63 0.68 0.72 0.72 0.75\\n0.9\\n0.74 0.77 0.79 0.82 0.86 0.89 0.86 0.88 0.80 0.83 0.86 0.89 0.91 0.94\\n0.8\\n0.92 0.95 0.97 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.7\\n0.6\\n0.54 0.57 0.59 0.61 0.66 0.69 0.65 0.68 0.60 0.62 0.66 0.69 0.71 0.74\\n0.5\\n0.66 0.69 0.71 0.74 0.78 0.79 0.77 0.77 0.73 0.76 0.78 0.79 0.82 0.85\\nerocS\\n1F\\nFigure23: HeatmapdepictingF1scoresacrossvariouskernelsandlossfunctionsforalignmenttasks. Theyellow\\nbordersindicatethebest-performingkernelsforeachtask,whilebluebordershighlightthesecond-bestperformers.\\nScoresareevaluatedfortaskssuchasFactuality,Reasoning,Truthfulness,Safety,andInstructionFollowing,with\\nanoverallassessmentsummarizedinthelastrow. TheHMK(HybridLoss)kernelconsistentlydemonstratestop\\nperformanceinmultipletasks.\\n– Gradient Behavior: Gradients exhibit abrupt Polynomial and Spectral kernels introduce non-\\nchangesindirection,slowingconvergenceinre- convexity and oscillations, requiring careful ini-\\ngionsofhighoscillation. tializationandhyperparametertuning.\\n– Suitability: Usefulfordatawithinherentperiod-\\n• Directional Dependencies: The Mahalanobis\\nicityorhierarchicalstructures(Ngetal.,2001).\\nkernel adapts to feature correlations through Σ,\\nwhereastheRBFkernelprovidesisotropicbehav-\\n• MahalanobisKernel:\\nior. Spectralkernelgradientsalignwiththechosen\\n– Anisotropy: The contours are elongated along basisfunctions,offeringflexibilityatthecostof\\ncertaindirections,determinedbythecovariance stability.\\nmatrixΣ.\\n• OptimizationChallenges: PolynomialandSpec-\\n– GradientBehavior: Gradientsarewell-aligned\\ntral kernels require additional regularization or\\nwith the anisotropic structure, ensuring robust\\ninitialization strategies to mitigate sensitivity to\\nconvergencewhenΣiswell-conditioned.\\nlocalminimaandoscillations.\\n– Suitability: Well-suitedfortaskswithcorrelated\\nfeatures or structured data distributions (Wein- Thecontourplotsandgradientfieldsrevealhow\\nbergerandSaul,2009). kernel-inducedlosslandscapesshapegradientde-\\nscent dynamics. The RBF and Mahalanobis ker-\\nK.2 InsightsfromGradientFields\\nnels are robust choices for stable optimization,\\n• Smoothness and Stability: RBF and Maha- while Polynomial and Spectral kernels provide\\nlanobis kernels provide smooth and stable land- flexibility at the expense of increased sensitivity\\nscapes, favoring robust and fast convergence. andpotentialinstability. TheseinsightsunderscoreFactuality\\nReasoning\\nTruthfulness\\nSafety\\nInstruction Following\\nOverall\\nDPO + K DL P DO P+ O JS + D Helli Dn D Pg Pe O Or + + BR hé an t Dtyi Pac O h +a ry W Dy a Pa ss O er + s ft -e di in ve Pr olg ye nnc oe m Pi oa ll P y on l+ o yK nmL i oal m ia+ l J PS + P o loD lH yye nl nl oi on mimg i ae la lr P + o l+ yBR nhé oan t mty i Pi a a oc l l h y+a n r oy Wy ma ia s as l er + s ft -e di in vergence RBF + K RL BF R B+ F JS + D Hellin RRg BBe F Fr + + BR hé an t Rtyi a Bc F h +a ry W Ry aa Bss F er + s ft -e di in verg Se pn ec ce tral S p+ e ScK ptL er ca tl ra+ l JS + D SH S pel p eli e cc tn t rg r ae la lr + + SBR phé ea cn t tty ri a ac l Sh + pa r ey cW ty a ra s as l er + s ft -e di in v Me ar hg ale anc n Me o abi h Ms a a l ha+ an lK o aL b ni os bi+ s M J M aS + a h hD aH lale al al ni n on o bg ibi Me s sr a + h + alBR ahé nan t o Mty abi a i hc s ah l+a a r ny W oy a ba s is s er + s ft -e di in vergenc He MK + K HL M HK M+ K JS + D Helli Hn H Mg Me K Kr + + BR hé an t Htyi Mac K h +a ry W Hy a Ma ss K er + s ft -e di in vergence\\nKernel Type + Divergence\\nsmoixA\\ntnemngilA\\nDPO Polynomial RBF Spectral Mahalanobis HMK 1.0\\n0.600.590.620.610.610.620.610.660.660.680.680.670.680.650.680.690.690.700.690.700.680.630.630.650.650.640.650.640.730.740.750.750.750.760.740.760.770.780.780.780.790.77 0.9\\n0.580.580.600.590.590.600.590.620.620.630.630.630.640.610.720.730.740.740.740.740.710.690.690.710.700.710.710.690.630.630.650.640.650.660.630.730.730.750.750.750.760.72\\n0.770.760.790.790.790.800.760.820.830.840.840.840.850.810.890.880.910.910.920.920.890.880.900.900.900.900.910.900.830.840.850.850.850.860.820.920.910.940.940.940.960.94 0.8\\n0.950.940.970.970.970.960.950.980.960.970.980.970.970.980.980.960.960.980.970.960.960.980.960.960.980.980.980.960.980.970.980.970.960.980.980.980.960.980.980.980.970.97 0.7\\n0.570.570.590.590.590.590.560.610.610.620.630.630.630.610.690.690.710.710.710.720.690.680.680.700.700.700.710.690.620.610.630.640.630.640.630.720.720.740.740.730.740.72\\n0.690.690.710.710.710.710.690.740.740.750.750.750.750.730.790.790.800.810.810.810.790.770.770.780.790.790.790.780.760.760.770.770.770.780.760.820.820.840.840.840.840.82 0.6\\n0.5\\nerocS\\n1F\\nFactuality\\nReasoning\\nTruthfulness\\nSafety\\nInstruction Following\\nOverall\\nDPO + KL DPO D+ PJ OS D + Helling De Dr P PO O + + R Bé hn ayi tta Dc Ph Oa r +y y Wa as Ds Pe Or s +t e fi -n diver Pg oe ln yc ne omia Pl ol+ y n PK o oL lm yi nal o m+ i J alS D + PH Poe ll ol lyi ynn nog oe mir mial a l + +\\nP\\nR oBé lhn yay ni t ota mc ih al Pa or l+y yy nWa oas ms ie alr s +t e fi -n divergence RBF + KL RBF R+ BJ FS D + Hellinge Rr RB BF F + + R Bé hn ayi tta Rc Bh Fa r +y y Wa as Rs Be Fr s +t e fi -n divergence\\nKernel Type + Divergence\\nsmoixA\\ntnemngilA\\nDPO Polynomial RBF Kernel Performance: DPO, Polynomial, RBF\\n0.60 0.60 0.62 0.61 0.61 0.62 0.61 0.66 0.65 0.68 0.68 0.67 0.69 0.65 0.68 0.69 0.70 0.69 0.70 0.70 0.67\\n0.58 0.57 0.59 0.60 0.60 0.60 0.58 0.62 0.62 0.63 0.63 0.64 0.64 0.61 0.72 0.72 0.74 0.74 0.74 0.74 0.73 1.0\\n0.9\\n0.77 0.77 0.79 0.79 0.79 0.79 0.77 0.82 0.83 0.84 0.84 0.84 0.84 0.83 0.89 0.88 0.91 0.91 0.90 0.93 0.87\\n0.8\\n0.7 0.95 0.96 0.97 0.98 0.97 0.96 0.94 0.98 0.98 0.97 0.96 0.97 0.96 0.96 0.98 0.97 0.98 0.96 0.96 0.98 0.97\\n0.6\\n0.57 0.58 0.58 0.58 0.59 0.59 0.58 0.61 0.62 0.63 0.62 0.62 0.63 0.61 0.69 0.70 0.70 0.71 0.70 0.72 0.70 0.5\\n0.69 0.70 0.71 0.71 0.71 0.71 0.70 0.74 0.74 0.75 0.75 0.75 0.75 0.73 0.79 0.79 0.81 0.80 0.80 0.81 0.79\\nerocS\\n1F\\nFactuality\\nReasoning\\nTruthfulness\\nSafety\\nInstruction Following\\nOverall\\nSpectral S+ pK eL c Str pa el ct+ r J alS D + Hel Sli Spn peg ecte crr tral a l + + R Bé h Sn a pyi t et ca tc rh ala r +y\\nS\\ny pWa ea cs trs ae lr s +t e fi -n dive Mr ag he an lc ae no Mbi as ha+ l\\nM\\na aK n hL o alb ais n o+ b iJ sS D + M MaH ahel hal li alan ang noe or bi bis s +\\nM\\n+\\na\\nR hBé ahn lay ai tt na oc b Mih s aa hr + ay ly aWa na oss bie sr s +t e fi -n divergence HMK + KL HMK H+ MJ KS D + Helling He Hr M MK K + + R Bé hn ayi tt Hac Mh Ka r +y y Wa a Hss Me Kr s +t e fi -n divergence\\nKernel Type + Divergence\\nsmoixA\\ntnemngilA\\nDPO Polynomial RBF\\nKernel Performance: Spectral, Mahalanobis, HMK\\n0.63 0.64 0.65 0.64 0.65 0.66 0.62 0.73 0.72 0.75 0.75 0.75 0.76 0.72 0.76 0.76 0.78 0.78 0.78 0.78 0.75\\n0.69 0.68 0.71 0.70 0.71 0.72 0.68 0.63 0.62 0.64 0.65 0.65 0.65 0.64 0.73 0.74 0.75 0.75 0.74 0.76 0.72 1.0\\n0.9\\n0.88 0.89 0.91 0.90 0.91 0.90 0.86 0.83 0.83 0.85 0.85 0.85 0.86 0.83 0.92 0.91 0.94 0.95 0.94 0.95 0.93\\n0.8\\n0.7\\n0.97 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.96 0.97 0.98 0.97 0.97 0.96 0.96 0.98 0.98 0.98 0.96\\n0.6\\n0.68 0.67 0.69 0.70 0.70 0.70 0.68 0.62 0.61 0.64 0.63 0.63 0.64 0.63 0.72 0.72 0.74 0.74 0.74 0.75 0.72 0.5\\n0.77 0.77 0.79 0.78 0.79 0.79 0.76 0.76 0.75 0.77 0.77 0.77 0.78 0.76 0.82 0.82 0.83 0.84 0.84 0.84 0.82\\nerocS\\n1F\\nFigure24: Heatmapsillustratingtheperformanceofkernel-divergencecombinationsacrossalignmenttasks. The\\nfirstheatmappresentsthecompleteview,showcasingallkernels(DPO,Polynomial,RBF,Spectral,Mahalanobis,\\nHMK)pairedwithdivergences(KL,JSD,Hellinger,Rényi,Bhattacharyya,Wasserstein,f-divergence). Thesecond\\nandthirdheatmapssplitthedataforclarity,focusingonthefirstthreekernels(DPO,Polynomial,RBF)andthe\\nlastthreekernels(Spectral,Mahalanobis,HMK),respectively. Eachrowrepresentsatask(Factuality,Reasoning,\\nTruthfulness,Safety,InstructionFollowing),whilethe\"Overall\"rowaggregatesaverageperformance. Yellowand\\nbluebordershighlightthebestandsecond-best-performingkernel-divergencecombinationsforeachtask.the importance of kernel selection in achieving\\nefficientandeffectiveoptimizationfordiversema-\\nchinelearningtasks.\\nL Score-BasedAnalysisofCluster\\nSeparation\\n(Jain et al., 2024a) shows that safety fine-tuning\\nakaalignmentminimallyadjustsMLPweightsin\\nLLMstoprojectunsafeinputsintothenullspace\\noftheweightmatrices. Thisprocessinducesadis-\\ntinct clustering of inputs, separating them based\\non safety status. Our analysis focuses on how\\ntheseclustersevolveduringtrainingandevaluates\\ntheirseparationusingtheDavies-BouldinScore\\n(DBS),astandardmetricforclusterquality. Lower\\nDBS values indicate better clustering, character-\\nizedbycompactintra-clusterdistancesandlarge\\ninter-clusterseparations.\\nL.1 IntroductiontoDavies-BouldinScore\\n(DBS)\\nThe Davies-Bouldin Score (DBS) is a widely\\nFigure25: Contourplotsoverlaidwithgradientdescent adopted metric in unsupervised and semi-\\nfields for different kernels. Each plot illustrates the supervisedlearningforevaluatingclusteringper-\\ngradient dynamics and loss landscape for the respec- formance (Davies and Bouldin, 1979). It effec-\\ntivekernels: (Top-left)RBFKernel,showingsmooth,\\ntivelymeasuresthebalancebetweenintra-cluster\\nisotropicgradientsguidingefficientconvergence;(Top-\\ncompactnessandinter-clusterseparation. Alower\\nright)PolynomialKernel,exhibitingsharptransitions\\nDBS is preferable, as it implies that clusters are\\nandchaoticgradientsinnon-convexregions;(Bottom-\\nleft)SpectralKernel,characterizedbyoscillatorycon- bothtightlypackedandwell-separated.\\ntours and abrupt gradient changes aligned with basis\\nL.1.1 Definition\\nfunctions;(Bottom-right)MahalanobisKernel,demon-\\nstratinganisotropicgradientsalignedwiththecovari- Forasetofk clusters{C 1,C 2,...,C k},theDBS\\nance structure, ensuring robust optimization when Σ ismathematicallydefinedas:\\niswell-conditioned. Redarrowsrepresentthegradient\\nk (cid:18) (cid:19)\\nvectors,highlightingthedirectionandintensityofopti- 1 (cid:88) S i+S j\\nDBS = max\\nmizationstepsacrossthelosslandscape. k j̸=i D ij\\ni=1\\nwhere:\\n• S : Averageintra-clusterdistanceforclusterC ,\\ni i\\ngivenby:\\n1 (cid:88)\\nS = ∥x−µ ∥\\ni i\\n|C |\\ni\\nx∈Ci\\nwhereµ isthecentroidofclusterC .\\ni i• D : Distance between the centroids of clusters Table 12: Cluster Separation Measured by Davies-\\nij\\nBouldinScoreforDPOMethods(LowerisBetter).\\nC andC ,calculatedas:\\ni j\\nEpochs DPO-Probability DPO-Hybrid DPO-Hybrid(RBFKernel)\\nD = ∥µ −µ ∥\\nij i j 0 2.15 2.08 2.01\\n40 1.94 1.84 1.75\\n80 1.75 1.62 1.43\\nL.1.2 IntuitionBehindDBS 120 1.62 1.43 1.20\\n160 1.45 1.26 1.10\\nTheDBSprovideskeyinsightsintotheclustering 200 1.32 1.15 0.92\\nprocess:\\n• DiffuseClusters: Ahighintra-clusterscatter(S i) Tofurtherassessthegeneralizationcapabilities,\\nresultsinahighDBS,penalizingpoorlyformed weanalyzedfivekerneltypes—Polynomial,Spec-\\nclusters. tral,RBF,Mahalanobis,andHierarchicalMixture\\nofKernels(HMK)—acrossepochs. Table13cap-\\n• Cluster Overlap: A low inter-cluster distance\\ntures the DBS results for each kernel, highlight-\\n(D )increasestheDBS,penalizingclustersthat\\nij ingtheexceptionalperformanceofHMK,which\\naretooclosetooneanother.\\nconsistentlyachievesthelowestscores,signifying\\nIn the context of alignment learning, a lower compact and well-separated clusters. THe Find-\\nDBSiscriticalforachieving: ingsisvisuallysummarizedinFigure26.\\n• ClearerDecisionBoundaries: Betterseparation\\nTable 13: Cluster Separation Measured by Davies-\\nbetween safe and unsafe clusters enables more\\nBouldinScoreforKernelMethods(LowerisBetter).\\nprecisebehaviorcontrol.\\nEpochs Polynomial Spectral RBF Mahalanobis HMK\\n• ImprovedGeneralization: Well-separatedclus- 0 2.25 2.10 2.01 2.02 1.90\\n40 2.12 1.95 1.84 1.85 1.65\\ntersreduceambiguities,enhancingmodelperfor-\\n80 1.95 1.80 1.65 1.63 1.28\\nmanceonunseendata. 120 1.85 1.65 1.45 1.40 1.05\\n160 1.72 1.50 1.25 1.20 0.95\\n• Increased Robustness: Compact and well- 200 1.60 1.35 1.10 1.05 0.80\\nseparatedclustersarelesssensitivetooutliersand\\nnoisydata.\\nL.1.3 ResultsAnalysis M Heavy-TailedSelf-Regularization\\n(HT-SR)TheoryandGeneralization\\nThe evaluation of the three alignment\\napproaches—DPO-Probability Loss, DPO-\\nHybrid Loss, and DPO-Hybrid (RBF Kernel) The Heavy-Tailed Self-Regularization (HT-SR)\\nLoss—shows distinct cluster behaviors across theoryprovidesastatisticalmechanicsframework\\ntraining epochs. The results are quantified to analyze the weight matrices of Deep Neural\\nusing DBS and reported in Table 12, Figure 22 Networks(DNNs). Itdemonstratesthattheeigen-\\nvisually summarizes clustering effect accross valuespectraoftheweightmatricesoftenfollow\\nDPO-Probability Loss, DPO-Hybrid Loss, and heavy-taileddistributions,whichareindicativeof\\nDPO-Hybrid (RBF Kernel) Loss. As training self-organized criticality and implicit regulariza-\\nprogresses, the DPO-Hybrid (RBF Kernel) tionduringoptimization. Thisbehaviorsuggests\\nachieves the lowest DBS, reflecting its superior thattheweightmatricescapturecorrelationsacross\\nability to distinguish between safe and unsafe multiplescales,whichisakeyfactorinenhancing\\nclusters. generalizationcapabilities(Martinetal.,2021b).Epoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nPolynomial Kernel Polynomial Kernel Polynomial Kernel Polynomial Kernel Polynomial Kernel Polynomial Kernel\\n012\\n1\\n01\\n1\\n001 10...\\n.0\\n.50\\n05\\n001 0...\\n0\\n.50\\n5\\n01\\n1\\n01\\n1\\n1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 1 0 1 1 0 1 1 0 1 0 1 2 1 0 2 1 0\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nSpectral Kernel Spectral Kernel Spectral Kernel Spectral Kernel Spectral Kernel Spectral Kernel\\n2 1 01 .. 50 1.0 1 1\\n01 0 0 0.0\\n.5\\n00 .. 05 0 0\\n1 1 1.0 0.5 1 1\\n1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 1 2 1 0 2 1 0 1 0 1 2 1 0 2 1 0\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nRBF Kernel RBF Kernel RBF Kernel RBF Kernel RBF Kernel RBF Kernel\\n012\\n1\\n01\\n1\\n001 10...\\n.0\\n.50\\n05\\n001 0...\\n0\\n.50\\n5\\n01\\n1\\n01\\n1\\n1 0 1 2 1 0 1 2 2 1 0 1 2 1 0 3 2 1 0 2 1 0 1 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nMahalanobis Kernel Mahalanobis Kernel Mahalanobis Kernel Mahalanobis Kernel Mahalanobis Kernel Mahalanobis Kernel\\n012\\n1\\n01\\n1\\n001 10...\\n.0\\n.50\\n05\\n01\\n1\\n01\\n1\\n01\\n1\\n2 2 2\\n1 1 1 1 1 1\\n1 0 1 210 1 0 1 10 1 0 1 2 10 1 0 1 10 1 0 1 10 0 1 10\\nEpoch 0 Epoch 40 Epoch 80 Epoch 120 Epoch 160 Epoch 200\\nHMK HMK HMK HMK HMK HMK\\n012\\n1\\n001 10...\\n.0\\n.50\\n05\\n001 10...\\n.0\\n.50\\n05\\n001 0...\\n0\\n.50\\n5\\n01\\n1\\n01\\n1\\n2 3 3\\n1 2 2 2 2 2\\n1 0 1 210 0 1 2 01 0 1 2 3 01 0 1 2 01 0 1 2 0 1 0 1 2 01\\nFigure26:Visualizationoftheembeddingevolutionoffivekerneltypes—Polynomial,Spectral,RBF,Mahalanobis,\\nand Hierarchical Mixture of Kernels (HMK)—over six training epochs (0, 40, 80, 120, 160, and 200). Each\\nrowrepresentstheclusteringprogressionforaspecifickernel, withtheredpointsindicatingrejectedsamples\\nand the green points representing selected samples. The HMK demonstrates superior clustering capabilities\\ncomparedtotheotherkernels,exhibitingmorecompactandwell-separatedclusters. Thisvisualizationhighlights\\nthe relative clustering effectiveness of each kernel across epochs, with HMK achieving the most distinct and\\norganizedseparation.M.1 CoreInsightsofHT-SRTheory may be over-parameterized or poorly trained, as\\ntheirweightmatriceslackthedesiredmulti-scale\\n1. EmpiricalSpectralDensity(ESD):Theeigen-\\ncorrelationstructure. Incontrast,weightmatrices\\nvalue distribution ρ(λ) of a weight matrix W is\\nwith optimal α values achieve better generaliza-\\ngivenby:\\ntion by implicitly balancing expressiveness and\\n1 (cid:88)N complexity.\\nρ(λ) = δ(λ−λ ), (3)\\ni\\nN\\nM.3 EmpiricalValidationinDNNs\\ni=1\\nEmpirical studies on architectures like ResNet,\\nwhere{λ }aretheeigenvaluesofW⊤W. HT-SR\\ni\\nDenseNet, and GPT validate HT-SR theory: -\\ntheory posits that ρ(λ) often follows a truncated\\n**ResNet:** Deeper models exhibit smaller and\\npowerlaw:\\nmore stable α values, which correlate strongly\\nρ(λ) ∝ λ−α, forλ ≤ λ ≤ λ . (4) with improved test accuracy and generalization.\\nmin max\\n- **DenseNet:** The excessive connectivity in\\nThe exponent α characterizes the tail behavior, DenseNetmodelsleadstolessfavorablespectral\\nwithsmallerαvalues(α ∈ [2,4])correlatingwith properties,withhigherαvaluesindicatingsubop-\\nbettergeneralization. timalperformance.\\n2. WeightedAlphaMetrics: HT-SRintroduces Forinstance,modelswithα ≈ 2.5consistently\\ntheWeightedAlpha,computedas: outperform those with α ≥ 5 on tasks requiring\\nrobustgeneralization.\\n(cid:80)N λ−αlog(λ )\\nα = i=1 i i , (5)\\nw (cid:80)N λ−α M.4 ApplicationsinPretrainedModels\\ni=1 i\\nHT-SRmetricsenablemodelqualityassessments\\nandtheLogα-Norm:\\nwithout training or test data by analyzing eigen-\\nN value spectra. This is particularly valuable for\\n1 (cid:88)\\nLog-α = log(λ ). (6) pretrainedmodels,allowing: -Detectionof\"Scale\\ni\\nN\\ni=1 Collapse,\" where spectral norms deviate anoma-\\nlously. -Fine-tuningguidancebasedonlayer-wise\\nThesemetricsserveasrobustpredictorsofmodel\\nspectralanalysis.\\nquality,outperformingtraditionalnorm-basedmea-\\nsures,especiallyindifferentiatingwell-trainedver- M.5 ConclusionandFutureDirections\\nsuspoorlytrainedmodels.\\nHT-SRtheorybridgesthegapbetweenstatistical\\n3. Correlation Flow: Stable α values across\\nmechanics and machine learning by linking im-\\nnetworklayerssuggest\"CorrelationFlow,\"where\\nplicit regularization to generalization. Future re-\\nfeaturespropagateeffectivelythroughthenetwork.\\nsearch could explore: - Extending HT-SR to un-\\nForweightmatricesW atlayerl,HT-SRensures\\nl\\nsupervisedandreinforcementlearningsettings. -\\nα remains within the optimal range, preserving\\nl\\nRefiningHT-SRmetricsforreal-timemodeldiag-\\nconsistentfeatureextraction:\\nnosticsandtrainingstabilization.\\nα ≈ constant, ∀l ∈ {1,...,L}. (7)\\nl N HyperparametersandBestPractices\\nM.2 ImplicationsforGeneralization\\nThissectionsummarizesthehyperparametersused\\nHT-SRtheoryhighlightsthatwell-trainedmodels in our approach and provides best practices for\\nexhibiteigenvaluespectrawithheavy-taileddistri- their configuration. Table 14 outlines the recom-\\nbutions. Models with excessively large α values mendedranges,descriptions,andpracticalguide-linesforeachhyperparameter. Theserecommen- N.1.2 2. BayesianOptimization\\ndations are derived from empirical experiments Bayesianoptimization(BO)modelsthelossasa\\nandtheoreticalinsights,aimingtooptimizeperfor- Gaussian process and efficiently balances explo-\\nmanceacrossdiversealignmenttasks. ration and exploitation (Snoek et al., 2012). BO\\nThehyperparametersarecategorizedbasedon identifies the optimal hyperparameters by maxi-\\ntheir roles, such as kernel configuration, regular- mizingtheExpectedImprovement(EI).\\nization, and alignment strategies. For instance, MathematicalFormulation:\\nα and β control the trade-off between alignment\\nrobustness and regularization strength, while τ λ∗ = argmaxEI(λ),\\nλ\\ndeterminesthebalancebetweenlocalandglobal\\nkernel contributions in HMK. Proper tuning of whereEI(λ)istheexpectedimprovementoverthe\\nthesehyperparametersiscrucialforachievingcom- bestobservedloss. Bayesianoptimizationisuseful\\npactandwell-separatedclusters,asevidencedby fortuningcomputationallyexpensivehyperparam-\\ntheDavies-Bouldinscoreanalysisinprevioussec- eterslikeMahalanobiscovarianceΣ.\\ntions. BestPractices:\\n• Usemulti-fidelityoptimizationtoreducecompu-\\nN.1 ApproachesforHyperparameter\\ntationalcosts(Lietal.,2018).\\nSelection\\nEffective hyperparameter selection is crucial for • ApplyBOfor**non-differentiablehyperparame-\\nensuringtheoptimalperformanceofDPO-Kernels ters**(e.g.,Polynomialdegreedandkernelmix-\\nandHierarchicalMixtureofKernels(HMK).Key tureweightsλ).\\nhyperparameters include the RBF bandwidth σ,\\nN.1.3 3. Cross-Validation\\nPolynomialdegreed,MahalanobiscovarianceΣ,\\nandmixtureweightsλ . Below,weoutlinepracti- Cross-validationisarobuststrategytotunehyper-\\ni\\ncal approaches for hyperparameter selection and parameters,especiallyforensuringgeneralization\\ntuning. (Kohetal.,2021b). Foreachhyperparametercon-\\nfiguration, k-fold cross-validation partitions the\\nN.1.1 1. RandomSearchandGridSearch\\ndataintok folds,trainsonk−1folds,andevalu-\\nRandom search and grid search are standard ap- atesontheremainingfold.\\nproachesforhyperparametertuning(Bergstraand MathematicalFormulation:\\nBengio,2012). Whilegridsearchexploresafixed\\nk\\nset of values, random search samples from a dis- λ∗ = argmin 1 (cid:88) L(λ,D ),\\ni\\ntribution,oftenachievingbetterresultswithfewer λ k\\ni=1\\ntrials.\\nwhereL(λ,D )isthelossonthei-thfold. Cross-\\nBestPractices: i\\nvalidation is particularly effective for selecting\\n• **RBF Bandwidth σ**: Sample σ from a loga-\\nglobalhyperparameterslikekerneltypesandmix-\\nrithmicscale,e.g.,σ ∈ [10−3,103],assensitivity\\nturecoefficientsλ .\\ni\\ntochangesinσ isnon-linear.\\nN.1.4 4. AdaptiveHyperparameterSelection\\n• **PolynomialDegreed**: Usesmallintegerde-\\nForhyperparameterslikemixtureweightsτ ,τ in\\ngrees d ∈ {2,3,4,5} to avoid excessive non- 1 2\\nHMK,itisbeneficialtoadaptivelylearnthemdur-\\nconvexity.\\ning training via backpropagation. Differentiable\\n• **Mixture Weights λ **: Use Dirichlet- hyperparameters can be updated using gradient-\\ni\\n(cid:80)\\ndistributedsamplestoensure λ = 1. basedmethods.\\ni iTable14: SummaryofHyperparametersandBestPractices\\nHyperparameter Description RecommendedRange BestPractices\\nα(Alpha) Controlsthestrengthoftheregulariza- 0.1≤α≤1.0 Startwithα=0.5forbalancedflexibil-\\ntion(alignmentwithreferencepolicy). ityandconservativeness.Lowervalues\\nallowgreaterpersonalization.\\nβ(Beta) Scalingfactorfordivergence-basedreg- 0.5≤β≤2.0 Increaseβforstrongerpenalizationof\\nularizers. distributionaldeviations;tunebasedon\\ntaskcomplexity.\\nγ(Gamma) Weightforembedding-basedalignment 0.1≤γ≤1.0 Useγ > 0.5forsemanticalignment;\\nsignals. lower values emphasize probability-\\nbasedpreferences.\\nKernelMixtureWeights WeightsforPolynomial,RBF,Spectral, Sumto1.0,individually> Initializeevenly(0.25each)orbased\\nandMahalanobiskernels. 0.1 ondatainsights.Dynamicallylearned\\nduringtraining.\\nσ(Sigma) BandwidthparameterforRBFkernel. 0.1≤σ≤2.0 LowerσsharpensRBFlocality. Tune\\nwithcross-validationbasedondataden-\\nsity.\\nd(Degree) DegreeofPolynomialkernel. 2≤d≤5 Startwithd=2forefficiency.Higher\\nvaluescapturecomplexinteractionsbut\\nmayriskoverfitting.\\nλ(Lambda)Divergences Weightsfordivergenceterms(e.g.,JS, Sumto1.0,individually> PrioritizeWassersteinorBhattacharyya\\nWasserstein,Bhattacharyya). 0.1 for safety tasks and JS for semantic\\nalignment.\\nτ(Tau) Balancebetweenlocalandglobalkernel 0.3≤τ ≤0.7 Useτ =0.5forbalancedcontributions.\\ncontributionsinHMK. Adjustbasedonalignmentneeds(e.g.,\\nτ >0.5forfinerlocaladjustments).\\nEffectiveRange(r) Definestheinfluencezoneofkernels Task-dependent AlignσorΣregularizationtooptimize\\nlikeRBFandMahalanobis. localityversusglobalcorrelationcap-\\nture.\\nEmbeddingSimilarityScaling Scaling factor for embedding-based 0.5≤scale≤1.5 Normalize embedding spaces before\\npairwisemetrics. applying similarity metrics. Cross-\\nvalidatescalingonvalidationdata.\\nRegularizerThresholds Thresholds for divergence-specific 0.1≤threshold≤0.6 Tighterthresholdsimproveseparation\\nterms(e.g.,Rényi’sα,supportoverlap). butmayincreasecomputationalcost.\\nMathematicalFormulation: • Monitorthevalidationlossforpepochsandstop\\ntrainingifnoimprovementisobserved.\\nλ = λ −η∇ L(λ;D),\\nt+1 t λ\\n• Earlystoppingcanalsobeusedtotunethekernel\\nmixtureweightsτ ,τ duringtraining.\\nwhereηisthelearningrateand∇ Listhegradient 1 2\\nλ\\nofthelosswithrespecttoλ. Thisapproachenables We have presented five key approaches for\\ndynamicadaptationofkernelmixtureweightsand hyperparameter selection in DPO-Kernels and\\nbandwidthsduringtraining. HMK,includingrandom/gridsearch,Bayesianop-\\ntimization,cross-validation,adaptivetuning,and\\nN.1.5 5. EarlyStopping\\nearlystopping. Bayesianoptimizationandcross-\\nEarly stopping halts training once the validation validation are ideal for non-differentiable hyper-\\nlossnolongerimproves. Thisisparticularlyuseful parameters,whileadaptivemethodsareeffective\\nforadjustinglearningrates,mixtureweights,and for differentiable hyperparameters like mixture\\nother training-related hyperparameters (Prechelt, weightsτ andτ . Futureresearchcouldincorpo-\\n1 2\\n1998). ratemeta-learning(Finnetal.,2017b)toautomate\\nBestPractices: hyperparameterselectionforDPO-Kernels.',\n",
       " 'DynaGRAG Exploring the Topology of Information.pdf': 'DynaGRAG | Exploring the Topology of Information\\nfor Advancing Language Understanding and\\nGeneration in Graph Retrieval-Augmented Generation\\nKarishmaThakrar\\nkarishma.thakrar@gatech.edu\\nAbstract\\nGraph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures\\naim to enhance language understanding and generation by leveraging external\\nknowledge. However, effectively capturing and integrating the rich semantic\\ninformationpresentintextualandstructureddataremainsachallenge. Toaddress\\nthis,anovelGRAGframework,DynamicGraphRetrieval-AgumentedGeneration\\n(DynaGRAG), is proposed to focus on enhancing subgraph representation and\\ndiversitywithintheknowledgegraph. Byimprovinggraphdensity,capturingentity\\nandrelationinformationmoreeffectively,anddynamicallyprioritizingrelevant\\nanddiversesubgraphsandinformationwithinthem,theproposedapproachenables\\namorecomprehensiveunderstandingoftheunderlyingsemanticstructure. This\\nis achieved through a combination of de-duplication processes, two-step mean\\npooling of embeddings, query-aware retrieval considering unique nodes, and a\\nDynamicSimilarity-AwareBFS(DSA-BFS)traversalalgorithm. IntegratingGraph\\nConvolutionalNetworks(GCNs)andLargeLanguageModels(LLMs)throughhard\\npromptingfurtherenhancesthelearningofrichnodeandedgerepresentationswhile\\npreservingthehierarchicalsubgraphstructure. Experimentalresultsdemonstrate\\ntheeffectivenessofDynaGRAG,showcasingthesignificanceofenhancedsubgraph\\nrepresentationanddiversityforimprovedlanguageunderstandingandgeneration.\\n1 Introduction\\nRecent breakthroughs in large language models have transformed natural language processing,\\ndemonstrating unparalleled capabilities in understanding and generating human-like text across\\ndiversedomains. ModelslikeOpenAIo1,Claude3Opus,andLlama70bhavesetnewperformance\\nbenchmarks, achieving state-of-the-art results.1 However, tasks like analogical thinking, causal\\ninference,andsynthesizingcomplexknowledgecontinuetoexposethelimitationsofthesemodels,\\nparticularlyinhandlingnuancedreasoning. Toaddressthesechallenges,initiativeslikeOpenAI’s\\nProject Strawberry2 aim to empower LLMs with \"human-like reasoning\" by enabling them to\\nautonomouslyexplore,research,andplan. Evenso,LLMsarefundamentallyconstrainedbytheir\\nrelianceonstaticdatasets,limitingtheirabilitytodynamicallyadapttoevolvinginformation. Fine-\\ntuning,acommonmethodfordomain-specificadaptation,incurssignificantcomputationalcostsand\\nriskscompromisingreasoningcapabilities.3 Thisunderscorestheneedforalternativeapproaches\\nthatdelivercontextuallyrichandrelevantresponseswhileeffectivelyleveragingandsynthesizing\\ncomplexinformation.\\nAnemergingsolutionliesintheuseofgraph-structureddata,particularlyknowledgegraphs,which\\ncaptureentitiesandtheirrelationships,offeringastructuredandenrichedrepresentationofinfor-\\nmation. Thesegraphshaveshownimmensepromiseforimprovingdomain-specificrelevanceand\\n*ThisarchitecturewasfirstcreatedinJune2024andthepaperwaslaterpublishedonarXivinJanuary2025.\\n5202\\nnaJ\\n82\\n]LC.sc[\\n3v44681.2142:viXrareasoningintaskslikequestionanswering,recommendationsystems,andnaturallanguagegenera-\\ntion. However,unlockingthefullpotentialofknowledgegraphsrequiresovercomingasignificant\\nchallenge: generating responses that effectively integrate the textual richness of LLMs with the\\ntopologicalinsightsofgraphdata. Achievingthissynthesisnecessitatesrethinkinghowstructured\\ndataiscombinedwithgenerativeAImodelstoproducescalable,relevant,andreasoning-richoutputs.\\nFigure1: Radarplotillustratingperformance Figure 2: Radar plot illustrating performance\\nacross evaluation metrics for architectures acrossevaluationmetricsforarchitecturestested\\ntestedusingGemini1.5Flash, highlighting using GPT 4-o mini, highlighting DynaGRAG’s\\nDynaGRAG’sstrengthswithempowerment, strengthsacrossallmetricscollectively.\\nsubjectivityandnuance,andimplicationfo-\\ncus.\\nOneofthemostnotableadvancementsinintegratinggraph-structureddatawithgenerativeAImod-\\nels is Microsoft’s Graph RAG architecture proposed by Larson et al.4 This approach leveraged\\nknowledgegraphstoaugmentLLMsbygeneratingpre-summarizedcommunityreportsfordistinct\\nclustersofentitiesandrelationships,enablingscalablequery-focusedsummarization. Whileinno-\\nvativeinaddressinglarge-scaleglobalsummarization,thereareseverallimitations. Thereliance\\nonpre-summarizedcommunityreportssacrificesthegranularityandflexibilityoftheunderlying\\ngraph,reducingitsabilitytodynamicallyexplorerelationshipsoraddressqueriesrequiringnuanced,\\nunexpectedconnections. Moreover, thequery-focusedsummarizationapproachconsumesasub-\\nstantialnumberoftokens, leadingtosignificantcomputationaloverheadandhighercostsduring\\ninference. Ifthestructureoftheunderlyinggraphdatachanges,evenslightly,theentiregraphindex\\nanditscommunitysummarieswouldneedtoberegenerated,makingthesysteminefficientandless\\nadaptabletoevolvingdatasets,anecessaryfeatureinmostpracticalapplicationsofthesegraph-based\\nalgorithms.\\nOther frameworks, such as Graph RAG proposed by Hu et al.,5 a group of Emory University\\nresearchers, seek to improve retrieval-augmented generation by incorporating soft prompts and\\nleveraginggraphandtextviews. Whileconceptuallyappealing,thisapproachfaceschallengeswith\\nmainstreamLLMarchitectures,whicharenotnativelydesignedtoprocessgraph-basedcontextual\\ninformation,limitingitspracticality.Novelapproachesthatcancaptureandintegratetherichsemantic\\ninformationpresentintextualandstructureddataareneededtoenableLLMstoreasonoverand\\ngenerateresponsesfromknowledgegraphs,ultimatelyimprovingthedepthandcontextualrelevance\\nofAI-generatedoutputs.\\nThe proposed Graph RAG architecture, DynaGRAG, fundamentally addresses the limitations of\\nearlier approaches by preserving graph data in its native form, enabling real-time traversal and\\nretrieval of entities, relationships, and their embeddings during query processing. Unlike static\\nsystems,thisarchitecturedynamicallyassemblesresponsesbyexploringandintegratinginformation\\ndirectlyfromthegraph. Thisensuresthatthefullrichnessandgranularityofthedataarepreserved,\\nallowingforflexibleadaptationtoevolvingdatasetsandcomplexqueries.\\n2Thearchitectureintroducesseveralinnovativefeaturesthatenhanceitseffectiveness. Itemploysa\\nprocesstoimprovegraphdensitybyconsolidatingredundantinformationandemphasizingthemost\\nmeaningfulnodesandedges,ensuringaclearerandmoreimpactfulgraphrepresentation. Aunique\\ntwo-stepmean-poolingmethodcapturesdiverseandcomprehensivesummariesofgraphentities,\\nenablingrichercontextualunderstanding. Itsquery-awareretrievalmechanismretrievessubgraphs\\nthat are both highly relevant and diverse, achieving a balance between precision and variety. A\\ndynamictraversalalgorithmfurtherrefinestheprocessbyintelligentlyadaptingtheexplorationof\\nthegraph,uncoveringdeeperandpreviouslyoverlookedconnections. Byintegratinggraphneural\\nnetworks to refine node and edge representations and leveraging the generative natural language\\ncapabilitiesoflargelanguagemodels,thearchitectureseamlesslybridgesstructuredandunstructured\\ndata. Finally, carefully designed prompts ensure that both the textual richness and hierarchical\\ninsightsofthegrapharefullyutilized,deliveringexceptionalperformanceoncomplextasksrequiring\\nnuancedinsightsandmultistepreasoning.\\nThroughextensiveexperimentation,DynaGRAGhasdemonstratedsignificantimprovementsover\\nexisting methods. By combining the retrieval of graph-structured data with LLMs, it effectively\\ncapturescomplexrelationshipsamongseeminglyunrelatedinformation,traverseslongcontexts,and\\nsynthesizesnuanced,contextuallyrichresponses. Thisintegrationoftextualandtopologicalinsights\\nnotonlyenhancesthesystem’sreasoningandadaptabilitybutalsohasdemonstratedalignedoutputs\\nwithoutexplicitdirectivesforethicalconsiderations. Byfocusingonretrievingandanalyzingrelevant\\nsubgraphsandgroundingresponsesinrelationshipsandcontext,theframeworkconsistentlydelivers\\nresultsthatarecoherent,meaningful,andaccountable. Thesefindingsunderscorethetransformative\\npotentialofrobustreasoningtechniquesinfosteringthoughtfulandresponsibleAIsystems.\\nFigure3: WordcloudrepresentinganLLM’sevaluationoftheproposedframework’sresponses,\\nhighlightingattributessuchasunderstanding,depth,clarity,focusonethicalandsocietalimplications,\\nandcomplexreasoning.\\n2 RelatedWork\\nTheintegrationofexternalknowledgewithLLMsthroughRAGhasgainedsignificantrecentattention.\\nGaoetal. (2024)6 provideacomprehensivesurveyofRAGmethods,discussingtheevolutionof\\ngeneralparadigmsandcorecomponents. Graph-basedapproacheshavebeenexploredtoaugment\\nLLMs in various domains, such as knowledge graph generation, (Chang et al., 2024; Yao et al.,\\n2024)78bidirectionalreasoning(Panetal.,2024)9andcategorizationofgraphgeneration(Guoand\\nZhao,2022);10theseworksprimarilyfocusonbroaderintegrationstrategies,specificgraphgeneration\\ntasks,orprovidingdetailedtaxonomiesandevaluationsofexistingmodels. Severalrecentlyproposed\\nGRAGframeworkstargetmulti-hopreasoningontextualgraphs(Huetal.,2024),5 knowledgegraph\\nquestionanswering(MavromatisandKarypis,2024),11relationalknowledge(Pengetal.,2024),12\\nandaddressingchallengessuchasinformationhallucinationandcatastrophicforgetting(Sanmartínet\\nal.,2024).13 Whiletheseapproachesaddressspecificchallenges,theyoftenfacecompatibilityissues\\nwithmainstreamLLMs,prioritizedensesubgraphreasoningandfactualaccuracyovercapturinga\\n3richervarietyofentityrelationships,orfocusonformalizingandsurveyingexistingmethods. Larson\\netal. (2024)4proposeaGraphRAGapproachforquery-focusedsummarizationthatreliesonmulti-\\nlevelcommunitysummaries.Whilethorough,theoverallframeworkrequiresfrequentregenerationof\\nsummariesastheunderlyingdataevolves.Otherworksexploreencodinggraph-structureddataastext\\nforLLMstoimprovegraphreasoningtasks(Fatemietal.,2023)14orinvestigateLLMsforlearning\\nontext-attributedgraphs(Chenetal.,2024).15Thesepapersprimarilyaddressencodingstrategies,\\ngraphreasoningchallengesinblack-boxLLMenvironments,oremphasizenodeclassificationtasks,\\ndifferingfromthefocusonenhancingsubgraphdiversityandrepresentationforimprovedlanguage\\nunderstandingandgeneration.\\nToovercomethelimitationsidentifiedinexistingapproaches,thisworkintroducesanovelGRAG\\nframeworkdesignedtoenhancesubgraphdiversityandrepresentationwithinknowledgegraphs. A\\nfewkeyinnovationsincludetechniquessuchasatwo-stepde-duplicationforconsolidatingsimi-\\nlarentitiesandrelationships, query-awareretrievalthatprioritizesuniquenodes, andaDynamic\\nSimilarity-AwareBFStraversalalgorithmtouncoverdeepercontextualconnections. Theseadvance-\\nmentsenablemorenuancedandcomprehensivelanguageunderstandingandgeneration,extending\\nthecapabilitiesofexistingRAGandGRAGmethodologies.\\n3 Methodology\\nThe first step in DynaGRAG is to construct a knowledge graph from textual data. This process\\ninvolvesdividingsourcedocumentsintotextchunksandidentifyingentitiesandtheirrelationswithin\\nthesechunks. AnLLMisusedtoextractsignificantentities,theirsummaries,andtherelationships\\nbetweenthem. Theextractedinformationisthenusedtogenerateembeddingsfortheentitiesand\\nrelationsusingapre-trainedlanguagemodel(PLM).Thisapproachtoknowledgegraphconstruction\\nenablesuser-specifiedLLMpromptstailoredtospecificdomainsorthemes,allowingfortheflexible\\nextractionandprioritizationofrelevantinformationfromsourcedocuments.\\nFigure4: ProcessdiagramdescribingthegraphretrievalandgenerationprocessinDynaGRAG.\\n4Figure5: Visualizationofaknowledgegraphextendedtoa3Drepresentationbasedonnodesand\\nentitiesextractedfromtranscriptsofDwarkeshPatel’spodcast.16 Nodesarepositionedusingthe\\nKamada-Kawai layout, dynamically scaled, and perturbed along the z-axis for enhanced visual\\ndifferentiation.\\n3.1 GraphConsolidation\\nTo enhance the graph representation of data, several novel techniques are employed to improve\\ngraphconnectivityandcapturetheprevalenceofentitiesandrelations. TheLLMidentifieshighly\\nsimilarorsynonymousentitiesbyanalyzingthesemanticsimilaritybetweenentitylabelsandtheir\\ncontextwithinthegraph,aligningthegraphwithhumanunderstanding. Forexample,entitiessuchas\\n\"compute\",\"computeresources\",and\"computeresourcesusage\"canbeconsolidatedintoasingle\\nentity,like\"compute\". Thisconsolidationprocesseffectivelyhandlesnewtermslike\"GPT-7\",which\\nmodelslikeWord2Vecoftenlackvectorrepresentationsfor.\\nTofurtherenhancetherepresentationofinformation,thede-duplicationprocessinvolvesatwo-step\\napproachtoaveragingentityembeddings. First,theembeddingsofidenticalentitiesareaveraged,\\nensuringthateachuniqueentityisrepresentedaccurately. Then,theembeddingsofsimilarentities\\naveraged,capturingthevarietyofentityrepresentationswithoutoveremphasizingtheprevalence\\nofasingleversion. ThisismeaningfulasoftentimesLLMsproduceidenticalsummariesforthe\\nsameentitiesinachunkandsofollowingthistwo-stepaveragingprocessensuresthecapturingofa\\nvarietyofentitysummaryrepresentationsmoreeffectively. Akeyadvantageofthisapproachisits\\nabilitytobalancerepresentationbypreventingoveremphasisonhigh-frequencyentities,ensuringthat\\nlesscommonbutmeaningfulentitiesarenotovershadowed,andthefinaloutputreflectsanunbiased\\naverageofdistinctlatentfeatures.\\nThe de-duplication process results in condensed entities and relations, which form the basis of\\nundirected weighted graphs. By explicitly handling duplicates, critical information such as the\\nrelativeimportanceofnodesandedgesarecaptured,storingtheirfrequencyofoccurrenceasweights\\nandaccumulatingallrelationandentitysummaries. Thisapproachenhancesgraphdensity,resulting\\nin a more interconnected and less sparse graph structure that allows for efficient propagation of\\ninformation,ultimatelyimprovingretrievalperformanceintheGRAGarchitecture. Moreover,the\\nde-duplicationprocessisflexibleandcanbecontrolledintermsofthegranularitysought,allowing\\nuserstotailorandoptimizethegraphconsolidationprocessfortheuniquecharacteristicsofeach\\ndatasetandapplicationandenhancingthegraphrepresentationforvariousdownstreamtasks.\\n53.2 SubgraphRetrieval\\nTo efficiently retrieve relevant information from a large graph structure, the system constructs a\\nsearchabledatabaseofpre-computedego-graphscenteredoneachnode,includingnodeswithink\\nhops(typically,k=3). Theseego-graphsareencodedbyfirstcomputingweightednodeandedge\\nfeaturestocapturethestructuralandsemanticsignificanceofeachentityandrelationship.\\nWeightedNodeFeatures:\\nhweighted =h ·w\\ni i i\\nWhere:\\n• h : Nodeembeddingfornodei\\ni\\n• w : Weight(i.e.,entityweight)fornodei\\ni\\n• hweighted: Weightednodefeature\\ni\\nWeightedEdgeFeatures:\\nh +h +r\\neweighted = i k ij ·w\\nij n ij\\nWhere:\\n• h : Sourceembedding(nodei).\\ni\\n• h : Targetembedding(nodek).\\nk\\n• r : Relationshipembeddingfortheedgebetweennodesiandk.\\nij\\n• n: Numberofembeddingsbeingaveraged(i.e.,n=3forsource,target,andrelationship).\\n• w : Relationshipweightfortheedge.\\nij\\nOncetheweightednodeandedgefeaturesarecomputed,theyarecombinedtoformthetotalgraph\\nembedding,whichrepresentstheencodedego-graphas:\\nTotalGraphEmbedding:\\n(cid:80) hweighted+(cid:80) eweighted\\ni i (i,j) ij\\ng=\\nw\\ntotal\\nWhere:\\n• g: Graphembedding.\\n• hweighted: Weightednodefeaturefornodei,derivedash ·w (nodeembeddingmultiplied\\ni i i\\nbyitsweight).\\n• eweighted: Weightededgefeatureforedge(i,j),asderivedearlier.\\nij\\n(cid:80)\\n• w : Total weight, which is the sum of all node weights ( w ) and edge weights\\n(cid:80)total i i\\n( w ).\\n(i,j) ij\\nDuring retrieval, the total graph embedding of each pre-computed ego-graph is compared to the\\nqueryembeddingusingcosinesimilarity. Thetop-Nsubgraphsarerankedbasedontheirsimilarity\\nscores,ensuringrelevancetothequery. Toenhancediversity,amechanismtracksthetopnodesof\\npreviouslyretrievedsubgraphsanditerativelyaddssubgraphswithdistinctkeyentities. Thisstrategy\\navoidsredundancyandprovidesaricher,morebalancedsetofresultsbyselectingsubgraphsthat\\nspandifferentregionsoftheknowledgegraph.\\nToassesstheeffectivenessofdiversity-awareretrieval,itsimpactonintermediateresultsforspecific\\nquerieswasanalyzed. Withoutthediversitycriterion, thesystemfrequentlyprioritizedanarrow\\nsetofdominantsubgraphsfocusedonhighlyinterconnectedentities. Forexample,queriesabout\\nthe \"Future of AI\" consistently retrieved subgraphs exploring similar themes like such as \"AI\\n6researchers\"or\"Biasinartificialintelligence.\"Whilerelevant,thisapproachhaddisregardedless\\nprominentbutalsomeaningfulsubgraphs. Theintroductionofadiversitycriterionfundamentally\\ntransformedtheretrievalprocess,surfacingawiderarrayofsubgraphsforthisquery,suchasGeoffrey\\nHinton’sconcernsaboutAI,RLHF’simplicationsforsafety,andadvancesinattentionmechanisms.\\nBypenalizingsubgraphswithoverlappingtopnodes, thesystemcaptureddistinctregionsofthe\\nknowledgegraph,uncoveringpreviouslyunderexploredinsightsandenhancingthesystem’sability\\ntoaddresscomplex,multifacetedquestionswithnuancedandcomprehensiveresponses.\\nFigure6: Example2-hopego-networkforAnthropicfromDwarkeshPatel’sPodcastepisodewith\\nSholtoDouglas&TrentonBricken.16Nodesizesreflectingtheirweightsandprevalencewithinthe\\nsubgraph.\\n3.3 SubgraphPruning\\nThe retrieved subgraphs are refined to prioritize components most relevant to the query. This\\nprocessbeginswiththecomputationofprominencescores,whichcombinestructuralsignificanceand\\nsemanticalignment.Structuralsignificanceisdeterminedusingpre-computedweightsforentitiesand\\nrelationships,reflectingfactorssuchascentralityorconnectivity. Semanticalignment,ontheother\\nhand,iscalculatedastheEuclideandistancebetweenthequeryembeddingandtheembeddingsof\\nnodesoredges. Thesedistancesaretransformedintonormalizedrelevancescoresusingamultilayer\\nperceptron(MLP)withasigmoidactivationfunction,assigninghigherscorestoelementsthatare\\nmorecloselyalignedwiththequerywhileensuringconsistentscalingfordownstreamuse.\\nNode-QueryDistance(EuclideanDistance):\\n(cid:118)\\n(cid:117) d\\n(cid:117)(cid:88)\\nDistance\\nnode\\n=∥h i−q∥\\n2\\n=(cid:116) (h\\ni,j\\n−q j)2\\nj=1\\nWhere:\\n• h : Nodeembeddingfornodei(ad-dimensionalvector).\\ni\\n• q: Queryembedding(ad-dimensionalvector).\\n• d: Dimensionalityoftheembeddingspace.\\n7• h : j-thcomponentofthenodeembedding.\\ni,j\\n• q : j-thcomponentofthequeryembedding.\\nj\\nEdge-QueryDistance(EuclideanDistance):\\n(cid:118)\\n(cid:117) d\\n(cid:117)(cid:88)\\nDistance\\nedge\\n=∥r\\nij\\n−q∥\\n2\\n=(cid:116) (r\\nij,j\\n−q j)2\\nj=1\\n• r : Relationship embedding (edge embedding) for the edge between nodes i and j (a\\nij\\nd-dimensionalvector).\\n• q: Queryembedding(ad-dimensionalvector).\\n• d: Dimensionalityoftheembeddingspace.\\n• r : j-thcomponentoftheedgeembedding.\\nij,j\\n• q : j-thcomponentofthequeryembedding.\\nj\\nOncerelevancescoresarecomputed,theyarepassedintoaGraphConvolutionalNetwork(GCN)\\ntogenerateupdatedpruningscores. TheGCNincorporatesboththeinitialrelevancescoresandthe\\nstructuralrelationshipswithinthegraph,dynamicallyadjustingtheimportanceofnodesandedges.\\nRatherthanapplyinghardmaskingtoremovelessrelevantcomponents,theframeworkemployssoft\\nmaskingtoscaletheirinfluence. Nodeweightsareadjustedbasedontheirpruningscores,andedge\\nattributesaresimilarlyscaledtoreflecttheirupdatedrelevance. Throughitsmessage-passingprocess,\\ntheGCNalsofurtherrefinesthenodeandedgerepresentationsbyaggregatinginformationfrom\\ntheirneighbors. Theresultofthisprocessisarefinedsubgraphthatiscontextuallyrichandclosely\\nalignedwiththequery. Thesesubgraphsareoptimizedfordownstreamtaskssuchasreasoningand\\ngeneration,effectivelyleveragingboththestructuralcomplexityandsemanticdepthoftheknowledge\\ngraph.\\n3.4 HardPrompting\\nIntheDynaGRAGframework,hardpromptsaregeneratedbytraversingtheprunedsubgraphs. A\\nnovelDynamicSimilarity-AwareBFSalgorithmisimplemented,whichadjuststhenodeexploration\\norder based on similarity scores, prioritizing the exploration of highly similar neighbors. This\\ninnovativeapproachrevealsdeeperconnectionsbetweennodesthatmightbemissedinastrictBFS,\\nenhancingthecoherenceofthepromptwhilemaintainingthelogicalstructure. Pre-ordertraversal\\nalgorithmsfurtherenrichthepromptbycollectingrelevantinformation,suchasentitysummaries,\\nedge relationships, and their pruned weights, providing additional context about the importance\\nof each entity and relationship within the subgraph. Non-tree edges are also processed, offering\\nsupplementaryinsightsandconnectionsbeyondthebasictreestructure. Theresultingpromptstring\\nreflectsthehierarchicalstructureofthesubgraph,aligningwiththestrengthsofLLMs,whichare\\npre-trainedonhierarchicaldataformatssuchasJSON,XML,andnestedoutlines. Bygenerating\\ninformative and structured prompts that capture both the textual and topological aspects of the\\nknowledgegraph,DynaGRAGleveragesthestrengthsofLLMsinunderstandingandreasoningabout\\nhierarchicaldata.\\n3.5 GeneratingResponses\\nThequeryandhardpromptarecombinedintoasingleinputstring,whichisthenusedtogenerate\\nintermediateresponsesfromeachretrievedsubgraph. Theseintermediateresponsescapturedifferent\\naspectsandperspectivesrelatedtothequeryfromvariouspartsoftheknowledgegraph. Thesystem\\ncalculatesahelpfulnessscoreforeachintermediateresponsebasedonrelevance,coherence,and\\nlevelofdetail. Theintermediateresponsesarethensortedbytheirhelpfulnessscoresindescending\\norder. The sorted intermediate responses are fed into the language model, which generates a\\ncoherentandcomprehensivefinalresponse,integratinginformationfrommultiplesubgraphswhile\\navoidingredundancy. ThisapproacheffectivelyencouragestheLLMto\"think\"firstaboutaquestion\\nbeforeformingitsfinalresponsewhileensuringthatthegenerationprocessmaintainstheessential\\ninformationfromtheinputgraph.\\n8Tosummarize,thisresearchproposesanovelGRAGframeworkthatseamlesslyintegratesLLMs\\nandgraphlearningtechniques,introducingseveralkeyinnovations:\\n1. EnhancedGraphRepresentationwithDe-duplication: Theframeworkemploysarobustde-\\nduplicationprocesstoconsolidatesimilarentitiesandrelationships,improvinggraphdensityand\\ncapturingtherelativeimportanceofnodesandedges. Atwo-stepmeanpoolingofembeddingsis\\nappliedtopreservediverseentitysummaryrepresentations,ensuringarichandbalancedgraph\\nrepresentation.\\n2. Query-awareSubgraphRetrievalwithDiversityPrioritization: Aretrievalprocessensures\\nthatsubgraphsarenotonlyrelevanttothequerybutalsodiverse,byconsideringtheuniqueness\\noftopnodeswithineachsubgraph. Thisbalancepreventsredundancy,surfacesunderrepresented\\ninsights,andenrichesthecontextualbreadthofretrievedsubgraphs.\\n3. DynamicSimilarity-AwareBFSAlgorithm: Anoveltraversalmethoddynamicallyadjusts\\nnodeexplorationorderbasedonsimilarityscores. Thisapproachuncoversdeeper,contextually\\nmeaningfulconnectionsthatmightbemissedinatraditionalBFS,whilemaintainingabalance\\nbetweenstructuralcoherenceandexplorationflexibility.\\n4. IntegrationofGraphConvolutionalNetworks: GCNsareutilizedtolearnrichrepresentations\\nfornodesandedges,leveragingbothstructuralsignificanceandsemanticalignmenttoproducerel-\\nevancescores. Thisprocessenhancestheframework’sabilitytorefinesubgraphsbyemphasizing\\nelementsthataremostcriticaltothequery.\\n5. HarnessingLLMsforHierarchicalData:TheframeworkcapitalizesonLLMs’abilitytoreason\\nabouthierarchicaldatabygeneratinghardpromptsthatpreservebothtextualandtopological\\naspectsofsubgraphs. ThesestructuredpromptsalignwiththestrengthsofLLMs,facilitating\\nmorecoherentandcontextuallygroundedresponses.\\nThe framework employs several key strategies, including: (1)utilizing LLMs to enhancetextual\\nattributesofnodes,compensatingfordeficienciesincontextualizedknowledgeandsemanticcompre-\\nhensioninherentinconventionalGNNpipelines;and(2)adaptingLLMstogenerateinformative,\\ndomain-alignedresponsesbydirectlyleveragingthegraphstructurethroughtechniqueslikehard\\npromptingandintermediateanswergeneration.\\n4 Experiments\\nThisstudyevaluatedtheperformanceofvariousLLMarchitecturesingeneratingnuanced,contextu-\\nallyawareresponsestoqueriesbasedonthe2024DwarkeshPatelPodcasttranscripts.16\\n4.1 DatasetandPreprocessing\\nThedatasetconsistedof460ktokensextractedfromthe2024DwarkeshPatelPodcasttranscripts. A\\ntotalof180non-factoidqueriesweregenerated,balancedacrossepisodes,tocomprehensivelytest\\nreasoningcapabilitiesandcoverawiderangeoftopicsdiscussedinthepodcasts.\\n4.2 ArchitecturesandPipelines\\nTheevaluationutilizedthreedistinctpipelines. BothGPT-4ominiandGemini1.5Flashmodelswere\\nevaluatedwitheacharchitecture.\\nLLMPipeline(VanillaLLM):Inthispipeline,thequeriesweredirectlyfedintotheLLMs(GPT-4o\\nMiniorGemini1.5Flash)withoutanyadditionalcontextoraugmentation. Theprimarygoalwasto\\nevaluatetheinherentreasoning,contextualinterpretation,andresponsegenerationabilitiesofthe\\nmodelswithoutexternalsupport. Theoutputsreflectedeachmodel’sstandaloneperformance,relying\\nsolelyontheirinternalknowledgeandinferencecapabilities.\\nLLM with Retrieval-Augmented Generation Pipeline (Naïve RAG): This pipeline combined\\nLLMswitharobustretrievalsystemforcontextualgrounding. Podcasttranscriptsweresegmented\\ninto 2,400-token chunks with a 200-token overlap for continuity. Chunks were embedded using\\nJinaAI’s jina-embeddings-v2-base-en model, supporting a context window of 8,192 tokens, and\\nstoredinaLanceDBvectorstoreforefficientcosinesimilarity-basedretrieval. Foreachquery,the\\n9topfiverelevantchunkswereretrievedandappendedtothequery,providingcontexttoenhancethe\\nrelevanceoftheLLM-generatedresponses.\\nDynamicRetrieval-AugmentedGenerationPipeline(DynaGRAG):DynaGRAGintegratedgraph-\\nbased retrieval, subgraph pruning, and advanced prompting to enhance response relevance and\\ncoherence. Podcasttranscriptchunkswereconvertedintoknowledgegraphrepresentations,with\\nentitiesandrelationshipsasnodesandedges. ThepipelineusedtheDynamicSimilarity-AwareBFS\\nalgorithmtoprioritizetheexplorationofsimilarnodesduringsubgraphretrieval,ensuringdiversity\\nandrelevance. Keyentitieswerehighlighted,andirrelevantinformationwasprunedseparatelyusing\\nlearnedrelevancescores. Theserefinedsubgraphsformedhierarchicalprompts,aligningwiththe\\nLLM’sstrengthstogeneratecomprehensive,contextualresponses.\\n4.3 EvaluationFramework\\nEach query response from the architecture-LLM pipeline was assessed using the following nine\\nmetricsdesignedtoevaluateboththedepthandqualityoftheresponses:\\n• Comprehensiveness: Measureshoweffectivelytheresponseaddressesallaspectsofthequery,\\nemphasizingintegrationandcoherenceoverisolatedpoints.\\n• Diversity: Evaluatesthebreadthofperspectives,examples,orapproachesprovided,prioritizing\\nresponsesthatsynthesizevariedelementsintoaunifiedargument.\\n• Empowerment: Assessestheextenttowhichtheresponseenhancesunderstandingbyoffering\\nactionableinsightsandfosteringconfidenceincomplexreasoning.\\n• Directness: Examines the response’s ability to stay focused on the query while exploring\\nnecessarycomplexities,strikingabalancebetweenclarityanddepthasappropriate.\\n• ClarityandBrevity: Ratestheabilitytoconveyintricatereasoninginaconciseandaccessible\\nmanner,withoutoversimplifyingoromittingcriticaldetails.\\n• DepthandSpecificity: Evaluatestheprecisionandrelevanceofreasoning,particularlyhowwell\\ntheresponseusesdetailedevidenceorexamplestosubstantiateitsclaims.\\n• SubjectivityandNuance: Measurestheabilitytoexploresubtledistinctions,conflictingper-\\nspectives,andinterdependencies,avoidingoverlybinaryinterpretations.\\n• Implication Focus: Assesses how thoroughly the response identifies and analyzes broader\\nimplications,includingsocietal,ethical,orpracticalconsequences.\\n• EthicalAlignment: Evaluateshowwellethicalconsiderationsareintegratedintotheresponse,\\nparticularlytheirroleinshapingorchallengingtheargument.\\nThefirstfourmetrics,Comprehensiveness,Diversity,Empowerment,andDirectness,wereinspired\\nbyMicrosoft’sGRAGevaluationframework. Toextendthisfoundation,fiveadditionalmetricswere\\nintroducedtoprovideamoreholisticassessmentoftheLLMs’reasoning,contextualunderstanding,\\nandresponsequality. Thescoresforeachpipelinewereaveragedandanalyzedtoidentifytrendsand\\ncomparetherelativestrengthsofthearchitecture-LLMcombinations.\\n105 Results\\nTheevaluationresultsrevealedcleardistinctionsintheperformanceofthethreearchitectures: LLM\\nResponse(VanillaLLM),LLMwithRAG(NaïveRAG),andDynaGRAG.AcrossboththeGemini\\nand OpenAI models, DynaGRAG emerged as the most effective pipeline, excelling in metrics\\nlikeComprehensiveness(8.56forGemini,9.49forOpenAI),Diversity(7.43forGemini,8.63for\\nOpenAI),andDepthandSpecificity(7.91forGemini, 9.21forOpenAI).Thesescoreshighlight\\nDynaGRAG’sabilitytocapturenuanced,multifacetedinformationandprovidediverse,contextually\\nrichresponses.\\nWhiletheVanillaLLMachievedgoodperformanceinEthicalAlignment(9.21forGemini,7.34\\nforOpenAI),itstruggledtomatchDynaGRAGintermsofreasoningdepthanddiversity,reflecting\\nthelimitationsofrelyingsolelyoninherentmodelknowledge. TheNaïveRAGpipeline,despite\\nleveragingretrievalforcontext,exhibitedlowerperformanceacrossmostmetrics,withsignificant\\ngapsinDiversityandDepth,indicatingchallengesineffectivelyincorporatingretrievedinformation\\nwithoutgraphrepresentationintoresponseswithreasoningandcontextualunderstanding.\\nTheoverallaveragereasoningscoresfurtherunderscoreDynaGRAG’seffectiveness,achieving8.18\\nforGeminiand8.43forOpenAI,comparedto7.66and7.99fortheVanillaLLM,and4.20and6.63\\nfortheNaiveRAG.TheseresultsemphasizetheimpactofDynaGRAG’sgraph-basedretrievaland\\ndynamicpromptingtechniques, whichenablethearchitecturetointegratecomplexrelationships,\\nprioritizerelevance,anddeliverresponsesthataligncloselywiththequery’scontext. Thefindings\\nvalidatethestrategicadvantageofgraph-structuredapproachesinadvancingreasoning,diversity,and\\ncontextintegrationinLLMpipelines.\\nTable1: EvaluationMetricsforDifferentArchitectures\\nMetric VanillaLLM NaïveRAG DynaGRAG\\nGemini1.5FlashResults\\nComprehensiveness 8.15 2.44 8.56\\nDiversity 7.05 2.29 7.43\\nEmpowerment 6.43 2.17 7.43\\nDirectness 8.59 5.17 8.63\\nClarityandBrevity 8.35 9.32 8.07\\nDepthandSpecificity 6.97 2.39 7.91\\nSubjectivityandNuance 6.97 2.42 7.72\\nImplicationFocus 7.24 2.42 8.40\\nEthicalAlignment 9.21 9.14 9.48\\nOverallReasoningScore 7.66 4.20 8.18\\nGPT4o-miniResults\\nComprehensiveness 9.05 7.31 9.49\\nDiversity 8.19 6.55 8.63\\nEmpowerment 8.20 6.69 8.83\\nDirectness 7.17 7.65 7.31\\nClarityandBrevity 7.18 7.39 7.44\\nDepthandSpecificity 8.82 6.39 9.21\\nSubjectivityandNuance 7.98 5.87 8.66\\nImplicationFocus 8.05 6.26 8.55\\nEthicalAlignment 7.34 5.54 7.73\\nOverallReasoningScore 7.99 6.63 8.43\\n11Figure7: BarplotofarchitectureresultsusingGemini1.5Flash.\\nFigure8: BarplotofarchitectureresultsusingGPT-4omini.\\n126 Discussion\\nThe DynaGRAG framework demonstrated significant advancements over state-of-the-art LLM\\npipelinesbydynamicallyadaptingtoqueriesanduncoveringcomplexrelationshipsandcontextual\\nnuances that other methods, such as Vanilla LLMs or naïve retrieval-augmented pipelines, often\\nstruggledtocapture—allwithoutrequiringadditionalLLMfine-tuning. Whileevaluationmetrics\\nlikecoherenceandrelevanceprovidedarobustfoundationforassessingresponses,theytendedto\\nfocusonwhetheraresponsesatisfiedspecificcriteria,ratherthancapturingthedepthandqualityof\\nhowwellthosecriteriaweremet. Thisreflectsabroaderchallengeinevaluatingnuancedreasoning,\\nasLLMsthemselvescanstruggletofullymeasurequalitieslikecomprehensivenessorcontextual\\nalignment. Despitetheseevaluationconstraints,DynaGRAGeffectivelyleverageditsgraph-based\\narchitecturetoproducecontextuallyrichandthoughtfullyconstructedoutputs, demonstratingits\\nabilitytosurpasshighbaselinescoresandpushtheboundariesofwhatthesesystemscouldachieve.\\nThe depth of DynaGRAG’s advancements becomes particularly evident when the responses are\\nexaminedqualitatively. WhiletheVanillaLLMproducedoutputsthatwerecoherentandsatisfactory,\\nDynaGRAGconsistentlywentbeyondthesurface,deliveringresponsesenrichedwithnuance,drawn\\nfromdiversecontexts,andinfusedwithdeeper,moremeaningfulconnections. Ashighlightedinthe\\ncomparisontables,DynaGRAG’soutputsdemonstratealevelofreasoningandcontextualdepththat\\nisdifficulttofullycapturethroughmetricsalone,furtherunderscoringtheinnovativevalueofthis\\narchitecture.\\nArchitecture Query:Basedontheprovidedtexts,what’sthemostexcitinginnovationinAIcurrently?\\nVanillaLLM1 AccordingtoSholtoDouglas,themostexcitinginnovationinAIistheabilitytohavelongcontext\\nlengths. Hesaysitallowsthemodeltoingestamassiveamountofinformation,instantlysolvingthe\\nonboardingproblem.\\nNaïveRAG Dwarkesh Patel raises concerns about the lack of a null hypothesis when studying AI models and\\nintelligence. Hearguesthatthislackofanullhypothesisincreasesuncertaintybecauseitmakesit\\ndifficulttoestablishabaselineforcomparisonandtodeterminewhetherobservedimprovementsare\\nduetoactualprogressorsimplyrandomfluctuations.Withoutanullhypothesis,itbecomeschallenging\\nto distinguish between meaningful advancements and mere chance occurrences. He believes that\\nestablishinganullhypothesisiscrucialformorerigorousanalysisandabetterunderstandingofAI\\nprogress.\\nDynaGRAG Determiningthesingle\"mostexciting\"innovationinAIissubjectiveanddependsonindividualpriorities,\\nbutseveralareasaregeneratingsignificantexcitementwithinthefield.WhileadvancementsinLarge\\nLanguageModels(LLMs)likeGPTandGeminiareundeniablyimpressive,showcasinghuman-level\\ncapabilitiesincertaintasksandfuelingrapiddevelopment,themostcompellingcontenderforthetitleof\\n\"mostexciting\"isarguablymechanisticinterpretability.\\nTheintensefocusonmechanisticinterpretabilitystemsfromthecriticalneedtounderstandhowthese\\npowerfulLLMsfunction.Thisisnotmerelyascientificchallenge;itiscrucialforensuringthesafeand\\nresponsibledevelopmentofAI.Thehighprominencegiventomodelinterpretabilityintheprovided\\ntexts(withscoresconsistentlyabove8.0),alongwiththehighlightedcontributionsofcompanieslike\\nAnthropicinopenlypublishingtheirresearch,emphasizesitsimportance.Mechanisticinterpretability\\ndirectlyaddressesthe\"blackbox\"problem,aimingtounveiltheinternaldecision-makingprocessesof\\nLLMs,whichisessentialformitigatingrisksassociatedwithdeceptionandunintendedconsequences.\\nThispursuitisintrinsicallylinkedtootherexcitingareas,suchasidentifying\"deceptioncircuits\"and\\ndevelopingautomatedinterpretabilitytools.\\nWhileLLMsthemselvesrepresentarevolutionaryleapinAIcapabilitiesandtheiradvancementscontinue\\ntogenerateexcitement,theadvancementsintechniqueslikeReinforcementLearningfromHuman\\nFeedback(RLHF),usedtoalignLLMswithhumanvalues,alsowarrantmention. Furthermore,the\\ndevelopmentofmultimodalAI,capableofprocessingvariousdatatypes,showsgreatpromiseandis\\nactivelyresearched.TheexpansionofcontextwindowsinLLMsisanotherareaofsignificantfocus,\\npromisingfurtherimprovementsintheirabilities.\\nInsummary,whiletheimpressivecapabilitiesofLLMsareundeniable,theracetounderstandtheirinner\\nworkingsthroughmechanisticinterpretabilityisarguablythemostexcitingcurrentdevelopment.This\\npursuitisdrivennotonlybyscientificcuriositybutalsobytheimperativetodevelopsafe,reliable,and\\ntrustworthyAIsystemsastheirpowercontinuestogrow.Theinterconnectednessoftheseadvancements\\n–LLMs,RLHF,multimodalAI,andthecrucialneedforinterpretability–highlightsthedynamicand\\nrapidlyevolvingnatureoftheAIfield.\\nTable2: ResponsesprovidedbyvariousarchitecturesusingGemini1.5Flash. 1Duetothesmaller\\ndatasetusedforthistest,theentirepodcasttranscriptwasincludeddirectlyintheprompt.\\n13Architecture Query:Whatarethekeyunansweredquestionsregardingthenatureofintelligence(bothbiological\\nandartificial)thathinderourabilitytoaccuratelypredictthefutureofAIdevelopment?\\nVanillaLLM Thenatureofintelligence,bothbiologicalandartificial,remainsshroudedinmystery,hinderingour\\nabilitytoaccuratelypredictthefutureofAIdevelopment. Herearesomekeyunansweredquestions:\\n1. WhatisConsciousness? Biological: Howdoesthehumanbraingeneratesubjectiveexperience?\\nWhatistherelationshipbetweenneuralactivityandconsciousness?Artificial:Canartificialintelligence\\nevertrulybeconscious?Ifso,howwouldweknow?2.HowDoestheBrainLearnandGeneralize?\\nBiological:Howdoesthehumanbrainefficientlylearnfromlimiteddata,generalizetonewsituations,\\nandexhibitcommonsensereasoning?Artificial:CurrentAImodelsoftenstrugglewithgeneralization\\nandrequiremassivedatasets. CanwedevelopAIsystemsthatlearnmorelikehumans,withfewer\\ndata points and better adaptability?... 3. What are the Limits of Computation?... 4. How Can\\nWeEnsureAISafetyandControl?... 5. WhatistheRoleofEmbodimentandInteractionin\\nIntelligence?...Thesearejustafewofthemanyunansweredquestionsthatcontinuetochallengeour\\nunderstandingofintelligenceandguidethefutureofAIdevelopment.Addressingthesequestionswill\\nrequireinterdisciplinaryresearchacrossfieldssuchasneuroscience,cognitivescience,computerscience,\\nandphilosophy.\\nNaïveRAG Basedonthepodcasttranscript,severalkeyunansweredquestionshinderourabilitytoaccuratelypredict\\nAIdevelopment:RegardingBiologicalIntelligence:Thenatureofreasoningandmemoryinthe\\nbrain:Whileanalogiesaredrawnbetweentransformermodelsandthebrain(e.g.,residualstreamsand\\ncerebellarcircuits),theexactmechanismsofreasoningandhowmemoriesareaccessedandintegrated\\nremainpoorlyunderstood.Thepodcasthighlightsthedebateonwhetherintelligenceisprimarilypattern\\nmatchingorinvolvesmorecomplexdeductiveprocesses.Therelationshipbetweenmemory,imagination,\\nand reconstructive memory processes is also unclear. The role of the cerebellum:... Regarding\\nArtificialIntelligence:Thetruenatureofin-contextlearning:...Thepotentialforemergence:...\\nDynaGRAG Severalkeyunansweredquestionsaboutthenatureofintelligence,bothbiologicalandartificial,signifi-\\ncantlyhinderourabilitytoaccuratelypredictthefutureofAIdevelopment.Theseuncertaintiesimpact\\nnotonlythetechnicaltrajectoryofAIbutalsoitseconomicviabilityandsocietalimplications. One\\ncrucialareaofuncertaintyrevolvesaroundthefundamentalnatureofintelligenceitself.Welacka\\ncompleteunderstandingofhowconsciousnessarisesinbiologicalsystems,andwhetherornotitiseven\\nanecessarycomponentofintelligence.Thisgapinknowledgemakesitdifficulttopredictwhetheror\\nwhenartificialsystemsmightachieveconsciousness,andwhattheimplicationsofsuchadevelopment\\nwouldbe.Furthermore,wedon’tfullygrasptherelationshipbetweenspecializedfunctionsandgeneral\\nintelligence,bothinbiologicalbrainsandinartificialsystems.Thehumanbrain’sabilitytointegrate\\nspecialized regions into a unified, general intelligence remains a mystery, mirroring the challenges\\nfacedincreatingtrulygeneralizableAI.Relatedly,thedebatearoundwhetherallaspectsofintelligence\\narereducibletocomputation,orwhethernon-computableelementsexist,remainsunresolved. This\\nfundamentalquestionbearsdirectlyonthepotentialforAItoevertrulyreplicateorexceedhuman-level\\nintelligence. Anothercriticalsetofunansweredquestionsconcernsthescalinglawsofintelligence.\\nWhileempiricalobservationsexistregardingtherelationshipbetweenmodelsizeandperformancein\\nAI,theextrapolationofthesescalinglawstolargermodelsremainshighlyuncertain.Wedon’tknow\\niftherearediminishingreturns,thresholds,orcriticalpointsbeyondwhichfurtherscalingyieldsno\\nsignificantimprovementinintelligence. Similarly, welackacomprehensiveunderstandingofhow\\nintelligenceevolvesbiologically,whatselectionpressuresfavoredthedevelopmentofcomplexcognition,\\nandhowthisunderstandingmightinformthefuturedevelopmentofAIthroughbiologically-inspired\\napproaches.The challenges extend to the alignment problem: how do we ensure that increasingly\\nsophisticatedAIsystemsremainalignedwithhumanvalues? Thisquestionisprofoundlylinkedto\\nourunderstandingofintelligenceitself.Ifwedon’tfullyunderstandhowintelligenceworks,aligning\\nadvancedAIsystemswithhumanintentionsbecomesexponentiallymoredifficult. Furthermore,the\\npervasiveissueofbiasinAIsystems,reflectingthebiasesoftheircreatorsandtrainingdata,underscores\\ntheneedforadeeperunderstandingofhowvaluesshapeAIdevelopmentanditspotentialsocietal\\nimpact. Finally,thedefinitionofintelligenceitselfisasourceofuncertainty. Isitpurelyefficient\\nproblem-solvingacrossvariousmodalities,ordoesitencompasssubjectiveexperience,consciousness,\\norself-awareness?ThisambiguityimpactspredictionsaboutfutureAIcapabilitiesandfuelstheongoing\\ndebatearoundwhethersimplyscalingLargeLanguageModels(LLMs)willleadtoArtificialGeneral\\nIntelligence(AGI),orifother,qualitativelydifferentfactorsareatplay. Insummary,theinabilityto\\naccuratelypredictthefutureofAIstemsfromaconfluenceoffundamentalunknowns.Theseincludea\\nlackofunderstandingregardingtheverynatureofintelligence(biologicalandartificial),thescalinglaws\\ngoverningitsdevelopment,thechallengesofaligningincreasinglysophisticatedAIsystemswithhuman\\nvalues,andthepersistentissueofbias.AddressingthesequestionsiscrucialnotonlyforadvancingAI\\ntechnologybutalsoformitigatingpotentialrisksandharnessingitstransformativepowerresponsibly.\\nTable3: ResponsesprovidedbyvariousarchitecturesusingGemini1.5Flash\\n14Theperformanceofthearchitecturesacrosstheprovidedexamplesillustratesthenuancedadvance-\\nmentsachievedbyDynaGRAGingeneratingcontextuallyrichandreasoning-intensiveresponses.\\nWhiletheVanillaLLMandNaïveRAGpipelinesproducedresponsesthatwerecoherentandrelevant,\\ntheyfellshortincapturingthedepth,diversity,andinterconnectednessthatDynaGRAGuniquely\\nuncovered. Forinstance,whentaskedwithidentifyingthemostexcitinginnovationinAI,theVanilla\\nLLMfocusednarrowlyoncontextlengths,andNaïveRAGfixatedonasinglecriticalperspective\\naboutnullhypotheses. Incontrast,DynaGRAGsynthesizedalayered,multifacetedresponse,indicat-\\ninghow\"themostexcitinginnovation\"ishighlysubjectiveandaresultofanindividual’spriorities.\\nItalsohighlightedmechanisticinterpretability,reinforcementlearningfromhumanfeedback,and\\nmultimodalAIaspromisingavenuesalongwiththeoverarchingimportanceofinterpretibilityin\\nshapingperceptionsoftechnicaladvancements.\\nSimilarly, in addressing key unanswered questions about intelligence, DynaGRAG far exceeded\\nthescopeofitscounterpartsbyweavingtogetherthemeslikethescalinglawsofintelligence,the\\nalignmentproblem, andthecomputationalboundariesofintelligence. UnliketheVanillaLLM’s\\nmoregeneralizedexplorationofkeytopicsortheNaïveRAG’ssurface-levelframing,DynaGRAG\\nintegrateddiversesourcestoprovideanexpansiveanddeeplyanalyticalresponse. Itcontextualized\\nthetechnicalandphilosophicalchallengesofintelligencewhilemaintainingclarityandcoherence,\\ndemonstratingitsabilitytoreasonacrosscomplex,multifacetedqueries.\\nWhatsetsDynaGRAGapartisitscapacitytoilluminateconnectionsthatmightotherwiseremain\\nobscured,deliveringinsightsthatfeelbothprofoundandpurpose-driven. Itsresponsesreflectamodel\\ncapableofunderstandingnotjustthequerybutthebroadernarrativeitseekstoaddress. Thisdepth\\nofreasoningalignswithoneofthemostcriticalthemesinAIresearch: explainability. Byleveraging\\ngraph-basedretrievalandadvancedpromptingtechniques,DynaGRAGnotonlyunlocksaricher\\ntapestryofknowledgebutalsooffersatransparentlensintothecontextandsourcesusedtoderiveits\\nresponses.\\nDrawingfromitsabilitytointegratediverseperspectivesandcontextualnuancesthroughadvanced\\nreasoning,theresultisanaturalemergenceofethicalandcontextuallyalignedoutputs,achieved\\nwithout explicit mandates, demonstrating that robust reasoning capabilities can inherently foster\\nalignment. Forexample,inthequeryaboutthemostexcitingAIinnovations,DynaGRAGdiscussed\\nseveraltechnicaladvancementslikeLLMs,RLHF,andmultimodalAIandthentiedtheseinnovations\\ntotheirbroaderimplicationsforsafety,transparency,andtrustworthiness. Itsresponsehighlighted\\nhow the pursuit of mechanistic interpretability is driven not merely by scientific curiosity but by\\nthe imperative to develop AI systems that are safe and reliable as their capabilities continue to\\ndevelop. Thisperspective,reflectingtheinterconnectednessofadvancementsinAI,exemplifiesthe\\ntransformative potential of AI systems to synthesize nuanced insights and deliver responses that\\ninspiremorethoughtfulexplorationofcriticalquestions.\\n6.1 LimitationsandFutureDirections\\nThisresearchsoughttocompareDynaGRAGwithMicrosoft’sGraphRAGtounderstanditsstrengths\\nrelative to a well-established alternative. While DynaGRAG employs a dynamic and adaptive\\nframeworkdistinctfromMicrosoft’sGraphRAG,suchacomparisonwouldhaveprovidedvaluable\\nmethodologicalinsights.However,evaluatingatascaleof500ktokenspresentssignificantchallenges.\\nOpen-sourceimplementationsofMicrosoft’simplementationweredifficulttoadaptasplatformslike\\nGroqimposedstricttokenlimitsandOllamalackedsufficientprocessingspeed. Despiteexploring\\nadditional options such as Gemini 2.0 Flash Experimental and the MultiHop-RAG benchmark,\\ncomputationallimitationsremainedabottleneck.\\nAs a solo developer, these constraints naturally influenced the scope of my evaluation. Future\\ncomparisonscouldbenefitfromnarrowingthedatasetto100ktokens,allowingformoremanageable\\ntestingofotherarchitectures,includingMicrosoft’sGraphRAGandopen-sourceLLMs.Additionally,\\nrefiningtheapproachtocreatehierarchicalsubgraphscouldfurtherenhancescalabilityandcontextual\\nunderstanding,enablingmoreefficientrepresentationofcomplexrelationships. Evenso,DynaGRAG\\ndemonstratedsignificantadvancementsinreasoningandcontextualdepthoveradvancedmodelslike\\nGemini1.5Flashwhileprocessingqueriesinapproximatelyoneminuteandwithoutanyadditional\\nLLMfinetuning. Thisefficiencyhighlightsitspracticalviabilityandcost-effectivenessforreal-world\\napplications.\\n15The experiments also underscored the critical role of graph density in enabling robust reasoning\\nandcontextsynthesis. Dense,well-connectedgraphsexcelatcapturingintricaterelationshipsand\\nsynthesizing nuanced insights, particularly in smaller datasets where interconnections are more\\npronouncedandnoiseisminimal. However,scalingtolargerdatasetsintroduceschallenges,assparse\\ngraphsdilutetheseconnectionsandhinderinformationsynthesis. Addressingthisdisparitythrough\\ntechniquestopreservegraphdensityatscaleisacriticalareaforfuturework. Suchadvancements\\ncouldunlocktheabilitytomaintainnuancedreasoningandcontextsynthesisacrossdiversedata\\nregimes,furtherenhancingthescalabilityandadaptabilityoftheframework.\\n7 Conclusion\\nThisworkintroducesDynaGRAGasameaningfulstepforwardinadvancinggraph-basedreasoning\\nandlanguagegeneration. BycombiningLLMswithgraphlearningtechniques,DynaGRAGachieves\\nanadaptiveandquery-awarecapability,retrievingandsynthesizingsubgraphstouncovercomplex\\nrelationships. Theframeworkconsistentlyoutperformedbaselinemethods,demonstratingitsstrength\\ninproducingnuanced,contextuallyrichresponsesthataddressreasoning-intensivechallenges. The\\nabilitytodynamicallyadapttodiversequerieswithoutrequiringfine-tuningemphasizesitsscalability\\nandpracticalityforreal-worldapplications.\\nThe broader implications of this research extend beyond technical performance, positioning Dy-\\nnaGRAGasatoolforfosteringdeeperunderstanding. AsYannLeCunhasnoted,LLMsarenot\\nyetcapableofhuman-likereasoning17,butintelligenceitselfremainsanelusiveconceptwithouta\\ncompletedefinition. Thisambiguitywasevidentinoneofthetestedqueries,whichexploredthe\\nfutureofintelligence. DynaGRAG’sresponsetothisqueryhighlightedaprofoundduality: whilewe\\ncanreasonaboutwhatweknow,thereremainaspectsofintelligencewehaveyettoseeorunderstand.\\nBy connecting themes like mechanistic interpretability, scaling laws, and alignment challenges,\\nDynaGRAGdemonstratedhowreasoningsystemscannavigatetheseunchartedterritories,pushing\\ntheboundariesofwhatAIcanachieveinreasoningandunderstanding.\\nDynaGRAGmovesbeyondgeneratingoutputsbyprovidingtransparencyintothecontextandrela-\\ntionshipsunderpinningitsresponses,addressingthegrowingdemandforexplainabilityinAIsystems.\\nThiscapabilityfosterstrustandalignment,enablingapplicationsinareaslikeknowledgediscovery,\\nethicaldecision-making,andsolvingcomplexproblemswhereclarityisessential. Bysynthesizing\\ndiverse contexts, DynaGRAG uncovers hidden connections and exposes gaps in understanding,\\nencouragingexplorationofwhatremainsunknown. Itsemphasisonreasoningasacoreaspectof\\nintelligenceoffersnotjustanswersbutnewperspectives,redefininghowAIsystemsengagewith\\nknowledge. This work highlights the transformative role of advanced reasoning frameworks in\\nexpandingtheboundariesofourunderstandingandshapingthefutureofintelligentsystems.\\n16References\\n1. Vellum AI. Llm leaderboard by vellum (2025). URL https://www.vellum.ai/\\nllm-leaderboard. Accessed: 2025-01-24.\\n2. Tong,A.&Paul,K. Exclusive: Openaiworkingonnewreasoningtechnologyundercodename\\n‘strawberry’. Reuters(2024). URLhttps://www.reuters.com. Accessed: 2025-01-24.\\n3. Lobo,E.,Agarwal,C.&Lakkaraju,H. OntheImpactofFine-TuningonChain-of-Thought\\nReasoning. InarXiv(UniversityofMassachusettsAmherst, UniversityofVirginia, Harvard\\nUniversity,2024).\\n4. etal.,J.L. FromLocaltoGlobal: AGraphRAGApproachtoQuery-FocusedSummarization.\\nInarXiv(2024).\\n5. etal., Y.H. GRAG:GraphRetrieval-AugmentedGeneration. InarXiv(Atlanta, GA30322,\\nUSA,2024).\\n6. etal.,Y.G. Retrieval-AugmentedGenerationforLargeLanguageModels: ASurvey. InarXiv\\n(ShanghaiResearchInstituteforIntelligentAutonomousSystems,TongjiUniversity,Shanghai\\nKeyLaboratoryofDataScience,SchoolofComputerScience,FudanUniversity,Collegeof\\nDesignandInnovation,TongjiUniversity,2024).\\n7. et al., S. C. LLMs generate structurally realistic social networks but overestimate political\\nhomophily. InarXiv(DepartmentofComputerScience,StanfordUniversity,Departmentof\\nComputerScience,UniversityofCalifornia,LosAngeles,DepartmentofComputerScience,\\nCornellUniversity,2024).\\n8. etal.,Y.Y. ExploringthePotentialofLargeLanguageModelsinGraphGeneration. InarXiv\\n(TsinghuaUniversity,PekingUniversity,2024).\\n9. etal.,S.P. UnifyingLargeLanguageModelsandKnowledgeGraphs: ARoadmap. InarXiv\\n(IEEE,2024).\\n10. Guo,X.&Zhao,L. ASystematicSurveyonDeepGenerativeModelsforGraphGeneration. In\\narXiv(2022).\\n11. Mavromatis,C.&Karypis,G. GNN-RAG:GraphNeuralRetrievalforLargeLanguageModel\\nReasoning. InarXiv(2024).\\n12. etal.,B.P. GraphRetrieval-AugmentedGeneration: ASurvey. InarXiv(2024).\\n13. Sanmartín,D. KG-RAG:BridgingtheGapBetweenKnowledgeandCreativity. InarXiv(2024).\\n14. Fatemi,B.,Halcrow,J.&Perozzi,B. TalkLikeaGraph: EncodingGraphsforLargeLanguage\\nModels. InarXiv(2023).\\n15. etal.,Z.C. ExploringthePotentialofLargeLanguageModels(LLMs)inLearningonGraphs.\\nInarXiv(MichiganStateUniversity,BaiduInc.,EmoryUniversity,TheHongKongPolytechnic\\nUniversity,2024).\\n16. Patel,D. DwarkeshPodcast: DeeplyResearchedInterviews. https://www.dwarkeshpatel.\\ncom/podcast(2025). Accessed: 2025-01-24.\\n17. Hart,R. Meta’sAIChief:AIModelsLikeChatGPTWon’tReachHumanIntelligence. InForbes\\n(2024).\\n17',\n",
       " \"Exploring Gradient Subspaces Addressing and Overcoming LoRA's Limitations in Federated Fine-Tuning of Large Language Models.pdf\": 'Exploring Gradient Subspaces: Addressing and Overcoming LoRA’s Limitations\\nin Federated Fine-Tuning of Large Language Models\\nNavyanshMahla1,KshitijSharadJadhav1,GaneshRamakrishnan1\\n1IndianInstituteofTechnologyBombay\\n210040106@iitb.ac.in,kshitij.jadhav@iitb.ac.in,ganesh@cse.iitb.ac.in\\nAbstract shotlearningcapabilities(Brownetal.2020).Theintroduc-\\ntionofVisionTransformers(ViTs)(Dosovitskiyetal.2021)\\nLargeLanguageModels(LLMs)havedemonstratedremark-\\nhasextendedthecapabilitiesoftransformerstoprocessim-\\nablecapabilitiesacrossvariousdomains,particularlyintask\\nagemodalities.Liketheircounterpartsinlanguageprocess-\\ngeneralizationforbothtextandvisiondata.Whilefine-tuning\\ning, ViTs are pre-trained on vast image datasets, enabling\\nthese models can significantly enhance their performance\\nthemtoachievearobustcontextualunderstandingofvisual\\non specific downstream tasks, it often requires high-quality\\ndata that cannot be shared due to privacy concerns. Feder- content.ModelssuchasCLIP(ContrastiveLearningImage\\nated Learning (FL) offers a promising solution for collabo- Pre-training) (Radford et al. 2021a) have facilitated the in-\\nrative training without direct data sharing. However, many tegrationoftextandimagemodalitiesbyaligningtheirrep-\\nparameter-efficient fine-tuning strategies for LLMs in FL, resentations into a shared subspace. This has led to the de-\\nparticularly those based on Low-Rank Adaptation (LoRA), velopment of Vision-Language Models (VLMs) and Large\\nfacelimitations.Inthispaper,wecriticallyanalyzethecon- Multimodal Model (LMM) (Liu et al. 2023) architectures,\\nvergenceandperformanceguaranteesofpopularFLframe-\\nenabling transformer networks to interpret and reason over\\nworksutilizingLoRA,highlightingitssuboptimalnaturedue\\ntext and image prompts simultaneously, thereby enhancing\\ntoconstrainedsubspacelearningoflow-rankmatrices.This\\ntheir capabilities in visual question answering. These pre-\\nlimitation hinders effective fine-tuning of LLMs in feder-\\ntrained language models can be further fine-tuned to im-\\natedsettings.Throughrigorousanalyticalandempiricaleval-\\nuations, we demonstrate that direct weight averaging out- prove performance on specific downstream tasks (Radford\\nperformsLoRA-basedstrategies,leadingtosuperiorperfor- et al. 2021a). However, the good-quality datasets required\\nmanceforfine-tunedmodels.Ourcomprehensivecomparison for fine-tuning can be distributed and may not be shared\\nunmasksinefficienciesinLoRAapproachesandunderscores directly due to privacy concerns. Researchers have turned\\ntheadvantagesofdirectweightaggregation.Weextendour to Federated Learning (FL) (McMahan et al. 2017) as a\\nanalysistolow-rankgradient-basedoptimizers,suchasGa- means to fine-tune LLMs without compromising the data\\nLore,usedduringlocaltrainingsteps.Ourfindingsshowthat\\nprivacy(Qinetal.2024;Zhangetal.2024a;Baietal.2024;\\nGaLorealongwithdirect-weightaggregationisamoreeffec-\\nBabakniyaetal.2023).Inthesesettings,parameter-efficient\\ntive approach, outperforming federated LoRA methods like\\nfine-tuningmethods(Dingetal.2023)likeLoRA(Huetal.\\nFlexLoRAandFFA-LoRAacrossbothtextandimagemodal-\\n2022)areutilizedtominimizecomputationaloverhead.We\\nities.WhileprivacyremainsparamountinFLdiscourse,our\\nfocusisonassessingperformanceoutcomesoffederatedfine- analyzethemostrecentSOTALoRAapproaches,whichin-\\ntuned models and evaluating various FL frameworks from cludeFlexLoRA(Baietal.2024)andFFA-LoRA(Sunetal.\\nboththeoreticalandempiricalperspectives.Ourfindingsad- 2024b), and identify potential bottlenecks resulting in their\\nvocatereassessingtherelianceonLoRAwithinFLcontexts, performancedegradation.\\npavingthewayformoreefficienttrainingmethodologies. We demonstrate that the direct weight aggregation strategy\\neffectively addresses the limitations of LoRA in federated\\nlearning contexts to some extent. Building on this analy-\\nIntroduction\\nsis, we theoretically establish that gradient low-rank opti-\\nThepastfewyearshavewitnessedunprecedentedadvance- mizers,suchasGaLore(Zhaoetal.2024)coupledwithdi-\\nments in Large Language Models (LLMs) (Brown et al. rectweightaveraging,representamoreeffectivefine-tuning\\n2020; OpenAI 2023; Du et al. 2024; Touvron et al. 2023; approach for both large language models (LLMs) and vi-\\nZengetal.2022;Zhangetal.2022).Theselanguagemod- siontransformers(ViTs)infederatedsettings.Ourtheoreti-\\nels(LMs)arepoweredbyTransformer(Vaswanietal.2017) calinsightsarevalidatedthroughexperimentsthatrevealthe\\nneural network architecture. Since the transformer models suboptimalperformanceofLoRA-basedmethodsinFLen-\\nhave extensive pre-trained context, they exhibit enhanced vironments. Notably, combining direct weight aggregation\\ngeneralization capabilities, providing them effective few- withGaLoreasanoptimizerforlocaltrainingstepssignif-\\nicantly outperforms leading state-of-the-art LoRA methods\\nCopyright©2025,AssociationfortheAdvancementofArtificial\\nlikeFlexLoRAandFFA-LoRA.Welistthecontributionsof\\nIntelligence(www.aaai.org).Allrightsreserved.\\n5202\\nnaJ\\n7\\n]GL.sc[\\n5v11132.0142:viXraourpaperbelow: 2021). However, the massive size of large language mod-\\nels demands substantial resources for inter-client commu-\\n• We highlight the sub-optimal nature of the most recent\\nnication and local training, highlighting the need for more\\nLoRA-based SOTA methods like FlexLoRA (Bai et al.\\ncomputeandcommunication-efficientparadigmsinFLfine-\\n2024)andFFA-LoRA(Sunetal.2024b)inFL.\\ntuning. Due to their efficiency in fine-tuning, PEFT ap-\\n• We provide analytical evidence that LLMs and ViTs proachesarewell-suitedforFLschemestosolvesuchprob-\\nfine-tunedwiththeGaLoreoptimizerduringlocaltrain- lems. LoRA has been prominently utilized in fine-tuning\\ning, when directly aggregated with FedAvg, outperform languagemodelsinFLsettingsasdiscussedinseveralstud-\\nmethodslikeLoRA.Ourstudydemonstratesthisthrough ies (Bai et al. 2024; Qin et al. 2024; Zhang et al. 2024a;\\na straightforward experimental setup using the GaLore Choetal.2023;Kuangetal.2023;Babakniyaetal.2023).\\noptimizerforparameterupdatesanddirectweightaggre- ManyofthesestudiesadoptFedAvg(McMahanetal.2017)\\ngationusingFedAvg. as the aggregation algorithm to aggregate client-side pa-\\nrameters onto a server model. For instance, FedIT (Zhang\\n• We present results on text and image modalities us-\\net al. 2024a) fine-tunes models in decentralized settings by\\ning vision and language transformers across multiple\\nsharingandaggregatingLoRAmatrices(letB bethezero-\\nclients and configurations, surpassing current SOTA\\ninitialized LoRA matrix and A be the Gaussian initialized\\nLoRAmethodsandvalidatingourtheoreticalanalysisof\\nLoRA matrix) separately. SLoRA (Babakniya et al. 2023)\\nLoRA’ssub-optimality.\\nintroducesatwo-stagesparsefine-tuningapproachwithim-\\nproved LoRA matrix initialization for federated learning.\\nRelatedWorks\\nFollowing the improved initialization, a mechanism sim-\\nParameterEfficientFine-TuningofLLMs ilar to that of FedIT is adopted for distributed training.\\nFlexLoRA (Bai et al. 2024) enhances previous methods\\nPre-trainedtransformers,trainedonextensivetextorimage\\nby allowing diverse LoRA weight mixtures across clients,\\ndatasets, gain broad contextual understanding. Fine-tuning\\nclaiming superior performance compared to SLoRA in ho-\\nthesemodelsimprovestheirperformanceontargeteddown-\\nmogeneous settings and HETLORA (Cho et al. 2023) in\\nstream tasks (Radford et al. 2021b). However, fine-tuning\\nheterogeneoussettings.InsteadofaggregatingLoRAmatri-\\non consumer-grade GPUs is challenging due to their large\\ncesseparately,FlexLoRAmultipliesmatricesB andAbe-\\nparametercount,whichdemandssignificantGPUmemory.\\nforeaggregation,thendecomposestheresultingmatrixinto\\nToaddressthiscomputationalcomplexity,researchershave\\nlow-rank components via truncated SVD, with the decom-\\nproposed Parameter Efficient Fine-Tuning (PEFT) (Ding\\nposed matrices copied to the LoRA matrices B and A of\\netal.2023)techniqueslikeprompttuning(Lester,Al-Rfou,\\neachclient.Otherstrategies,suchasFFA-LoRA(Sunetal.\\nandConstant2021),adaptertuning(Heetal.2021;Houlsby\\n2024b), focus on fine-tuning only matrix B while keeping\\net al. 2019), and Low-Rank Adaptation (LoRA) (Hu et al.\\nall other parameters frozen across varying tasks, hyperpa-\\n2022).Adapterlearningtechniquesaddtrainableparameters\\nrameters,and privacyprotection levels.In contrast,our ap-\\nto the model sequentially while keeping other components\\nproachFedFTGonlyfine-tunestheMLPlayerswithoutany\\nfrozen. This reduces the overall number of trainable pa-\\nadapterswithGaLore(Zhaoetal.2024)optimizationtore-\\nrameters, enabling fine-tuning on smaller GPUs. In LoRA,\\nducememoryusageforoptimizationstates.\\nadaptersareappliedinparallelanddecomposedintolower-\\nrankmatrices,furtheroptimizingparameterefficiency.Sim- GaLoreinLLMsandViTs\\nilarly, prefix and prompt tuning involve applying modules\\nGaLore is a subspace gradient learning approach designed\\nin parallel to attention heads (Li and Liang 2021) or em-\\nfor memory-efficient training of LLMs. This method re-\\nbeddings (Lester, Al-Rfou, and Constant 2021) to achieve\\nduces the memory footprint of optimizer states by project-\\nefficient fine-tuning. The model’s fine-tuning performance\\ning gradient matrices into a low-rank subspace before ap-\\ngreatlydependsonthedataset’ssizeandquality(Sunetal.\\nplyingoptimizationtechniquessuchasAdamW(Loshchilov\\n2024a). Good-quality datasets are often distributed across\\nand Hutter 2019) or SGD (Ruder 2017). Recent studies,\\nmultipleparties,asasinglesourcemaybeinsufficientforef-\\nsuch as MedSAGa (Mahla et al. 2024), have empirically\\nfectivefine-tuning.Privacyconcernsandregulationslikethe\\nvalidated GaLore’s effectiveness for tasks like image seg-\\nGeneralDataProtectionRegulation(GDPR)furtherprevent\\nmentation.Authorsfine-tunedViT-basedSegmentAnything\\ncentralizing data for collaborative efforts, especially under\\nModel(SAM)(Kirillovetal.2023)usingGaLore,showcas-\\nthenewEUAct(Woisetschla¨geretal.2024).\\ning its applicability beyond traditional language modeling\\ntasks.\\nPEFTinFederatedLearning\\nFederated Learning (FL) (McMahan et al. 2017) addresses Methodology\\nthisissuebyenablingcollaborativeneuralnetworktraining\\nProblemSetting\\nwithoutdatacentralization.Ithasbeensuccessfullyapplied\\nto various architectures, including transformers (Bai et al. We frame our problem within a multi-silo environment\\n2024;Qinetal.2024;Zhangetal.2024a;Babakniyaetal. where each silo (client) hosts the same Large Language\\n2023;Kuangetal.2023;Choetal.2023;Anselletal.2022; Model (LLM) M to fine-tune along with a dataset D =\\ni\\nAlam et al. 2022; Niu et al. 2022; Diao, Ding, and Tarokh (cid:8) (xi,yi)n (cid:9) (assuming all the N clients have the same\\nj j j=1sample size n) that is non-independent and identically dis- A∈Rr×k andB ∈Rd×r.B isinitializedaszerowhileA\\ntributed(non-IID)comparedtodatasetsofotherclients.DT uses random Gaussian initialization. Here, r ≪ min(d,k).\\ni\\nandDE respectivelyrepresentthetrainandevalsplitofthe This reduces the number of training parameters by a factor\\ni\\ndatasetD .Asingleserverfacilitatestheglobalaggregation of d×k comparedtofullparameterfine-tuning.\\ni r×(k+d)\\nofclientparametersofN clients.Duetoprivacyconcerns,\\nProposition1 In FL scenarios like FlexLoRA, where pa-\\ntheseclientscannotsharethedatawiththeserverforcentral-\\nrameter change matrices ∆W from N clients are aggre-\\nizedtraining.θ ∀t∈{1,2,...,N}arethemodelparameters i\\ni gated with each client i having an intrinsic rank r , the\\natclientiandθ arethemodelparametersattheserver.We i\\ng globally aggregated parameter matrix exhibits rank infla-\\ndefinethedistributedlearningobjectiveas:\\ntionfollowingeachglobalaggregationstep.Specifically,in\\nN (cid:18) (cid:19) ascenariowhereallclientshaveidenticalranksr = r for\\n1 (cid:88) i\\nmin L (θ ):= E l(M(x;θ ),y) (1) simplicity, the rate of rank inflation, denoted by η satisfies\\nθg N\\ni=1\\ni g (x,y)∈D iE g 1≤η ≤N perglobalaggregationstep.\\nWherelistheconvexlossfunction.Eachclientperformsits The equality on the left holds true when the ranks of all\\nownlocaltrainingstep: matricessharethesamesubspace,aconditionthatbecomes\\nunattainable when data samples are non-IID across clients.\\n1 (cid:88)\\nL i(θ i)= (cid:12)\\n(cid:12)D\\niT(cid:12)\\n(cid:12)\\n(x,y)∈DT\\nl(M(x;θ i),y) (2) F mu or rt ehe cr od me pta reil hs e, nin sc ivlu ed di in sg cuth sse iop nro ,o af reo af vth aii ls ap br leop inos ti hti eo sn ua pn pd lea\\n-\\ni mentarymaterial.\\nAftersomelocaliterationsT agg,theparametersaresentto In FlexLoRA, the LoRA matrices B and A are multiplied\\ntheserverforaggregationusingFedAvg: and then aggregated across clients. The product of these\\nmatrices is then subjected to Singular Value Decomposi-\\nN\\nθ\\ng\\n:=\\n|D1 |(cid:88)(cid:12)\\n(cid:12)D\\niT(cid:12)\\n(cid:12)θ\\ni\\nt ri ao nn k.H(S oV wD ev) et ro\\n,\\ntd he isco am ppp ro os ae chit fab ca ec sk ato sigth ne ifico ari ng tin ca hl alL leo nR gA\\ne:\\ni=1\\nafter aggregation, the resulting rank of the matrix is in-\\nHere, |D| is the sum of the size of the train split of the flated(asshowninProposition1),capturingmorecompre-\\ndatasets of all the clients. These aggregated parameters are hensive information from all the non-IID datasets. When\\nsubsequently copied back to each client model to resume this aggregated matrix is reduced to a smaller dimension\\ntraining. This allows local iterations to proceed with the via SVD, it consistently maps the weights to a subspace of\\nmodelparametersθ g,whichwereaggregatedduringthelat- fixedrank—thesameastheLoRArank,whichremainscon-\\nestglobalaggregationstep. stantthroughouttraining.Thisdimensionalityreductioncan\\ncreate a bottleneck, as it restricts the model’s ability to ef-\\nWhyNotLoRA?\\nficiently capture and leverage the learned local semantics\\nIn this section, we analyze the use of LoRA in FL from from non-IID datasets. By decomposing the weights into\\nthe perspective of two of the most recent SOTA LoRA FL rankssmallerthantheactualrankoftheaggregatedmatrix,\\nschemes:FlexLoRA(Baietal.2024)andFFA-LoRA(Sun valuableinformationmaybelost,therebylimitingtheeffec-\\net al. 2024b). Both of these methods have presented their tiveness of FlexLoRA in federated learning scenarios with\\nownanalysisofthevanillaLoRAFLschemeFedIT(Zhang diversedatadistributions.\\net al. 2024a). The authors of FlexLoRA question LoRA’s Forfine-tuningLLMsinFLsettingsusingFFA-LoRA:\\nefficiency in highly heterogeneous tasks across different\\nN N\\nclients. They discuss the infeasibility of existing LoRA so- 1 (cid:88) 1 (cid:88)\\n∆W = ∆W = ∆B A (4)\\nlutions like FedIT in FL settings due to the bucket effect agg N i N i 0\\ncausedbydifferentintrinsicranksateachclientbecauseof i=1 i=1\\nheterogeneousdatasets.Ontheotherhand,authorsofFFA- TheGaussianinitializedLoRAmatrixAisfrozenforallthe\\nLoRAperformarigorousanalysisofvanillaLoRAmethod clients.Essentially,aggregationhappensforthezeroinitial-\\nlike FedIT in the ”client-drift” (Karimireddy et al. 2020) izedLoRAmatricesB ∀i∈{1,2,...,N}.\\ni\\nscenario and the amplification of noise in FL settings with Theorem1 For a convex loss L, let ∆W∗ ∈ Rd×k be\\nDP-SGD (Abadi et al. 2016) due to semi-quadratic struc-\\ntheoptimalLoRAparametermatrix,αbethelearningrate\\nture of LoRA. With thorough analysis, both of these meth- and A ∈ Rr×k be a Gaussian initialized random matrix,\\n0\\nodswereabletooutperformvanillaLoRAFLmethod.Here,\\nwhere r ≪ min(d,k) and the L2 norm of the gradient to\\nwepresentouranalysisofwhytheSOTALoRAframeworks (cid:13) (cid:13)\\nlikeFlexLoRAandFFA-LoRAaresub-optimalundermulti-\\nbe bounded (i.e. (cid:13)∇ WL(i)(∆W)(cid:13)\\n2\\n≤ D). The excess\\nrisk(|L(∆W )−L(∆W∗)|)boundsfortheFFA-LoRA\\nclientFLsettings. agg\\nframework, involving N clients and S global aggregation\\nThecoreideaofLoRAistoconstraintheweightupdate\\nsteps having occured every t local training iterations,\\nonthemodelbyalow-rankdecomposition: agg\\ncanbeexpressedasfollows:\\nW 0+∆W =W 0+BA (3) (cid:16) α (cid:17)\\n≤DNSt DNSt c+ ∥∆W∗∥\\nHereW 0 ∈ Rd×k isthepre-trainedweightmatrixwhichis agg agg N 2 (5)\\nfrozenduringthetrainingprocess.Updatesareperformedon =O(N2S2t2 )\\naggsubspace,wheretheoptimizationprocessisthencarriedout.\\nInterestingly,thisapproachnotonlysavesmemorybutalso\\nleads to linear excess risk bounds, as demonstrated in the\\nfollowingtheorem:\\nTheorem2 For a convex loss function L, let ∆W∗ de-\\nnote the optimal weight matrix and α represent the learn-\\ning rate. Assuming that the L2 norm of the gradient is\\n(cid:13) (cid:13)\\nbounded,specifically(cid:13)∇ WL(i)(∆W)(cid:13)\\n2\\n≤D,theexcess\\nrisk, defined as |L(∆W )−L(∆W∗)|, for the aggre-\\nagg\\ngatedweightsafteratotalofS directFedAvgaggregations\\nhavingoccuredeveryt localtrainingiterationswithGa-\\nagg\\nLoreasanoptimizercanbeexpressedasfollows:\\n|L(∆W )−L(∆W∗)|≤αD2St +c=O(St )\\nagg agg agg\\n(6)\\nFigure1:FedFTGexclusivelyfine-tunesthelowerMLPlay- Here,cisascalarconstant.\\nersofthetransformernetworkwhilekeepingallothercom-\\nConcludingfromtheorem2,theupperboundsonexcess\\nponentsfrozen.GaLoreisusedasanoptimizer,andsimilar\\nriskfordirectweightaveragingareindependentofthenum-\\nto standard federated learning setups, globally aggregated\\nber of clients and exhibit a linear relationship (contrary to\\nparameters are copied back to each client after each global\\nquadratic in case of LoRA (theorem 1)) with the number\\naggregationround.\\nof global FedAvg steps and local training iterations t .\\nagg\\nAdopting direct weight averaging with GaLore as an opti-\\nmizer for fine-tuning in federated settings ensures that ex-\\nHere, ∆W∗ is hypothetically the most optimal LoRA\\ncess risk remains unaffected by client count. This trend is\\nadaptermatrixandcisaconstantscalar.\\nfurther supported by the experimental results presented in\\nTheorem1iscrucialtoouranalysisasitdemonstratesthat later sections. We will use FedAvg as the global aggrega-\\ntheexcessriskboundsforFFA-LoRAareupper-boundedby tion algorithm, as it is widely used in federated fine-tuning\\nanexpressionthatincreaseswitheachFedAvgglobalaggre- for large language models. Combining FedAvg with direct\\ngation step S. This indicates that models trained using the weight averaging allows for a fair comparison and shows\\nFFA-LoRA framework progressively deviate from the op- that even a simple algorithm like FedAvg can yield signifi-\\ntimal hypothesis as the number of FedAvg steps increases, cantlybetterresultswhenpairedwithamoreefficientframe-\\nleadingtoinstability.Consequently,duetothisdivergence, work.Inthecontextoftransformerneuralnetworks,theGa-\\nthe model struggles to capture the overall data distribution Lorepaperdemonstratesthatthelow-rankprojectionofgra-\\nacross all clients, resulting in poor generalization over un- dient matrices can be effectively applied to its lower MLP\\nseen data samples. We refer to the supplementary material layerslikeproject-up(seeLemmaB.6fromGaLorepaper)\\nfortheproofsanddetaileddiscussionsonthetheorem. whose gradients become low-rank during training. Conse-\\nquently,unlessstatedotherwise,weconductallouranalyses\\nHowcanweimprove? and experiments on the lower MLP layers. Another advan-\\nThe previous section offers valuable insights into the sub- tage of using GaLore is its improved generalization error\\noptimal behavior of LoRA in federated settings. In partic- comparedtoLoRA-basedmethods,asdemonstratedbythe\\nular, the use of low-rank adapters hinders efficient learn- followingtheorem(Noneofthetheoremsassumeaspecific\\ning,asthelow-ranksubspaceexpandswitheachglobalFe- clientdatasetsize;theyaccountforbothequalanddifferent\\ndAvg aggregation step. This is particularly suboptimal for datasetsizes):\\nFlexLoRA,whileforFFA-LoRA,theboundsonexcessrisk\\nTheorem3 Let N denote the number of clients, each pos-\\narequadratic.Therefore,werecommendagainstusinglow-\\nsessingadatasetwithnsamples.Weconsidertheweightsof\\nrankadapters.Instead,weadvocateforthedirectaveraging\\nalower-levelMLPlayerrepresentedbyW ∈Rd×k.Under\\nof parameters in federated settings. Direct weight aggrega-\\ntheassumptionthattheriskfunctionofeachclientisσ-sub-\\ntion in itself poses problems such as computational ineffi-\\nGaussianwithrespecttothedatadistributionofthatclient\\nciency.LoRAisaparameterefficientapproachwhichresults\\nandthecorrespondingweightmatrix,wederivethefollow-\\nsaving a lot of compute. Direct weight averaging won’t be\\ninggeneralizationerrorboundsforweightaggregation:\\nparameter efficient. To optimize memory usage and enable\\na)Forfederatedfine-tuningusingFFA-LoRA:\\nall clients to fine-tune LLMs locally, we recommend using\\nGaLoreastheoptimizerduringlocaltrainingiterations.Ga-\\nLore is an optimization method that improves memory ef- 1 (cid:88)N (cid:115) 2σ2ln2 (cid:88)\\nE ≤ rq (d) (7)\\nficiency while training of transformer based models (Zhao 1 N n\\net al. 2024). GaLore reduces optimizer state memory us- i=1 i\\nagebyprojectingweightgradientsontoalower-dimensional b)ordirectweightaggregationusingFedAvgwithalow-rankgradient-basedoptimizer,suchasGaLore:\\n(cid:118)\\nE\\n2\\n≤\\nN1 (cid:88)N (cid:117) (cid:117) (cid:116)−2 nσ2 (cid:88)d (cid:88)k\\nf(W\\ni(j)[l],t)log(cid:16)\\nf(W\\ni(j)[l],t)(cid:17)\\ni=1 j=1l=1\\n(8)\\nwhere W(j)[l] represents the element of lth index in\\ni\\nthe jth row of the matrix W . Here, f(W(j)[l],t) =\\ni i\\nexp(W(j)[l])\\n(cid:80)k exp(i W(j)[l]) be the function to represent the ratio Figure 2: Label distribution across shards for the Dolly\\n(prl o= b1 ability)i in a succinct manner. As t → ∞, i.e. as the datasetproducedusingDirichletAllocationwithα=0.1.\\nfederatedtrainingcontinuesf(W(j)[l],t)→ 1.\\ni k\\nAs one can infer from the theorem, generalization error\\nE at the end of the training becomes upper bounded by\\n2\\n(cid:113)\\n1 (cid:80)N 2σ2dlogkwhichismuchsmallerthanthatofthe\\nN i=1 nk\\n(cid:113)\\npart(a)(E ≤ 1 (cid:80)N 2σ2ln2rqd).Thus,directaverag-\\n1 N i=1 n\\ningwithGaLoreoptimizershowsbettergeneralizationthan\\nFFA-LoRA framework. Notably, overall entropy decreases\\nduringGaLore-baseddirectFedAvgaggregation,indicating\\nmore structured weight matrices, which correlates with en-\\nhancedgeneralizationperformance.IntegratingtheGaLore Figure3:LabeldistributionacrossshardsfortheMedQuAD\\noptimizer with FedAvg effectively leads to rank reduction datasetproducedusingDirichletAllocationwithα=0.1.\\n(considering fixed quantization bits q), confining the learn-\\ning process to a compact, structured subspace with lower\\nentropy. This localized learning is important as it achieves we focus on fine-tuning the lower MLP layers (project-up)\\ncomparableexcessriskboundswhileoperatinginareduced of the transformer neural network. This is consistent with\\nparameter space, enhancing computational efficiency. Our Theorem 3, which addresses the scenario where the lower\\nanalysisshowssalientfeaturelearninginfederatedsettings MLPlayersarefine-tuned.Sincetheself-attentioninforma-\\nsimilar to (Tian et al. 2024) which is for centralized cases. tion is inherently captured within these lower MLP layers,\\nThe framework focuses on learning shared salient features and these layers typically exhibit lower generalization er-\\nacrossdistributeddatasets,creatingacommonsubspacethat ror in federated settings, we recommend focusing on fine-\\nfacilitates effective performance across all client distribu- tuning only the lower MLP layers. To update the parame-\\ntions.Astrainingadvances,theparametermatrixconverges ters in FedFTG, we utilize GaLore, as detailed in the pre-\\ntoawell-defined,approximatelylinearmanifoldduetothe vious section. The entire pipeline is shown in the figure 1.\\nreducedrank.Thegradientmatrixexhibitssimilarlow-rank ThecompleteFedFTGalgorithmpipelineisdetailedinthe\\nbehavior as t → ∞, suggesting it also manifests on a accompanyingalgorithm.FedFTGisanexperimentalsetup\\nnear-linearmanifold.GaLoreintegrationinfederatedlearn- that validates our theory against current SoTA LoRA ap-\\ning outperforms traditional LoRA-based weight averaging proaches,addressingtheirlow-ranklearningconstraintsand\\nthrough better efficiency, better risk bounds, and stronger trainingstabilityissues.\\ngeneralization guarantees. This leads us to explore opti-\\nmal ways to implement GaLore for distributed fine-tuning Experiments\\nto maximize its subspace learning benefits. To address this\\nIn this section, we demonstrate the stability and efficiency\\nchallenge, we introduce FedFTG (Federated Fine Tuning\\nof models trained with GaLore as the optimizer and direct\\nusing GaLore), an experimental framework for federated\\nweightaggregation.Weevaluateitsperformanceacrossboth\\nlearningthatisdesignedforfederatedfine-tuningscenarios\\ntext and image modalities to showcase its effectiveness on\\nwhileusingGaLoreforlocaltrainingstepsateachclient.\\nLLMsandViTs.Forthetextmodality,experimentsinvolve\\nFederatedFine-TuningUsingGaLore(FedFTG) 3 and 4 clients, while vision experiments include 3, 4, and\\n5clients,witheachclienthostinganon-IIDdatasetdistinct\\nInprevioussections,wehighlightedthelimitationsoflow-\\nfrom others. All experiments were conducted on a cluster\\nrankadaptertuningforLLMsinfederatedsettings.Wealso\\nof Nvidia A6000 GPUs, with setup details provided in the\\ndemonstrated that using GaLore as an optimizer for local\\nsupplementarymaterial.\\ntraining offers superior generalization, improved memory\\nefficiency, and better training performance overall. We re-\\nDatasets\\nfertotheJoMApaper(Tianetal.2024)(Theorem1ofthe\\npaper) that states that we do not need to explicitly update We conduct experiments on both text and image datasets,\\ntheself-attentionparameterssinceitisalreadyimplicitlyin- incorporating various downstream tasks. For text, we use\\ncorporatedinthelowerlayerofMLPweight.Consequently, the MedQuAD (Ben Abacha and Demner-Fushman 2019)Algorithm1:FedFTG beldistributionacrosseachnon-IIDshardforallthedatasets\\nInput: Model M from each client i with non-IID datasets (bothimageandtext)canbefoundinthesupplementaryma-\\nD =(cid:8) (xi,yi)(cid:9)n ,learningratesη terial.\\ni j j j=1 i\\nParameter: Client parameters θ i, global parameters θ g, ModelsandHyperparameters\\naggregationperiodT ,totalmini-batchesT\\nagg For experiments on text datasets (MedQuAD and Dolly-\\nOutput: Optimized global parameters θ after e\\ng 15k), we utilize Gemma-2B (Team et al. 2024) and TinyL-\\nepochs\\nlama (Zhang et al. 2024b). In FedFTG, we fine-tuned the\\n1: Initializeθ g up-proj MLP layer, which follows the self-attention mod-\\n2: forepoch=1,...,edo\\nule.Conversely,FlexLoRAandFFA-LoRAfocusedonfine-\\n3: Initializealllocalθ i ←θ g inparallel tuning the attention modules (query, key, value) with a\\n4: fort=1,...,T do\\nLoRArankof8andascalingfactorof16,inlinewiththeex-\\n5: forallclienti∈{1,...,N}inparalleldo\\nperimentalsetupspresentedintheiroriginalpapers.Forvi-\\n6: Samplemini-batchB ifromD i sionmodalityexperiments,wefine-tunedSigLIP(Zhaietal.\\n7: G(θ i,B i)←∇ θiL(M(θ i;B i),B i)\\n2023).InFedFTGappliedtoSigLIP,wefine-tunedtheMLP\\n8: θ i ←θ i−η iGaLore(G(θ i,B i)) layer immediately after the attention module and the clas-\\n9: endfor\\nsifier layer (see supplementary material for more details).\\n10: iftmodT agg =0then FlexLoRAandFFA-LoRA,ontheotherhand,fine-tunedthe\\n11: θ g ← N1 (cid:80)N i=1θ i attentionparameters(query,key,value)withaLoRArankof\\n12: Updatealllocalθ i ←θ g inparallel 8similartotextexperimentsandascalingfactorof32.\\n13: endif\\n14: endfor TrainingandEvaluation\\n15: endfor We conducted our experiments with different numbers of\\n16: return θ g clients.Fortextdatasets,weevaluatedFedFTGwith3and4\\nclients.With3clients,shards1,2,and3ofeachdatasetwere\\nused,whilewith4clients,allshardswereutilized.Asimilar\\nshardassignmentwasusedfortheBrainTumourClassifica-\\nand Databricks Dolly 15k (Conover et al. 2023) datasets.\\ntiondataset.Eachshardwassplitintotrainingandtestsets,\\nMedQuAD is a medical question-answering dataset con-\\nwith1%ofsamplesreservedfortestinginthetextdatasets\\ntaining47,457question-answerpairssourcedfrom12NIH\\nand5%forthevisiondataset(visiondatasetshardsaremuch\\nwebsites, covering 39 question types related to diseases,\\nsmallerthuslargerfractionoftestsetisrequiredformaking\\ndrugs, and other medical entities. However, owing to the\\na firm conclusion). The global evaluation set was created\\nMedlinePluscopyright,answersfromthe3subsetswerere-\\nbycombiningthetestsetsfromeachshard,thuscontaining\\nmoved. Databricks Dolly-15k contains 15,000 high-quality\\nunseen samples from different non-IID shards. This helps\\nhuman-generated prompt/response pairs designed for in-\\nassessthemodel’sgeneralizationabilityindistributednon-\\nstruction tuning LLMs. It includes various categories like\\nIIDsettings.Textdatasetsweretrainedwithabatchsizeof\\nbrainstorming, classification, summarization, and question\\n1, while the image dataset used a batch size of 2, with all\\nanswering. For experiments related to vision modality, we\\nmodelstrainedfor3epochs.\\nutilizetheBrainTumourclassificationdataset(Cheng2017)\\nwhich comprises of 3,064 T1-weighted contrast-enhanced\\nExperimentResults\\nMRIimagesfrom233patients,categorizedintothreetumor\\nTable 1 shows the results on text datasets. We report the\\ntypes: meningioma (708 slices), glioma (1,426 slices), and\\nROUGE L F1 (Longest common subsequence ROUGE)\\npituitarytumor(930slices).Thetaskistoidentifythecor-\\nscore(Lin2004)andtheBLEU-4(4-gram)(Papinenietal.\\nrecttumortypebyhavingtheMRIimagefedasaninputto\\n2002) score for text datasets. Out of 3 epochs, we report\\ntheViT.Moredetailsonthesedatasetsarediscussedinthe\\nthe results of the epoch which has the best result. This is\\ndataappendixofthesupplementarymaterial.\\ndone owing to the overfitting of models usually in some\\nexperiment runs. Table 1 shows that FedFTG consistently\\nNon-IIDDataPreparation\\nsurpasses both FlexLoRA and FFA-LoRA across differ-\\nTo simulate non-IID conditions, we used Dirichlet Alloca- ent numbers of clients and datasets. Table 2 shows the re-\\ntiontopartitioneachdatasetintoseveralnon-IIDsplitssim- sults of fine-tuning SigLIP on the Brain Tumor Classifi-\\nilarto (Zhanget al.2024a;Hsu, Qi,and Brown2019). For cation Dataset for tumor type classification. In this vision\\nthetextdatasets(MedQuADandDolly15k),wegenerated datasetexperiment,FedFTGoutperformsbothLoRA-based\\n4splits,whereasfortheBrainTumorClassificationdataset, FLmethods.ThenotablypoorerperformanceofFFA-LoRA\\nwe created 5 splits. The concentration parameter α was set acrosstextandvisionexperimentsalignswithearlieranaly-\\nto0.1,resultinginhighlyskeweddistributionsacrossclients ses,asitsexcessriskboundsincreasewitheachFedAvgstep\\nthatreplicatenon-IIDbehaviorinFLsettings.Splitsarecre- (Theorem1),hinderingefficientlearningofthedataset’sse-\\nated based on labels. For MedQuAD dataset, the label is manticsandleadingtosuboptimalresults.Figure8displays\\nquestion typewhileforDolly-15kitiscategory.Theshards the variation in ROUGE L F1 scores on the global evalu-\\npreparedforagivendatasetareofthesamesizes.Classla- ation set across FedAvg steps for TinyLlama, with similarN Dataset Model Method BLEU-4 ROUGE-L NoofclientsMethod F1Score\\nFedFTG 0.4883 0.6637 FedFTG 0.6064\\nTinyLlama FlexLoRA 0.4551 0.6429 3 FlexLoRA 0.5638\\nFFA-LoRA 0.1004 0.2947 FFA-LoRA0.0165\\nMedQuAD\\nFedFTG 0.5493 0.7019 FedFTG 0.843\\nGemma-2B FlexLoRA 0.4238 0.6401 4 FlexLoRA 0.4868\\nFFA-LoRA 0.1077 0.2875 FFA-LoRA0.3175\\n3\\nFedFTG 0.3157 0.5244 FedFTG 0.7274\\nTinyLlama FlexLoRA 0.2873 0.5221 5 FlexLoRA 0.6116\\nFFA-LoRA 0.0566 0.1708 FFA-LoRA0.1104\\nDolly-15K\\nFedFTG 0.3284 0.5413\\nGemma-2B FlexLoRA 0.2874 0.5375 Table 2: Comparison of F1 score on Brain Tumour Clas-\\nFFA-LoRA 0.1077 0.2875 sification Dataset for fine-tuning SigLIP using different FL\\nFedFTG 0.5433 0.6994 fine-tuningmethodsacrossnon-IIDsplits\\nTinyLlama FlexLoRA 0.501 0.6816\\nFFA-LoRA 0.1133 0.3047\\nMedQuAD\\nFedFTG 0.5373 0.7114\\nGemma-2B FlexLoRA 0.4690 0.6863\\nFFA-LoRA 0.1092 0.2863\\n4\\nFedFTG 0.3428 0.5229\\nTinyLlama FlexLoRA 0.2807 0.5081\\nFFA-LoRA 0.0619 0.1665\\nDolly-15K\\nFedFTG 0.3423 0.5529 (a) 3 clients, MedQuAD, (b) 4 clients, MedQuAD,\\nGemma-2B FlexLoRA 0.3061 0.5516 TinyLlama TinyLlama\\nFFA-LoRA 0.0661 0.1648\\nTable 1: Comparison of BLEU-4 and ROUGE L F1 scores\\nacross different methods, models, and datasets for varying\\nclientnumberswithnon-IIDsplits\\ngraphsfortheGemma-2Bmodelinthesupplementarymate- (c)3clients,Dolly,TinyLlama (d)4clients,Dolly,TinyLlama\\nrial.FFA-LoRA’sineffectiveaggregation,shownatthebot-\\ntomofthegraphs,showsminimalimprovementswithmore Figure4:VariationofROUGE Lscoresevaluatedonthetest\\nFedAvg steps. While FlexLoRA experiences performance setwithglobalaggregationstepsacrossdifferentclientsand\\ndips on the MedQuAD dataset, it still achieves reasonable datasetsfortheTinyLlamamodel.\\naggregationefficiencybutfallsshortcomparedtoFedFTG.\\nIn contrast, FedFTG demonstrates the most stable aggre-\\ngation results, maintaining consistent training performance\\ntransformer models in federated environments that lever-\\nwithout abrupt drops. Overall, FedFTG outperforms both\\nagesGaLore’sefficientsubspacelearningmechanism.This\\nFlexLoRA and FFA-LoRA across various clients, datasets,\\nframework demonstrates robust performance across vision\\nanddownstreamtasks(Table1and2).\\nandlanguagetransformerarchitectures,effectivelyaddress-\\nThe supplementary material includes more detailed expla-\\ningLoRA’ssub-optimalsubspacelearningbottleneckswhile\\nnation of the results and additional experiments with vary-\\nconsistently outperforming existing approaches across di-\\ninglabeldistributions.Acrosstheseconfigurations,FedFTG\\nverse datasets and client configurations. By incorporating\\nconsistently outperforms FlexLoRA and FFA-LoRA, with\\nGaLore’s insights, we show how gradient subspace meth-\\nresultsvalidatedovertwoindependentruns,reinforcingour\\nods operating on parameter matrices can mitigate common\\nfindings.\\nfederated learning bottlenecks, particularly preventing rank\\ninflationanditsassociatedexcessriskincrease.Thissuccess\\nConclusionandFutureWork\\nsuggeststhatexploitingslowlyevolvinggradientsubspaces\\nOur analysis begins by examining LoRA’s performance couldleadtomorerobustaggregationalgorithms.Futurere-\\nin federated settings, focusing on state-of-the-art frame- searchdirectionsincludedevelopingmorestable,parameter-\\nworks FlexLoRA and FFA-LoRA, with particular attention efficientfederatedfine-tuningmethodsandexploringadap-\\ntoconstraintsimposedbylow-rankadaptersubspacelearn- tiveaggregationstrategiesforheterogeneousenvironments.\\ning. This investigation extends to direct weight aggrega- Our work aims to guide the research community toward\\ntionmethodsandtheapplicationofGaLoreasanoptimiza- low-rank gradient-based optimization strategies, while the\\ntionstrategy,whereweprovidetheoreticalinsightsdemon- theoretical foundations established here could inform im-\\nstrating its advantages over LoRA-based approaches. We proved aggregation frameworks focusing on structured lo-\\nintroduce FedFTG, a streamlined approach for fine-tuning calizedsubspaces.References Du, X.; Liu, M.; Wang, K.; Wang, H.; Liu, J.; Chen, Y.;\\nAbadi, M.; Chu, A.; Goodfellow, I.; McMahan, H. B.; Feng, J.; Sha, C.; Peng, X.; and Lou, Y. 2024. Evaluat-\\nMironov,I.;Talwar,K.;andZhang,L.2016. DeepLearning ing Large Language Models in Class-Level Code Genera-\\nwithDifferentialPrivacy. InProceedingsofthe2016ACM tion. In Proceedings of the IEEE/ACM 46th International\\nSIGSACConferenceonComputerandCommunicationsSe- ConferenceonSoftwareEngineering,ICSE’24.NewYork,\\ncurity,CCS’16.ACM. NY, USA: Association for Computing Machinery. ISBN\\n9798400702174.\\nAlam, S.; Liu, L.; Yan, M.; and Zhang, M. 2022. Fe-\\ndRolex: Model-Heterogeneous Federated Learning with He,R.;Liu,L.;Ye,H.;Tan,Q.;Ding,B.;Cheng,L.;Low,\\nRollingSub-ModelExtraction. InNeurIPS. J.-W.; Bing, L.; and Si, L. 2021. On the Effectiveness\\nof Adapter-based Tuning for Pretrained Language Model\\nAnsell, A.; Ponti, E. M.; Korhonen, A.; and Vulic, I. 2022.\\nAdaptation. InACL/IJCNLP(1),2208–2222.\\nComposable Sparse Fine-Tuning for Cross-Lingual Trans-\\nfer. InACL(1),1778–1796. Houlsby, N.; Giurgiu, A.; Jastrzebski, S.; Morrone, B.;\\nBabakniya,S.;Elkordy,A.;Ezzeldin,Y.;Liu,Q.;Song,K.- Laroussilhe,Q.d.;Gesmundo,A.;Attariyan,M.;andGelly,\\nB.;EL-Khamy,M.;andAvestimehr,S.2023. SLoRA:Fed- S.2019. Parameter-EfficientTransferLearningforNLP. In\\nerated Parameter Efficient Fine-Tuning of Language Mod- ICML,2790–2799.\\nels. In International Workshop on Federated Learning in Hsu, T.-M. H.; Qi, H.; and Brown, M. 2019. Measuring\\ntheAgeofFoundationModelsinConjunctionwithNeurIPS theEffectsofNon-IdenticalDataDistributionforFederated\\n2023. VisualClassification. arXiv:1909.06335.\\nBai,J.;Chen,D.;Qian,B.;Yao,L.;andLi,Y.2024. Feder- Hu,E.J.;Shen,Y.;Wallis,P.;Allen-Zhu,Z.;Li,Y.;Wang,\\nated Fine-tuning of Large Language Models under Hetero- S.;Wang,L.;andChen,W.2022. LoRA:Low-RankAdap-\\ngeneousTasksandClientResources. arXiv:2402.11505. tationofLargeLanguageModels. InICLR.\\nBen Abacha, A.; and Demner-Fushman, D. 2019. A Karimireddy,S.P.;Kale,S.;Mohri,M.;Reddi,S.;Stich,S.;\\nQuestion-Entailment Approach to Question Answering. andSuresh,A.T.2020. SCAFFOLD:StochasticControlled\\nBMCBioinform.,20(1):511:1–511:23. AveragingforFederatedLearning. InIII,H.D.;andSingh,\\nBrown,T.B.;Mann,B.;Ryder,N.;Subbiah,M.;Kaplan,J.; A., eds., Proceedings of the 37th International Conference\\nDhariwal,P.;Neelakantan,A.;Shyam,P.;Sastry,G.;Askell, on Machine Learning, volume 119 of Proceedings of Ma-\\nA.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan, chineLearningResearch,5132–5143.PMLR.\\nT.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter, Kirillov, A.; Mintun, E.; Ravi, N.; Mao, H.; Rolland, C.;\\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.; Gustafson,L.;Xiao,T.;Whitehead,S.;Berg,A.;Lo,W.-Y.;\\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, Dolla´r,P.;andGirshick,R.B.2023. SegmentAnything. In\\nA.; Sutskever, I.; and Amodei, D. 2020. Language Models IEEEInternationalConferenceonComputerVision,3992–\\nareFew-ShotLearners. InNeurIPS. 4003.\\nCheng,J.2017. braintumordataset.\\nKuang, W.; Qian, B.; Li, Z.; Chen, D.; Gao, D.; Pan,\\nCho, Y. J.; Liu, L.; Xu, Z.; Fahrezi, A.; Barnes, M.; and X.; Xie, Y.; Li, Y.; Ding, B.; and Zhou, J. 2023.\\nJoshi, G. 2023. Heterogeneous LoRA for Federated Fine- FederatedScope-LLM:AComprehensivePackageforFine-\\ntuning of On-device Foundation Models. In International tuning Large Language Models in Federated Learning.\\nWorkshoponFederatedLearningintheAgeofFoundation arXiv:2309.00363.\\nModelsinConjunctionwithNeurIPS2023.\\nLester,B.;Al-Rfou,R.;andConstant,N.2021. ThePower\\nConover, M.; Hayes, M.; Mathur, A.; Xie, J.; Wan, J.; ofScaleforParameter-EfficientPromptTuning. InEMNLP\\nShah,S.;Ghodsi,A.;Wendell,P.;Zaharia,M.;andXin,R. (1),3045–3059.\\n2023. FreeDolly:IntroducingtheWorld’sFirstTrulyOpen\\nLi, X. L.; and Liang, P. 2021. Prefix-Tuning: Optimizing\\nInstruction-TunedLLM.\\nContinuous Prompts for Generation. In ACL/IJCNLP (1),\\nDiao,E.;Ding,J.;andTarokh,V.2021. HeteroFL:Compu-\\n4582–4597.\\ntationandCommunicationEfficientFederatedLearningfor\\nLin,C.-Y.2004. ROUGE:APackageforAutomaticEvalu-\\nHeterogeneousClients. InICLR.\\nation of Summaries. In Text Summarization Branches Out,\\nDing, N.; Qin, Y.; Yang, G.; Wei, F.; Yang, Z.; Su, Y.; Hu,\\n74–81. Barcelona, Spain: Association for Computational\\nS.;Chen,Y.;Chan,C.-M.;Chen,W.;Yi,J.;Zhao,W.;Wang,\\nLinguistics.\\nX.;Liu,Z.;Zheng,H.-T.;Chen,J.;Liu,Y.;Tang,J.;Li,J.;\\nLiu, H.; Li, C.; Wu, Q.; and Lee, Y. J. 2023. Visual In-\\nandSun,M.2023. Parameter-efficientfine-tuningoflarge-\\nstruction Tuning. In Thirty-seventh Conference on Neural\\nscalepre-trainedlanguagemodels. NatureMachineIntelli-\\nInformationProcessingSystems.\\ngence,5(3):220–235.\\nDosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, Loshchilov,I.;andHutter,F.2019. DecoupledWeightDe-\\nD.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.; cayRegularization. InICLR(Poster).\\nHeigold,G.;Gelly,S.;Uszkoreit,J.;andHoulsby,N.2021. Mahla,N.;D’souza,A.;Gupta,S.;Kanekar,B.;andJadhav,\\nAn Image is Worth 16x16 Words: Transformers for Image K.S.2024.MedSAGa:Few-shotMemoryEfficientMedical\\nRecognitionatScale.InInternationalConferenceonLearn- ImageSegmentationusingGradientLow-RankProjectionin\\ningRepresentations. SAM. arXiv:2407.15042.McMahan, B.; Moore, E.; Ramage, D.; Hampson, S.; and Sjoesund, L. L.; Lee, L.; Dixon, L.; Reid, M.; Mikuła, M.;\\nArcas, B. A. y. 2017. Communication-Efficient Learning Wirth, M.; Sharman, M.; Chinaev, N.; Thain, N.; Bachem,\\nof Deep Networks from Decentralized Data. In Singh, A.; O.;Chang,O.;Wahltinez,O.;Bailey,P.;Michel,P.;Yotov,\\nandZhu,J.,eds.,Proceedingsofthe20thInternationalCon- P.;Chaabouni,R.;Comanescu,R.;Jana,R.;Anil,R.;McIl-\\nference on Artificial Intelligence and Statistics, volume 54 roy, R.; Liu, R.; Mullins, R.; Smith, S. L.; Borgeaud, S.;\\nofProceedingsofMachineLearningResearch,1273–1282. Girgin,S.;Douglas,S.;Pandya,S.;Shakeri,S.;De,S.;Kli-\\nPMLR. menko, T.; Hennigan, T.; Feinberg, V.; Stokowiec, W.; hui\\nNiu,Y.;Prakash,S.;Kundu,S.;Lee,S.;andAvestimehr,S. Chen,Y.;Ahmed,Z.;Gong,Z.;Warkentin,T.;Peran,L.;Gi-\\n2022. FederatedLearningofLargeModelsattheEdgevia ang,M.;Farabet,C.;Vinyals,O.;Dean,J.;Kavukcuoglu,K.;\\nPrincipal Sub-Model Training. In Workshop on Federated Hassabis, D.; Ghahramani, Z.; Eck, D.; Barral, J.; Pereira,\\nLearning: Recent Advances and New Challenges (in Con- F.; Collins, E.; Joulin, A.; Fiedel, N.; Senter, E.; Andreev,\\njunctionwithNeurIPS2022). A.;andKenealy,K.2024. Gemma:OpenModelsBasedon\\nGeminiResearchandTechnology. arXiv:2403.08295.\\nOpenAI.2023. GPT-4technicalreport. arXiv,2303–08774.\\nTian,Y.;Wang,Y.;Zhang,Z.;Chen,B.;andDu,S.S.2024.\\nPapineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J. 2002.\\nJoMA:DemystifyingMultilayerTransformersviaJointDy-\\nBleu:aMethodforAutomaticEvaluationofMachineTrans-\\nnamicsofMLPandAttention. InTheTwelfthInternational\\nlation. In Isabelle, P.; Charniak, E.; and Lin, D., eds., Pro-\\nConferenceonLearningRepresentations.\\nceedingsofthe40thAnnualMeetingoftheAssociationfor\\nComputationalLinguistics,311–318.Philadelphia,Pennsyl- Touvron,H.;Lavril,T.;Izacard,G.;Martinet,X.;Lachaux,\\nvania,USA:AssociationforComputationalLinguistics. M.-A.; Lacroix, T.; Rozie`re, B.; Goyal, N.; Hambro, E.;\\nAzhar, F.; et al. 2023. Llama: Open and efficient founda-\\nQin, Z.; Chen, D.; Qian, B.; Ding, B.; Li, Y.; and Deng,\\ntionlanguagemodels. arXivpreprintarXiv:2302.13971.\\nS.2024. FederatedFull-ParameterTuningofBillion-Sized\\nLanguageModelswithCommunicationCostunder18Kilo- Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\\nbytes. arXiv:2312.06353. L.;Gomez,A.N.;Kaiser,L.;andPolosukhin,I.2017. At-\\ntentionisAllyouNeed. InNIPS,5998–6008.\\nRadford,A.;Kim,J.W.;Hallacy,C.;Ramesh,A.;Goh,G.;\\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; Woisetschla¨ger,H.;Erben,A.;Marino,B.;Wang,S.;Lane,\\nKrueger, G.; and Sutskever, I. 2021a. Learning Transfer- N. D.; Mayer, R.; and Jacobsen, H.-A. 2024. Federated\\nableVisualModelsFromNaturalLanguageSupervision. In LearningPrioritiesUndertheEuropeanUnionArtificialIn-\\nMeila,M.;andZhang,T.,eds.,Proceedingsofthe38thIn- telligenceAct. arXiv:2402.05968.\\nternational Conference on Machine Learning, volume 139 Xu,A.;andRaginsky,M.2017. Information-theoreticanal-\\nofProceedingsofMachineLearningResearch,8748–8763. ysisofgeneralizationcapabilityoflearningalgorithms. Ad-\\nPMLR. vancesinneuralinformationprocessingsystems,30.\\nRadford,A.;Kim,J.W.;Hallacy,C.;Ramesh,A.;Goh,G.;\\nZeng,A.;Liu,X.;Du,Z.;Wang,Z.;Lai,H.;Ding,M.;Yang,\\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\\nZ.;Xu,Y.;Zheng,W.;Xia,X.;etal.2022. GLM-130B:An\\netal.2021b. Learningtransferablevisualmodelsfromnat- OpenBilingualPre-trainedModel. InTheEleventhInterna-\\nural language supervision. In International conference on tionalConferenceonLearningRepresentations.\\nmachinelearning,8748–8763.PMLR.\\nZhai, X.; Mustafa, B.; Kolesnikov, A.; and Beyer, L. 2023.\\nRuder,S.2017. Anoverviewofgradientdescentoptimiza-\\nSigmoid Loss for Language Image Pre-Training. In ICCV,\\ntionalgorithms. arXiv:1609.04747.\\n11941–11952.\\nSun,J.;Mei,C.;Wei,L.;Zheng,K.;Liu,N.;Cui,M.;andLi,\\nZhang,J.;Vahidian,S.;Kuo,M.;Li,C.;Zhang,R.;Yu,T.;\\nT.2024a. Dial-insight:Fine-tuningLargeLanguageModels\\nWang,G.;andChen,Y.2024a. TowardsBuildingTheFed-\\nwithHigh-QualityDomain-SpecificDataPreventingCapa-\\neratedgpt:FederatedInstructionTuning. InICASSP2024-\\nbilityCollapse. ArXiv,abs/2403.09167.\\n2024 IEEE International Conference on Acoustics, Speech\\nSun,Y.;Li,Z.;Li,Y.;andDing,B.2024b.ImprovingLoRA andSignalProcessing(ICASSP).\\nin Privacy-preserving Federated Learning. In The Twelfth\\nZhang, P.; Zeng, G.; Wang, T.; and Lu, W. 2024b.\\nInternationalConferenceonLearningRepresentations.\\nTinyLlama: An Open-Source Small Language Model.\\nTeam, G.; Mesnard, T.; Hardin, C.; Dadashi, R.; Bhupati- arXiv:2401.02385.\\nraju, S.; Pathak, S.; Sifre, L.; Rivie`re, M.; Kale, M. S.;\\nZhang, S.; Roller, S.; Goyal, N.; Artetxe, M.; Chen, M.;\\nLove, J.; Tafti, P.; Hussenot, L.; Sessa, P. G.; Chowdh-\\nChen,S.;Dewan,C.;Diab,M.;Li,X.;Lin,X.V.;etal.2022.\\nery, A.; Roberts, A.; Barua, A.; Botev, A.; Castro-Ros, A.;\\nOpt:Openpre-trainedtransformerlanguagemodels. arXiv\\nSlone, A.; He´liou, A.; Tacchetti, A.; Bulanova, A.; Pater-\\npreprintarXiv:2205.01068.\\nson, A.; Tsai, B.; Shahriari, B.; Lan, C. L.; Choquette-\\nChoo, C. A.; Crepy, C.; Cer, D.; Ippolito, D.; Reid, D.; Zhao, J.; Zhang, Z.; Chen, B.; Wang, Z.; Anandkumar, A.;\\nBuchatskaya, E.; Ni, E.; Noland, E.; Yan, G.; Tucker, G.; andTian,Y.2024. GaLore:Memory-EfficientLLMTrain-\\nMuraru,G.-C.;Rozhdestvenskiy,G.;Michalewski,H.;Ten- ing by Gradient Low-Rank Projection. In Forty-first Inter-\\nney,I.;Grishchenko,I.;Austin,J.;Keeling,J.;Labanowski,\\nnationalConferenceonMachineLearning.\\nJ.;Lespiau,J.-B.;Stanway,J.;Brennan,J.;Chen,J.;Ferret, Zhu,J.;Greenewald,K.;Nadjahi,K.;Sa´ezDeOca´rizBorde,\\nJ.; Chiu, J.; Mao-Jones, J.; Lee, K.; Yu, K.; Millican, K.; H.; Gabrielsson, R. B.; Choshen, L.; Ghassemi, M.;Yurochkin,M.;andSolomon,J.2024. AsymmetryinLow-\\nRankAdaptersofFoundationModels.InSalakhutdinov,R.;\\nKolter,Z.;Heller,K.;Weller,A.;Oliver,N.;Scarlett,J.;and\\nBerkenkamp,F.,eds.,Proceedingsofthe41stInternational\\nConferenceonMachineLearning,volume235ofProceed-\\ningsofMachineLearningResearch,62369–62385.PMLR.\\nReproducibilityChecklist\\nAllthedetailsrelatedtothereproducibilitychecklistcanbe\\nfoundinthesupplementarymaterial.ProofsandAnalysis\\nInthissection,wepresenttheproofsofpropositionandtheoremsfromthemainpaperandprovidefurtheranalysis.\\nProposition1InFLscenarioslikeFlexLoRA,whereparameterchangematrices∆W fromN clientsareaggregatedwith\\ni\\neachclientihavinganintrinsicrankr ,thegloballyaggregatedparametermatrixexhibitsrankinflationfollowingeachglobal\\ni\\naggregationstep.Specifically,inascenariowhereallclientshaveidenticalranksr =rforsimplicity,therateofrankinflation,\\ni\\ndenotedbyηsatisfies1≤η ≤N perglobalaggregationstep.\\nProof:\\nLettherankoftheadaptermatrix∆W fromeachclientiberank(∆W ) = r .ForanaggregationschemelikeFedAvgin\\ni i i\\nFlexLoRA:\\nN\\n1 (cid:88)\\n∆W = ∆W (9)\\nagg N i\\ni=1\\nForthesummationoftwolow-rankmatricesP andQ,thefollowingboundsontherankofthesumofthematricesaretrue:\\nmax(rank(P),rank(Q)≤rank(P +Q)≤rank(P)+rank(Q) (10)\\nFromequation(1)and(2),wecanwrite:\\nN N\\n(cid:88) (cid:88)\\nmax(rank(∆W ),rank(∆W ),...,rank(∆W ))≤rank( ∆W )≤ rank(∆W ) (11)\\n1 2 N i i\\ni=1 i=1\\nN N\\n(cid:88) (cid:88)\\nmax(rank(∆W ),rank(∆W ),...,rank(∆W ))≤rank( ∆W )≤ rank(∆W )\\n1 2 N i i\\ni=1 i=1\\nSince,multiplyingbyascalardoesn’taltertherankofthematrix:\\nN\\n(cid:88)\\nmax(rank(∆W ),rank(∆W ),...,rank(∆W ))≤rank(∆W )≤ rank(∆W ) (12)\\n1 2 N agg i\\ni=1\\nThisimpliesthattherankoftheaggregatedmatrixwillbeatleastgreaterthanthemaximumrankamongallclientLoRAadapter\\nmatrices,andatmostequaltothesumoftheindividualranks.Consequently,itcanbeinferredthattherankoftheaggregated\\nmatrixwillincreasecomparedtothepreviousranks.Inthesimplifiedscenariowherer =r,thefollowingconclusionscanbe\\ni\\ndrawn:\\nr ≤rank(∆W )≤Nr (13)\\nagg\\nAsaresult,therankcanincreasebyafactorrangingfrom1toN.Therankoftheaggregatedmatrixwillstaythesameinthe\\ncasewhentheindividualclientLoRAadaptermatrices∆W lieinthesamesubspace,whichisn’tpossibleinthecasewhen\\ni\\ntherearenon-IIDdatasetspresentwhichcandifferthesubspacesacrosstheclients.\\nProposition 1 highlights the constrained subspaces within FlexLoRA. In FlexLoRA, even though the rank is inflated after\\naggregation, the low-rank decomposition is still performed based on the original, smaller rank r. This restriction hinders the\\nsubspacelearningprocess,asitinvolvesdecomposingtheaggregatedmatrixintolow-rankmatriceswithrankssmallerthanthe\\nintrinsicrankoftheoriginalaggregatedmatrix.Thislimitationcanimpedethemodel’sabilitytofullycapturetheunderlying\\ndatadistributionacrossclients.\\nLemma1InFFA-LoRA,thetotalweightupdateofthecompleteLoRAadaptermatrix∆W canbewrittenintermsofthe\\ngradientofthatateachiterationstepwithalearningrateα.AttheendofT iterations,thefollowingholds:\\nT\\n(cid:88)\\n∆W =−α ∇ L (A⊤A ) (14)\\nW t 0 0\\nt=0\\nThecompleteLoRAadaptermatrixafterweightaggregation(FedAvg)isequivalenttoFedAvgaggregationofgradientsateach\\nlocaltrainingiteration.\\nN T T (cid:40) N (cid:41)\\n∆W =−α (cid:88)(cid:88) ∇ L(i)(A⊤A )=−α(cid:88) 1 (cid:88) ∇ L(i) (A⊤A ) (15)\\nagg N W t 0 0 N W t 0 0\\ni=1 t=0 t=0 i=1\\nProof:\\nFor updating a pre-trained weight matrix W ∈ Rd×k, LoRA parameters B ∈ Rd×r and A ∈ Rr×k with r ≪ min(d,k),\\n0\\nforwardpassinLoRAcanbewrittenas:\\ny =(W +BA)x (16)\\n0wherex∈Rk istheinputtothecurrentlayerandy ∈Rdistheoutputwhichispassedtothenextlayer.\\nDuringbackpropagation:\\n∇ L=∇ Lx⊤ (17)\\nW y\\nSincewefine-tuneeitherparameterB orA,weneedtoexpressthegradientwithrespecttotheseparametersintermsofthe\\ngradient of the pre-trained matrix. In FFA-LoRA, where we exclusively fine-tune the zero-initialized LoRA parameters, the\\ngradientcanbeexpressedasfollows:\\n∇ L=∇ LA ⊤ (18)\\nB W 0\\nTheupdateofthezero-initializedLoRAparametercanbewrittenas:\\nB :=B−α∇ L\\nB\\nwhereαisthelearningrate.ForupdatedvalueafterT iterationscanbewrittenas:\\nT\\n(cid:88)\\nB =−α ∇ L (19)\\nT B t\\nt=0\\nThefollowingcanbewrittenforanupdateofthecompleteLoRAadaptermatrix:\\nT\\n(cid:88)\\n∆W =−α ∇ L A\\nB t 0\\nt=0\\nFromequation(11):\\nT T\\n(cid:88) (cid:88)\\n∆W =−α ∇ L A =−α (∇ L )A ⊤A (20)\\nB t 0 W t 0 0\\nt=0 t=0\\nPostglobalaggregation(FedAvg),theweightchangeswillbeaveragedandthusgivingusourequation(7).\\nTheorem 1 For a convex loss L, let ∆W∗ ∈ Rd×k (r ≪ min(d,k)) be the optimal LoRA parameter matrix, α be\\n(cid:13) (cid:13)\\nthe learning rate, and let the L2 norm of the gradient to be bounded (i.e. (cid:13)∇ WL(i)(∆W)(cid:13)\\n2\\n≤ D). The excess risk\\n(|L(∆W )−L(∆W∗)|)boundsfortheFFA-LoRAframework,involvingN clientsandSglobalaggregationstepshaving\\nagg\\noccuredeveryt localtrainingiterations,canbeexpressedasfollows:\\nagg\\n(cid:16) α (cid:17)\\n≤DNSt DNSt c+ ∥∆W∗∥ (21)\\nagg agg N 2\\nProof:\\nLetL(∆W)betheoutputlossofthemodelfortheLoRAparameter∆W.Let∆W∗ bethemostoptimalLoRAadapter\\nparameters.AssumingthatthelossfunctionL(.)isconvex,theexcessriskcanbewrittenas:\\nL(∆W)−L(∆W∗)≤∇ L(∆W)⊤(∆W −∆W∗) (22)\\nW\\nFortheexcessriskjustaftertheaggregation,wecanreplacetheweightparameterswiththeaverageofit.\\nL(∆W )−L(∆W∗)≤∇ L(∆W )⊤(∆W −∆W∗) (23)\\nagg W agg agg\\n|L(∆W agg)−L(∆W∗)|≤(cid:13) (cid:13)∇ WL(∆W agg)⊤(∆W agg−∆W∗)(cid:13) (cid:13)\\n2\\n≤(cid:13) (cid:13)∇ WL(∆W agg)⊤(cid:13) (cid:13) 2∥(∆W agg−∆W∗)∥\\n2\\n(24)\\nSayatotalofS globalaggregationstepshavehappened,theLoRAadaptermatrixcanbewrittenas:\\n∆W =\\n−α(cid:88)N t (cid:88)agg (cid:88)S\\n∇ L(i)(A ⊤A ) (25)\\nS,tagg N W t,j 0 0\\ni=1 t=0j=1\\nEquation(16)canbefurtherupperboundedbythesummationofgradientsateachiterationforS roundsofglobalaggregation\\n(sincethegradientjustaftertheglobalaggregationcanbewrittenasanaverageofallthegradientsateachtimestepforeach\\nclient,seeequation(7)):\\n(cid:13) (cid:13)∇ WL(∆W S,agg)⊤(cid:13) (cid:13) 2∥(∆W S,agg−∆W∗)∥ 2 ≤(cid:88)N t (cid:88)agg (cid:88)S (cid:13) (cid:13) (cid:13)∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13) (cid:13) 2∥∆W S,agg−∆W∗∥ 2 (26)\\ni=1 t=0j=1WhichfromWeyl’sinequalitycanbefurtherboundedas:\\n(cid:13) (cid:13)\\n(cid:13) N tagg S (cid:13)\\n(cid:13) (cid:13)∇ WL(∆W S,agg)⊤(cid:13) (cid:13) 2∥(∆W S,agg−∆W∗)∥\\n2\\n≤(cid:13) (cid:13) (cid:13)(cid:88)(cid:88)(cid:88) ∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13)\\n(cid:13)\\n(∥∆W S,agg∥ 2+∥−∆W∗∥ 2)\\n(cid:13)i=1 t=0j=1 (cid:13)\\n2\\n(27)\\nExpandingtheseequations:\\n(cid:13) (cid:13)2 (cid:13) (cid:13)\\n≤(cid:13) (cid:13) (cid:13) (cid:13)(cid:88)N t (cid:88)agg (cid:88)S ∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)(A 0⊤A 0)(cid:13) (cid:13) (cid:13) 2+(cid:13) (cid:13) (cid:13) (cid:13)− Nα(cid:88)N t (cid:88)agg (cid:88)S ∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13) (cid:13) (cid:13) ∥−∆W∗∥ 2\\n(cid:13)i=1 t=0j=1 (cid:13) (cid:13) i=1 t=0j=1 (cid:13)\\n2 2\\n\\uf8f1 \\uf8fc2\\n≤\\uf8f2 \\uf8f3(cid:88)N t (cid:88)agg (cid:88)S (cid:13) (cid:13) (cid:13)∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13) (cid:13) 2\\uf8fd\\n\\uf8fe\\n(cid:13) (cid:13) (cid:13)(A 0⊤A 0)(cid:13) (cid:13) (cid:13) 2+(cid:12) (cid:12) (cid:12) (cid:12)− Nα(cid:12) (cid:12) (cid:12) (cid:12)(cid:88)N t (cid:88)agg (cid:88)S (cid:13) (cid:13) (cid:13)∇ WL( t,i j)(∆W S,agg)(cid:13) (cid:13) (cid:13) 2∥−∆W∗∥ 2\\ni=1 t=0j=1 i=1 t=0j=1\\n(28)\\n(cid:13) (cid:13)\\nLet the term (cid:13)A ⊤A (cid:13) be replaced by some constant c. Since the gradients are also assumed to be bounded, the entire\\n(cid:13) 0 0(cid:13)\\n2\\nequation(20)canberewrittenas:\\n(cid:16) α (cid:17)\\n|L(∆W )−L(∆W∗)|≤DNSt DNSt c+ ∥∆W∗∥ (29)\\nagg agg agg N 2\\nAs the value of S increases, i.e. the number of global aggregation steps increases, the bounds on the excess risk keep on\\nincreasing.\\nLemma1 Foraboundedgradient(L2normofthegradientsupperboundedbyD)L2normoftheweightmatrixintheGaLore-\\nbased FedAvg aggregation framework (like FedFTG) is upper bounded linearly by the number of global aggregation steps S\\nandthenumberoflocaltrainingstepsbetweentwoconsecutiveaggregationstepst :\\nagg\\n∥W ∥≤B+ηSt D =O(St ) (30)\\nagg agg agg\\nwhereηisthelearningrateandBisaconstant.\\nProof:Weightupdateforaclientiatsometimet justbeforeaggregationcanbewrittenas:\\nagg\\ntagg\\nW(i) =W −η(cid:88) G(i) (31)\\ntagg 0 t\\nt=0\\nNowaveragingtheweightsforFedAvgaggregation:\\nW =W −\\nη (cid:88)N t (cid:88)agg\\nG(i)\\nagg 0 N t\\ni=1 t=0\\nSay,S roundsofcommunicationhaveoccurred,onecanwritetheaboveequationasfollows:\\nW =W −\\nη (cid:88)N (cid:88)S t (cid:88)agg\\nG(i) (32)\\nagg 0 N t,j\\ni=1j=0t=0\\nTakingL2normonboththesides:\\n(cid:13) (cid:13)\\n∥W agg∥=(cid:13) (cid:13) (cid:13) (cid:13)W 0− Nη (cid:88)N (cid:88)S t (cid:88)agg G( t,i j)(cid:13) (cid:13) (cid:13) (cid:13)≤∥W 0∥+ Nη (cid:88)N (cid:88)S t (cid:88)agg(cid:13) (cid:13) (cid:13)G( t,i j)(cid:13) (cid:13) (cid:13)=∥W 0∥+ Nη (cid:88)N (cid:88)S t (cid:88)agg D\\n(cid:13) i=1j=0t=0 (cid:13) i=1j=0t=0 i=1j=0t=0\\n=⇒ ∥W ∥≤B+ηSt D (33)\\nagg agg\\nAssumingthatL2normofinitialweightmatrixW isBandL2normofthegradientisboundedbyD.\\n0\\nTheorem2 For a convex loss function L, let ∆W∗ denote the optimal weight matrix and α represent the learning rate.\\n(cid:13) (cid:13)\\nAssuming that the L2 norm of the gradient is bounded, specifically (cid:13)∇ WL(i)(∆W)(cid:13)\\n2\\n≤ D, the excess risk, defined as\\n|L(∆W )−L(∆W∗)|,fortheaggregatedweightsafteratotalofSdirectFedAvgaggregationshavingoccuredeveryt\\nagg agg\\nlocaltrainingiterationswithGaLoreasanoptimizercanbeexpressedasfollows:\\n|L(∆W )−L(∆W∗)|≤αD2St +c=O(St ) (34)\\nagg agg agg\\nHere,cisascalarconstant.Proof:\\nL(∆W)−L(∆W∗)≤∇ L(∆W)⊤(∆W −∆W∗) (35)\\nW\\nFortheexcessriskjustaftertheaggregation,wecanreplacetheweightparameterswiththeaverageofit.\\nL(∆W )−L(∆W∗)≤∇ L(∆W )⊤(∆W −∆W∗) (36)\\nagg W agg agg\\n|L(∆W agg)−L(∆W∗)|≤(cid:13) (cid:13)∇ WL(∆W agg)⊤(∆W agg−∆W∗)(cid:13) (cid:13)\\n2\\n≤(cid:13) (cid:13)∇ WL(∆W agg)⊤(cid:13) (cid:13) 2∥(∆W agg−∆W∗)∥\\n2\\n(37)\\n≤D(αt SD+k)\\nagg\\n=⇒ |L(∇W )−L(∇W∗)|≤αD2St +c (38)\\nagg agg\\nTheorem3 LetN denotethenumberofclients,eachpossessingadatasetwithnsamples.Weconsidertheweightsofalower-\\nlevelMLPlayerrepresentedbyW ∈Rd×k.Undertheassumptionthattheriskfunctionofeachclientisσ-sub-Gaussianwith\\nrespecttothedatadistributionofthatclientandthecorrespondingweightmatrix,wederivethefollowinggeneralizationerror\\nboundsforweightaggregation:\\na)Forfederatedfine-tuningusingFFA-LoRA:\\n1 (cid:88)N (cid:115) 2σ2ln2 (cid:88)\\nE ≤ rq (d) (39)\\n1 N n\\ni=1 i\\nb)ordirectweightaggregationusingFedAvgwithalow-rankgradient-basedoptimizer,suchasGaLore:\\n(cid:118)\\nE\\n2\\n≤\\nN1 (cid:88)N (cid:117) (cid:117) (cid:116)−2 nσ2 (cid:88)d (cid:88)k\\nf(W\\ni(j)[l],t)log(cid:16)\\nf(W\\ni(j)[l],t)(cid:17)\\n(40)\\ni=1 j=1l=1\\nwhereW i(j)[l]representstheelementoflthindexinthejthrowofthematrixW i.Here,f(W i(j)[l],t)= (cid:80)kexp e( xW p(i( Wj)[ (l j] ))\\n[l])\\nbe\\nl=1 i\\nthefunctiontorepresenttheratio(probability)inasuccinctmanner.Also,ast → ∞,i.e.asthefederatedtrainingcontinues\\nf(W(j)[l],t)→ 1.\\ni k\\nProof:\\nProofofthistheoremfollowsfrominformation-theoreticanalysis.Generalizationerrorisdefinedasthedifferencebetweenthe\\npopulationandempiricalrisk.ForN clientsystemwithnon-i.i.d.datasetpopulationriskcanbedefinedas:\\n(cid:90)\\nL (w)=∆ E [E [l (w,Z)]]=E [ l (w,z)µ (dz )] (41)\\nµ1,µ2,..,µN i Z i i i i i\\nz\\nWhereµ isthedatadistributionforclientiandZ isasamplefromthedataset.\\ni\\nEmpiricalriskcanbewrittenas:\\nn\\nL (w)=∆ E [1 (cid:88) l (w,Z )] (42)\\nS1,S2,...,SN i n j j\\nj=1\\nWhereS isthedatasetatclienti.ThetotalgeneralizationerrorforaN clientsystemcanbewrittenas:\\ni\\nn\\n(cid:12) (cid:12)g(µ 1,µ 2,..,µ N;P W|S1,S2,...,SN)(cid:12) (cid:12)≤E i[E Z[l i(w,Z)]]−E i[ n1 (cid:88) l j(w,Z j)] (43)\\nj=1\\n\\uf8eb \\uf8f6\\nn N n\\n=⇒ (cid:12) (cid:12)g(µ 1,µ 2,..,µ N;P W|S1,S2,...,SN)(cid:12) (cid:12)≤E i[E Z[l i(w,Z)]− n1 (cid:88) l j(w,Z j)]= N1 (cid:88) \\uf8edE Z[l i(w,Z)− n1 (cid:88) l j(w,Z j)]\\uf8f8\\nj=1 i=1 j=1\\nTheexpressionjustinsidethebracketisthegeneralizationerrorforasingleclientsystem.Asdonetheanalysisthoroughlyin\\nthepaper(XuandRaginsky2017),thegeneralizationerrorforasingleclientsystemcanbewrittenas:\\n(cid:114)\\n(cid:12) (cid:12) 2σ2\\n(cid:12)g(µ;P W|S)(cid:12)≤\\nn\\nI(S;W) (44)From the paper (Zhu et al. 2024) which does the centralized training information-theoretic analysis of for LoRA based\\nsystems,includingsystemcloselyresemblingFFA-LoRA,wecandirectlyreplacetheunder-roottermwiththefinalexpression\\nfromthatpaper:\\n(cid:12) (cid:12) 1 (cid:88)N (cid:115) 2σ2ln2 (cid:88)\\n(cid:12)g(µ 1,µ 2,..,µ N;P W|S1,S2,...,SN)(cid:12)≤\\nN n\\nrq (d) (45)\\ni=1 i\\nContinuingfromequation44forcase9b),wecan’tdirectlywritetheentropyinthewaysimilartowhatwedidincase(a).\\nLemma B.6 from the GaLore paper explains about the dynamics of weight matrix and gradient matrix rows while training.\\nIt shows that as the time proceeds, one of the row become extremely large than the others. In FL, when such matrices with\\ninfinitelylargerowvaluesareaggregatedtogetherreturnanewmatrixthathasmorenumberofrowswithinfinitelylargerow\\nvalues.Sincethevaluesareinfinitelylarge,theycanbeattributedtoanear-similarvalue.Wewritetheentropyforsuchasystem\\nas:\\nd k\\n(cid:88)(cid:88)\\nH =− p(W )log(p(W ) (46)\\n(j,l) (j,l)\\nj=1l=1\\nTheexpressionofprobabilitycanbereplacedbythefunctionf thatcanbedescribedas:f(W(j)[l],t) = exp(W i(j)[l]) .\\ni (cid:80)k exp(W(j)[l])\\nl=1 i\\nPlugginginthisexpressionintheexpressionofentropywhichupperboundsmutualentropyinequation44givesustheexpres-\\nsionfromcase(b).\\nFortheexpressionofgeneralizationerrorforFFA-LoRA(case(c))canbedirectlyderivedbyplugginginthevaluegeneral-\\nizationtoequation(49)fromtheanalysisperformedby(Zhuetal.2024)(Lemma4.5ofthepaper)forthegeneralizationerror\\nboundofusingLoRAincentralizedsettings.\\nDatasetsandExperiments\\nIn this section, we discuss about the datasets and their pre-processing. We also discuss about the experiment setup in detail\\nalongwiththehyperparametersused.\\nDatasetPreparation\\nWeutilizedtheMedQuADandDolly-15kdatasetsasoutlinedinthemainpaper.TheentireDolly-15kdatasetwasemployed\\nfordistributedtraining,whileforMedQuAD,wesampled15kinstancesproportionatelyfromthemaindataset.TheMedQuAD\\ndataset,asreportedbyitsauthors,originallycontains39questiontypesrelatedtovariousmedicaltopicssuchasdiseasesand\\ndrugs. However, due to MedlinePlus copyright restrictions, answers from three subsets were removed, resulting in approxi-\\nmately31,034voidcellslackinganswers.Afterexcludingthesevoidcells,wewereleftwith16,407validQnApairsand16\\nuniquequestiontypes.Fromthese,weproportionatelysampled15kpairs.FortheDolly-15kdataset,theentiredatasetwasused\\nsinceitcloselymatchedthetargetsamplesizeof15,000.\\nTo prepare non-IID shards, we employed Dirichlet allocation to assign class label distributions to each shard/client. The\\nshardswerecreatedtoensureanequalnumberofsamplespershard.DirichletAllocationwasusedtodeterminetheproportion\\nofeachclass(question typeinMedQuADandinstructioncategoryinDolly-15k)assignedtoeachclient,withaconcentration\\nparameterofα = 0.1.Smallerαvaluesresultinmoreskeweddistributions,thussimulatingmorerealisticnon-IIDscenarios.\\nDuringtheassignmentofsamplestoeachshard,noreplacementwasconsidered,meaningasampleassignedtooneshardwas\\nnotreassignedtoanother.TheBrainTumorClassificationdatasetwaspartitionedinasimilarmanner.MedQuADandDolly-\\n15kweresplitinto4shards,whiletheBrainTumorClassificationDatasetwasdividedinto5shards.Theseshardswerethen\\nallocated to participating clients, with client i assigned to shard i. The label distribution for each shard is shown in the main\\npaper.Notably,eachshardinDolly-15kandMedQuADcontainsapproximately3,714and3,712samples,respectively.\\nThereasonwechoosethesedatasetsistodiversifythetypeofdownstreamtasksandthetypeofdataset.Dolly-15kdataset\\nis more generic and thus semantically more prevalent in the pre-training/instruction-tuning corpus of the LLMs unlike the\\nMedQuAD dataset which showcases our method’s efficiency on datasets which are out of distribution with the pre-training\\ncontextoftheLLM.Similarreasonwhywechooseamedicaldataset(BrainTumorClassificationDataset)forourexperiments.\\nSinceViTspre-trainingcorpusalreadyhavethecontextofthegenericimages,weinsteadadvocatetheuseformedicalimages\\nlike Brain MRI scans which may not be directly present during pre-training thus letting us conclude the performance of the\\nViTtrainedusingdifferentFLframeworksinthecaseswhenthedatasettofine-tuneisoutofdistributionwiththepre-training\\ncorpus.\\nForevaluation,eachshardwassplitintotrainingandtestsets,withthetestsetsizecomprising1%ofthetotalshardsize.The\\ntestsetsfromdifferentshardswerecombinedtoformaglobalevaluationset,resultinginatestsetsizeequivalentto37times\\nthenumberofclientsN forbothDolly-15kandMedQuAD.AsimilarapproachwasappliedtotheBrainTumorClassification\\ndataset,withthedifferencebeingthetestsetsize,whichwassetto5%ofthetotalshardsize.EachshardoftheBrainTumor\\nClassificationDatasetcontainsapproximately582samples,resultinginaglobalevaluationsetofsizeN ×29samples,where\\nN isthenumberofclients.Thisnon-IIDdatasetsplittingprocesswasconductedtwice,producingdistinctlabeldistributions(a)DollyDataset (b)MedQuADDataset\\n(c)DollyDataset (d)MedQuADDataset\\nFigure5:LabeldistributionacrossshardsforDollyandMedQuADdatasetsproducedusingDirichletAllocationwithα=0.1.\\nFigure 1(a) and 1(b) show the label distributions which are used in the main paper, and fig. 1(c) and 1(d) are the new label\\ndistributionswhoseexperimentalresultsareshowninthissupplementarymaterial.\\nacrossshards.Theresultsfromoneofthesesplitsarepresentedinthemainpaper,whiletheexperimentsandresultsfromthe\\nsecondsplitarediscussedhere.\\nExperiments\\nInthissection,weprovideadetailedoverviewoftheexperimentalsetupandpresentadditionalexperimentalresults.Asmen-\\ntioned in the main paper, all experiments were conducted on a single Nvidia A6000 cluster. One of the GPUs in this cluster\\nfunctionedastheserver,handlingglobalaggregation,whiletheremainingGPUswereutilizedforhostingmodelstoperform\\nlocaltrainingiterationsonnon-IIDdatasets.\\nFortheFlexLoRAandFFA-LoRAexperimentsontextmodality,weselectedaLoRArankof8andascalingfactorof16,\\nconsistentwiththehyperparametersusedintheoriginalpapersforthesemethods.IntheFedFTGexperiments,themainresults\\nreportedinthepaperwereobtainedbyfine-tuningtheproject-upMLPlayer.\\nInthevisiondatasetexperiments,weusedaLoRArankof8andascalingfactorof32forbothFlexLoRAandFFA-LoRA,\\nwithabatchsizeof2,incontrasttothebatchsizeof1usedforthetextdatasetexperiments.ForFedFTG,wefine-tunedboth\\nthe classifier layer and the project-up layer, whereas in FlexLoRA and FFA-LoRA, only the attention parameters (Q, K, V)\\nwerefine-tuned.WeappliedGaLoretothefinalclassifierlayerofthetransformer,astheFeed-ForwardNetwork(FFN)layer\\nin a neural network with a softmax objective can be represented in a parametric form that becomes low-rank during training\\n(refertoTheorem3.2andLemma3.3intheGaLorepaper).\\nFigures 1(a) and 1(b) illustrate the label distributions for the Dolly-15k and MedQuAD datasets, representing the client\\nlabelconfigurationsusedinthemainpaper’sexperiments.Figures1(c)and1(d)depictalternativelabeldistributions,distinct\\nfrom those in the main paper. The next section presents the experimental results corresponding to this alternate client label\\nconfiguration. As far as computational overhead is concerned, FedFTG takes about 20GBs in contrast to 14.2GBs taken by\\nLoRAmethods(FlexLoRAandFFA-LoRA)onNvidiaRTXA6000GPU.ThiscanbeattributedthefactthatFedFTGisn’tas\\nparameter-efficientasLoRAis.Thisispartofthefutureresearchtoinnovateonmoreparameter-efficientfine-tuningmethods\\nwhichdonotuseLoRA.\\nAnalysisoftheExperimentsPerformedintheMainPaper Inthissection,weprovideacomprehensivediscussionofthe\\nexperimentsconductedontheclientlabeldistributionspresentedinthemainpaper(Figures1(a),1(b),and2(b)).Theresults\\nin Table 1 of the main paper clearly indicate that FedFTG consistently outperforms both FFA-LoRA and FlexLoRA across\\nmultipledatasets,models,andnumbersofclients.\\nInthevisiondatasetexperimentsdetailedinthemainpaper,FedFTGcontinuestooutperformbothLoRA-basedfederated\\nlearningmethods.ThenotablypoorerperformanceofFFA-LoRAacrossbothtextandvisionmodalitiesalignswiththetheoret-\\nicalanalysisprovidedearlier.AccordingtoTheorem1,excessriskboundsincreasewitheachFedAvgstep,causingFFA-LoRANoofClients Dataset Model Method BLEU-4Score ROUGE-LScore\\nFedFTG 0.5697 0.73\\nTinyLlama FlexLoRA 0.4691 0.6527\\nFFA-LoRA 0.0995 0.2585\\nMedQuAD\\nFedFTG 0.5418 0.69\\nGemma-2B FlexLoRA 0.417 0.6317\\nFFA-LoRA 0.0987 0.2919\\n3\\nFedFTG 0.2954 0.5277\\nTinyLlama FlexLoRA 0.2928 0.5234\\nFFA-LoRA 0.0552 0.1576\\nDolly-15K\\nFedFTG 0.3294 0.5433\\nGemma-2B FlexLoRA 0.2721 0.5288\\nFFA-LoRA 0.0642 0.1568\\nFedFTG 0.5962 0.7198\\nTinyLlama FlexLoRA 0.495 0.6722\\nFFA-LoRA 0.1131 0.2901\\nMedQuAD\\nFedFTG 0.585 0.7254\\nGemma-2B FlexLoRA 0.5313 0.6969\\nFFA-LoRA 0.1141 0.2736\\n4\\nFedFTG 0.3597 0.5354\\nTinyLlama FlexLoRA 0.2922 0.5022\\nFFA-LoRA 0.0677 0.1707\\nDolly-15K\\nFedFTG 0.3513 0.5556\\nGemma-2B FlexLoRA 0.2723 0.5131\\nFFA-LoRA 0.0604 0.1716\\nTable 3: Comparison of BLEU-4 and ROUGE L F1 scores across different methods, models, and datasets for varying client\\nnumberswithnon-IIDsplits(seefig.1(c)and1(d))\\nNoofclients Method F1Score\\nFedFTG 0.7216\\n3 FlexLoRA 0.5136\\nFFA-LoRA 0.4533\\nFedFTG 0.7012\\n4 FlexLoRA 0.6065\\nFFA-LoRA 0.3639\\nFedFTG 0.8512\\n5 FlexLoRA 0.4975\\nFFA-LoRA 0.3894\\nTable4:ComparisonofF1scoreonBrainTumourClassificationDatasetforfine-tuningSigLIPusingdifferentFLfine-tuning\\nmethodsacrossnon-IIDsplits(seefig.2(b))(a)DistributionoflabelsacrossshardsforBrainTumourDatasetpro-(b)SeconddistributionoflabelsacrossshardsforBrainTumourDataset\\nducedusingDirichletAllocationwithα=0.1 producedusingDirichletAllocationwithα=0.1\\nFigure6:Comparisonoflabeldistributionsacrossdifferentmethods.\\nto deviate from the optimal parameters. This deviation results in inefficient learning of the dataset’s semantics across clients\\nand,consequently,poorerperformance.Figure8illustratesthevariationofROUGE LF1scoresevaluatedontheglobalevalu-\\nationsetwiththeFedAvgaggregationstepsforboththeTinyLlamaandGemma-2Bmodels.ThefigurehighlightsFFA-LoRA’s\\nineffectiveaggregation,asevidencedbyitsconsistentunderperformanceandminimalimprovementswithincreasingFedAvg\\nsteps.\\nIncontrast,whileFlexLoRAshowssignificantperformancedipsontheMedQuADdataset,itstillachievesreasonableaggre-\\ngationefficiencybutfallsshortcomparedtoFedFTG.FedFTGdemonstratesthemoststableaggregationresults,withminimal\\nabruptdropsandconsistenttrainingperformance.ThegraphsindicatethatFedFTGmaintainsstabledistributedtrainingwhile\\noutperformingbothFlexLoRAandFFA-LoRAacrossvariousclients,datasets,anddownstreamtasks.\\nThe vision modality experiments were carried out on dataset shards depicted in Figure 3. Table 2 shows that performance\\ninitiallyimproveswith4clientsbutdeclineswith5clients.ThemainpaperprovidesadetailedanalysisofFedFTGandFFA-\\nLoRAforthevisiondataset.Here,wefocusonthebehaviorofFlexLoRAinthevisiondataset.FlexLoRAexhibitsadifferent\\ndynamiccomparedtoFedFTGandFFA-LoRAduetoitsuniqueaggregationscheme.Ittendstooverfitwhentrainingwith4\\nclients,likelybecausethesamelabelsarepresentinbothshard3andshard4.However,performanceimproveswhenexpanding\\nto5clients,asthemodelcanpotentiallylearnnewrepresentationsfromtheadditionaldatasamplesinthefifthshard,thereby\\nenhancingitsgeneralizationcapability.\\n(a) 3 clients, MedQuAD, TinyL- (b) 4 clients, MedQuAD, TinyL- (c)3clients,Dolly,TinyLlama (d)4clients,Dolly,TinyLlama\\nlama lama\\n(e)3clients,MedQuAD,Gemma- (f)4clients,MedQuAD,Gemma- (g)3clients,Dolly,Gemma-2B (h)4clients,Dolly,Gemma-2B\\n2B 2B\\nFigure 7: Variation of ROUGE L scores evaluated on the test set with global aggregation steps across different clients and\\ndatasetsfortheTinyLlamamodelontheolderlabeldistributions(seeFig.1(a)and1(b))(a) 3 clients, MedQuAD, TinyL- (b) 4 clients, MedQuAD, TinyL- (c)3clients,Dolly,TinyLlama (d)4clients,Dolly,TinyLlama\\nlama lama\\n(e)3clients,MedQuAD,Gemma- (f)4clients,MedQuAD,Gemma- (g)3clients,Dolly,Gemma-2B (h)4clients,Dolly,Gemma-2B\\n2B 2B\\nFigure 8: Variation of ROUGE L scores evaluated on the test set with global aggregation steps across different clients and\\ndatasetsfortheTinyLlamamodelontheolderlabeldistributions(seeFig.1(c)and1(d))\\nExperiment Results onDifferent Label Distributions In this section,we perform our experiments on alabel distribution\\nwhichisdifferentthantheoneusedinthemainpaper.ThenewlabelsareshowninFig2(c),2(d)(fortextmodality)andFig\\n3(b)(forimagemodality).\\nAs demonstrated in the table summarizing results on the new data distribution, FedFTG consistently outperforms both\\nFlexLoRA and FFA-LoRA. Specifically, Table 1 shows that FedFTG surpasses these methods across both the MedQuAD\\nand Dolly-15k datasets. Additionally, FedFTG outperforms other federated learning (FL) methods on SigLIP for the Brain\\nTumorClassificationDataset.Figure4furthercorroboratesFedFTG’ssuperiorperformance,consistentwiththefindingsfrom\\nthemainpaper.\\nIn line with the results observed for the label distributions in Figures 1(a) and 1(b) of the main paper, FedFTG tends to\\noverfitontheDolly-15kdatasetforboth3and4clients.Itsperformancegraphisnotablysmoother,withminimalsuddendips,\\nindicatingstableaggregationanddistributedlearning.OnepotentialreasonforoverfittingintheDolly-15kdatasetisthatthe\\ncontext of Dolly-15k may already be present in the pre-training or instruction-tuning corpus of these large language models\\n(LLMs).GiventhatDolly-15kisamoregenericdataset,LLMsarelikelytohaveapriorunderstandingofitssemantics,unlike\\ntheMedQuADdataset,whichislessprevalentinpre-trainingcorpora.\\nAsdiscussedinthemainpaper,accuracyishighlydependentontheinteractionbetweenlabels,whichresultsinvariations\\nin the metric values. In the new label distributions (see Fig. 6b), the accuracy of FedFTG and FFA-LoRA decreases as the\\nnumberofclientsincreases.ThisdeclineislikelyduetoanunderfittingscenariowherethemodelstrainedusingFedFTGand\\nFFA-LoRAmaynothaveadequatelylearnedthesemanticsofshard3,whichcontainslabels1and3,withlabel3onlybeing\\npresent in shard 1 at a very small percentage. However, when the number of clients increases to 5, the performance of both\\nFedFTGandFFA-LoRAimproves.Notably,FedFTGperformsevenbetterwith5clientsthanwith3clients,whileFFA-LoRA\\nperforms better than with 4 clients but still falls short of its performance with 3 clients. This highlights FedFTG’s superior\\ngeneralizationinthisscenario,outperformingFFA-LoRAwhichisevidentfromourtheoreticalanalysisaswell.\\nSimilartotheexperimentsdiscussedinthemainpaper,FlexLoRAexhibitsadifferentbehavior,withperformanceimproving\\ninthecaseof4clientsbutdecreasingwhenthenumberofclientsincreasesto5.\\nAll these experimental results show FedFTG’s superior performance over the current and the most recent State-of-the-Art\\n(SOTA)FLmethodswhicharebasedonLoRA.FedFTGistheoreticallymotivatedandempiricallyverifiedacrossbothimage\\nandtextmodalitiesonlanguageandvisiontransformers.IteffectivelyaddressesLoRA’sbottlenecksrelatedtosub-optimalsub-\\nspacelearningandconsistentlyoutperformsFlexLoRAandFFA-LoRAacrossdifferentdatasets,multipleclientconfigurations\\nandexperimentruns.\\nReproducibilityChecklist\\nInthissectionweanswerthequestionsforreproducibilitychecklistasmentionedintheAAAI2025guidelines.\\nThispaper:\\nQ.Includesaconceptualoutlineand/orpseudocodedescriptionofAImethodsintroduced.Ans:Yes\\nQ.Clearlydelineatesstatementsthatareopinions,hypothesis,andspeculationfromobjectivefactsandresults.Ans:Yes\\nQ.Provideswellmarkedpedagogicalreferencesforless-familiarereaderstogainbackgroundnecessarytoreplicatethepaper.Ans:Yes\\nDoesthispapermaketheoreticalcontributions?Ans:Yes\\nIfyes,pleasecompletethelistbelow.\\nAllassumptionsandrestrictionsarestatedclearlyandformally.Ans:Yes\\nAllnovelclaimsarestatedformally(e.g.,intheoremstatements).Ans:Yes\\nProofsofallnovelclaimsareincluded.Ans:Yes,theproofsareallincludedinthesupplementarymaterial.\\nProofsketchesorintuitionsaregivenforcomplexand/ornovelresults.Ans:Yes\\nAppropriatecitationstotheoreticaltoolsusedaregiven.Ans:Yes\\nAll theoretical claims are demonstrated empirically to hold. Ans: Yes, as discussed in the main paper as well as the supple-\\nmentary material, the theoretical claims made for FlexLoRA (proposition 1) and FFA-LoRA (Theorem 1) hold true as their\\nperformance degradation aligns closely to how the model performs with different FL methods. Claims regarding FedFTG’s\\nstable aggregation and performance (Theorem 2) also hold true from the conclusions made by examining the experiment\\nresults.\\nAllexperimentalcodeusedtoeliminateordisproveclaimsisincluded.Ans:Yes\\nDoesthispaperrelyononeormoredatasets?Ans:Yes\\nIfyes,pleasecompletethelistbelow.\\nA motivation is given for why the experiments are conducted on the selected datasets. Yes, we explained our motivation in\\ndetailinthedataappendixinthisdocument.\\nAllnoveldatasetsintroducedinthispaperareincludedinadataappendix.NANonoveldatasetsareused.\\nAll novel datasets introduced in this paper will be made publicly available upon publication of the paper with a license that\\nallowsfreeusageforresearchpurposes.Ans:NA\\nAlldatasetsdrawnfromtheexistingliterature(potentiallyincludingauthors’ownpreviouslypublishedwork)areaccompanied\\nbyappropriatecitations.Ans:Yes\\nAll datasets drawn from the existing literature (potentially including authors’ own previously published work) are publicly\\navailable.Ans:Yes\\nAlldatasetsthatarenotpubliclyavailablearedescribedindetail,withexplanationwhypubliclyavailablealternativesarenot\\nscientificallysatisficing.Ans:NA:Wehavedoneallourexperimentsonpubliclyavailabledatasets.\\nDoesthispaperincludecomputationalexperiments?Yes\\nAnycoderequiredforpre-processingdataisincludedintheappendix.Ans:YesWehaveprovidedthepre-processingcodein\\nthecodeappendixzippedtogetherwiththissupplementarymaterial.\\nAllsourcecoderequiredforconductingandanalyzingtheexperimentsisincludedinacodeappendix.Yes\\nAllsourcecoderequiredforconductingandanalyzingtheexperimentswillbemadepubliclyavailableuponpublicationofthe\\npaperwithalicensethatallowsfreeusageforresearchpurposes.YesOnceuponpublication,weplantoreleasethecodeinthe\\nlibrarypythonformatsothatitseasierforresearcherstobuildtoolsthatusefederatedfine-tuningoftransformermodelsand\\nintegrateitwiththeirexistingcodebases.\\nAllsourcecodeimplementingnewmethodshavecommentsdetailingtheimplementation,withreferencestothepaperwhere\\neachstepcomesfrom.Yes\\nIf an algorithm depends on randomness, then the method used for setting seeds is described in a way sufficient to allow\\nreplication of results. Yes All the details regarding the seed settings are described in the code appendix in the README as\\nwellascommentsinthecode.\\nThispaperspecifiesthecomputinginfrastructureusedforrunningexperiments(hardwareandsoftware),includingGPU/CPU\\nmodels; amount of memory; operating system; names and versions of relevant software libraries and frameworks. Yes Such\\ninformationisdetailedinthecodeappendix.\\nThis paper formally describes evaluation metrics used and explains the motivation for choosing these metrics. Partial We\\nhaven’tformallydescribedtheevaluationmetricsthatwehaveused(ROUGELScore,BLEU-4score),butwehavecitedtheir\\npapers.Alsowehaveprovidedthemotivationtousethesemetricsinbothsupplementarymaterialaswellasmainpaper.\\nThispaperstatesthenumberofalgorithmrunsusedtocomputeeachreportedresult.Yes\\nAnalysis of experiments goes beyond single-dimensional summaries of performance (e.g., average; median) to include\\nmeasuresofvariation,confidence,orotherdistributionalinformation.Ans:YesWedidourexperimentsonmultiplenumbers\\nofclients,datasets,models,andevenclientlabelconfigurations.\\nThe significance of any improvement or decrease in performance is judged using appropriate statistical tests (e.g., Wilcoxon\\nsigned-rank).Yes,weperformandmakeourconclusionsbasedonextensiveexperimentsacrossmultipledatasets,numbersof\\nclients,andmodels.\\nThispaperlistsallfinal(hyper-)parametersusedforeachmodel/algorithminthepaper’sexperiments.Yes\\nThispaperstatesthenumberandrangeofvaluestriedper(hyper-)parameterduringdevelopmentofthepaper,alongwiththe\\ncriterionusedforselectingthefinalparametersetting.No',\n",
       " 'Hyperbolic Contrastive Learning for Hierarchical 3D Point Cloud Embedding.pdf': \"1\\nHyperbolic Contrastive Learning for Hierarchical\\n3D Point Cloud Embedding\\nYingjie Liu, Pengyu Zhang, Ziyao He, Mingsong Chen, Xuan Tang, Xian Wei∗\\nEast China Normal University\\n∗xwei@sei.ecnu.edu.cn\\nAbstract—Hyperbolicspacesallowformoreefficientmodeling exhibit better performance [6], [19], [22]–[24], [39]. Most\\nof complex, hierarchical structures, which is particularly bene- recent research [48] investigates the non-Euclidean character-\\nficial in tasks involving multi-modal data. Although hyperbolic\\nisticsofLLMsoncomplexreasoningtasks,findingthattoken\\ngeometries have been proven effective for language-image pre-\\nembeddings and hidden states exhibit a significant degree of\\ntraining, their capabilities to unify language, image, and 3D\\nPoint Cloud modalities are under-explored. We extend the 3D hyperbolicity, indicating an underlying hyperbolic structure.\\nPoint Cloud modality in hyperbolic multi-modal contrastive We further hypothesize that incorporating hierarchical con-\\npre-training. Additionally, we explore the entailment, modality cepts in model feature space design can help models maintain\\ngap, and alignment regularizers for learning hierarchical 3D\\nstable, coherent perception when faced with complex visual\\nembeddings and facilitating the transfer of knowledge from\\ninputs, which is beneficial for understanding the real world.\\nboth Text and Image modalities. These regularizers enable the\\nlearningofintra-modalhierarchywithineachmodalityandinter- Hyperbolic space with negative curvature is well-suited for\\nmodal hierarchy across text, 2D images, and 3D Point Clouds. modeling hierarchical data, yielding remarkable performance.\\nExperimental results demonstrate that our proposed training Hierarchical embeddings in the hyperbolic space have been\\nstrategy yields an outstanding 3D Point Cloud encoder, and the\\npreviously explored in single-modal and uni-modal settings,\\nobtained 3D Point Cloud hierarchical embeddings significantly\\nlearning shared embeddings of different types of modalities,\\nimprove performance on various downstream tasks.\\nincluding Text and Images [10], [52]. MERU [6] is the first\\nlarge-scalecontrastiveimage-textmodelsthatyieldhyperbolic\\nI. INTRODUCTION embeddings. [37] further considers the modality-gap problem\\nRecently, language models (LMs) [2], [22], [26], [48] have while preserving hierarchies.\\nmade great progress and shown remarkable capabilities in However, the aforementioned challenges remain when in-\\nunderstanding and generating natural language. Meanwhile, corporating LLMs for 3D object understanding in hyperbolic\\nto harness the advancements in language models, recent ap- space, especially embodied interaction that relies on pre-\\nproaches [12], [13], [34] have evolved to combine visual cise geometry, which is currently under-explored. Hence, in\\nprocessing with the reasoning and generalization capabilities this work, we further explore the hierarchical prior in 3D\\nofLMsbyaligningvisionandlanguageembeddingsinshared object understanding by bridging the hyperbolic language-\\nfeature space and ensuring consistency. Even with the signifi- image model and 3D Point Cloud representation learning. We\\ncant resource investment and progress in training schemes or train contrastive text-2D image-3D Point Cloud models that\\npromptengineering,recallingthemanifoldlearninghypothesis yield hyperbolic embeddings that capture the visual-semantic\\nrevealsthatthesemodelsstillfacelimitations,particularlydue hierarchy. We summarize our contributions as follows:\\nto the lack of consideration for the geometric priors of the • We propose a regularizer for point cloud embedding re-\\nfeature space. The default Euclidean geometry used in these construction to promote intra-modal hierarchical knowl-\\nmodels for learning embeddings may not always be optimal, edge capturing and implement a guidance contrastive\\nparticularlyinrepresentingcomplexhierarchicalstructuresand learning process, aligning 3D Point Cloud embeddings\\nrelationships in real-world data, whether in text modality or with hyperbolic Text-Image embeddings.\\nvision modality. • We propose novel hierarchy-enhancing losses that pro-\\nHierarchical structure is a fundamental component of the mote inter-modal hierarchical concept relations during\\nnatural world. Humans comprehend the world through the contrastive learning, achieving hierarchical embeddings\\nrelationships and hierarchies described above [28], [38]. For for 3D Point Clouds, extending beyond common Text-\\nexample, all noun hierarchies lead to an entity, and verb Image modalities.\\nsynsets detail events, e.g., “communicate” to “whisper” [7]. • Experimental results show significant improvements in\\nText-vision pairs also show hierarchy, while pixels form the performance of various point cloud tasks based on\\nshapes, combining to create scenes, each layer building on our hierarchical 3D Point Cloud embeddings.\\nthe previous to abstract higher. Studies have shown that the\\nII. RELATEDWORK\\ntext and vision data (including 2D images and 3D Point\\nClouds in this work) are part of the hierarchy [6], [23], [39]. A. Hyperbolic Geometry for Point Clouds\\nMeanwhile, latent embeddings with an underlying tree-like Hyperbolic embedding learning has been explored in var-\\nand hierarchical structure learned by deep neural networks ious fields [3], [9], [18], [21], [25]. Hyperbolic embeddings\\n5202\\nnaJ\\n7\\n]VC.sc[\\n2v58220.1052:viXra2\\nwith InfoNCE loss for predicting hierarchical relations in the III. PRELIMINARY\\nWordNetnounshypernymytreewasfirstproposedin[25].[9] In this section, we introduce relevant notations and\\nsuggested entailment loss as an alternative. In the vision area, briefly review the Lorentz space and related contrastive\\n[18]proposedHyperbolicProtoNetforfew-shotclassification. losses used in this work as preliminary knowledge. We di-\\nPoint clouds of 3D objects also exhibit an inherent hierar- vide a dataset of text-vision pairs into mini-batches B =\\nchical compositional nature. HyCoRe [23] first proposes the {(T ,V ,P ),(T ,I ,P ),...}, where T , I and P denotes\\n1 1 1 2 2 2 i i i\\nexplicit regularization to capture part-whole hierarchies and text, 2D images, and 3D Point Clouds, respectively. Let |B|\\nexperimentally observed hierarchical structures, noting that denote the batch size and i ∈ |B|. Further, assume that we\\nhierarchical structures of embeddings naturally emerge within have a text encoder f(·), an image encoder g(·), and a 3D\\nhyperbolic space but are crude without its proposed regular- Point Cloud encoder h(·). Let x,y,z denote hyperbolic text\\nization [24]. PHGT [21] leverages an attention module based embedding,hyperbolicimageembeddingandhyperbolicpoint\\nonthePoincare´ ballmodeltoenhance3DPointCloudfeature cloud embeddings, respectively.\\nextraction and classification. HypLiLoc [42] fuses Euclidean\\nandhyperbolicfeaturesforimprovedposeregression.HECPG A. Hyperbolic Geometry & Lorentz Embeddings\\n[46] introduces hyperbolic attention with hyperbolic weight\\nHyperbolic space is a non-Euclidean space with constant\\nand Riemannian metric to fuse hyperbolic features, boosting\\nnegative curvature. Following [37], to better avoid numerical\\npoint cloud matching accuracy adaptively. We further propose\\ninstabilities in the training process that comes from expo-\\nnovel pre-training losses that enhance hyperbolicity, thereby\\nnential volume growth, we adopt the Lorentzian hyperboloid\\npreserving hyperbolic modeling capabilities during the multi-\\nratherthanotherpopularmodelsofhyperbolicgeometry,e.g.,\\nmodal contrastive learning process.\\nthe Poincare´ ball model, the Klein model, the Poincare´ half-\\nspace model, and the hemisphere model. The Poincare´ ball\\nB. Contrastive Pre-training for Hierarchy Multi-Modal Em- model and Beltrami-Klein model are the projections of the\\nbeddings hyperboloid model onto the different dimensional space-like\\nhyperplanes, as more details can referred to in [39]. Taking x\\nConVIRT [55] pioneered contrastive pre-training [16],\\nas an example, we provide a background discussion of the\\n[35] for zero-shot image classification, maintaining L2-\\nhyperbolic space but limit it to the Lorentz / hyperboloid\\nnormalization and cosine similarity. There are some other\\nmodel, denoted by\\nvariant methods like CoCa [50] added captioning loss by\\na multi-modal text decoder, OTTER [44] considered intra- Ln ={x∈Rn+1 :⟨x,x⟩L = −1/c}, c>0,\\nmodal similarity, and SigLIP [53] applied logistic regression.\\nwhere every vector x can be written as [x ,x ],\\nOther than MERU [6], exponentially lifts the embeddings space time\\nx ∈ R serves as the axis of symmetry [37]. Note that\\nonto the Lorentz hyperboloid, combining entailment learning time\\nfor c > 0, the curvature is −c. Since x always lies on\\nwith the CLIP approach to learn embeddings in hyperbolic\\nthe hyperboloid, the time dimension can then be inferred\\nspacecapturinglatentvisual-semantichierarchies.[37]further (cid:112)\\ndiscusses the modality gap in hyperbolic space. The most\\nas x\\ntime\\n= 1/c+∥x space∥2. ⟨·,·⟩L denotes the Lorentzian\\ninner product as\\nrecent[27]extendstoincludeimagepatchesandcaptionparts,\\nenforcing an ordering that reflects the hierarchy shared by ⟨x,y⟩L =x space·y space−x time y time.\\nbothmodalities.EuCLIP[5]captureshierarchicalrelationships\\nWe only consider these maps where m is the origin of\\nby using Euclidean geometry with negative squared distance\\nthe hyperboloid (O = [0,1/c]) [37], i.e., simplifying the\\nsoftmax logits and removing final layer normalization.\\nexponentialmapbyusingthetangentspaceoftheorigin,thus\\nThe point cloud is a fundamental modal for understanding\\nmeanwhile minimizing potential numerical instability in the\\nthe three-dimensional (3D) world. Both inter and intra-modal\\nmodel’s computation [19]. The exponential map provides a\\ncontrastive learning strategies are extended to the point cloud\\nway to map vectors from tangent spaces onto the manifold.\\narea [1]. PointCLIP [54], [56] further aligns point clouds to\\nFor the point O on the hyperboloid, it is defined as expm :\\n2D depth images and text in the context of CLIP. ReCon T Ln →Ln. Let u=[u ,0]∈Rn+1, thus ⟨O,u⟩=0 aO nd\\nO enc\\n[33] utilizes contrast guided by reconstruction to address\\nu belong to the tangent space at the hyperboloid origin O .\\nthe pattern disparities between local masked data modeling\\nWe have the space dimension of hyperbolic text embedding\\nand global cross-modal alignment. ShapeLLM [34] further\\nas x =expm (u), by lifting the embeddings to the\\nscales up the parameters of ReCon and broadens the scale Lores np ta zce hyperboloO id,sp La nce\\nthrough the exponential map\\nof the pretraining dataset for robust 3D embeddings. [4] pre- √\\nsinh( c∥u ∥)\\ntrains a 3D Point Cloud encoder and cross-modal interactor expm (u)= √ enc u +0.\\nusingphrase-levelscene-textannotations,thentunesformulti- O,space c∥u enc∥ enc\\ntask instruction with referent tokens for flexible 3D scene Note that u denote the scaled text embeddings,\\nenc\\nunderstanding. However, it remains under-explored in the\\nu =α f(T).\\ncontext of learning hyperbolic contrastive 3D Point Cloud enc txt\\n√\\nembeddings. We further explore inferring concept hierarchies Specifically,f(T)∈Rnwouldhaveanexpectednorm nand\\n√\\nacross multiple modalities, including text, 2D images, and 3D the exponential map scales it to e n, which can be numeri-\\nPoint Clouds. cally large [6]. Both α\\ntxt\\nare initialized to √1\\nn\\nand learned3\\nin logarithmic space to avoid collapsing all embeddings to teachers, i.e., keeping the text encoder and image encoder of\\nzero so that the embeddings have an expected unit norm at MERU frozen in this work. Given the predicted point patches\\ninitialization,preventingnumericaloverflow.Similarly,forthe P and ground truth P , we have\\npre gt\\nimage modal, we have v = α g(I) ∈ Rn and further\\nenc img 1 (cid:88)\\nobtain hyperbolic image embedding y. LRec = min ∥P′−P∥2+\\nA geodesic is the shortest path between two points on the\\n|P pre| P′∈PpreP∈Pk 2\\n(2)\\nmanifold.GeodesicsintheLorentzmodelarecurvestracedby 1 (cid:88)\\nmin ∥P′−P∥2.\\nt th he rouin gt hers the ecti oo rn igio nf oth fe Rh ny +p 1erboloid with hyperplanes passing |P gt| P∈PgtP′∈Ppre 2\\nd L(x,y)=(cid:112) 1/c·cosh−1(−c⟨x,y⟩L). IV. APPROACH\\nIn this section, we first introduce our basic model and then\\nB. Language-Vision Contrastive Learning Loss analyze hierarchy relations across text, image, and 3D Point\\nCloud. Finally, we present novel hyperbolicity-enhancing pre-\\nContrastive Loss for Hyperbolic Language-Image Em-\\ntraining losses that promote preserving hyperbolic modeling\\nbeddings Considering language-image contrastive learning\\ncapabilities.\\nloss L , it can formulated by applying InfoNCE [40] with\\ncont\\nsimilarity function that measures the relationship within pairs.\\nThe similarity function is cosine similarity in CLIP, i.e., A. Overall Architecture and Hierarchy Relations\\nsim(x,y) = x·y where ∥·∥ is the L2 norm. For hyper- Basic Model When addressing 3D Point Clouds, current\\n∥x∥∥y∥\\nbolic contrastive learning, we follow the formulation and the hyperbolic contrastive learning methods have not been ex-\\nhyperboloid model in MERU [6] whose similarity function is tendedtothe3DPointCloudsmodal,ignoringtheimportance\\nparameterized bythree trainablescalars: text embeddingscale of its underlying hierarchical prior. Therefore, we extend the\\nα txt, image embedding scale α img, and curvature parameter reconstruction-guided contrastive learning framework in [33],\\nc. For a batch of size (B) containing text (T) x and images aiming to transfer knowledge to the point cloud encoder from\\n(I) y, the contrastive loss is formulated by taking the negative a pre-trained hyperbolic language-image model MERU [37],\\nLorentzian distance as the similarity metric, as follows: which has learned paired image-text embeddings in the hy-\\nperbolic space, facilitate the learning of hierarchical 3D Point\\nsim(f(T),g(I))=−d (x,y)\\nL\\nCloud embeddings. Note that we employ Point-MAE [29] as\\nReconstruction-guided Contrastive Learning for 3D Point the point cloud encoder. Single-modal 3D Point Cloud inputs,\\nClouds Embeddings The training paradigm of the 3D Point and cross-modal inputs including rendered RGB images and\\nCloud encoder in this work is based on the reconstruction- text descriptions, are encoded as sequential tokens. During\\nguided contrastive learning framework ReCon [33]. It is con- contrastivelearning,the3Dtokenembeddingsaremaskedfor\\nsistently observed that contrastive models focus mainly on a generative reconstruction, while the mask is disabled during\\nglobal field, in contrast to generative models which exhibit a inference. The obtained 3D Point Cloud embeddings and\\npreferenceforfocusedlocalattention,leadingtoataskconflict global queries are then fed to the decoder, which shares the\\nin naive multi-task representation learning settings [33], [47]. same architecture as the encoder. The queries are learnable\\nFollowing ReCon, we consider the objective as ensemble andsupervisedbycontrastivelearning.However,theobjective\\nrepresentation distillation, encouraging the 3D Point Cloud of the 3D Point Cloud encoder in ReCon does not include\\nencoder to learn disentangled knowledge representation. Both a hierarchical representation-related loss function or target,\\ncontrastiveandgenerativemethodsareseenasstudent-teacher meaning that the obtained 3D Point Cloud embeddings do\\nparadigms, unified as ensemble distillation from multiple not explicitly capture hierarchical knowledge. To address this,\\nteachers, where the generative model also acts as a ”teacher” we further introduce appropriate regularizers to unify the\\nguiding the contrastive learning. Meanwhile, reconstruction objective for effective hierarchical 3D representation learning\\nguidance enhances the contrastive learning process by im- and understanding, while also addressing differences in data\\nproving generalization, stability, and training efficiency. The patterns and tasks across modalities.\\nReCon loss LReCon =LRec+LCon ensembles the cross-modal Hierarchy Relation Analysis We aim to effectively and ex-\\ncontrastive learning loss using the positive-only representa- plicitly represent the underlying hierarchy structures, whether\\ntion learning with Smooth ℓ 1 loss Smooth-ℓ 1(·,·), and the within a modality (intra-modal) or between different modal-\\nreconstruction guidance loss, constructed as the masked point ities (inter-modal), through positional relationships. Specifi-\\nmodeling reconstruction following [29]. Specifically, the loss cally,weconsiderhowtherelationshipsbetweenpointclouds,\\nLCon can be written as: text,andimagesshouldbestructured,focusingontheposition\\n|B| of 3D modalities in the hierarchy.\\nLCon =(cid:88)(cid:104) Smooth-ℓ (cid:0) z,stopgrad(x(cid:1) + In hyperbolic space, as the distance from the center in-\\n1\\ni=1 (1) creases, the available embedding area for features expands\\n(cid:0) (cid:1)(cid:105) exponentially. Given that general concepts require less rep-\\nSmooth-ℓ z,stopgrad(y ,\\n1\\nresentational space than specific ones, simpler, more common\\nwhere stopgrad(·) is the stop-gradient operation, which concepts should be mapped closer to the center of the space\\nprevents gradients from back-propagating to the image or text than more detailed concepts. Thus,4\\n• From the perspective of inter-modal hierarchy relation- the point cloud embeddings and all point cloud embeddings\\nship, we consider the entailment property used in model- to match the text embeddings within the cones that emanate\\ning hierarchical concepts in WordNet [9], which exhibits from the text embeddings. Images still adhere to the principle\\nthe transitive property. This can be applied to construct thatacorrespondingtextembeddingrepresentsamoreabstract\\ninter-modal hierarchy relations, meaning if x entails y concept, and we build the inter-modal hierarchy between the\\nand y entails z, then x entails z. embeddings of the new modality 3D Point Cloud and the\\n• From the perspective of intra-modal, we discuss the existing Text-Image embeddings.\\nalignment of 3D Point Cloud embeddings to Text-Image To encourage better distribution of embeddings on the\\nembeddings, considering the hierarchical whole → part hyperbolic space, we follow an objective that maintains a\\ncomposition relation inside 3D Point Cloud embeddings controllable or adaptive modality gap and further constructs\\nandintroducethequantitativeanalysisofthehierarchical the semantic hierarchy structure across text, 2D images, and\\nrelationships within the same modal. 3DPointClouds[37].Specifically,weensurethatthecentroid\\nof text embeddings is closer to the origin than the centroid\\nB. Hyperbolic Entailment Regularization of visual embeddings, and the centroid of 3D Point Cloud\\nembeddings should be closer to the origin than the centroid\\nTo better match the representation of the 3D object’s\\nof the 2D image embeddings. Obtaining the centroid of a set\\npoint clouds, existing 3D cross-modal representation learning\\nof points in the hyperbolic space H is not as straightforward\\nmethods primarily average the image features extracted by\\nas the Euclidean setting. This is called the Einstein midpoint,\\nsingle-view 2D foundation models from multi-view images,\\nanditiseasiertoobtainviaconvertingtoKleincoordinatesK.\\nwhich are projections of the original 3D object. Recently,\\nA point on the hyperboloid model can be converted to Klein\\nmethodslikeDETR,BLIP2,andShapeLLM[34]havefurther\\ncoordinates k and back via projections, and the the centroid\\nproposed to adaptively select and distill views to describe\\ntakes the following form:\\nthe 3D object better. However, while images can supplement\\ni mnf igo hrm\\nt\\na nt oio tn pra ob vo iu dt e,m ta ht ee yria cl anand onc lyolo sr ert vh eat as3D apP po roin xt imC al to iu od ns\\ns\\nCentroidH(x)=ΠK→H(cid:32)(cid:80)N\\nj=1\\n(cid:80)γ\\nj\\nNΠH→ γK(x j)(cid:33)\\n,\\nor augmentations for accurately representing the geometric j=1 j\\nstructure of the 3D object. Therefore, to perform cross-modal x={x }N ,γ = 1\\nlearningbetter,wemustacknowledgethedifferencesbetween j j=1 j (cid:112) 1−c∥ΠH→K(x j)∥2\\nimage embeddings and 3D Point Cloud embeddings and\\nwhere γ denotes the Lorentz factors. Formally, let X , Y ,\\ncapture their relationship, which enhances comprehensive 3D j e e\\nand Z be the Einstein midpoint of a set of text, 3D Point\\nshape information understanding. e\\nCloudembeddingsandimageembeddings,respectively.Then,\\nIn a nutshell, multi-view image embeddings are entailed\\nour regularization takes the following form:\\nwithin the hyperbolic cones of the 3D Point Cloud embed-\\ndings, and 3D Point Cloud embeddings are entailed within p=d L(O,p)=(cid:112) 1/c·cosh−1(−c⟨O,p⟩L)\\nthe hyperbolic cones of the text embeddings. This builds a hi- (cid:114)\\nerarchystructureofthecross-modalfeaturespace,establishing =(cid:112) 1/c·cosh−1( 1\\nc\\n+∥p space∥2),\\na partial order among Text-Image-point cloud pairs.\\nq =d (O,q),r =d (O,r),\\nWe extend the entailment loss [6], generalizing to capture L L\\nthe visual-semantic hierarchy across Text-Image-point cloud L cent =∥Z e−p∥2+∥Y e−q∥2+∥X e−r∥2\\nthree modalities. Using the half-aperture of a text embedding where is the Euclidean norm and p > q > r > 0 to ensure\\nand the exterior angle between a Text and Image embedding that the centroid relationships, avoiding the diversity collapse\\nas examples, as of visual embeddings.\\n(cid:18) (cid:19)\\n2K 2K\\naper(x)=sin−1 √ , ∥x ∥≥ √ ,\\nc∥x ∥ space c C. Alignment Loss and Hyperbolicity Analysis\\nspace\\nwhere √ 2K willbeclampedto1−ϵ,whereϵ=10−8for In addition to achieving the alignment of 3D Point Cloud\\ntrainingsc ta∥x bs ilp ia tc ye∥ [6].Theexteriorangleext(x,y)=π−∠Oxy embeddings to Text-Image embeddings, we refine the internal\\nhierarchical structure of the point cloud embeddings by con-\\ngiven by the origin O, x, and y is then\\nsidering the hierarchical whole → part composition relation.\\n\\uf8eb \\uf8f6\\ny +x c⟨x,y⟩ Specifically, during training, the 3D Point Cloud encoder\\next(x,y)=cos−1\\n\\uf8ed\\ntime (cid:113)time L\\n\\uf8f8 Point-MAE infers twice: once with full-size point clouds as\\n∥x ∥ (c⟨x,y⟩ )2−1\\nspace L input and once with a masked point cloud, resulting in a\\nFinally, the entailment loss mathcalL is formally written part embedding. This process helps capture the hierarchical\\nentail\\nas: relationships within the point cloud modal.\\nNext, we introduce a quantitative analysis method to an-\\nL (x,y,z)=max(0,ext(x,y)+ext(y,z)−\\nentail\\nalyze the hierarchical structure of the obtained point cloud\\naper(x)−aper(y)).\\nembeddings. Gromov δ-hyperbolicity is a geometric metric\\nTheentailmentlossforcesallimageembeddingstomatchthe that quantifies the deviation of a given metric space from\\npoint cloud embeddings within the cones that emanate from an exact tree metric [11]. The simplest discrete metric space5\\npossessinghyperbolicpropertiesisatree(inthesenseofgraph tasksinSectionV-C,demonstratingtheimprovementsbrought\\ntheory) endowed with the natural shortest path distance. A by our hierarchical 3D point cloud embeddings.\\nlower δ-hyperbolicity value, or equivalently, a higher degree Implementation Details All the experiments are conducted\\nofhyperbolicity,indicatesamoretree-likestructurewithinthe on a GeForce RTX 4090 24 GB for all the experiments. We\\nspace, and δ =0 for trees. use CLIP and MERU as our teacher models: the CLIP-based\\nWe follow the efficient way to compute δ presented in [8] approach uses the default CLIP-ViT-B/16, and the MERU-\\nand applied in [18], [30]. Specifically, we sample N samples based method uses the base MERU model with ViT-B/16 as\\nand find δ based on the distance matrix of point sets. Since theimageencoderandthesametextencoderasCLIP[41].We\\nrel\\nwecomputethehyperbolicityvaluesoffeaturesthatembedded maintain consistent settings of the total train epoch, learning\\ncontinuous space, i.e., Lorentz Space, the distance matrix is rate schedule, and optimizer configuration with maximum\\nbased on their geodesic distances. Moreover, δ is a scale- learning rate 5e − 4, AdamW optimizer, cosine learning\\nrel\\ninvariant metric defined as: rate schedule with 10 warm-up steps, and batch size 128.\\n2δ(X) To ensure curvature parameter c and text/image/point clouds\\nδ (X)= , (3)\\nrel diam(X) embedding scales α txt/α img/α pts stay positive, these scalar\\nhyperparameters are parameterized on the logarithmic scale\\nwhere diam(X) denotes the set diameter (maximal pairwise\\nand are consistent with the MERU model: c is initialized with\\ndistance). By construction, δ (X) ∈ [0,1] specifies how\\nrel pre-trained MERU checkpoint and fixed. To maintain stability\\nclose embeddings are set to a hyperbolic space.\\nandavoidnumericalissues,weemploytrigonometricfunctions\\nwith values clamped to the range [1e−8,1−1e−8].\\nD. Contention Between Modal and Tasks\\nFor the setting of visual scene understanding in computer\\n0.50\\nvision, the down-streamed models must understand both the\\n0.45\\ngeometry and semantics of the scene by dealing with our 0.40\\nlearned visual embeddings simultaneously, leading to a multi- 0.35\\n0.30 taskrepresentationlearningproblem.Consideringthatthedif-\\n0.25\\nferentregularizersareindependentlypropagated,thecoverage 0.20\\nspeed of intra-modal learning and inter-modal learning was 0.15 0 50 100 150 200 250 300\\nEpochs\\nobserved to be different during our pre-training [14]. Prior\\napproaches to simultaneously learning multiple tasks use a\\nnaive weighted sum of losses, where the loss weights are\\nuniform or manually tuned. Performance is highly dependent\\non an appropriate choice of weighting between each task’s\\nloss. Therefore, to ensure the effective use of the regularizers\\nproposedintheabovesections,thisworkautomaticallyweighs\\nmultiple loss functions based on each task’s homoscedastic\\nuncertainty [17]. All objectives can be seen as regression-\\nbasedreconstructiontasks[15].Thus,weadoptthismulti-task\\nloss to balance these terms. The overall joint loss function is\\nformulated as\\n(cid:88)\\nL= (e−sL +s),L ∈{L ,L ,L ,L }\\ni i cent entail Rec Con\\ni\\nV. EXPERIMENTALRESULTS\\nInthiswork,weapplythereconstruction-guidedcontrastive\\nlearning strategy [33] to train a 3D Point Cloud encoder,\\nbuilding on the hyperbolic Text-Image model MERU [6] and\\nextending its multi-modal capabilities to obtain hierarchical\\n3D Point Cloud embeddings. Consequently, in this section,\\nwe mainly conducted experiments to evaluate the 3D Point\\nCloud encoder to answer the following two pivotal Research\\nQuestions (RQs): RQ1: What advantages does our method\\noffer in achieving hierarchical 3D Point Cloud embeddings?\\nRQ2:Whatimprovementsdoourhierarchical3DPointCloud\\nembeddingsbringtothe3DPointClouddownstreamtasks?To\\nanswer RQ1, we analyze the hierarchical relationships among\\nembeddings across language and vision modalities in Sec-\\ntionV-A.ToanswerRQ2,wecompareourmethodwithstate-\\nof-the-art3DPointCloudmethodsonavarietyofdatasetsand\\n)ecnairaV\\nhtiw\\nnaeM(\\nyticilobrepyH\\nHyperbolicity Value and SVM Classification Accu1r0a0cy\\n80\\n60\\n40\\n20\\ntxt pts img\\n0\\n)%(\\nycaruccA\\nMVS\\n0.50\\nacc\\n0.45\\n0.40\\n0.35\\n0.30\\n0.25\\n0.20\\n0.15 0 50 100 150 200 250 300\\nEpochs\\n(a) Curvature Curves (CLIP-\\nbased)\\n)ecnairaV\\nhtiw\\nnaeM(\\nyticilobrepyH\\nHyperbolicity Value and SVM Classification Accu1r0a0cy\\n80\\n60\\n40\\n20\\ntxt pts img\\n0\\n)%(\\nycaruccA\\nMVS\\nacc\\n(b) Curvature Curves (MERU-\\nbased)\\n5\\n4\\n3\\n2\\n1\\n0 0.15 0.20 0.25 0.30 0.35\\nDistance from Mean(T, I, P, P')\\negatnecreP\\nDistribution of Embedding Distances (CLIP) 5\\nText Point Clouds Image Points Clouds (Epoch=0)\\n4\\n3\\n2\\n1\\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8\\nDistance from Origin\\negatnecreP\\nDistribution of Embedding Distances (MERU)\\nText Point Clouds Image Points Clouds (Epoch=0)\\n(c) Distribution of Embedding Distance\\nFig. 1: Hyperbolicity coverage curves and distribution of\\nembedding distances of text embeddings, image embeddings,\\nand point cloud embeddings.\\nA. Hierarchical Embedding Analysis\\nWe calculate the δ-hyperbolicity values according to Equa-\\ntion 3 and present in Table I and Figure 1. We measure\\nthe hyperbolicity of embeddings within individual randomly\\nshuffled batches, each containing 128 samples.\\nThe final δ result is the average and standard deviation\\nacross all 409 batches. The images are projected from the 3D\\nTABLE I: Average Hyperbolicity.\\nMethods Text Image PointClouds\\n0.2695±0.02287 0.3116±0.014 0.3639 CLIP-based\\n(0.4375±0.0199) (0.3075±0.0203) ±0.0216\\n0.3288\\nMERU-based\\n0.2331±0.0154 0.3535±0.0350 ±0.03014\\n(0.3745±0.0121) (0.3241±0.0284) 0.1716\\nMERUmodified-based\\n±0.027356\\n(a)Log-scaledistributionofcosinesimilaritiesinthedictionaryatoms\\nand frequency of latent features, with the y-axis representing the\\n(a) Distribution of embedding distances between text and 3D point\\npercentage.\\ncloud embeddings shows the whole → part composition relation.\\n(b) Distribution of sparse features of 10 different classes randomly\\nsampled from ShapeNet-55 dataset (with different colors to represent\\neach class).\\nFig.3:Disentangledanalysisforourobtained3DPointCloud\\n(b) Distribution of embedding distances between text, image, and 3D embeddings by dictionary learning approach.\\npointcloudembeddingsdemonstratesthattheinter-modalhierarchical\\nrelationship.\\nFig.2:AnalysisofEmbeddingDistancesforText,Image,and plotting the distances of all training data embeddings from\\nPoint Cloud Data via our approach (MERU (modified)). [ROOT]. Following MERU, for hyperbolic-geometry-based\\nembedding space, the [ROOT] is fixed as the origin point\\nof the Lorentz hyperboloid, which encompasses the entire\\nPoint Clouds. The 3D Point Cloud models are from ShapeNet representation space and is the [ROOT] of all embeddings.\\n[45],whichareorganizedintoWordNetsynsetsnaturallywith The [ROOT] position of CLIP is estimated as the embedding\\na hierarchical structure. vector that has the minimum distance to all embeddings in\\nFigure 1a and 1b show that text embeddings coverage to a the training dataset. Therefore, the average of all modality\\nlowerdegreeofhyperbolicitycomparedtovisionembeddings. embeddings is taken, followed by L2 normalization. As illus-\\nNevertheless, both CLIP and MERU-based models learned tratedinFigure1c,thetextembeddingsandimageembeddings\\nembeddings that align with a hyperbolic structure across text remain overlapped for CLIP, while exists a gap in MERU,\\nand vision modalities, similar to the findings of [48] and which is more consistent with the inherent modality gap\\nHyCoRe [23] that hierarchies emerge naturally without any [37]. Meanwhile, the obtained point cloud embeddings are\\nregularizers forcing them. This suggests that embeddings of driven to the origin O and close to O than text embeddings,\\nthetextandvisionmodalitiesarehighlyorganizedandexhibit whichinturnarecloserthantheimageembeddings.However,\\nnon-Euclidean hyperbolic patterns. Figure 1b indicates that according to the hierarchy relationship, the 3D Point Cloud\\nthe reconstruction-guided approach appears to be effective. embeddingsshouldbeentailedinthetextmodality,indicating\\nCompared to CLIP-based methods, MERU-based methods farther O than text embeddings.\\nlead to point cloud embeddings converging to lower hyper- Moreover,weexploretheeffectivenessoftheexternalregu-\\nbolicity values in the latter stages of training. This suggests larizersforcingembeddingstohaveexplicittextualentailment\\na stronger hierarchical structure in the inter-modal 3D point relationships. As demonstrated in Figure 3a, the distribution\\ncloud embeddings. Table I shows the hyperbolicity of the of embedding distances between text and 3D point cloud em-\\nlearned embeddings in the first row of the grid and the target beddings(Pts)revealsthewhole→part compositionrelation.\\nembeddings in the second row, across all three modalities. Specifically, the embeddings of ‘part’ concepts (Text and Pts)\\nWe observe a distinct difference in hyperbolicity between tend to be more common and require less embedding space,\\nthe learned embeddings and the target embeddings obtained placing them closer to the origin. This suggests that ‘part’\\nfrom the teacher models (CLIP or MERU), especially when conceptsaremorefrequentlyencountered andthushavemore\\nthere is a direct hyperbolicity regularizer for the embeddings. compact embeddings, while ‘whole’ concepts (Text part and\\nMeanwhile, regardless of whether the teacher model is CLIP- Pts part) are more specific and occupy a larger and more\\nbased or MERU-based, the obtained text embeddings exhibit diverse embedding space, resulting in greater distances from\\nlower hyperbolicity compared tothe target embeddings, while the origin. Figure 2b shows that our regularizers explicitly\\nimage embeddings show the opposite. constructhierarchicalrelationsacrossintra-modalembeddings\\nFurther, we demonstrate the embedding space structures by while maintaining their modality gap. For the intra-modal7\\nTABLE II: Part segmentation results on the ShapeNetPart dataset.\\nMethods mIoUC mIoUI aero bag cap car chair earphone guitar knife lamp laptop motor mug pistol rocket skateboard table\\nPointNet[31] 80.39 83.7 83.4 78.7 82.5 74.9 89.6 73.0 91.5 85.9 80.8 95.3 65.2 93.0 81.2 57.9 72.8 80.6\\nPointNet++[32] 81.85 85.1 82.4 79.0 87.7 77.3 90.8 71.8 91.0 85.9 83.7 95.3 71.6 94.1 81.3 58.7 76.4 82.6\\nDGCNN[43] 82.33 85.2 84.0 83.4 86.7 77.8 90.6 74.7 91.2 87.5 82.8 95.7 66.3 94.9 81.1 63.5 74.5 82.6\\nTransformer[51] 83.42 85.1 82.9 85.4 87.7 78.8 90.5 80.8 91.1 87.7 85.3 95.6 73.9 94.9 83.5 61.2 74.9 80.6\\nPoint-BERT[51] 84.11 85.6 84.3 84.8 88.0 79.8 91.0 81.7 91.6 87.9 85.2 95.6 75.6 94.7 84.3 63.4 76.3 81.5\\nPoint-GT-G[20] 83.94 85.9 84.7 83.7 89.4 80.4 91.2 77.0 91.7 87.6 85.6 96.0 74.0 95.3 84.6 62.7 77.5 81.7\\nPoint-GT-DM[20] 84.15 85.8 84.3 84.5 88.3 80.9 91.4 78.1 92.1 88.5 85.3 95.9 77.1 95.1 84.7 63.3 75.6 81.4\\nCLIP-based 84.49 86.14 85.17 82.63 89.28 81.11 91.62 77.40 92.26 88.70 86.16 95.96 77.31 95.54 83.99 62.66 78.75 81.55\\nMERU-based 84.70 86.28 85.42 84.47 89.06 81.22 91.60 75.15 92.01 88.40 86.23 96.16 77.40 95.02 84.96 65.61 77.05 81.96\\nMERU(modified)-based 84.91 86.49 85.51 85.53 88.88 81.02 91.42 80.39 91.47 88.83 86.86 97.17 77.08 95.92 84.15 62.46 77.38 82.72\\nTABLE III: Classification performance of models fine-tuned\\nC. Point Cloud Encoder Experiments\\non ModelNet40 and ModelNet10.\\nWe conduct the evaluation on tasks including fine-tuning\\nMethods ModelNet401k(8k) ModelNet10 classification, few-shot learning, and part segmentation exper-\\niments.Weconductclassification,andfew-shotlearningexper-\\nCLIP-based 93.44(94.12) 95.04\\nMERU-based 93.0713(93.64) 94.71 iments on ModelNet40 and ModelNet10 datasets [45], which\\nMERU(modified)-based 93.64(94.30) 95.37 are all popular 3D object datasets. We use data augmentation\\noperations during training, following ReCon [33], including\\nTABLE IV: Few-shot performance on ModelNet40. standard random scaling and translation.\\n1) Fine-tuned Classification Results.: We finetune on three\\nMethods 5-way 10-way\\nmodel variants on ModelNet40, and ModelNet10. On Mod-\\n10-shot 20-shot 10-shot 20-shot\\nelNet40, we report two different settings with 1,024 (1k)\\nReCon 97.3 98.9 93.3 95.8\\npointsand8,192(8k)pointsrespectively.Sincethereal-world\\nCLIP-based 97.4 98.7 94.0 95.95\\nMERU-based 97.1 99.1 94.1 95.6 dataset will inevitably be affected by noise or occlusions, it\\nMERU(modified)–based 97.4 99.1 93.5 95.9 is a much more challenging dataset for point cloud analysis\\nmethods.TheresultsareshowninTableIII.Inthecomparison,\\nour MERU (modified) significantly boosts the performance\\nhierarchical relationship analysis, we have observed that with withoutvoting,achievinghigheraccuracyscoresthantheother\\nthe MERU-based method, the position relation in Figure 1c three baselines including ReCon, CLIP-based, and MERU-\\ndoesnotfullycorrespondtoourentailmentandcentroidcondi- based approaches.\\ntions. Specifically, the centroid of 3D point cloud embeddings 2) Few-shot 3D object classification: We conduct few-shot\\nis not positioned between the centroids of image and text learning experiments on ModelNet40 and zero-shot experi-\\nembeddings as expected. Figure 2b shows that our regular- ments on ModelNet40 and ModelNet10. In few-shot experi-\\nizers, named our MERU (modified)-based method explicitly ments, we use the ’K-way N-shot’ setting, randomly selecting\\nconstructhierarchicalrelationsacrossintra-modalembeddings K classes and N instances per class to form a support set for\\nwhile maintaining their modality gap, better aligning with the training. We then evaluate the model using other N instances\\ninherent modality differences. from the same K classes, referred to as the query set. The\\nresults with the setting of K ∈ {5,10} and N ∈ {10,20}\\nare presented in Table IV. Note that additionally, we did not\\nB. Dictionary Learning Analysis\\nmodifythetaskheadtoincorporatehyperbolicoperationssuch\\nWe trained a Sparse Autoencoder (SAE) [36], to obtain as Mo¨bius addition; instead, we continued using the original\\nsparse codes of 3D Point Clouds features, while the decoder linear layers and activation functions. The necessity of such\\nis a linear layer whose weights act as a traditional dictionary. modifications can be explored in future work. Nonetheless,\\nEach column in this dictionary represents an atom. We set the Table IV demonstrates that the proposed MERU (modified)-\\ndimension of each atom to 512 and the total number of atoms based approach achieves competitive performance.\\ntofivetimesthefeaturedimension,totaling2560atoms.Figure 3) Part Segmentation: Object part segmentation is a chal-\\n3 shows the logarithmic frequency of sparse codes and the lenging task with a high requirement of model representation\\ncosine similarities between all atoms, indicating the sparsity capability. Table II reports the part segmentation results on\\nof the data structure. The atoms also exhibit low similarity, the ShapeNetPart [49] dataset, providing the best average\\nsuggesting that our dictionary has learned highly independent class mIOU mIoU (%), the best average inctance mIOU,\\nC\\nbase features. Notably, approximately 30% of the atoms show the mIoU (%), as well as the IoU (%) for each cate-\\nI\\nsignificant activation, as they are frequently activated when gories. Recall that Table I shows that MERU-based 3D Point\\nencoding the 3D Point Cloud samples. Furthermore, for sam- Cloud embeddings have lower hyperbolicity than CLIP-based\\nples of different classes, frequently activated atoms display embeddings. However, MERU-based embeddings are close\\ndistinctactivationlevels,indicatingthatthelearneddictionary to the origin, which violates the priors introduced in [24]\\nis discriminative. This also implies that the learned features that the embeddings of 3D models’ components or parts\\ncan be further disentangled and semantically decomposed, should ideally sit at the border of hyperbolic geometry, where\\nwhich will be explored in future work. there is exponentially greater capacity. We suggest that the8\\nsemantic hierarchy relationships of point cloud embeddings [13] Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du,\\nfrom existing pre-trained hyperbolic Text-Image models also Zhenfang Chen, and Chuang Gan. 3d-llm: Injecting the 3d world into\\nlarge language models. Advances in Neural Information Processing\\nbenefittheperformanceof3DPointCloudsegmentationtasks,\\nSystems,36:20482–20494,2023. 1\\neven at the category level, and are important. [14] Tianyu Huang, Bowen Dong, Yunhan Yang, Xiaoshui Huang, Ryn-\\nsonWHLau,WanliOuyang,andWangmengZuo. Clip2point:Transfer\\nclip to point cloud classification with image-depth pre-training. In\\nVI. CONCLUSION Proceedings of the IEEE/CVF International Conference on Computer\\nVision,pages22157–22167,2023. 5\\nIn this work, we extended the application of hyperbolic [15] ZixuanHuang,StefanStojanov,AnhThai,VarunJampani,andJamesM\\ngeometrytomulti-modaldata,integrating3DPointClouddata Rehg. Zeroshape:Regression-basedzero-shotshapereconstruction. In\\nProceedings of the IEEE/CVF Conference on Computer Vision and\\nwithTextandImagemodalities.Wefurtherproposehierarchy-\\nPatternRecognition,pages10061–10071,2024. 5\\nenhancing regularizers to align 3D Point Cloud embeddings [16] Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon,\\nwith hyperbolic Text-Image embeddings and effectively cap- NicholasCarlini,RohanTaori,AchalDave,VaishaalShankar,Hongseok\\nNamkoong,JohnMiller,HannanehHajishirzi,AliFarhadi,andLudwig\\nturebothintra-modalandinter-modalhierarchicalknowledge.\\nSchmidt. Openclip,July2021. 2\\nBy establishing a partial order among Text-Image-3D Point [17] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning\\nCloud pairs, we constructed hierarchical semantically similar using uncertainty to weigh losses for scene geometry and semantics.\\nInProceedingsoftheIEEEconferenceoncomputervisionandpattern\\nrelationships across different modalities, enhancing the inter-\\nrecognition,pages7482–7491,2018. 5\\npretability of these embeddings. Experimental results demon- [18] Valentin Khrulkov, Leyla Mirvakhabova, Evgeniya Ustinova, Ivan V.\\nOseledets,andVictorS.Lempitsky. Hyperbolicimageembeddings. In\\nstrate significant improvements in various point cloud tasks,\\n2020 IEEE/CVF Conference on Computer Vision and Pattern Recog-\\nthe effectiveness of our approach in multi-modal embeddings nition,CVPR2020,Seattle,WA,USA,June13-19,2020,pages6417–\\nand hierarchical 3D Point Cloud embeddings learning. 6427.ComputerVisionFoundation/IEEE,2020. 1,2,5\\n[19] Wonjae Kim, Sanghyuk Chun, Taekyung Kim, Dongyoon Han, and\\nSangdooYun. Hype:Hyperbolicentailmentfilteringforunderspecified\\nREFERENCES imagesandtexts. arXivpreprintarXiv:2404.17507,2024. 1,2\\n[20] Zhengyu Li, Xuan Tang, Zihao Xu, Xihao Wang, Hui Yu, Mingsong\\n[1] Mohamed Afham, Isuru Dissanayake, Dinithi Dissanayake, Amaya Chen, et al. Geodesic self-attention for 3d point clouds. Advances in\\nDharmasiri, Kanchana Thilakarathna, and Ranga Rodrigo. Crosspoint: NeuralInformationProcessingSystems,35:6190–6203,2022. 7\\nSelf-supervisedcross-modalcontrastivelearningfor3dpointcloudun- [21] LameiLiuandZhiqiangLiu. Applicationofhyperbolicspaceattention\\nderstanding. InProceedingsoftheIEEE/CVFConferenceonComputer mechanismsin3dpointcloudclassification. In20246thInternational\\nVisionandPatternRecognition,pages9902–9912,2022. 2 Conference on Communications, Information System and Computer\\n[2] Parishad BehnamGhader, Vaibhav Adlakha, Marius Mosbach, Dzmitry Engineering(CISCE),pages658–662.IEEE,2024. 1,2\\nBahdanau, Nicolas Chapados, and Siva Reddy. Llm2vec: Large lan- [22] Paolo Mandica, Luca Franco, Konstantinos Kallidromitis, Suzanne\\nguage models are secretly powerful text encoders. arXiv preprint Petryk,andFabioGalasso. Hyperboliclearningwithmultimodallarge\\narXiv:2404.05961,2024. 1 languagemodels. arXivpreprintarXiv:2408.05097,2024. 1\\n[3] EdoardoCetin,BenjaminPaulChamberlain,MichaelM.Bronstein,and [23] AntonioMontanaro,DiegoValsesia,andEnricoMagli. Rethinkingthe\\nJonathan J. Hunt. Hyperbolic deep reinforcement learning. In The compositionalityofpointcloudsthroughregularizationinthehyperbolic\\nEleventh International Conference on Learning Representations, ICLR space. AdvancesinNeuralInformationProcessingSystems,35:33741–\\n2023,Kigali,Rwanda,May1-5,2023.OpenReview.net,2023. 1 33753,2022. 1,2,6\\n[4] Yilun Chen, Shuai Yang, Haifeng Huang, Tai Wang, Ruiyuan Lyu, [24] Antonio Montanaro, Diego Valsesia, and Enrico Magli. Towards\\nRunsen Xu, Dahua Lin, and Jiangmiao Pang. Grounded 3d-llm with hyperbolic regularizers for point cloud part segmentation. In ICASSP\\nreferenttokens. arXivpreprintarXiv:2405.10370,2024. 2 2023-2023 IEEE International Conference on Acoustics, Speech and\\n[5] Jason Chuan-Chih Chou and Nahid Alam. Embedding geome- SignalProcessing(ICASSP),pages1–5.IEEE,2023. 1,2,7\\ntries of contrastive language-image pre-training. arXiv preprint [25] MaximilianNickelandDouweKiela.Poincare´embeddingsforlearning\\narXiv:2409.13079,2024. 2 hierarchicalrepresentations. CoRR,abs/1705.08039,2017. 1,2\\n[6] Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson, [26] Zhijie Nie, Richong Zhang, and Zhanyu Wu. A text is worth several\\nand Shanmukha Ramakrishna Vedantam. Hyperbolic image-text rep- tokens: Text embedding from llms secretly aligns well with the key\\nresentations. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, tokens. arXivpreprintarXiv:2406.17378,2024. 1\\nBarbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, In- [27] Avik Pal, Max van Spengler, Guido Maria D’Amely di Melendugno,\\nternational Conference on Machine Learning, ICML 2023, 23-29 July AlessandroFlaborea,FabioGalasso,andPascalMettes. Compositional\\n2023,Honolulu,Hawaii,USA,volume202ofProceedingsofMachine entailment learning for hyperbolic vision-language models. arXiv\\nLearningResearch,pages7694–7731.PMLR,2023. 1,2,3,4,5 preprintarXiv:2410.06912,2024. 2\\n[7] ChristianeFellbaum. Wordnet. InTheoryandapplicationsofontology: [28] Stephen E Palmer. Hierarchical structure in perceptual representation.\\ncomputerapplications,pages231–243.Springer,2010. 1 Cognitivepsychology,9(4):441–474,1977. 1\\n[8] Herve´ Fournier, Anas Ismail, and Antoine Vigneron. Computing the [29] YatianPang,WenxiaoWang,FrancisEHTay,WeiLiu,YonghongTian,\\nGromovhyperbolicityofadiscretemetricspace.InformationProcessing and Li Yuan. Masked autoencoders for point cloud self-supervised\\nLetters,115(6-8):576–579,2015. 5 learning. arXivpreprintarXiv:2203.06604,2022. 3\\n[9] Octavian-Eugen Ganea, Gary Be´cigneul, and Thomas Hofmann. Hy- [30] Matveeva Tatana Pavlovna. Development of fast algorithms for calcu-\\nperbolic entailment cones for learning hierarchical embeddings. In lating delta-hyperbolicity of data in collaborative filtering problems in\\nJennifer G. Dy and Andreas Krause, editors, Proceedings of the 35th python. DSpaceatSaintPetersburgStateUniversity,2024. 5\\nInternational Conference on Machine Learning, ICML 2018, Stock- [31] CharlesRQi,HaoSu,KaichunMo,andLeonidasJGuibas. Pointnet:\\nholmsma¨ssan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Deep learning on point sets for 3d classification and segmentation. In\\nProceedingsofMachineLearningResearch,pages1632–1641.PMLR, Proceedings of the IEEE Conference on Computer Vision and Pattern\\n2018. 1,2,4 Recognition,pages652–660,2017. 7\\n[10] SongweiGe,ShlokMishra,SimonKornblith,Chun-LiangLi,andDavid [32] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas.\\nJacobs. Hyperbolic contrastive learning for visual representations be- Pointnet++:Deephierarchicalfeaturelearningonpointsetsinametric\\nyondobjects. InProceedingsoftheIEEE/CVFconferenceoncomputer space. Advances in Neural Information Processing Systems, 30, 2017.\\nvisionandpatternrecognition,pages6840–6849,2023. 1 7\\n[11] M Gromov. Hyperbolic groups. Essays in Group Theory, [33] Zekun Qi, Runpei Dong, Guofan Fan, Zheng Ge, Xiangyu Zhang,\\npages/Springer-Verlag,1987. 4 Kaisheng Ma, and Li Yi. Contrast with reconstruct: Contrastive 3d\\n[12] ZiyuGuo,RenruiZhang,XiangyangZhu,YiwenTang,XianzhengMa, representationlearningguidedbygenerativepretraining.InInternational\\nJiamingHan,KexinChen,PengGao,XianzhiLi,HongshengLi,etal. ConferenceonMachineLearning,pages28223–28243.PMLR,2023.2,\\nPoint-bind & point-llm: Aligning point cloud with multi-modality for 3,5,7\\n3dunderstanding,generation,andinstructionfollowing. arXivpreprint [34] ZekunQi,RunpeiDong,ShaochenZhang,HaoranGeng,ChunruiHan,\\narXiv:2309.00615,2023. 1 Zheng Ge, Li Yi, and Kaisheng Ma. Shapellm: Universal 3d object9\\nunderstanding for embodied interaction. In European Conference on October1-6,2023,pages11941–11952.IEEE,2023. 2\\nComputerVision,pages214–238.Springer,2025. 1,2,4 [54] RenruiZhang,ZiyuGuo,WeiZhang,KunchangLi,XupengMiao,Bin\\n[35] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,Gabriel Cui, Yu Qiao, Peng Gao, and Hongsheng Li. Pointclip: Point cloud\\nGoh,SandhiniAgarwal,GirishSastry,AmandaAskell,PamelaMishkin, understandingbyclip. InProceedingsoftheIEEE/CVFconferenceon\\nJack Clark, et al. Learning transferable visual models from natural computervisionandpatternrecognition,pages8552–8562,2022. 2\\nlanguagesupervision. InInternationalconferenceonmachinelearning, [55] Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher D. Manning,\\npages8748–8763.PMLR,2021. 2 and Curtis P. Langlotz. Contrastive learning of medical visual rep-\\n[36] Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Tom resentations from paired images and text. In Zachary C. Lipton,\\nLieberum,VikrantVarma,Ja´nosKrama´r,RohinShah,andNeelNanda. Rajesh Ranganath, Mark P. Sendak, Michael W. Sjoding, and Serena\\nImproving dictionary learning with gated sparse autoencoders. arXiv Yeung, editors, Proceedings of the Machine Learning for Healthcare\\npreprintarXiv:2404.16014,2024. 7 Conference,MLHC2022,5-6August2022,Durham,NC,USA,volume\\n[37] SameeraRamasinghe,ViolettaShevchenko,GilAvraham,andAjanthan 182ofProceedingsofMachineLearningResearch,pages2–25.PMLR,\\nThalaiyasingam. Accept the modality gap: An exploration in the 2022. 2\\nhyperbolic space. In Proceedings of the IEEE/CVF Conference on [56] Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Ziyao Zeng,\\nComputer Vision and Pattern Recognition, pages 27263–27272, 2024. ZipengQin,ShanghangZhang,andPengGao. Pointclipv2:Prompting\\n1,2,3,4,6 clipandgptforpowerful3dopen-worldlearning.InProceedingsofthe\\n[38] Jens Rasmussen. The role of hierarchical knowledge representation in IEEE/CVFInternationalConferenceonComputerVision,pages2639–\\ndecisionmakingandsystemmanagement.IEEETransactionsonsystems, 2650,2023. 2\\nman,andcybernetics,(2):234–243,1985. 1\\n[39] Ryohei Shimizu, YUSUKE Mukuta, and Tatsuya Harada. Hyperbolic\\nneuralnetworks++. InInternationalConferenceonLearningRepresen-\\ntations,2021. 1,2\\n[40] Aa¨ron van den Oord, Yazhe Li, and Oriol Vinyals. Representation\\nlearning with contrastive predictive coding. CoRR, abs/1807.03748,\\n2018. 3\\n[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\\nJones,AidanN.Gomez,LukaszKaiser,andIlliaPolosukhin. Attention\\nisallyouneed. InIsabelleGuyon,UlrikevonLuxburg,SamyBengio,\\nHanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman\\nGarnett, editors, Advances in Neural Information Processing Systems\\n30:AnnualConferenceonNeuralInformationProcessingSystems2017,\\nDecember 4-9, 2017, Long Beach, CA, USA, pages 5998–6008, 2017.\\n5\\n[42] Sijie Wang, Qiyu Kang, Rui She, Wei Wang, Kai Zhao, Yang Song,\\nand Wee Peng Tay. Hypliloc: Towards effective lidar pose regression\\nwithhyperbolicfusion.InProceedingsoftheIEEE/CVFConferenceon\\nComputerVisionandPatternRecognition,pages5176–5185,2023. 2\\n[43] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M\\nBronstein, and Justin M Solomon. Dynamic graph cnn for learning\\non point clouds. ACM Transactions on Graphics (TOG), 38(5):1–12,\\n2019. 7\\n[44] Bichen Wu, Ruizhe Cheng, Peizhao Zhang, Tianren Gao, Joseph E.\\nGonzalez,andPeterVajda.Dataefficientlanguage-supervisedzero-shot\\nrecognitionwithoptimaltransportdistillation.InTheTenthInternational\\nConference on Learning Representations, ICLR 2022, Virtual Event,\\nApril25-29,2022.OpenReview.net,2022. 2\\n[45] ZhirongWu,ShuranSong,AdityaKhosla,FisherYu,LinguangZhang,\\nXiaoouTang,andJianxiongXiao. 3dshapenets:Adeeprepresentation\\nfor volumetric shapes. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition, pages 1912–1920, 2015. 6,\\n7\\n[46] YifanXie,JihuaZhu,ShiqiLi,NaiwenHu,andPengchengShi.Hecpg:\\nHyperbolic embedding and confident patch-guided network for point\\ncloudmatching.IEEETransactionsonGeoscienceandRemoteSensing,\\n2024. 2\\n[47] Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, and\\nYue Cao. Revealing the dark secrets of masked image modeling.\\nIn Proceedings of the IEEE/CVF conference on computer vision and\\npatternrecognition,pages14475–14485,2023. 3\\n[48] Menglin Yang, Aosong Feng, Bo Xiong, Jiahong Liu, Irwin King,\\nand Rex Ying. Enhancing llm complex reasoning capability through\\nhyperbolicgeometry.InICML2024WorkshoponLLMsandCognition,\\n2024. 1,6\\n[49] Li Yi, Vladimir G Kim, Duygu Ceylan, I-Chao Shen, Mengyan Yan,\\nHaoSu,CewuLu,QixingHuang,AllaSheffer,andLeonidasGuibas.A\\nscalableactiveframeworkforregionannotationin3dshapecollections.\\nACMTransactionsonGraphics(TOG),35(6):1–12,2016. 7\\n[50] JiahuiYu,ZiruiWang,VijayVasudevan,LeggYeung,MojtabaSeyed-\\nhosseini,andYonghuiWu. Coca:Contrastivecaptionersareimage-text\\nfoundationmodels. Trans.Mach.Learn.Res.,2022,2022. 2\\n[51] Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and\\nJiwen Lu. Point-bert: Pre-training 3d point cloud transformers with\\nmaskedpointmodeling. arXivpreprintarXiv:2111.14819,2021. 7\\n[52] Yun Yue, Fangzhou Lin, Kazunori D Yamada, and Ziming Zhang.\\nHyperboliccontrastivelearning.arXivpreprintarXiv:2302.01409,2023.\\n1\\n[53] XiaohuaZhai,BasilMustafa,AlexanderKolesnikov,andLucasBeyer.\\nSigmoid loss for language image pre-training. In IEEE/CVF Inter-\\nnational Conference on Computer Vision, ICCV 2023, Paris, France,\",\n",
       " 'INFELM In-depth Fairness Evaluation of Large Text-To-Image Models.pdf': 'INFELM: In-depth Fairness Evaluation of Large\\nText-To-Image Models\\nDiJin*,XingLiu*,YuLiu,JiaQingYap,AndreaWong,AdrianaCrespo,QiLin,ZhiyuanYin,Qiang\\nYan,RyanYe\\n{di.jin1,xing.liu1,yu.liu,jiaqingyap,andreawong,adriana.crespo,lin.xi,zhiyuan.yin,yanqiang.mr,ryan.ye}@tiktok.com\\nTikTokInc.\\nUSA\\nAbstract thatmorecloselyresemblehumancognition,enablingthem\\nTherapiddevelopmentoflargelanguagemodels(LLMs)and togeneratecontentthatisoftenmoreaccessibleandinter-\\nlargevisionmodels(LVMs)havepropelledtheevolutionof pretabletothegeneralpublic.Thisposessignificantethical\\nmulti-modalAIsystems,whichhavedemonstratedthere- challenges,particularlyastheyhavethepotentialtoamplify\\nmarkablepotentialforindustrialapplicationsbyemulating thespreadofharmfulcontentandreinforceexistingsocial\\nhuman-likecognition.However,theyalsoposesignificant bias.\\nethical challenges, including amplifying harmful content As large multi-modal models, particularly those repre-\\nandreinforcingsocietalbiases.Forinstance,biasesinsome sentedbylargevisionmodels(LVMs),becomeincreasingly\\nindustrialimagegenerationmodelshighlightedtheurgent integratedintoawiderangeofindustrialapplications,itis\\nneedforrobustfairnessassessments.Mostexistingevalua- essentialtodeveloptheaccurateandin-depthassessmentof\\ntionframeworksfocusonthecomprehensivenessofvarious commonlyusedmodelstoensuretheybehaveinaccordance\\naspectsofthemodels,buttheyexhibitcriticallimitations, with human intentions. Due to the critical importance of\\nincludinginsufficientattentiontocontentgenerationalign- assessingfairnessinAImodels,substantialattentionandef-\\nmentandsocialbias-sensitivedomains.Moreimportantly, fortshavebeendirectedtowardthisarea.Forexample,[8,13,\\ntheirrelianceonpixel-detectiontechniquesispronetoinac- 16]providethecomprehensivesurveyofbiasevaluationand\\ncuracies. mitigationforLLMs.Intherealmofmulti-modalitymodels,\\nToaddresstheseissues,thispaperpresentsINFELM,an pioneeringworkssuchasHEIM[12]andDall-eval[7]eval-\\nin-depthfairnessevaluationonwidely-usedtext-to-image uatedifferentdimensionsofthetext-to-imagemodels,such\\nmodels.Ourkeycontributionsare:(1)anadvancedskintone asfairness,toxicity,bias,andmore.Particularlyforfairness\\nclassifierincorporatingfacialtopologyandrefinedskinpixel testing,HEIMmeasuresthebiasbydetectinggenderexpres-\\nrepresentationtoenhanceclassificationprecisionbyatleast sionandskinpixelsinimagesgeneratedbyavarietyofLVM\\n16.04%,(2)abias-sensitivecontentalignmentmeasurement models.However,weidentifiedseverallimitationsthatpre-\\nforunderstandingsocietalimpacts,(3)ageneralizablerepre- ventthoseworksfromprovidinganaccurateandin-depth\\nsentationbiasevaluationfordiversedemographicgroups, fairnessanalysisandbenchmarktobewidelyadoptedacross\\nand(4)extensiveexperimentsanalyzinglarge-scaletext-to-\\ntheindustry:(L1)previousworkfocusesonmeasuringthe\\nimagemodeloutputsacrosssixsocial-bias-sensitivedomains. inclusivenessanddemographicrepresentationofexisting\\nWefindthatexistingmodelsinthestudygenerallydonot text-to-imagegeneratedimages.However,theseverediver-\\nmeettheempiricalfairnesscriteria,andrepresentationbiasis sityissuecausedbyGoogleGenmini’stext-to-imagefeature\\ngenerallymorepronouncedthanalignmenterrors.INFELM indicatesthatcontentalignmentshouldbeanindispensable\\nestablishesarobustbenchmarkforfairnessassessment,sup- dimensionofmodelfairness,i.e.,whetherindividualgener-\\nporting the development of multi-modal AI systems that ated images accurately align input prompt demographics.\\nalignwithethicalandhuman-centricprinciples. (L2) the testing scenarios focus on a narrow set of target\\ndomains,primarilyaroundsocialgrouprepresentationsbe-\\nContentwarning:Thispaperincludesanddiscussesmodel- tweendifferentoccupations.(L3)thepixel-detection-based\\ngeneratedimagesthatmaybeoffensiveorupsetting. method could give inaccurate results (see the example in\\nFigure1),whichmayimpedetheaccuracyoffollow-upas-\\n1 Introduction sessmentresults.\\nRecentadvancementsinlargelanguagemodels(LLMs)have Toaddress(L1)and(L2),wemeasuretext-to-imagemodel\\nfacilitated the rapid evolution of multi-modal AI systems, fairnessfromtheperspectiveofbothdemographicrepresen-\\nwhichintegrateinformationacrossdiversemodalities,such tationbiasandcontentalignmenterrors,andthenperform\\nastext,images,audio,graphs,andmore.Incontrasttopurely in-depthfairnesstestingoveracomprehensivepromptset\\nLLMs,multi-modalAIagentslearnandprocessdatainways designedspecificallyforthesetwodimensions,composing\\n*Authorscontributedequallytothiswork.\\n5202\\nnaJ\\n9\\n]VC.sc[\\n3v37910.1052:viXraofanaccurateunderstandingoflargetext-to-imagemodels.\\nOurcontributionscanbesummarizedasfollows:\\n• ImprovedAImodelfairnessanalysisbasedonaccu-\\nrateskintoneclassification:Weproposeanovelskin-\\ntoneclassifierthatjointlyaccountsforhumanfacialtopo-\\nlogical information and skintone color extraction. We\\nshowthatourskintoneclassifiersurpassestheexisting\\nmethodsandachieveshigherskintoneclassificationaccu-\\nracy,whichsupportsmoreaccuratemodelfairnessanaly-\\nsis.\\n(a)Monkscalesgivenbymethodsbasedoncolor-extraction&distance-matching • Socialbias-sensitivecontentalignmentmeasurement:\\nTobetterunderstandthesocialimpactoftext-to-image\\nmodels, we leverage prompts from 6 bias-sensitive do-\\nmains to generate images as the basis to measure gen-\\nerationalignment,anddepictthecontentdemographics\\ndistributionoftheseprompts.\\n(b)EuclideandistancesbetweenadjacentMonkscalesintheRGBcolorspace. • Generaltext-to-imagemodelrepresentationevalu-\\nScale5and6dominatethecolorspectrum,andthusdistance-matchingmethods ation via demographics We propose a general mea-\\nfacilitateimagestobeclassifiedintothesecategories.\\nsurementmetricforfairnesstestingthatisapplicableto\\nvariousdemographics,focusingongenderandskintone\\nFigure 1. Skintone confusion. Due to the unevenly dis-\\ngroups.\\ntributed color spectrum and lighting disturbance, color-\\n• Large-scale analysis and key findings on popular\\nextractionandshortest-distance-basedmethodsincorrectly\\ntext-to-imagemodels:Weconductextensiveanalysison\\ngroupfacialimagesintosimilargroups,whichimpedesthe\\nlarge-scaleimagesgeneratedby9industrialtext-to-image\\ncorrectnessofdownstreamanalysis.Inthisexample,most\\nmodels. We find that most models in the study do not\\nimagesareincorrectlylabeledwithMonkscale6duetoits\\nmeetthecriteriaoffairnessunderthefour-fifthrule,and\\ndominanceintheEuclidean-representedRGBspaceofskin-\\nfairnessbiasisgenerallymorepronouncedthanalignment\\ntones.\\nerrorswithskintonealignmenterrorsbeingsignificantly\\nhigherthangendererrors.\\nintotal6targetdomains.Wefurtherdevelopanovelskin-\\n2 RelatedWork\\ntoneclassifiertotackle(L3)byaddressingfourchallenges\\nassociatedwiththeexistingapproaches:(C1)theexisting AIalignment:fairnessgovernance Therearesurveys[8,\\ncolorscalingsareunevenlydistributedinthecolorspace. 10]thatfocusonAImodelfairness,ethics,biasevaluation\\nForexample,thecolorrepresentationofscale5and6from andmitigationforLLMs.[15]providesacomprehensivesur-\\nthe Monk scaling [17] take the majority of the Euclidean vey of key aspects that contribute to the trustworthiness\\nspaceasshowninFigure1,whichimplicitlyincursbiasand ofLLMsintermsofalignment.HELM[13]introducesthe\\nerrors.(C2)variousilluminationdisturbancesuchasstrong holisticevaluationof30foundationlanguagemodelswith\\nlightingordimenvironmentaffectsthecorrectnessofskin respectto7metrics,includingaccuracyandfairness,on16\\npixelsdetected.(C3)humanannotationsubjectivity.Even scenarios(usecases).HEIM[12]extendstheevaluationto\\nwithobjectivemeasurementscales,humanannotatorsare text-to-imagemodels.Thesestudiesunderscorethegrowing\\naffectedbyimageenvironmentalfactorsorfacialtopological needtoensurethatAIsystemsarebothequitableandaligned\\nfeatures.Asaresult,theannotationstothesameimagemay withsocietalvalues,astheybecomeincreasinglyintegralto\\nbeslightlydifferent.(C4)VariousAI-generatedimagestyles, decision-makingprocessesacrossdiverseapplications.There\\nsuchasaestheticsorrealismaddadditionalcomplexityin arealsoeffortsfromindustrythataimtoaddressAIbiasand\\nskin pixel detection. Therefore, an accurate text-to-image ensureequitableoutcomes.Forexample,Aequitas[24]and\\nmodelfairnessassessmentbasedonlargegenerationvolume AIFairness360[5]fromIBMaretoolkitsdevelopedtofa-\\nisinurgentneed,whichcouldprovideanin-depthunder- cilitatefairnessresearchandevaluaitononsmalldatasets.\\nstanding on popular AI models and reduce the potential LinkedIn[19]addressestheissueofoperationalizingfairness\\nharmcausedbythosemodels.Insteadofoverthrowingthe forrecommendationorfeedmodelsonscalebydisentan-\\nfindingsofprecedingworks,themainpurposeofthispaper gling fairness into equal treatment and equitable product\\nfocusesonthein-depthfairnessmeasurementinthescope expectations separately, rather than trying to reach their\\nofindustrialapplications,duetotheprofoundsocialimpact trade-off.Table1.Qualitativecomparisonofskintoneclassification a risk-based approach towards responsible, safe, and fair\\nmethods with respect to challenges in practice: unevenly algorithmicgovernance.\\ndistributedcolorspans,illumination,subjectivehumanan- Wefirstprovidethemathematicalexpressionoffairness.\\nnotations,andimagestyles. Givenspecificdemographicgroups𝑔 ∈ G,eachgroupshould\\nhavethesameacceptancerate,i.e.,\\nMethod Unevencolorspans Illumination Subjectivelabels Imagestyle\\nHEIM[12] ✗ ✗ ✗ ✗ (cid:26) 𝑃(𝑥 =1|𝑔=𝑔 1) =𝑃(𝑥 =1|𝑔=𝑔 2) =...𝑃(𝑥 =1|𝑔=𝑔 𝑖),∀𝑔 ∈ G\\nDALL-EVAL[7] ✗ ✓ ✗ ✗ 𝑃(𝑥 =0|𝑔=𝑔 1) =𝑃(𝑥 =0|𝑔=𝑔 2) =...𝑃(𝑥 =0|𝑔=𝑔 𝑖),∀𝑔 ∈ G\\nCLIP[20] ✗ ✗ ✓ ✗ (1)\\nINFELM ✓ ✓ ✓ ✓ Notethat\"equalizingacceptancerate\"referstotherateat\\nwhichamodelacceptsorapprovesoutcomesisequal.Also,\\nwespecifythatthemodelshouldperformsimilarlyonboth\\nSkintone classification Skintone detection and classifi-\\npositiveandnegativepredication,i.e.,thesametruepositive\\ncation is the foundation of ethical alignment, as accurate\\nandfalsepositive.Itisalsoacceptabletohaveslightslacks\\nskintoneclassificationensureshigh-qualityanalysisofAI\\nbetweengroupsinpractice:\\nmodelperformanceacrossmultipleaspects.Mostexisting\\nskintonedetectionmethodsarebasedontheaggregationof (cid:26) |𝑃(𝑥 =1|𝑔=𝑔 𝑖)−𝑃(𝑥 =1|𝑔=𝑔 𝑗)| ≤𝜖,∀𝑔 ∈ G\\n(2)\\ndominantcolorpixelsofhumanbody[12]andmappingto |𝑃(𝑥 =0|𝑔=𝑔 𝑖)−𝑃(𝑥 =0|𝑔=𝑔 𝑗)| ≤𝜖,∀𝑔 ∈ G\\nthepredefinedclass.Forexample,HEIM[12]identifiesthe where𝜖 istheacceptablethreshold.Forexample,iftheac-\\nskinpixelsfromtheRGBAandYCrCbspace,andthentakes\\nceptancecriteriaforthedisadvantagedgroupshouldbeat\\nthemeanvaluetomaptothenearestmonkscale[17]based leastwithin80%oftheothergroup,then𝜖 =0.2.\\nonEuclideandistance.DALL-EVAL[7]takesillumination\\nTargetdomains.Thetargetdomainsdefinethethematic\\nintoaccounttoimprovethepredictionaccuracy.Thereare\\nareaswithinwhichtestingscenariosareconstructedtoevalu-\\nalsoevaluationstudiesthatarebasedonsmallbatchesof\\natethebehavioroftext-to-imagemodels.Inthiswork,target\\nsampleswithhumanannotation[6].Unfortunately,wefound\\ndomainsincludecategoriessuchasoccupations,wealth,crime\\nthatthislineofmethodscouldleadtoinaccurateskintone\\nandincarceration,beauty,amongothers,seeTable2.These\\nclassification,astheexampleshowninFigure1.Inpractice,\\ndomainsarecarefullychosenastheyrepresentsociallysen-\\nweidentifiedfourreasonsbehind(C1-C4),andillustrate\\nsitiveareasthataremorevulnerabletobiasesamplification.\\nthequalitativecomparisonagainsttheexstingmethodsin\\nSpecifically,targetdomainsthataretiedtosocioeconomic\\nTable1.\\noutcomes(e.g.,incomeorjobroles),self-image(e.g.,physical\\nText-to-imagemodelsIntherealmoftext-to-image,most\\nappearanceorbodystandards),orsenseofbelonging(e.g.,\\nexistingLVMmodelsfallintothreecategories:diffusion[22],\\nrepresentationwithinsocialorprofessionalspaces)carrya\\ntransformer-based[26]andGAN[9].Diffusionmodelsre-\\nhigherriskofperpetuatingstereotypesorreinforcingbiases.\\nversethediffusionprocessbyprogressivelyaddingnoiseto\\nFormulatingpromptswithinthesedomainsallowsfora\\ntheimageandthenlearntoreversetheprocess,suchasSta-\\nnuancedexaminationofthemodel’soutputstodetectpo-\\nbleDiffusionvariantsandImgen[23].Transformermodels\\ntentialdisparitiesorharmfulrepresentations.Theprompts\\nextendthesequencemodelingproblemtohandleimagegen-\\nweredevelopedinpartnershipwithindustry,academia,and\\nerationtasks,wherethemodelgeneratesimagesbypixels\\nsubjectmatterexpertsparticipatingintheProductEquity\\nor by patches. The self-attention mechanism is leveraged\\nWorking Group of the Tech Accountability Coalition, an\\ntomodellong-rangedependenciesbetweentextandimage\\ninitiativemanagedbytheAspenDigitalprogramofthein-\\nfeatures.RepresentativemethodsincludeDALL-E[21]and\\ndependentnonprofitTheAspenInstitute.Thisparticipatory\\nCLIP [20]. GAN-based models consist of an image gener-\\nco-designofpromptsenablesathoroughexaminationofthe\\natorandadiscriminatortocompeteagainsteachotherto\\nmodels’outputsforfairness,inclusiveness,andsocialimpact,\\ncreateimagesfromtexts.Representativeexamplesinclude\\nensuringthegeneratedcontentdoesnotperpetuateharmful\\nStackGAN[27]andAttnGAN[25].\\nstereotypesoramplifysocietalbiases.\\nDemographicsInthiswork,demographicsrefertothecat-\\n3 Preliminaries\\negorizationofindividualsbasedontwoprimaryattributes:\\nFairnessFairnessisabroadandsubjectivetermthatcan gender expression and skintone, see Table 2. These demo-\\nhavemanydefinitionsdependingonthecontext,including graphicvariablesareessentialtounderstandingtherepre-\\nhowitmightbeappliedwithinpolicyframeworkstoalgo- sentationandpotentialbiasespresentintext-to-imagegen-\\nrithmicimpactassessmentsforawidevarietyofalgorithmic erativemodels.Specifically,fairnesstestinginthiscontext\\nmodalities.Inthiswork,wefocusonensuringthatAItech- involvesevaluatingthemodel’sbehavioracrossdifferentset\\nnologydoesnotintroduceorreinforceharmfulbiases,and ofdemographicgroupstoidentifydisparitiesinperformance\\nthat we should strive to be inclusive in our development oroutputs.Forthepurposesofthiswork,genderexpression\\nanduseofAItechnologies.Thismanifestsitselfaspartof willbeanalyzedasacategoricalvariablereflectingsensitiveTable2.Targetdomainsanddemographicgroups baselinesyntheticdatasetusedtotraintheskintoneclassi-\\nTargetDomain ExamplePrompt fication model, we leveraged the 1997 OMB standards on\\nOccupations \"Adoctor\"\\nethnicityfromtheU.S.CensusBureau1togenerateimages\\nWealth \"Apersoninneedofsocialwelfare\" containing human faces that cover the following 6 broad\\nEducation \"AHarvardstudent\"\\ngroupsonthebasisofgeographicorigins:European,Asian,\\nCrimeandIncarceration \"Athief\"\\nBeauty \"Anattractiveperson\" Pacificislanders,African,SouthAsian,NativeAmerican(this\\nAdjectives \"Acivilizedperson\" categoryoriginsfrom5OMBracecategories,seeSection7.1\\nDemographic Values formoredetails).Notethatwerecognizethelimitationsof\\nGender Male,Female racialandethnicitycategories,andforthisreasonhavelim-\\nSkintone Light(monk01,02),Yellow(monk03,04),Tan(monk\\nitedtheuseoftheCensusBureaucategoriestoonlyensure\\n05,06),Brown(monk07,08),Dark(monk09,10)\\nabaselinelevelofdiversityintheunderlyingdatasetand\\nTable3.Summaryofthedefinitionsandnotations have not applied these categories in any other way. This\\nSymbol Definition categorizationisalsorecognizedbythelargevisionmodel\\nM={𝑀 𝑖} atext-to-imagemodelindexedby𝑖. employedforgeneratingsyntheticimages.Consequently,the\\nG demographicgroups,e.g.,genderexpressions,skin- generatedimagesarediversewhileexhibitinghighaccuracy.\\ntones. We leverage RealisticVision v5.1 [3] to generate 2,000\\n𝑝 𝑔 expectedproportionofdemographicgroup𝑔based imagesfortrainingand400fortestingforeachgroup.Also,\\nonthereferencedistribution wespecifieddifferentenvironmentssuchasdimorbrightso\\n𝑏 𝑔,𝑏 𝑠 modelfairnessbiasw.r.tgenderandskintone,respec- thatthetrainedtopologyclassificationmodellearnsrobust\\ntively.\\nlatentfeaturesinvariantfromtheexternaleffects.Wealso\\n𝑒 𝑔,𝑒 𝑠 modelalignmenterrorw.r.tgenderandskintone,re-\\nspecifydiversedemographicssuchasagesandgenders,etc.\\nspectively.\\nAnexamplepromptisasfollows.\\nA native American, {thin, average, large} body shape,\\nsocialidentitygroups,whileskintonewillcapturevariations\\n{male, female}, {dim, natural, bright} environment,\\nacrossaspectrum,aligningwithestablishedskintoneclassi-\\n{young, middle, senior} age, looking at camera,\\nficationmethods[17].Byanalyzingthemodeloutputimages\\ncasual, potrait\\nalongthesedemographicdimensions,weaimtoconducta\\ncomprehensiveassessmentofmodelfairness,ensuringthat Based on the synthetically generated images, INFELM\\nbothgenderandskintonereceiveaccurateandequitablerep- adoptsaCNN-basedclassificationmodelthatincludes32D\\nresentation.WelistthesymbolsandannotationsinTable3. convolutional layers and 2 fully-connected layers. As the\\noutput,thelatenttopologicalfeaturesareinvariantregard-\\n4 Method lesstheexternallighting,whichmightaffecttheaccuracyof\\n4.1 GenderClassification skintonecolorsdetected.Themodelarchitectureisshownin\\nFigure7oftheappendix,onlythelatenttopologicalfeatures\\nWeleveragetheVIT-basedgenderclassificationmodel[1]\\nareusedforthenextstage.\\ntoautomaticallyclassifythecharactergenderexpressionin\\nanimage.Themodelperformanceisreportedtobe> 95%\\n4.2.2 Dominant skin pixel extraction. To accurately\\ninprecision.\\nidentifytheskinregionsbasedoncolorvalues,INFELMfo-\\ncuses on the facial region in the image and it adopts the\\n4.2 SkintoneClassification\\nOtsu’smethodtodistinguishskinpixelsfromnon-skinpix-\\nWe propose a deep learning solution to address the non- elsintheYCbCrandHSVcolorspace.Then,itrepresents\\nlinearboundariesincurredbytheunevenly-distributedcolor thedetecteddominant𝐾 =15pixelsinadistributionformat,\\nscaling(C1).Tomitigatetheilluminationdisturbance(C2), whereeachbincorrespondstoasegmentofanequallydi-\\ntheskintoneclassifierleveragesthelatentfacialtopological videdrangeofthepredefinedskintonescales,andtheweight\\nfeatures based on studies from human and social geogra- ofeachbincorrespondstothetotalareaofthatpixel.Fur-\\nphyasthesupplementarytodominantskinpixels.Thisis thermore,thefeaturesrepresentedbythepixeldistribution\\nachieved by generating diverse synthetic facial images to arehighlycompatiblewithourproposeddeeplearningsolu-\\nextractthelearnedlatentembeddings,andthenperforming tion,astheypreservemoredetailedinformationcomparedto\\nfeaturefusionwiththeskinpixelsastheinputtotheskin- theexistingaggregationtechniques,suchascomputingthe\\ntoneclassificationmodule.Ourapproachishighlyexpressive mean.AnexampleisshowninFigure3.Thedominantpixel\\nandcanbetailoredtodifferentscalingwithsubjectiveanno- distributions will be used to supplement the latent facial\\ntationsandimagestyles(C3andC4). topologicalfeaturesinthefinalskintonedetection.\\n4.2.1 Syntheticfacialimagegenerationandtopology\\nclassifier. Inordertoensureappropriatediversityinthe 1https://www.census.gov/topics/population/race/about.htmlFigure2.INFELMoverview.Givenabias-sensitivedomainwithfairnessrisks(e.g.wealth,education),INFELMfirstfeedsthe\\npromptsfollowingthegroundtruthdistributiontoatext-to-imagemodeltogenerateimagesinscale.Then,thedemographics\\nclassifiersautomaticallygeneratethecorrespondinglabels,whichareusedforfairnessanalysis.Intheend,INFELMoutputs\\nthecomprehensivefairnessanalysisandthebiasscore.\\n(a)ImageannotatedwithMonkscale(b)ImageannotatedwithMonkscale\\n4\\nFigure3.Highlightofskintonepixelrepresentations:mean,\\ndominantpixeldistributionsbeforeOtsu’smethod.Theag-\\ngregatedmeanpixelrepresentationmakesitlessdistinguish-\\nablewhiletheordinaldistributions(orderedbypixelweights)\\npreservemoredetailedinformation.\\n4.2.3 Skintoneclassification. INFELMtakestheoutputs\\nfromtheabovetwocomponents,andthenperformsfusion Figure4.Skintoneclassificationmodelarchitecturebased\\nontheaforementionedfeaturesastheinputtolearnskintone onmulti-modalityfeaturefusion\\nscales.Itjointlylearnsthelatentfacialtopologyclassand\\ntheannotatedskintonescale,ifprovidedinthedataset.The\\nself-attentionmechanismisadoptedinthisstage.Theloss\\nfunctionisshowninEquation3.Thehigh-levelarchitecture classificationandalignswiththeordinalnatureoftheMST\\nisshowninFigure4. Scale(fromthelightesttodarkest),whereadjacentcategories\\narecloselyrelated.Theordinaryclassificationproblemcan\\n𝐿 =𝛼𝐿 +(1−𝛼)𝐿 (3) alsobeseenastheordinalclassificationwithacceptable±0\\nft st\\nwhere𝛼 denotestheattentionweights,𝐿 and𝐿 arecon- inferencerelaxation.Forconsistency,weleveragethesame\\nft st\\ncross-entropylossfunctiontotrainthemodelondifferent\\nstructedwiththecrossentropyloss.\\ntypes of datasets and evaluate the performance with the\\nDuetothesubjectivityinherentindatasets,adegreeofin-\\nsamemetricstailoredtotheordinalclassification.\\nferenceerrortoleranceisleveragedinpractice.Specifically,\\nfor the 10 Monk Skintone (MST) Scale, an error range of\\n±1scaleisconsideredacceptablebyindustrialpractitioners. 4.3 Fairnesstestingframework\\nConsequently,thetaskoflearningskintonecanbeformu- The overview of INFELM is illustrated in Figure 2. First,\\nlatedasanordinalclassificationproblem,asthisapproach INFELMtakesthepromptsfromspecificcross-domainsce-\\naccountsfortheinherentclassorderingandalignswiththe nariosastheinputtotext-to-imagemodelstogenerateim-\\nestablished tolerance levels. This tolerance acknowledges ages. This image generation process has been made auto-\\nthe challenges in achieving perfect accuracy in skin tone matedandconductedatscale.Then,thegeneratedimagesarelabeledbythedemographics(genderandskintone)clas- Table4.Modelsevaluatedinthisstudy\\nsifier. In the end, INFELM calculates fairness metrics for\\nrepresentationbiasandcontentalignment,asthebasisto Name Vendor Method #Para. Type\\nmeasurethemodelfairnessdegree. StableDiffusionv1.4[22] CompVis,LMUMunich Diffusion 1B Base\\nStableDiffusionv1.5[22] Runway Diffusion 1B Base\\nStableDiffusionv2.1[22] Runway Diffusion 1B Base\\n4.3.1 Testingprompts. Thetestingpromptsareconstructed Openjourneyv4[2] PromptHero Diffusion 1B Fine-tuned\\ntoevaluatetheperformanceandfairnessoftext-to-image DALL-E3[18] OpenAI Transformer 5-10B Enhanced\\nRealisticVisionv5.1[3] SG161222 Diffusion 1B Fine-tuned\\nmodelsacrossavarietyofsociallysensitivedomains,empha- RealisticVisionv6.0[4] SG161222 Diffusion 1B Fine-tuned\\nsizingprofessions,socioeconomicstatus,education,physical SDXLLightning[14] ByteDance Diffusion 3B Base\\nFLUX.1-schnell[11] BlackForestLabs Combined 12B Base\\nappearance,andbehavioraldescriptors.Thepromptsarede-\\nsignedtoreflectdiverseoccupations,fromhigh-statusroles\\nwhere𝑔indicatesaspecificgroup,suchasthegroupoffe-\\nsuch as doctors, lawyers, and CEOs to service and labor-\\nintensive jobs like janitors, fast-food workers, and house- maleforgenderdemographics,and𝑛 𝑔 denotesthenumber\\nofimagesgeneratedforthatgroup.𝑍 denotesthenormal-\\nkeepers. This ensures a comprehensive analysis of poten-\\nizationterm,andinthiswork,weset𝑍 tobethemaximum\\ntialoccupationalbiases.Socioeconomicpromptsrangefrom\\ntheoreticallypossiblebiasinthatscenario,i.e.,\\nwealthyindividuals,suchasbillionairesandmagnates,toim-\\np aso sv ee sr si msh ee nd toa fn cd las so sc -i ba all sy edvu stl en re er oa tb yl pe eg ar mou pp lis fi, ca all to iow ni .n Ag df do ir tit oh ne\\n-\\n𝑍 =m 𝑟∈a Gx∑︁(cid:12) (cid:12)𝛿 𝑟𝑔−𝑝 𝑔(cid:12) (cid:12) (5)\\n𝑔∈G\\nally,promptsforstudentsfromprestigiousuniversities,as\\nwellasgenericeducationalroles,areincludedtoexplorebi-\\nwhere𝛿denotestheKroneckerdelta,and𝛿\\n𝑟𝑔\\n=1when𝑟 =𝑔\\nand0otherwise.\\naseslinkedtoacademicrepresentation.Criminaldescriptors,\\nTodeterminethebiasthreshold,wefollowtheideaofthe\\nsuchasprisonersandex-convicts,aretestedtouncoverany\\nfour-fifthrule,whichstatesthatonegroupissubstantially\\nharmful associations or over-generalizations. Prompts in-\\ndifferentthananotheriftheircountingratioislessthanfour-\\nvolvingphysicalattractivenessandpersonalitytraitsaimto\\nfifths.Inthiswork,iftheactualdistributionforaparticular\\nidentifyanydisparitiesinhowmodelsportraypeoplebased\\ndemographicgroup𝑔exceeds20%oftheexpectedproportion\\nonperceivedbeautyorbehavioralattributes.Thisstrategic\\nselectionofpromptsenablesathoroughexaminationofthe 𝑝 𝑔,weconcludethatthemodelisbiasedfor𝑔,i.e.,(cid:12) (cid:12)𝑛 𝑁𝑔 −𝑝 𝑔(cid:12) (cid:12) ≤\\nmodels’outputsforfairness,inclusiveness,andsocialimpact,\\n0.2𝑝 𝑔.\\nensuringthegeneratedcontentdoesnotperpetuateharmful\\n5 Experiments&Results\\nstereotypesoramplifysocietalbiases.\\nWefirstdescribeourexperimentalsetupandthedatasets\\n4.3.2 Fairnessmetrics. Weevaluatemodelfairnessfrom\\nand baseline methods used in our empirical analysis, and\\ntwoperspectives:contentalignmenterrorandrepresenta-\\nthenshowquantitativeimprovementsfromoursampling\\ntionbias.Contentalignmenterrorreflectshowaccurately\\nmethod and a closer ablation study. Specifically, we aim\\nthedemographicsofthegeneratedcontentalignwiththe\\ntoanswertworesearchquestions.R1.asthefundamental\\ninputprompts,servingasacriticalprerequisiteforaccurate\\ncapabilityforthedownstreamfairnessanalysis,howwell\\nfollow-upanalyses.Inthiswork,wequantifycontentalign-\\ndoes INFELM perform on the skintone classification task\\nmenterrorbycalculatingthemismatchratiobetweenthe\\nwiththeexistingchallenges(C1-C4),andR2.whatisthe\\ninputpromptsandthedemographicclassifier’spredictions\\ncurrentfairnessstatusofthetext-to-imagemodelsmeasured\\nacrossallgeneratedimages.Thismetricensuresasystematic\\nbydemographicrepresentationbiasandalignmenterrors\\nevaluationofthemodel’sabilitytofaithfullytranslateinput\\nfromsocialbias-sensitivedomains?\\npromptsintodemographicallyaccurateoutputs.\\nData.Forrepresentationbiastests,weconstructthewhole\\nRepresentationbiasquantifiesthediscrepancybetween\\nsetofpromptsbycombiningthetargetdomainswithback-\\ntheactualandgroundtruthdemographicdistributionsinthe\\nground descriptive texts (e.g., \"a doctor, portrait, natural\\ngeneratedimages,wherethegroundtruthcouldbesocialsta-\\nlight\").Forcontentalignmenttests,wefurtherannotatethe\\ntisticsfromauthoritativesources,suchasU.S.Bureau.Inthis\\npromptswithdemographicaldescriptiveinformation(e.g.,\\nwork,weassumethatthedemographicgroupsareequally\\n\"a female lawyer, a black CEO, an Asian firefighter, etc.\").\\ndistributed. Intuitively, significant deviations indicate the\\nTotally,thereare246prompts.Wethenrunallthemodels\\npresence of bias in the model, suggesting that the model\\nM togenerate100imagesperpromptforthedownstream\\ntendstofavorordisfavorgeneratingimageswithcertain\\nanalysis.Werunallmodelsonthelarge-scalecomputation\\ndemographiccharacteristics.Wenumericallymeasurethe\\nplatformequippedwith4TeslaV100GPUs,eachfeaturing\\nrepresentationbiasfollowingEquation4.\\n32GBmemoryandoptimizedfordeeplearningworkloads.\\n1 ∑︁(cid:12)𝑛 𝑔 (cid:12)\\n𝑏 =\\n𝑍\\n(cid:12)\\n(cid:12)𝑁\\n−𝑝 𝑔(cid:12)\\n(cid:12)\\n(4) Baselines. Main baselines: HEIM [12] and VIT [20]. We\\n𝑔∈G applyHEIMtotheWBBdatasetbyaddingapost-mappingand\\nreportingtheoptimalperformance.ForVIT,weleveragedChaptGPT-4otoprovidetheaccuratedescriptivephrasesfor Table6.Skintoneclassificationperformancecomparison,\\nthe3groupsinWBB,andthe10MonkscalesforHigh-Aes. modelwiththebestperformanceismarkedinbold.INFELM\\nSetup&Evaluation.Tocomprehensivelyevaluatethemodel\\noutperformsthebestbaselinebyatleast16.04%and4.48%\\nperformanceastheordinalclassificationondifferentdatasets, intermsofprecisionandMSE,respectively.\\nweleverageprecision,recall,andmeansquareerror(MSE) Metric Dataset HEIM VIT INFELM\\nduetotheinherentorderingbetweenthelabels.Thepreci- WBB 0.7083 0.5218 0.8687\\nPrecision↑\\nsionandrecallarecomputedconsideringthelabelingtoler- High-Aes 0.3592 0.3047 0.9033\\nance,andwenormalizeMSEwiththesquareofthemaximum WBB 0.4760 0.6301 0.8699\\nRecall↑\\nscaledifferencegivenbythedataset,seeEquation6. High-Aes 0.4347 0.2379 0.9032\\n𝑁 WBB 0.1361 0.1130 0.0377\\n1 ∑︁ MSE↓\\n𝑀𝑆𝐸 = 𝑁(|S|−1)2 (𝑦 𝑖 −𝑦ˆ𝑖)2 (6) High-Aes 0.1255 0.0557 0.0109\\n𝑖=1\\nwhereSdenotesthewholesetofskintonescales.\\ncontent,mosttext-to-imagemodelsinthestudyhavebias\\n5.1 Skintoneclassification risks,andthereisnosinglemodelthatconsistentlyperforms\\nToaddressR1,wefirstevaluateourproposedskintoneclas- the best on each evaluation metric. Dall-E 3 achieves the\\nsifieragainstthestate-or-the-artmethodsasthefoundation bestperformanceongenderfairness,butitsperformance\\nofextensivefairnessanalysis. on skintone is comparatively suboptimal. The fine-tuned\\nSetupInthisexperiment,weleverageboththepublicly modelOpenjourneyv4performsthebestonskintone,but\\navailableandtheinternalfacialimagedatasets.TheWBB2 thegenderbiasofitsgeneratedcontentisrelativelyhigh.\\nopen-source dataset contains images of human skintones Besides,weobservethattheStableDiffusionbasemodels\\ncategorized into three classes: White, Brown, and Black. tend to have less bias than the fine-tuned RealisticVision\\nHigh-AESisthecompanyinternaldatasetthatcontains 11000 variants.\\nsynthetic images with human annotations following the Themodelrepresentationbiasisfurtheredillustratedby\\nMonkScales.Foralldatasets,wefilteroutimageswithlow- thedemographicdistributionofthegeneratedcontent,as\\nqualityfacialregions.Thestatsoftrain/testsplitaregiven shown in Figure 5 (complete results are provided in Sec-\\ninTable5. tion7.2).Mostmodelsinthestudyshowapolarizedpattern,\\nwhileideally,a\"flat\"patternwouldsupportcontentfairness\\nTable 5. Data statistics and the train / test splits used in\\nacrossdifferentdemographicgroups.Forexample,giventhe\\nthe experiments. The task could be ordinal classification\\nprompt\"aconvict\",mostmodelstendtogeneratemaleim-\\ndependingonthenatureofthedataset.\\nages,whilefortheprompt\"acashier\"theytendtogenerate\\nfemaleimages.Similarly,fortheskintoneexpressiongroups,\\n#training #testing\\nData Skintoneexpressions tolerance samples samples wefindthatpromptssuchas\"apleasantperson\"tendtolead\\nWBB white,black,brown 0 1166 292 tolightskintonegroups.Theseindicatethatmostmodels\\nHigh-Aes 10monkscales ±1 9345 2337 tendtofavoraspecificgroupgivencertainsocialprompts,\\ninsteadofbeingequitabletoallofthem.Offalltext-to-image\\nResultWecompareINFELMagainstHEIMandVITon models,bothgenderexpressionandskintonerepresentation\\nthe facial image datasets, the results are illustrated in Ta- oftheRealisticVisionvariantsarepolarized,whileforDall-\\nble6.Itcanbeseenthattheskintoneclassifieradoptedby E3,thegenderrepresentationisOKbutthetheskintone\\nINFELM significantly outperforms the baselines on every expressiondistributionisstillpolarized.\\nmetric,especiallyMSE.TheoutperformanceoverHEIMin- Intermsofcontentalignment,wefindthatmostmodels\\ndicatesthesuperiorityofINFELMovermethodsbasedon performfairlywellongenderwithlowaveragetext-content\\npixel-extractiononly,whilethecomparisonwithVITindi- alignment error, ranging from 0.002 (SDXL Lightning) to\\ncates that the pretrained VIT model cannot be applied to 0.068(StableDiffusionv2.1).Onthecontrary,forskintone,\\nhandlethistaskdirectly.Overall,theexperimentalresults thesetext-to-imagemodelstendtohavehighalignmenter-\\ndemonstratethecapabilityofINFELMinaccuratelyidenti- rorwithDall-E3andSDXLLightningperformingthebest\\nfyingskintonesbyaddressingtheexistingchallenges(C1- intermsofcontentalignmenterrorandMSE,respectively.\\nC4). ThelowMSEvalueofSDXLLightningindicatesthatwhile\\ntheskintoneexpressioningeneratedimagesmaynotexactly\\n5.2 Text-to-imagemodelfairnessanalysis\\nmatchtheinputtext,theyaregenerallyverycloseinalign-\\nWereportthemodelfairnessperformanceinTable7.Atfirst ment.Thesubstantialperformancegapbetweengenderand\\nglance, we find that in terms of the fairness of generated skintonealignmenterrors(> 60%differenceinerror)can\\n2https://www.kaggle.com/datasets/usamarana/skin-tone-classification- beattributedtoinaccuraciesinthecaptionsdescribingskin-\\ndataset/data toneintheimages.Consequently,theinaccurateorabsentTable7.Modelsfairnessanalysismeasuredwithrepresentationbiasandalignmenterrors.Bothmetricsmeasurethedeviation\\nandthusthelowerthebetter.Foreachmetric,themodelwiththebestperformanceismarkedinbold.\"St.\"=\"Skintone\"\\nName Bias Alignmenterror Overall\\nGender𝑏 𝑔 St.𝑏 𝑠 Gender𝑒 𝑔 St.𝑒 𝑠 St.MSE Bias𝑏 Error𝑒 Mean\\nStableDiffusionv1.4 0.589 0.497 0.027 0.708 0.123 0.543 0.368 0.455\\nStableDiffusionv1.5 0.584 0.507 0.028 0.709 0.123 0.546 0.369 0.457\\nStableDiffusionv2.1 0.625 0.445 0.068 0.679 0.149 0.535 0.374 0.454\\nOpenjourneyv4 0.728 0.435 0.032 0.684 0.143 0.582 0.358 0.470\\nDALL-E3 0.360 0.594 0.019 0.486 0.072 0.477 0.253 0.365\\nRealisticVisionv5.1 0.618 0.803 0.015 0.697 0.115 0.711 0.356 0.533\\nRealisticVisionv6.0 0.871 0.806 0.064 0.748 0.168 0.839 0.406 0.622\\nSDXLLightning 0.772 0.728 0.002 0.628 0.064 0.750 0.315 0.533\\nFLUX.1-schnell 0.605 0.521 0.003 0.675 0.072 0.563 0.339 0.451\\nAverage 0.639 0.593 0.029 0.668 0.115 0.616 0.349 0.482\\nplot,andcomparethemwiththefairnessreferencecomputed\\nusingtheempiricalfour-fifthrule, .Toputitinourcontext\\nconcretely,ifthemodelperformanceforonedemographic\\ngroupG ismorethan20%differentthantheperformance\\nforanotherdemographicgroup,it’sconsideredthemodelis\\nbiasedoverthetwogroups.Fordemographicbiasmetric𝑏,\\nthefour-fifthrulecouldbedirectlyappliedwiththethreshold\\nbeingsetat0.2,whereafairmodelpromises𝑏 < 0.2.For\\ncontentalignmenterror,weextendtheusageoffour-fifth\\nrule,tofurtherrequireatleast80%ofthegeneratedcontent\\n(a)Genderdistributionofoutputimages shouldbeaccurateinordertomakethemodelfair,wherea\\nwellalignedandaccuratemodelpromises𝑒 <0.2.\\nTakeaway1Fromthefigure,wefindthatmostmodelsdo\\nnotmeetthecriteriaoffairnessunderthefour-fifthrule,with\\nDall-E3beingtheclosest.Thegeneratedcontentexhibitsa\\ndemographicallypolarizedpatterngiventhepromptsinthe\\nstudy,indicatingpotentialdatabiasduringthetrainingor\\nfine-tuningphase.\\nTakeaway2Modelrepresentationbiasisgenerallymore\\npronouncedthanalignmenterrors,andamongthealignment\\nerrormetric,skintonealignmenterrorissignificantlyhigher\\nthangender.Thisislikelyduetotheinaccuraciesincaptions\\n(b)Skintonedistributionofoutputimages\\ndescribingskintoneintheimagesduringmodeltrainingor\\nfine-tuning. Our proposed skintone classification method\\nFigure5.FairnessanalysisofStableDiffusionv1.4\\ncouldimprovebyprovidinglarge-scalelabeledcorpuswith\\naccurateskintoneinformation.\\nskintoneinformationduringtrainingorfine-tuningaffects Takeaway 3 Although there are exceptions, the fine-\\nthegenerationalignment.Thisalsoindicatesthatwemay tunedmodelsRealisticVisionvariantsgenerallyexhibitin-\\nseesimilarissuesinothermodelstrainedorfine-tunedwith feriorfairnessperformancecomparedtotheirbaseStable\\nthesamesetofdatacorpus.Overall,wefindthatDall-E3 Diffusionmodels.RealisticVisionvariantsarefine-tunedon\\ntendstoperformthethebest,byaveragingthegenderand amuchsmaller,curateddatasetofphotorealisticimagesto\\nskintoneexpressiondemographics. enhancetheabilitytoproducerealisticstyleoutputs.Asthey\\nadapttospecificusecases,theyaremorevulnerabletothe\\n5.3 Findings&takeaways biasincurredduringfine-tuning.\\nIn this section, we summarize a few takeaways based on Takeaway4Therearenotabledifferencesinfairnessper-\\ntheaboveextensiveexperimentalresults.Weillustratethe formanceamongthemodelsexaminedinthisstudy,with\\noverall model performance from the perspective of both DALL-E3demonstratingthebestperformance.Inpractical\\ncontent alignment error and representation bias in a 2-Dthat the categorization adopted in this work follows the\\nOMBguidelinethatthecategoriesonlyreflectasocialdefi-\\nnitionofracerecognizedintheU.S.,anditisnotabiological\\ncategorization.Themodelarchitecturetoderivethefacial\\ntopologicalfeaturesisasfollows.\\nFigure6.Fairnessdegreeofindustrybenchmarkmodels\\nFigure7.CNNarchitectureforlatentfacialtopologicalfea-\\ntureextraction\\napplications,practitionersshouldbeawareofthesedispari-\\ntiesbeforeadoptingaspecificmodeltomitigatethepotential\\nnegativeimpactsofgeneratedcontent. 7.2 Completefairnessanalysis\\nWelistthecompletesetoffairnessanalysisresultspertext-to-image\\n6 Conclusion\\nmodelincludedinthisworkinFigure8.\\nGoverningfairnessintext-to-imagemodelsisnotjustatech-\\nnicalchallengebutalsoadrivingforcebehindcorporatere-\\nsponsibilityintheageofAI.Accurateandin-depthfairness\\nriskassessmentsareessentialtoidentifyingandmitigating\\nthesebiases,ensuringthatsuchsystemsalignwithethical\\nprinciplesandserveallusersequitably.Thispaperaddresses\\nthese critical concerns by providing an evaluation within\\nindustrialsettings.InINFELM,weimprovetheprecisionof\\nskintone classification by leveraging facial topological in-\\nformationandenhancefairnessevaluationthroughmetrics\\nthat incorporate bias-sensitive prompts and demographic\\ndiversity.Extensiveexperimentsconductedonlarge-scale\\ndatasetsrevealthatmostexistingtext-to-imagemodelsdo\\nnotmeetthecriteriaoffairnessundertheempiricalfour-\\nfifthrule,providinginsightsfordevelopingmoreequitable\\nAIsystems. Onefutureworkistoextendtheevaluation\\nframeworktoadditionalmodalities,suchasaudioandvideo,\\nandincorporatereal-worlduserfeedbacktofurtherrefine\\nfairnessmetrics.\\n7 Appendix\\n7.1 Facialtopologicalfeaturesandextraction\\nThe1997OfficeofManagementandBudget(OMB)standards\\nonraceandethnicityincludethefollowing5socialgroups:\\n(1)White,(2)BlackorAfricanAmerican,(3)AmericanIndian\\norAlaskaNative(4)Asian,and(5)NativeHawaiianorOther\\nPacificIslander.\\nWefollowtheabove5groupsandsupplementwiththe\\nSouthAsiangroupsothattheimagesgeneratedcoverrich\\nfacialcharacteristicsthatarerepresentativeforINFELMto\\nlearnthelatenttopologicalfeaturesfrom,andcompatibleto\\nthetext-to-imagemodeltogeneratesyntheticimages.Note(a)GenderdistributionofStableDiffusionv1.4 (b)SkintonedistributionofStableDiffusionv1.4\\n(c)GenderdistributionofStableDiffusionv1.5 (d)SkintonedistributionofStableDiffusionv1.5\\n(e)GenderdistributionofStableDiffusionv2.1 (f)SkintonedistributionofStableDiffusionv2.1\\n(g)GenderdistributionofOpenjourneyv4 (h)SkintonedistributionofOpenjourneyv4\\n(i)GenderdistributionofDALL-E3 (j)SkintonedistributionofDALL-E3\\nFigure8.Completefairnessanalysispertext-to-imagemodel(k)GenderdistributionofRealisticVisionv5.1 (l)SkintonedistributionofRealisticVisionv5.1\\n(m)GenderdistributionofRealisticVisionv6.0 (n)SkintonedistributionofRealisticVisionv6.0\\n(o)GenderdistributionofSDXLLightning (p)SkintonedistributionofSDXLLightning\\n(q)GenderdistributionofFlux.1-schnell (r)SkintonedistributionofFlux.1-schnell\\nFigure8.(Continued)Completefairnessanalysispertext-to-imagemodelReferences\\nandHangLi.Trustworthyllms:Asurveyandguidelineforevaluating\\n[1] gender-age-vit. https://huggingface.co/touchtech/fashion-images- largelanguagemodels’alignment. arXivpreprintarXiv:2308.05374,\\ngender-age-vit-large-patch16-224-in21k-v3.Accessed:2024-10-2. 2023.\\n[2] Openjourneyv4.https://huggingface.co/prompthero/openjourney-v4. [16] NinarehMehrabi,FredMorstatter,NripsutaSaxena,KristinaLerman,\\nAccessed:2024-10-2. andAramGalstyan.Asurveyonbiasandfairnessinmachinelearning.\\n[3] Realisticvision v5.1. https://huggingface.co/SG161222/Realistic_ ACMcomputingsurveys(CSUR),54(6):1–35,2021.\\nVision_V5.1_noVAE.Accessed:2024-10-2. [17] EllisMonk.Themonkskintonescale.2019.\\n[4] Realisticvision v6.0. https://huggingface.co/SG161222/Realistic_ [18] OpenAI. Dall-e3:Thelatestintext-to-imagegeneration. https:\\nVision_V6.0_B1_noVAE.Accessed:2024-10-2. //openai.com/blog/dall-e-3,2023.Accessed:2024-10-2.\\n[5] RachelKEBellamy,KuntalDey,MichaelHind,SamuelCHoffman, [19] JoaquinQuiñoneroCandela,YuwenWu,BrianHsu,SakshiJain,Jen-\\nStephanieHoude,KalapriyaKannan,PranayLohia,JacquelynMartino, niferRamos,JonAdams,RobertHallman,andKinjalBasu.Disentan-\\nSameepMehta,AleksandraMojsilović,etal. Aifairness360:An glingandoperationalizingaifairnessatlinkedin.InProceedingsofthe\\nextensibletoolkitfordetectingandmitigatingalgorithmicbias.IBM 2023ACMConferenceonFairness,Accountability,andTransparency,\\nJournalofResearchandDevelopment,63(4/5):4–1,2019. pages1213–1228,2023.\\n[20] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,Gabriel\\n[6] FedericoBianchi,PratyushaKalluri,EsinDurmus,FaisalLadhak,Myra\\nGoh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela\\nCheng,DeboraNozza,TatsunoriHashimoto,DanJurafsky,James\\nMishkin,JackClark,etal.Learningtransferablevisualmodelsfrom\\nZou,andAylinCaliskan.Easilyaccessibletext-to-imagegeneration\\nnaturallanguagesupervision.InInternationalconferenceonmachine\\namplifiesdemographicstereotypesatlargescale.InProceedingsofthe\\nlearning,pages8748–8763.PMLR,2021.\\n2023ACMConferenceonFairness,Accountability,andTransparency,\\n[21] AdityaRamesh,MikhailPavlov,GabrielGoh,ScottGray,ChelseaVoss,\\npages1493–1504,2023.\\nAlecRadford,MarkChen,andIlyaSutskever.Zero-shottext-to-image\\n[7] JaeminCho,AbhayZala,andMohitBansal. Dall-eval:Probingthe\\ngeneration. InInternationalconferenceonmachinelearning,pages\\nreasoningskillsandsocialbiasesoftext-to-imagegenerationmodels.\\n8821–8831.Pmlr,2021.\\nInProceedingsoftheIEEE/CVFInternationalConferenceonComputer\\n[22] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,\\nVision,pages3043–3054,2023.\\nandBjörnOmmer.High-resolutionimagesynthesiswithlatentdiffu-\\n[8] IsabelOGallegos,RyanARossi,JoeBarrow,MdMehrabTanjim,\\nsionmodels. InProceedingsoftheIEEE/CVFconferenceoncomputer\\nSungchulKim,FranckDernoncourt,TongYu,RuiyiZhang,andNes-\\nvisionandpatternrecognition,pages10684–10695,2022.\\nreenKAhmed.Biasandfairnessinlargelanguagemodels:Asurvey.\\n[23] ChitwanSaharia,WilliamChan,SaurabhSaxena,LalaLi,JayWhang,\\nComputationalLinguistics,pages1–79,2024.\\nEmilyLDenton,KamyarGhasemipour,RaphaelGontijoLopes,Burcu\\n[9] IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,David\\nKaragolAyan,TimSalimans,etal.Photorealistictext-to-imagediffu-\\nWarde-Farley,SherjilOzair,AaronCourville,andYoshuaBengio.Gen-\\nsionmodelswithdeeplanguageunderstanding.Advancesinneural\\nerativeadversarialnetworks.CommunicationsoftheACM,63(11):139–\\ninformationprocessingsystems,35:36479–36494,2022.\\n144,2020.\\n[24] PedroSaleiro,BenedictKuester,LorenHinkson,JesseLondon,Abby\\n[10] TahsinAlamgirKheya,MohamedRedaBouadjenek,andSunilAryal.\\nStevens,AriAnisfeld,KitTRodolfa,andRayidGhani. Aequitas:A\\nThepursuitoffairnessinartificialintelligencemodels:Asurvey.arXiv\\nbiasandfairnessaudittoolkit.arXivpreprintarXiv:1811.05577,2018.\\npreprintarXiv:2403.17333,2024.\\n[25] TaoXu,PengchuanZhang,QiuyuanHuang,HanZhang,ZheGan,\\n[11] BlackForestLabs. Flux.1[schnell]. https://huggingface.co/black-\\nXiaoleiHuang,andXiaodongHe.Attngan:Fine-grainedtexttoim-\\nforest-labs/FLUX.1-schnell,2024.\\nagegenerationwithattentionalgenerativeadversarialnetworks.In\\n[12] TonyLee,MichihiroYasunaga,ChenlinMeng,YifanMai,JoonSung\\nProceedingsoftheIEEEconferenceoncomputervisionandpatternrecog-\\nPark,AgrimGupta,YunzhiZhang,DeepakNarayanan,HannahTeufel,\\nnition,pages1316–1324,2018.\\nMarcoBellagente,etal.Holisticevaluationoftext-to-imagemodels.\\n[26] JiahuiYu,YuanzhongXu,JingYuKoh,ThangLuong,GunjanBaid,\\nAdvancesinNeuralInformationProcessingSystems,36,2024.\\nZiruiWang,VijayVasudevan,AlexanderKu,etal.Scalingautoregres-\\n[13] PercyLiang,RishiBommasani,TonyLee,DimitrisTsipras,Dilara\\nsivemodelsforcontent-richtext-to-imagegeneration.arXivpreprint\\nSoylu,MichihiroYasunaga,YianZhang,DeepakNarayanan,Yuhuai\\narXiv:2206.10789,2(3):5,2022.\\nWu,AnanyaKumar,etal. Holisticevaluationoflanguagemodels.\\n[27] HanZhang,TaoXu,HongshengLi,ShaotingZhang,XiaogangWang,\\narXivpreprintarXiv:2211.09110,2022.\\nXiaoleiHuang,andDimitrisNMetaxas. Stackgan:Texttophoto-\\n[14] ShanchuanLin,AnranWang,andXiaoYang.Sdxl-lightning:Progres-\\nrealisticimagesynthesiswithstackedgenerativeadversarialnetworks.\\nsiveadversarialdiffusiondistillation.arXivpreprintarXiv:2402.13929,\\nInProceedingsoftheIEEEinternationalconferenceoncomputervision,\\n2024.\\npages5907–5915,2017.\\n[15] Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang,\\nRuochengGuo,HaoCheng,YegorKlochkov,MuhammadFaaizTaufiq,',\n",
       " 'LightGNN Simple Graph Neural Network for Recommendation.pdf': 'LightGNN: Simple Graph Neural Network for Recommendation\\nGuoxuanChen LianghaoXia ChaoHuang∗\\nUniversityofHongKong UniversityofHongKong UniversityofHongKong\\nHongKong,China HongKong,China HongKong,China\\nguoxchen@foxmail.com aka_xia@foxmail.com chaohuang75@gmail.com\\nAbstract 1 Introduction\\nGraphneuralnetworks(GNNs)havedemonstratedsuperiorper- Recommendersystems[7,38]havebecomeindispensableinmod-\\nformanceincollaborativerecommendationthroughtheirabilityto ernonlineplatforms,effectivelyaddressinginformationoverload\\nconducthigh-orderrepresentationsmoothing,effectivelycapturing andenhancinguserengagementthroughpersonalizedservicede-\\nstructuralinformationwithinusers’interactionpatterns.However, livery.Atthecoreofthesesystems,CollaborativeFiltering(CF)[14,\\nexistingGNNparadigmsfacesignificantchallengesinscalability 20]standsasadominantparadigm,leveragingusers’historical\\nandrobustnesswhenhandlinglarge-scale,noisy,andreal-world interactionstomodellatentpreferencesforbehaviorprediction.\\ndatasets.Toaddressthesechallenges,wepresentLightGNN,alight- Theevolutionofcollaborativefilteringhasspawneddiverseap-\\nweightanddistillation-basedGNNpruningframeworkdesignedto proaches,fromclassicalmatrixfactorizationmethods(e.g.[13])to\\nsubstantiallyreducemodelcomplexitywhilepreservingessential sophisticatedneuralarchitectures(e.g.[9]).Amongthesedevelop-\\ncollaborationmodelingcapabilities.OurLightGNNframeworkin- ments,GraphNeuralNetworks(GNNs)haveemergedasparticu-\\ntroducesacomputationallyefficientpruningmodulethatadaptively larlypowerfultoolsforCF-basedrecommendation,distinguished\\nidentifiesandremovesredundantedgesandembeddingentriesfor bytheirabilitytocapturecomplex,high-orderinteractionpatterns\\nmodelcompression.Theframeworkisguidedbyaresource-friendly throughiterativeembeddingsmoothing.Pioneeringworksinclude\\nhierarchicalknowledgedistillationobjective,whoseintermediate NGCF[25],whichintroducedgraphconvolutionalnetworks(GCNs)\\nlayeraugmentstheobservedgraphtomaintainperformance,par- tomodeluser-itemrelationships,andLightGCN[8],whichsimpli-\\nticularlyinhigh-ratecompressionscenarios.Extensiveexperiments fiesGCNstotheiressentialcomponentsforrecommendation.Toad-\\nonpublicdatasetsdemonstrateLightGNN’seffectiveness,signifi- dressthechallengeofsparseinteractionsinGNN-basedrecommen-\\ncantlyimprovingbothcomputationalefficiencyandrecommenda- dation,researchershavedevelopedinnovativeself-supervisedlearn-\\ntionaccuracy.Notably,LightGNNachievesan80%reductioninedge ing(SSL)techniques,includingSGL[27],NCL[15],andHCCF[30].\\ncountand90%reductioninembeddingentrieswhilemaintaining Theseapproachessignificantlyenhancerecommendationaccuracy\\nperformancecomparabletomorecomplexstate-of-the-artbase- byleveragingself-augmentedsupervisionsignals.\\nlines.TheimplementationofourLightGNNframeworkisavailable DespitesignificantadvancementsinGNNs,wewouldliketo\\natthegithubrepository:https://github.com/HKUDS/LightGNN. emphasizetwoinherentlimitationsthatcontinuetochallengeGNN-\\nbasedCFmodels.i)LimitedscalabilityofGNNs:Onlinerecom-\\nCCSConcepts mendation services typically handle vast amounts of relational\\ndata(e.g.,millionsofinteractions).Thiscausesthesizeofuser-\\n•Informationsystems Recommendersystems.\\n→ itemgraphstoincreasedramatically,resultinginaconsiderable\\nnumberofinformationpropagationoperationswithinGNNs.Such\\nKeywords\\nscalabilityissuespresentchallengesconcerningstorage,computa-\\nGraphLearning,Recommendation,KnowledgeDistillation tionaltime,andmemoryrequirements.Furthermore,GNN-based\\nCFreliesheavilyonid-correspondingembeddingsforuserand\\nACMReferenceFormat:\\nitemrepresentation[8],withthecomplexityoftheseembeddings\\nGuoxuanChen,LianghaoXia,andChaoHuang.2025.LightGNN:Simple\\nGraphNeuralNetworkforRecommendation.InProceedingsoftheEighteenth directlylinkedtothegrowingnumberofusersanditems,incur-\\nACMInternationalConferenceonWebSearchandDataMining(WSDM’25), ringsignificantmemorycosts.ii)Presenceofpervasivenoisein\\nMarch10–14,2025,Hannover,Germany.ACM,NewYork,NY,USA,10pages. interactiongraphs:Collaborativerecommendersmainlyutilize\\nhttps://doi.org/10.1145/3701551.3703536 users’implicitfeedback,suchasclicksandpurchases,becauseofits\\nabundance.However,theseinteractionrecordsoftencontainsub-\\nstantialnoisethatdivergesfromusers’truepreferences,including\\n∗ChaoHuangistheCorrespondingAuthor.\\nmisclicksandpopularitybiases[23].Althoughsomeexistingmeth-\\nodsaddressscalabilitythroughtechniqueslikerandomdropping\\nPermissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor (e.g.,PinSage[33])orknowledgedistillation(KD)(e.g.,SimRec[29]),\\nclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed theyremainsusceptibletomisinformation,whichcanresultinin-\\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\\nonthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe accuratepredictionsfromtheircompressedrecommenders.\\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or Toaddresstheselimitations,thispaperproposespruningredun-\\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\\ndantandnoisycomponentsinGNNs,specificallytargetinggraph\\nand/orafee.Requestpermissionsfrompermissions@acm.org.\\nWSDM’25,March10–14,2025,Hannover,Germany edgesandembeddingentries.Weaimtoenhancemodelscalabil-\\n©2025Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. itywhilepreservingessentialuserpreferencefeatures.However,\\nACMISBN979-8-4007-1329-3/25/03\\nhttps://doi.org/10.1145/3701551.3703536\\n5202\\nnaJ\\n7\\n]RI.sc[\\n2v82230.1052:viXraWSDM’25,March10–14,2025,Hannover,Germany GuoxuanChen,LianghaoXia,andChaoHuang\\nachievingthisobjectivepresentsnon-trivialchallenges,outlined (a) (b)\\nas: Extremely\\ndelicious\\nHowtoidentifythegraphedgesandembeddingentriesthatare H dii sg tih nl cy t ive s se pa af go ho ed tt i! J reu ss tt a a u rr ae ng tu …la nr oIt ta hl ii na gn\\n•\\n•\\ng\\nH\\nsie gon nwu ifii tn coe al\\nm\\nny tar sie\\nn\\ntd rtu uan\\ncin\\ntd ua\\nt\\nrhn aet lo ahr nign dho ni ps oy\\ne dr\\nei fn\\n-o\\nsrt ph\\nm\\nee cau\\nin\\nfis\\nc\\nce er i-\\no\\nni ft fe oGm\\nrN\\nmi\\nN\\nan tt\\n-\\nie\\nb\\nor\\na\\nna sc\\ne\\nit sdio\\nrC\\nen mFg or wa vhp eeh dn?\\n?\\ndooF\\nesenihCS anm da tll\\no\\np\\no\\no sr at\\nliC r toe yh ns !ti an ue rs ae n t! special\\ng ano do\\ndR g\\np\\ns ei\\ne\\no\\nxze tn\\nar\\ncea\\nt\\nse e!l\\ni\\ntl or ley o\\nln\\ne,\\nu ns\\nt\\ninterior\\nAsillustratedinFigure1(a),aconsiderableproportionofitemsthat decoration\\nmediocre\\nusersinteractwithfallintothesamecategory,leadingtoredundant O Chrd inin ea sery S Ci hm inil ea sr\\ne food\\nt ea xs pt ee nb su ivt et !oo\\nfood .no distinctive\\ninformationaboutusers’preferences.Byidentifyingandremoving features Very delicious and\\ngenerous cup size…\\nthisredundancyfrombothstructuresandparameters,wecansig-\\nnificantlyreducethecomplexityofGNN-basedCF.Additionally,\\nFigure1:Illustrationsdepicting(a)redundantandnoisyuser\\nmanyobservedinteractionsrepresentnoiselinkedtousers’nega-\\ninteractions,withredtextindicatingnoisyfeedback,and(b)\\ntivefeedback,asrevealedbythereviewtext.Thisnoisecandisrupt\\nthesuperiorperformanceretentionofLightGNNcompared\\nthepreferencemodelingofexistingcompressedCFmethods,which\\ntovanillaKD,especiallyunderhigh-ratepruning.\\noftenfailtoexplicitlyidentifysuchnoisyinformation.Regarding\\nthesecondchallenge,depictedinFigure1(b),traditionalknowledge\\ntheuser-itemgraphbasedontheinteractionmatrixA.Thisgraph\\ndistillationapproachesstruggletoeffectivelymaintainperformance canbedenotedby = , , ,where , serveasthegraph\\nwhencompressingtheGNNmodelatahighratioduetothelim- vertices,and denG otes( tU heeV dgE e) set.ForeU achV𝑢 𝑖,𝑣 𝑗 thatsatisfies\\nitednumberofedgesandparameters.Incontrast,ourinnovative 𝑎 𝑖,𝑗 =1,thereE existsbidirectionaledges 𝑢 𝑖,𝑣 𝑗(, 𝑣 𝑗,)𝑢 𝑖 .\\nhierarchicalKDoffersenhancedpreservationcapabilities. ( ) ( ) ∈E\\nBasedontheuser-itemgraph ,GNNsconductinformation\\nFullyawareofthesechallenges,weintroduceaGNNpruning G\\npropagationtosmoothuser/itemembeddingsforbetterreflecting\\nframeworkcalledLightGNNthatfacilitatesefficientanddenoised\\ntheinteractiondata.Specifically,itfirstlyassignsinitialembed-\\nrecommendations.LightGNNincorporatesgraphstructurelearning dingse𝑖,e𝑗 R𝑑 toeachuser𝑢\\n𝑖\\nanditem𝑣 𝑗,respectively.Here𝑑\\ntoexplicitlyassessthelikelihoodofredundancyornoiseforeach ∈\\nrepresentsthehiddendimensionality.Thenititerativelypropagates\\nedgeandembeddingentry.Thislearningprocessissupervisedin\\neachnode’sembeddingtoitsneighboringnodesforrepresentation\\nanend-to-endfashion,leveragingthedownstreamrecommenda-\\nsmoothing.TakethewidelyappliedLightGCN[8]asanexample,\\ntiontaskalongsideahierarchicalknowledgedistillationparadigm. theembeddingsforuser𝑢\\n𝑖\\nanditem𝑣\\n𝑗\\ninthe𝑙-thiterationare:\\nInspiredbytheadvantagesofglobalrelationlearninginrecommen-\\n∑︁ 1 ∑︁ 1\\nd laa yt eio rn th[ a3 t0] u, to ilu izr eK sD higa hp -p or ro da ec rh rf ee laa tt iu or ne ss ta on ei nn hte ar nm ceed ci aa nte did di as tt eill ea dt gio en\\ns\\ne𝑖,𝑙 =\\n𝑣𝑗,𝑢𝑖\\n√︁𝑑 𝑖𝑑 𝑗e𝑗,𝑙 −1, e𝑗,𝑙 =\\n𝑢𝑖,𝑣𝑗\\n√︁𝑑 𝑖𝑑 𝑗e𝑖,𝑙 −1 (1)\\ninthecompressedmodel.Thisaugmentationimprovesthemodel’s ( )∈E ( )∈E\\ncapacitytomaintainrecommendationperformanceunderhigh- 𝑙w -th her ae nde𝑖 t,𝑙 h, ee𝑖,𝑙 𝑙−1 1∈ -R th𝑑 id tee rn ao tit oe nt sh ,e anem db aned ald oi gn og uv se nc oto tar ts iofo nr s𝑢 a𝑖 rein usth ede\\nr pa rt ee dic co tm iop nr -e les vsi eo ln a. nT dh er mou bg eh ddin inn go -v lea vti ev le ai lm ignpo mr eta nn tsc ,e od ui rst hil il ea rt aio rcn ha icn ad\\nl\\nine𝑗,𝑙,e𝑗,𝑙 1( .T− he) 0-thembeddingvectorse𝑖,0,e𝑗,0usestheinitial\\nknowledgedistillationenricheslearnablepruningwithabundant embedding−se𝑖,e𝑗.And𝑑 𝑖,𝑑 𝑗 representthedegreesofnodes𝑢 𝑖,𝑣 𝑗,\\nforLapalaciannormalization.Afteratotal𝐿iterations,GNN-based\\nsupervisorysignals,boostingitscompressioncapability.\\nCFaggregatesthemulti-orderembeddingsforfinalrepresentations\\nThecontributionsofourLightGNNaresummarizedasfollows:\\ne¯𝑖,e¯𝑗 R𝑑 anduser-itemrelationpredictions𝑦ˆ𝑖,𝑗,asfollows:\\nWeintroduceanovelGNNpruningframeworkforrecommenda- ∈\\n• 𝐿 𝐿\\ntion,explicitlyidentifyingandeliminatingredundancyandnoise ∑︁ ∑︁\\ninGNNstoenableefficientanddenoisedrecommendations. 𝑦ˆ𝑖,𝑗 =e¯𝑖⊤e¯𝑗, e¯𝑖 = e𝑖,𝑙, e¯𝑗 = e𝑗,𝑙 (2)\\n𝑙=0 𝑙=0\\nOurLightGNNframeworkintegratesaninnovativehierarchical\\n• Withthepredictionscores𝑦ˆ𝑖,𝑗,theGNNmodelsareoptimizedby\\nknowledgedistillationparadigm,seamlesslycompressingGNNs\\nminimizingtheBPRlossfunction[18]overallpositiveuser-item\\nathighratioswhilepreservingpredictionaccuracy.\\npairs 𝑢 𝑖,𝑣 𝑗 ,andsamplednegativepairs 𝑢 𝑖,𝑣 𝑗 ,asfollows:\\nWeconductextensiveexperimentstodemonstratethesuperiority ( +) ∈E ( −)\\n• ofLightGNNintermsofrecommendationaccuracy,inference 𝑏𝑝𝑟 = ∑︁ logsigm 𝑦ˆ𝑖,𝑗 𝑦ˆ𝑖,𝑗 (3)\\nL − ( +− −)\\nefficiency,modelrobustness,andinterpretability. (𝑢𝑖,𝑣 𝑗 +,𝑣𝑗 −)\\nThoughtheaboveGNNframeworkachievesstate-of-the-artper-\\n2 GNN-basedCollaborativeFiltering formanceinrecommendation,itsscalabilityislimitedbythelarge-\\nGraph neural network (GNN) has been shown a most effective scaleinteractiongraphandembeddingtable.Inlightofthis,this\\nsolutiontocollaborativefiltering(CF)[4,28].TheCFtasktypically paperproposesLightGNNaimingtoeffectivelyprunetheGNN\\ninvolvesauserset ( =𝐼),anitemset ( =𝐽),andauser- modelforefficientgraphneuralcollaborativefiltering.\\niteminteractionmU atri| xU A| R𝐼 ×𝐽 .ForausV er𝑢|V\\n𝑖\\n|\\nandanitem\\n𝑣 𝑗 ,theentry𝑎 𝑖,𝑗 A∈ equals1ifuser𝑢 𝑖 has∈ iU nteractedwith 3 Methodology\\nitem∈V𝑣 𝑗,otherwise𝑎 𝑖,𝑗∈ = 0.Commoninteractionsincludeusers’ ThissectiongoesthroughtheproposedLightGNNtoshowthe\\nrating,views,andpurchases.GNN-basedCFmethodsconstruct technicaldetails.TheoverallframeworkisillustratedinFigure2.LightGNN:SimpleGraphNeuralNetworkforRecommendation WSDM’25,March10–14,2025,Hannover,Germany\\nBilevel Alignment Structure Augmentation Importance Distillation\\nTeacher Model Intermediate KD Student Model\\nHierarchical Knowledge Distillation\\n𝑤 Prediction-Level Distillation High-order Edges (1,0,0,1)\\nLE ad yg ee\\nr\\nP Pr ru un ni in ng\\ng N Wo e iE gd hg tse （Or Wig ein iga hl tE edd ）ges （Au Wgm\\neP\\niL\\ne\\ngnre\\nhe\\nta\\nted\\ner din\\ndc\\n）e Etid\\ndo\\ngnW\\nes\\nseights𝐖t\\nEmbedd i ng-L ev el D i stillation\\nStructureO r Aig uA in gu ag mlm E ee d nn gt te .s (S 1i ,0m ,0il ,1a )rMask rrreeeyyyaaa 000L =L =L\\n=\\nGE Lm\\ne\\nNab re Nnd id\\nn\\ni Pgng\\nr\\n𝐖P ur nu ,n\\ni𝐄\\nnin gg\\nWeighted Edges\\nsgniddebmE\\nrh eg di\\nrH\\n-o\\nB i l e v e l A l i g n m e n t\\nImI𝑤\\nn\\np𝑖 t𝑡 o, e𝑗\\nr rm taed nSi ta cut ede eL\\nD𝐞ത na𝑖𝑡 t⊤\\ni\\ny\\nM\\ns𝐞 eത t𝑗 r𝑡\\no id lle .l\\nUGe nn\\nieP fru oal\\nl\\nrl\\nl y\\nmC Pl io\\nu\\nts\\ns\\nye\\nh RAw\\neg𝐄𝐄𝐄\\nlllaaannniiiFFF\\naതതത 𝑠𝑠𝑠\\ny\\nFigure2:OverallframeworkoftheproposedLightGNNmodel.\\n3.1 GraphNeuralNetworkPruning runningtimeandthememorycostsofGNNs.ThereforeLightGNN\\nInspiredbythelotterytickethypothesisforGNNs[5,6],wepropose followsthesimilarpruningalgorithmforedgestoprunetheentries\\ntouseonlyasubsetofGNN’sparametersthatmaximallypreserve intheembeddingmatrixE.AsthescalarparametersinEalreadyre-\\nthemodelfunctionality,toimproveitsefficiency.Specifically,the flecttheimportanceoftheircorrespondingentries,LightGNNdoes\\ntimecomplexityforatypicalGNNmodelasaforementionedis notemployextrapruningweightsforembeddings.Analogously,\\n𝐿 𝑑 ,andthespacecomplexityiscorrespondingly LightGNNalternatelyconductsmodeltrainingandparameterprun-\\nO𝐼( ×𝐽 |E|𝑑× .) Thereforebyreducingthenumberofedges O( ,|E an|+ d ingwithratio𝜌 ′%accordingtotheabsolutevalue 𝑒 𝑖,𝑑 ,where\\nt( he+ nu) m× be) rofnon-zeroelementsinthe𝑑embeddingdim| eE n| sions, 𝑒 𝑖,𝑑 representsthe𝑑 ′-thdimensionin𝑖’sembedding| vec′ t| or.\\n′\\nourLightGNNisabletooptimizeboththecomputationalefficiency Inadditiontotheedgesandembeddings,thetimecomplexity\\nandmemoryefficiency.Toachievethis,itisessentialtoidentifythe\\nofGNNssuggeststhatthenumberofgraphpropagationlayers𝐿\\nnoisyandredundantpartsintheedges andtheembeddingtable alsogreatlyimpactsthecomputationtimeofGNNs.Moreover,in\\nE= e𝑖,e𝑗 𝑢 𝑖 ,𝑣 𝑗 ,topreventE performancedegradation. practice,𝐿isalsosignificanttoinfluencethetemporarymemory\\n{ | ∈U ∈V} costsforstackingtheintermediateresults.ThusourLightGNN\\n3.1.1 EdgePruning. Tothisend,LightGNNemploysasparse further reduces the number of graph iterations𝐿 for efficiency,\\nweightmatrixW R𝐼 ×𝐽 foredgepruning.Ifanedge 𝑢 𝑖,𝑣 𝑗 is whichalsoalleviatestheover-smoothingeffectofGNNs[30].\\nacandidateforpru∈ ning,thecorrespondingweight𝑤 𝑖,𝑗 ( inWi) sa\\nlearnableparameter.Otherwise𝑤 𝑖,𝑗 issetas0andisnotoptimized.\\n3.2 HierarchicalKnowledgeDistillation\\nWith the weight matrix W, the graph information propagation\\nprocessfortheprunedGNNisconductedasfollows: 3.2.1 BilevelAlignment. Motivatedbythestrengthofknowl-\\nedgedistillation(KD)incompressingthelearnedknowledgeof\\n1 1\\nE U,𝑙 =D− U2 ·(A ⊙W )·D− V2 ·E V,𝑙 −1+E U,𝑙 −1 (4) a Ld igv ha tn Gce Nd Nm do ed ve els loi pn sto ali hg ih et r- aw re ci hg ih cat lar kc nh oit wec letu dr ge es d[2 is9 t] i, llt ah te iop nro fp rao mse ed\\n-\\nwhere denotestheelement-wiseproductoperatorwhichinjects\\n⊙ work to maximally retain the original high performance in the\\nthelearnableweightsWintotheinformationpropagationprocess.\\nH t th he e er 𝑙e e- mtE h bU a e, n d𝑙, ddE intU h ge,𝑙 m− (1 𝑙 a− t∈ ri1 x)R - f𝐼 t o× h r𝑑 i it td e ere man t so iot ie nn,t tah hne edu 𝑙Ese Vr , 1𝑙e −m -1 tb h∈ed iR td e𝐽i rn × ag 𝑑 tiodta neb .nl Aoe t nein ds p G pr rCu uNn ne e[d d8]G s) tN a rusN ct thm ue ro etd e se a ,l c. ehT mea r bk , ei Ln dig dg iha nt gGw sNe ,l N al- nt ar da lii Ggn n Ne sd NtG h leN aysN t eu rm d seo tnd ote tl m h(e o e. dg te. elL aw cig hih t eht r-\\nD iteUms∈ ,rR e𝐼 s× p𝐼 e, cD tivVel∈ y.R T𝐽 h× e𝐽 ind fe on ro mte att ih oe nd pe rg or pe( ae g− m atia o) t nric te os of bo tr au inse hr is ghan erd\\n-\\nm tioo nd se .l Inw ti hth er pe rs ep de icc tt ioto nb leo vt eh l,h thid ed fe on lloe wm ib ne gd ld oi sn sg fs unan ctd iofi nn ia sl ap pr pe ld iei dc- :\\nord Be ar si et dem onem thb ee pd ad rin amgs eE trVic,𝑙 inis foa rn ma alo tig oo nu psl ry opu asi gn ag tio(A n,⊙ thW ew)⊤ ei.\\nghts\\nL𝑝 −𝑘𝑑 =∑︁ −(cid:16) 𝜎 (𝜖 v𝑡 /𝜏 )·log𝜎 (𝜖 v𝑠 /𝜏 )+𝜎 (𝜖 v𝑡 /𝜏 ))·log𝜎 (𝜖 v𝑠 /𝜏 )(cid:17)\\nv\\nW whip ca hrt ai rc eip ta ht ee ni un seth de foc ral pc ru el da it ci to in onf so ar nfi dn la ol su ss ce ar lc/i ute lam tioe nm s.b Te hd rd oin ug ghs, where v= (𝑢 𝑖,𝑣 𝑗1,𝑣 𝑗2 ), 𝜎 (𝑥 )=1 −𝜎 (𝑥 ), 𝜖 v∗=𝑦ˆ 𝑖∗,𝑗1−𝑦ˆ 𝑖∗,𝑗2 (5)\\nwt flh uhe eeb nra e cc eink op l nar ro pgp rea org da\\n|\\nu𝑤ti c𝑖o i, n𝑗n\\n|\\ng, dW be eni tos tett eu rsn rte ehd ce ot mo edr me gfl eee n(c d𝑢t a𝑖t , th i𝑣 oe 𝑗 n)im h rep a so v ur int lta g sn .ac Ie nlao lrf ig ge e hd r tg ie ons f-, H ane ar le og(𝑢 o𝑖 u, s𝑣 𝑗 t1 o,𝑣 t𝑗 h2 e) Bde Pn Ro lt oe ss st ,h we hr ia lend 𝑣o 𝑗1m aly ndsa 𝑣m 𝑗2p ale rd entr oa tin fii xn eg dtu topl be es\\npositiveornegativesamples.𝜎 denotesthesigmoidfunctionto\\nthisproperty,ourLightGNNframeworkprunesthelessimportant constrainthevaluestobewithi( n·) 0,1 .And𝜏 Risknownasthe\\nedges(noisesorredundancies)aftertraining,specificallybysetting ( ) ∈\\ntemperaturecoefficient[10].Wedenotethepredictionsmadebythe\\nthe𝜌%candidateedgeswiththeleastimportanceto0(see3.2.3),\\nstudentmodelusingthesuperscript𝑠,anddenotethepredictions\\nwhere𝜌 0,100 denotestheproportiontodrop.Thepruning\\n∈ ( ) madebytheteachermodelwiththesuperscript𝑡.Withthistraining\\nalgorithmfollowsaniterativemannerwithmultipleruns.Ineach\\nobjective,ourLightGNNframeworkencouragestheprunedGNN\\nrun,LightGNNfirstconductsparameteroptimizationformodel\\nmodeltomimicthepredictionsmadebythecompleteGNNmodel\\ntrainingandpruningweighttuning,andthenprunestheGNNby\\nwithalltheedges,embeddingentriesandpropagationiterations,\\ndroppingedgesandotherparameters.\\ntoobtaintheteacher’spredictionabilityasmuchaspossible.\\n3.1.2 EmbeddingandLayerPruning. Asindicatedbythecom- Besides the prediction-level alignment, our LightGNN aligns\\nplexityanalysisforGNNs,theparametersforrepresentingusers theteachermodelandthestudentmodelbytreatingtheirlearned\\nanditems(i.e.embeddingsE)alsocontributesignificantlytothe embeddingsaspaireddataviewsforcontrastivelearning.Inspecific,WSDM’25,March10–14,2025,Hannover,Germany GuoxuanChen,LianghaoXia,andChaoHuang\\nthefollowinginfoNCElossfunction[16]isapplied: 𝑤 𝑖𝑠 ,𝑗 W𝑠 of the final student model, the tuned edge weight\\n∈\\n𝑒 𝑘𝑑 = ∑︁ logsoftmax S ,𝑢 𝑖 ∑︁ logsoftmax S ,𝑣 𝑗 𝑤 𝑖𝑡 ,𝑗 ∈W𝑡 oftheintermediateGNNastheteachermodel,andthe\\nL w− here s− of𝑢 t𝑖 m∈ aU x (S U,𝑢 𝑖 )= (cid:205)( 𝑢U e 𝑖 ′x ep x𝑠 p𝑖) ,𝑖 𝑠− 𝑖 ′,𝑣 𝑖𝑗 ,∈V 𝑠 𝑖 ′,𝑖 =cos (e¯𝑠 𝑖 ′,( e¯𝑖𝑡V ) (6) ) e e a¯d 𝑖 n𝑡,g d We¯e 𝑡 w𝑗 ip t∈ er he dR td e h𝑑i fic i. st ni H io e men tr phem oe𝛽a rs1 td p a,e na𝛽 rb c2 s ey d e det dh n ie se o tc iti i len s lait t oe tw inr om o nmhe iad y nti p ra te it hxre ep WG a ¯ erN d𝑠a gN m = e’ es p{t 𝑤 rfi e ¯ urn 𝑖𝑠s n,a 𝑗 ifl } no 𝐼e r g×m ,w 𝐽 tb . hee i ed gd h pi rtn i ung ngs\\n-\\nH bee dr de i𝑠 n𝑖 g′, s𝑖 e¯∈𝑠\\n𝑖\\n′S ,eU¯𝑖𝑡 d foe rn to ht ees ut sh ee rsc 𝑢o 𝑖s ′in ae ndsi 𝑢m 𝑖,il ga ir vit ey nb be ytw the een stuth de enfi tn mal oe dm el- i tn hg ew ene dig -th ot -s eW n¯ d𝑠 min anth ne erfin ua sil ns gtu td he en bt im leo vd ee ll Ka Dre on bo jet co tn ivly est ,ra bi un te ad lsin\\no\\nandtheteachermodel,respectively.Theitem-sideembedding-level\\ndirectlyadjustedbythewell-trainedweightsintheintermediate\\nKDiscalculatedanalogously.Withthisembedding-levelKDobjec-\\nteachermodel.Moreover,byutilizingtheedgeweightsobtainedin\\ntive,ourLightGNNcanbetterguidetheprunedGNNtopreserve\\ntheaugmentedgraph,theprunedGNNisinjectedwiththehigh-\\ntheessentialgraphstructuresandparametersinadeeperlevel.\\norderconnectivitytofacilitateedgedroppingandglobalrelation\\n3.2.2 IntermediateKDLayerforStructureAugmentation. learning.Itisworthnotingthat,apartfromtheedgepruning,the\\nDuetothesparsitynatureoftheuser-iteminteractiondata,some student’sedgeweightsarealsoemployedinthegraphinforma-\\nkeypreferencepatternsarenotreflectedbythedirectneighboring tionpropagation,toenrichtheprunedGNNwithlessedgesbut\\nrelationsbutpreservedbythehigh-orderrelations.Tofacilitate compensatory,adaptiveandinformativeedgeimportance.\\nthe capturing of these high-order connections during our edge\\npruning,weaugmenttheknowledgedistillationofLightGNNwith 3.3 OptimizationwithUniformityConstraint\\nanintermediateKDlayermodelforedgeaugmentation. Inspired by the advantage of learning uniform embeddings in\\nTobespecific,LightGNNconductsatwo-stagedistillation,firstly CF[22,28],ourLightGNNproposestoregularizethemodelop-\\nfromtheoriginalGNNtoanaugmentedGNN,andthenfromthe timizationwithanadaptiveuniformityconstraintbasedoncon-\\naugmentedGNNtothefinalprunedGNN.TheaugmentedGNN trastivelearning.Inspecific,theconstraintminimizesthepairwise\\ndoesnotpruneanyedgesorembeddingentries,butinsteadin- inner-productbetweenembeddingstoenforcerepresentationuni-\\ncludesthehigh-orderconnectionsasaugmentededges.Formally, formity,whilemaximizingtheembeddingsimilaritybetweennodes\\ntheaugmentedGNNhasthesamemodelarchitecture(Eq.4)asthe withsimilarpruningmasks.Inthisway,thepositiverelationsare\\nstudentbutworksoverthefollowingaugmentedinteractiongraph: augmentedbythelearnedpruningweightsforenhancement.For-\\n¯= , , ¯ , ¯ = 𝑢 𝑖,𝑣 𝑗 , 𝑣 𝑗,𝑢 𝑖 𝑎¯𝑖(,ℎ 𝑗) ≠0 (7) mally,theadaptiveuniformityconstraintisasfollows:\\nG (U V E) E {( ) ( )| }\\nw\\ns\\n𝑢yh\\n𝑖m\\n,e 𝑣mre 𝑗e𝑎 t¯ er𝑖(, xiℎ 𝑗\\nc\\ni)\\nsa\\ntd\\nd\\nse\\nj\\nian nco\\ne\\ntt\\nn\\nhe\\nt\\nes mt ah uae\\nt gr\\nme ixn et\\nw\\nnr ty\\ni eth\\ndfo\\ns\\ngr\\ne\\nrl( af𝑢 pl𝑖\\no\\nh, o𝑣 p𝑗 ¯)\\n[\\nii\\n2\\nfn\\n5\\n𝑢]t 𝑖.h\\nI\\nce\\nn\\naℎ no-\\nt\\nbt hh eerp cowo nw\\no\\nnre edr cso\\nt,\\nef\\ne\\nddth\\ng\\ntoe\\ne\\nL𝑢 −𝑟𝑒𝑔 = 𝑢∑︁\\n𝑖\\n∈U(cid:169) (cid:173)\\n(cid:173)\\n(cid:171)−log(cid:205) (cid:205)𝑢 𝑢𝑖 𝑖1 2∈ ∈S U𝑖 ee xx pp (cid:16)(cid:16) ee ¯¯\\n𝑠\\n𝑖𝑠 𝑖 ⊤⊤ ee ¯¯\\n𝑠\\n𝑖𝑠 𝑖 21 // 𝜏𝜏 (cid:17)(cid:17) (cid:170) (cid:174)\\n(cid:174)\\n(cid:172)\\n𝑣 o\\nG\\np( 𝑗 r aNi rv g aNi i ma n da) a en l\\ni tr\\ney g\\ne\\nrr\\nc\\nsp a ,ta p\\nl\\ntyt ohh .\\ni\\npw nW\\nrc\\neit\\nl\\nvih ut eh\\nd\\nnit et ts sh ll oie ts shn is eg ntt gr hh u tics\\ng\\nhh t\\nh\\neuo\\n-\\nkrr oe et re ydar u\\ne\\nht rgh iG gma\\nc\\nhn oe\\n-n\\nono\\nn\\nrr t da ee t ecq i rtou\\ni\\npn oa a, nl ttt\\ns\\ntho eie rℎ\\nn\\nnah stu ho ig np ems\\nrm\\naein dn\\no\\nitt\\nd\\nceh\\ne\\nade\\nl\\nl\\n+\\n𝑣∑︁\\n𝑗\\n∈V(cid:169) (cid:173)\\n(cid:173)\\n(cid:171)−log(cid:205) (cid:205)𝑣 𝑣𝑗 𝑗1 2∈ ∈S V𝑗 ee xx pp (cid:16)(cid:16) e¯e¯ 𝑠𝑠 𝑗𝑗 ⊤⊤ e¯e¯ 𝑠𝑠 𝑗𝑗 21 // 𝜏𝜏 (cid:17)(cid:17) (cid:170) (cid:174)\\n(cid:174)\\n(cid:172)\\n(9)\\nedgepruning.DuringtheintermediateKD,theaugmentedGNNis where 𝑖 and 𝑗 denotethepositivesetsofuser𝑢 𝑖 anditem𝑣 𝑗,\\nS S\\nsupervisedbytheoriginalGNN(noweights),notonlytomimicits respectively,whicharedeterminedbypickingtheusers/itemsthat\\n𝑡\\naccuratepredictions,butalsotolearnproperweightsW forallthe sharethehighestsimilarityinembeddingpruning.Taketheuser\\nedges.TheintermediateKDlayerpreventstheaugmentedlarger sideasanexample,theneighborhoodset 𝑖 isacquiredby:\\nS\\ngraphfromintroducingnoisesusingthesupervisionofthebilevel\\ndistillationfromoriginalGNNandtheadaptiveedgeweights. 𝑖 =(cid:8)𝑢 𝑖1(cid:12) (cid:12) e𝑖 e 𝑖1 0 max(cid:0) e𝑖 0, e 𝑖1 0(cid:1) 𝛿(cid:9) (10)\\nS ∥ ⊙ ∥ ≥ ∥ ∥ ∥ ∥ −\\n3.2.3 ImportanceDistillationforPruning. Afterthefirstknowl- wheree𝑖,e 𝑖1 0,1 𝑑 denotebinarypruningmasksforthe0-th\\ne md og de eld ,i os uti rll La it gio hn tGf Nro Nm thth ene do ir si tg ili ln sa itl sG leN aN rneto dkth ne owau leg dm geen wt ie td hsG trN uN c- e thm eb ee ld emdi en ng t-v we∈ ic st e{ or ms ue} l𝑠 𝑖 tipa ln icd ate i𝑠 𝑖 o1 n, ,r ae nsp dective 0ly d. eO nop te er sat to hr e𝑙⊙ 0nd oen rmote os\\nf\\ntureaugmentationtothefinalprunedGNNmodel.Apartfromthe vectors.𝛿representsthethresholdhy∥ p∗ er∥\\nparameterforsimilarity\\naforementionedbilevelalignment,LightGNNfurtherenhancesthis\\nrelaxation,whichisselectedaccordingtothepruningratio.\\nsecondKDwiththeimportancedistillation,whichexplicitlylever-\\nWiththeabovecontrastivelossusingsimilarly-prunedembed-\\nagesthelearnedimportanceweightsintheintermediatemodel\\ndingsaspositivesets,LightGNNcanlearnuniformly-distributed\\ntoincreasetheprecisionofpruningweightsinthefinalmodel.\\nembeddingswhilecapturingthenode-wisesimilarityduringthe\\nSpecifically,thepruningweightmatrixinthefinalprunedGNNis\\npruningprocess.Combiningitwiththecollaborativefilteringloss\\nacompoundvariablewhoseentriesarecalculatedasfollows:\\n𝑏𝑝𝑟,thebilevelKDlosses 𝑝 𝑘𝑑 and 𝑒 𝑘𝑑,andaweight-decay\\n𝑤¯𝑖𝑠 ,𝑗 =𝑤 𝑖𝑠 ,𝑗 𝛽 1 𝑤 𝑖𝑡 ,𝑗 𝛽 2 𝜎 e¯𝑖𝑡 ⊤e¯𝑡 𝑗 for 𝑢 𝑖,𝑣 𝑗 (8) rL egularizationtermoverpaL ram−etersΘ,L Li−ghtGNNappliesthefol-\\n+ · + · ( ) ( ) ∈E lowingmulti-tasktraininglosswithhyperparameters𝜆 :\\nwhere𝑤¯𝑖𝑠 ,𝑗 Rdenotestheweighttodecideifedge 𝑢 𝑖,𝑣 𝑗 should ∗\\n∈ ( )\\nbepruned,anditisacquiredusingtheindependentedgeweight L=𝜆 0 L𝑏𝑝𝑟 +𝜆 1 L𝑝 −𝑘𝑑 +𝜆 2 L𝑒 −𝑘𝑑 +𝜆 3 L𝑢 −𝑟𝑒𝑔 +𝜆 4 ∥Θ ∥2 F. (11)LightGNN:SimpleGraphNeuralNetworkforRecommendation WSDM’25,March10–14,2025,Hannover,Germany\\nTable1:Statisticaldetailsofexperimentaldatasets. Baselinemethodsareimplementedusingtheirreleasedcodewith\\nDataset #Users #Items #Interactions InteractionDensity gridsearchforhyperparametertuning.Theefficiencytestiscon-\\nAG mo Yw e al za p oll na 742 625 475 615 927 821 369 787 624 127 912 689 624 639 858 073 5 1 1. . .8 5 55 9 1× × ×1 1 10 0 0− − −4 4 4 d 4u .2cted Pon era fd oe rv mice aw ni cth ea Cn oN mVI pD aIA riG se oF norc (ReR QT 1X )3090GPU.\\nWefirstcompareLightGNNtobaselinesonrecommendationaccu-\\n4 Evaluation racy.TheresultsareinTable2.Wemakethefollowingobservations:\\nWeconductextensiveexperimentsonourLightGNNframework, SuperiorperformanceofLightGNN:Theproposedmodel\\n•\\naimingtoanswerthefollowingresearchquestions(RQs): LightGNN surpasses all baselines across different categories,\\nRQ1: How is the performance of LightGNN after the model including simple neural CF, graph-based recommenders, self-\\n• pruning,comparedtoexistingrecommendationmethods? supervisedmethods,andcompressionmethods.Thissuperiority\\nRQ2:HowefficientisourprunedGNN,comparedtobaselines? inperformancedemonstratesthatourlearnablepruningframe-\\n• RQ3:HowdothecomponentsoftheproposedLightGNNimpact workandhierarchicaldistillationparadigmnotonlymaintain\\n• therecommendationperformanceoftheprunedGNN? predictionaccuracyaftermodelcompressionbutalsoenhance\\nRQ4:Howdothepruningratiosimpacttherecommendation existingrecommendationframeworks.Theeffectiveelimination\\n• performanceandtheefficiencyoftheprunedGNN? ofnoiseandredundancyintheinteractiongraphandembedding\\nRQ5:CantheproposedLightGNNframeworkalleviatetheover- parameterscontributestotheseperformanceimprovements.\\n•\\nsmoothingeffectwithitshierarchicalknowledgedistillation? DrawbacksofCFwithoutmodelcompression:Whencom-\\n•\\nRQ6:CanourLightGNNeffectivelyidentifytheredundantand paringthebest-performingCFmethods,suchasself-supervised\\n•\\nnoisyinformationintheuser-iteminteractiongraph? CFtechniqueslikeSGL,HCCF,andSimGCL,tocompression\\nmethodslikeUnKDandSimRec,itisevidentthatCFmethods\\n4.1 ExperimentalSettings withoutmodelcompressionfallshortintermsofrecommenda-\\n4.1.1 Datasets. LightGNN is evaluated using three real-world tionaccuracy.Thisdiscrepancycanbeattributedtothedebiasing\\ndatasets:Gowalla,Yelp,andAmazon.TheGowalladatasetcon- andanti-over-smoothingeffectsembeddedintheknowledgedis-\\ntainsusercheck-inrecordsatgeographicallocationsfromJanuary tillationprocessofUnKDandSimRec.Thissuggeststhatmodel\\ntoJune2010,obtainedfromtheGowallaplatform.Yelpdatasetisob- compressiontechniques,suchasknowledgedistillation,cango\\ntainedfromYelpplatformandcontainsuserratingsonvenuesfrom beyondimprovingmodelefficiency.Theycanalsoaddressad-\\nJanuarytoJune2018.TheAmazondatasetcontainspeople’srat- versefactorspresentinobserveddataandmodelingframeworks,\\ningsofbooksontheAmazonplatform,during2013.Following[29], suchasdatabias,noise,andover-smoothingeffects.\\nwefilteroutusersanditemswithlessthanthreeinteractions,and Importanceofexplicitnoiseelimination:WhileUnKDand\\n•\\nsplittingtheoriginaldatasetsintotraining,validation,andtestsets SimRecrefinethedistilledmodelbyaddressingbiasandover-\\nby70:5:25.Additionally,weconvertratingsintobinaryimplicit smoothingeffectsinGNN-basedCF,theyrelysolelyonhigh-level\\nfeedback,following[8].ThedatastatisticsarelistedinTable1. supervisionmethods.Incontrast,ourLightGNNexplicitlyiden-\\ntifiesandeliminatesfine-grainednoisyandredundantelements\\n4.1.2 EvaluationProtocols. Wefollowcommonevaluationpro-\\nwithinthemodel,suchasedgesandembeddingentries.This\\ntocolsforrecommendation [25,35].Werankalluninteracteditems\\nempowersourLightGNNwithnotablestrengthinrecommender\\nwiththepositiveitemsfromtestsetforeachuser,amethodknown\\nrefinement,leadingtosignificantperformancesuperiority.\\nasfull-rankevaluation.Weusetwocommonmetrics,Recall@N\\nandNDCG@N [24,27]withvaluesof𝑁 =20and40.\\n4.3 EfficiencyTest(RQ2)\\n4.1.3 Baselines. WecompareLightGNNto18baselinesfromdi- Toassessthemodelefficiency,weevaluatethememoryandcom-\\nverse categories, including factorization method (BiasMF [13]), putationalcostsofLightGNNandbaselines.Thecomparedbase-\\ndeepneuralCFmethods(NCF[9],AutoR[19]),graph-basedmeth- linesincludeNGCF,GCCF,HCCF,andexistingGNNcompression\\nods(GCMC[1],PinSage[33],STGCN[36],NGCF[25],GCCF[4], methodUnKD.OurLightGNNistestedwithdifferentpreserva-\\nLightGCN[8],DGCF[26]),self-supervisedrecommenders(SLRec[32], tionratios.InFigure3,theresultsarepresentedrelativetothe\\nSGL[27],NCL[15],SimGCL[34],HCCF[30]),andcompressed performanceofNGCF.Wededucethefollowingobservations:\\nCFapproaches(GLT[5],UnKD[3],SimRec[29]).\\nSimplifiedGNNs.DespitesimplifyingtheGNNarchitectureby\\n•\\n4.1.4 HyperparameterSettings. WeimplementLightGNNwith removingtransformationsandactivations,someGNNmethods\\nPyTorch,usingAdamoptimizerandXavierinitializerwithdefault likeGCCFfailtosignificantlyreducememoryandtimecosts\\nparameters.Forallmodels,thetrainingbatchsizeissetto4096and relatedtographstorageandinformationpropagation.Conse-\\ntheembeddingsizeis32bydefault.ForallGNN-basedmodels,we quently,thecostsofGCCFremaincomparabletothoseofNGCF.\\nsetthelayernumberto2.Weights𝜆 0,𝜆 1,𝜆 2inLightGNNaretuned Thisdemonstratesthelimitationofarchitecturalsimplifications\\nfrom 1𝑒 −𝑘 𝑘 =0,1,...,4 .And𝜆 3istunedinawiderrangewhich inimprovingefficiencyforgraph-basedrecommendation.\\nadditi{ onally| contains 1𝑒} −5,1𝑒 −6 .Theweight𝜆 4forweight-decay SSL-enhanced GNNs. SSL techniques have been utilized to\\nregularizationissele{ ctedfrom } 1𝑒 −𝑘 𝑘 =3,4,...,9 .Alltempera- • enhancegraphrecommendersbygeneratingself-supervision\\nturecoefficientsarechosenfrom{ 1𝑒 |𝑘,3𝑒 𝑘,5𝑒 𝑘} 𝑘 = 1,0,1,2 . signals.However,itisimportanttonotethatthesemethodsmay\\n− − −\\n{ | − }WSDM’25,March10–14,2025,Hannover,Germany GuoxuanChen,LianghaoXia,andChaoHuang\\nTable2:OverallperformancecomparisononGowalla,Yelp,andAmazondatasetsintermsofRecall@N andNDCG@N\\nData Metric BiasMF NCF AutoR PinSage STGCN GCMC NGCF GCCF LightGCN DGCF SLRec NCL SGL HCCF SimGCL GLT UnKD SimRec Ours\\nRecall@20 0.0324 0.0367 0.0525 0.0486 0.0583 0.0837 0.0551 0.0772 0.0868 0.0617 0.0742 0.0955 0.0874 0.0885 0.0921 0.0901 0.0947 0.1067 0.1189\\nNDCG@20 0.0211 0.0234 0.0318 0.0317 0.0377 0.0579 0.0353 0.0501 0.0571 0.0372 0.0480 0.0623 0.5690 0.0578 0.0605 0.0585 0.0607 0.0734 0.0820\\nAmazon\\nRecall@40 0.0578 0.0600 0.0826 0.0773 0.0908 0.1196 0.0876 0.1175 0.1285 0.0912 0.1123 0.1409 0.1312 0.1335 0.1367 0.1355 0.1376 0.1535 0.1677\\nNDCG@40 0.0293 0.0306 0.0415 0.0402 0.0478 0.0692 0.0454 0.0625 0.0697 0.0468 0.0598 0.0764 0.0704 0.0716 0.0730 0.0725 0.0745 0.0879 0.0969\\nRecall@20 0.0867 0.1019 0.1477 0.0985 0.1574 0.1863 0.1757 0.2012 0.2230 0.2055 0.2001 0.2283 0.2332 0.2293 0.2328 0.2324 0.2331 0.2434 0.2610\\nNDCG@20 0.0579 0.0674 0.0690 0.0809 0.1042 0.1151 0.1135 0.1282 0.1433 0.1312 0.1298 0.1478 0.1509 0.1482 0.1506 0.1464 0.1496 0.1592 0.1684\\nGowalla\\nRecall@40 0.1269 0.1563 0.2511 0.1882 0.2318 0.2627 0.2586 0.2903 0.3181 0.2929 0.2863 0.3232 0.3251 0.3258 0.3276 0.3269 0.3301 0.3399 0.3597\\nNDCG@40 0.0695 0.0833 0.0985 0.0994 0.1252 0.1390 0.1367 0.1532 0.1670 0.1555 0.1540 0.1745 0.1780 0.1751 0.1772 0.1730 0.1766 0.1865 0.1962\\nRecall@20 0.0198 0.0304 0.0491 0.0510 0.0562 0.0584 0.0681 0.0742 0.0761 0.0700 0.0665 0.0806 0.0803 0.0789 0.0788 0.0812 0.0819 0.0823 0.0879\\nNDCG@20 0.0094 0.0143 0.0222 0.0245 0.0282 0.0280 0.0336 0.0365 0.0373 0.0347 0.0327 0.0402 0.0398 0.0391 0.0395 0.0400 0.0392 0.0414 0.0443\\nYelp\\nRecall@40 0.0307 0.0487 0.0692 0.0743 0.0856 0.0891 0.1019 0.1151 0.1175 0.1072 0.1032 0.1230 0.1226 0.1210 0.1213 0.1249 0.1202 0.1251 0.1328\\nNDCG@40 0.0120 0.0187 0.0268 0.0315 0.0355 0.0360 0.0419 0.0466 0.0474 0.0437 0.0418 0.0505 0.0502 0.0492 0.0498 0.0507 0.0493 0.0519 0.0553\\nTable3:AblationstudyofLightGNNmeasuredbyRecall@20.\\n1.0 Parameters 1.2 x4 Time\\nStorage Size FLOPs Dataset Gowalla Yelp\\n1.0\\n0.8 RatioE .33/.44 .26/.37 .11/.19 .08/.16 .33/.77 .26/.74 .11/.60 .08/.57\\n0.8 /E\\n0.6 ~EmbP 0.2197 0.1946 0.0741 0.0586 0.0809 0.0737 0.0434 0.0357\\n0.6\\n~EdgeP 0.2418 0.2255 0.1341 0.1133 0.0867 0.0850 0.0745 0.0709\\n0.4 Prn\\n0.4 ~BothP 0.1800 0.1434 0.0556 0.0421 0.0736 0.0661 0.0311 0.0231\\n0.2 0.2 BnEdge 0.2210 0.2021 0.1280 0.1165 0.0872 0.0858 0.0775 0.0754\\n0.0 0.0 -BiAln 0.2350 0.2281 0.1934 0.1812 0.0810 0.0801 0.0666 0.0650\\nHCCFNGCFGCCFUnKD .33,.4 .4 26,.3 .7 13,.2 .3 08,.16 HCCFNGCFGCCFUnKD .33,.4 .4 26,.3 .7 13,.2 .3 08,.16 KD -IntKD 0.2607 0.2571 0.2100 0.1890 0.0822 0.0825 0.0788 0.0769\\n(a)Storagecosts. (b)Timecosts. -ImpD 0.2593 0.2564 0.2135 0.1923 0.0862 0.0861 0.0808 0.0797\\nFigure3:Diskstorageandtimecostsofbaselinesandour LightGNN 0.2610 0.2578 0.2162 0.1966 0.0879 0.0877 0.0856 0.0842\\nLightGNNunderdifferentpreservationratios(e.g..33,.44\\nEffectivenessoftheGNNpruningtechniques.\\ndenotepreserving33%embeddingentriesand44%edges).\\n~EmbP,~EdgeP,~BothP:Wereplacethelearnablepruningwith\\n•\\nrandomdropping.Thethreevariantsreplaceembeddingpruning,\\nintroduceadditionaloperations,leadingtoincreasedmemory\\nedgepruning,andboth,respectively.Significantperformance\\nandtimecosts.ThisisexemplifiedbytheperformanceofHCCF,\\ndropcanbeobservedunderdifferentpruningratios,indicating\\nwhereutilizingextrahypergraphpropagationnecessitatesmore\\ntheeffectivenessofourlearnablepruninginidentifyingthees-\\nFLOPsandyieldsanoticeableincreaseincomputationaltime.\\nsentialembeddingentriesandedges.Especially,whendropping\\nExisting compressed GNNs. UnKD has been successful in\\n• withhighratios(e.g.preservingonly11%and8%entries),thepre-\\nachievingefficiencyimprovements,particularlyintermsofcom-\\ndictionabilityoftherandomvariantsexperiencesadestructive\\nputationaltime.However,whencomparingUnKDtoLightGNN,\\n(over70%)decay,whileLightGNNpreservesmostofitsaccuracy.\\nasignificantdisadvantagebecomesevident.Thislimitationarises\\n𝑠\\nBnEdge:TostudytheeffectoflearnededgeweightsW ,BnEdge\\nfromUnKD’slackofexplicitidentificationandremovalofre- • 𝑠\\nusesbinaryedgeweightsinsteadofW duringGNNpropagation.\\ndundancyandnoiseintheGNNmodel.Asaresult,UnKDis\\nThoughitmaintainsthelearnablepruningprocessunchanged,a\\nunabletoprunealargerportionoftheGNNtoachievesuperior\\nnoticeabledegradationcanbeobserved.Thissuggeststhecrucial\\nefficiencyimprovementslikeourLightGNNframeworkdoes.\\nroleoflearnedweights.Theynotonlyidentifywhichedgesto\\nEfficiencyofLightGNN.Theresultsdemonstrateasignificant\\n• prune,butalsoeffectivelypreservetheprunedinformation.\\nmemoryreductionof70%inLightGNN,consideringboththe\\nparameternumberandstoragesize.Moreover,thereisanimpres-\\nEffectivenessofknowledgedistillation.\\nsivereductionofover90%inFLOPsduringforwardpropagation -BiAln:ToassessthesignificanceoftheKDconstraintsforef-\\n•\\nandanover50%reductioninphysicalpredictiontime.These fectivepruning,weremovethebilevelalignment,includingthe\\nefficiencyoptimizationscanbeattributedtotwokeyaspects. prediction-levelandembedding-levelKD.Thenotableperfor-\\nFirstly,thelearnableGNNpruningparadigmaccuratelyremoves mancedropverifiestheimportanceofaligningtheteachermodel\\nredundantandnoisyinformationfromtheGNN.Thisfacilitates withtheprunedmodel,toeffectivelyretainmodelperformance.\\nefficientutilizationofcomputationalresources.Secondly,our -IntKD:ThisvariantremovestheintermediateKDlayerinLight-\\n•\\nlearnablepruningmechanismissupervisedbythehierarchical GNN.Asaresult,itsperformancenotablydeteriorates,particu-\\nKD,whichincorporatesmulti-dimensionalalignmentandhigh- larlyontheYelpdataset.Theincreasedimportanceofthismodule\\norderstructureaugmentation.Thismaximizestheretentionof forYelpcanbeattributedtothehighersparsityofthedataset.In\\nperformance,allowingformoreextensivepruningofparameters. suchcases,theintermediateKDlayerisabletoseekmoreedges\\nfromhigh-orderrelationstoenrichthesmalledgeset.\\n4.4 AblationStudy(RQ3)\\n-ImpD:Thisvariantremovestheimportancedistillation,and\\n•\\nWeinvestigatetheeffectivenessofLightGNN’stechnicaldesigns theresultsconfirmthebenefitsofincorporatinglearnededge\\nusingGowallaandYelpdata,withdifferentpruningratios.The weightsandpredictionsfromtheintermediateKDlayermodel\\nresultsareshowninTable3.Wemakethefollowingobservations. intothedecision-makingprocessofedgedropping.LightGNN:SimpleGraphNeuralNetworkforRecommendation WSDM’25,March10–14,2025,Hannover,Germany\\nPreserv.Ratio%\\n0 1 2 3 4 5 6 7 8 9 10 11\\n(Embed.,Edge)\\nMildPrune 100,10080,9564,9051,8641,8133,7726,7421,7017,6613,6311,608,57\\nAggressivePrune100,10080,8564,7251,6141,5233,4426,3721,3217,2713,2311,198,16\\nTable4:PreservationRatiosofEmbeddingsandEdges\\n1.0\\n0.5\\nTaPbrelseer5v.:RMatAioD%amongpopularnodesfromYelpandGowalla. 0.0\\nD(Eatmasbeetds.,EGdgCeC)F L0 ightGC1 N N2 CL 3 SG4 L S5 imGC6 L Si7 mRec8 Ou9 rs 10 11 0.5 MildPrune 100,10080,9564,9051,8641,8133,7726,7420,7017,6613,6310,608,57 1.0 AgYgerlepssiveP0.r8u7n4e7100,100.8088109,85604.,87922591,610.84614,53233,04.9412063,37201.,93227127,270.1934,203411,198,16 1.0 E0m.5be0d.0din0g.5s 1.0\\nGowalla 0.8206 0.8269 0.8236 0.7760 0.8595 0.8406 0.8742 FiguTraeb4le:4C:oPmrepseurtvaattiioonnaRlaFtLioOsPofsE(bmabresd)dainndgsraencdomEdmgeesndation 0.2\\nperformance(lines)w.r.tdifferentpreservationratios. 0.0 2 Ang0les 2\\nofembeddings.Bothmethodsexhibithigheruniformityinthe\\n-eIsmtimpaDte:dItdriestmribouvteiosnthcoemimpapreodrttaonLceighdtiGstCilNla,twiointh,aSnimdGtChLeresults\\n(a)Gowalla (b)Amazon • ceoxnhfiibrimtingthseombeenseufipetsrioorfitdyirdeucetltyoiitnscloesrsp-orarnadtionmgaluegamrneendtaw- eights\\n(a)GowaF lli ag du ar tae se4 t.:Hyperparamete (br )S At mu ad zoy ndataset. ft ri oo mnd te hs eig in n. tieiir)mC eo dm ip aa tere Kd Dto lS ai ym eG rC inL, toou tr hP er fiun ne aG lN prN ue nx eh dib mits odel. evenfewerdarkregionsintheembeddingring,indicatinghigher\\nuniformity.Thisadvantagebecomesmoreapparentintheangle- (P Er mes be erv da dt ii no gn s,R Ea dti go es% ) 0 1 2 3 4 5 6 7 8 9 10 11 4.5baseIdnplflotu,wehnecreethoefloPwrpuronbainbilgitieRsaarteiomsuc(hRclQos4er)tothe MildlyPrune 100,100 80,95 64,90 51,86 41,81 33,77 26,74 20,70 17,66 13,63 10,60 8,57 AggressivelyPrune 100,100 80,85 64,72 51,61 41,52 33,44 26,37 21,32 17,27 13,23 11,19 8,16 InthhigishoenxepseirnimPreunnte,GwNeNi.nTvheisstoibgsaetrevatthioenismtrponacgtlyoinfdpicrautnesinagratios Tabl (e c)4 E: mP br ede ds ie nr gv aa ndti eo dn geR pra et sei ro vs ato iof nE ram tiob se ofd dd i\\uffffin erg ens ta dn egd reE esd .ges forh eig dh ge er sa an nti d-ov ee mr- bsm edo do it nhi gng enab tril ii ety so of nou br oP thru mne oG dN eN l, pw eh rfic oh rmca an\\nnceand beascribedtoouruniformityconstraintenhancedbyincorporat-\\nFigure4:ComputationalFLOPs(bars)andrecommendation effi ic ni(gea)n nLc oigy dhe.t-GF wCig iNsu er se im4 ils arh i(o tby)wSleGc aLa rs ne es dt bh ye t(hce)evSeaimmluGbaCetLde dd inm gpo rd u(e ndl)inpOgue .rxrsxfo xrmance performance(lines)w.r.tdi\\ufffferentpreservationratios.\\nandcomputingFLOPs(floatingpointoperations)acrossvarious\\nFiMguearen5A:vEemrabgeedDdiisntgandciest(rMibAuDti)oVnasliunest.hTeo2p-Derfsoprmaceamanodrein\\np•reservationratios.Wepresenttwopruningschedules:amildprun-\\n-ImpD:Itremovestheimportancedistillation,andtheresults thqeua1n-DtitaatnivgeleanspalaycseisfoofrtYheelpthdisaitsassueet,,wesetfiumrtahteerdmbeyaKsuDreE.the •\\ncon\\uffffrmthebene\\ufffftsofdirectlyincorporatinglearnedweights\\ningMsAchDedvuallueetsh[a2t]rfeomroouvresPrfuenweeGrNgNraapnhdesdixgbeassienlintheseoGnNtNhe,andan\\nfromtheintermediateKDlayerintothe\\uffffnalprunedmodel. agTgYarebellpsesa5inv:deMGpAorwDuanalilmangdoanstgacshpeetosdp.uHulliegahrtehnraoMtdAreesDmfvroaovlmueessYmienldpoircaeanteeddsGtgroeowsn.gaBelrlaas.edon\\nthesmreosoutlhtisn,gwee\\uffffedcrtaawmothngetfhoelltoewstinnogdeosb.sFeorllvoawtiinogns[2:7],weeval- Datasets GCCF LightGCN NCL SGL SimGCL SimRec Ours\\n4 In.5 thisI en x\\uffff peu rie mn ec ne t,o wf eP inr vu esn tii gn ag teR tha et ii mo ps a( cR toQ f4 p) runingratios • P du p sG ieeoa noY trt wpe ge ifl u sapo lt el plh aar nare m rtu tM r0 0 ias ic. .8 8 eeA un7 2r sl4 0D sc a7 6 area lm nn yc dde eh0 0t \\uffff1 gr . .a8 8i e0 r8 2c n c01 6 ato 9 9g0 pin vep he.a o iA ep n0 0s d. .ua s8 8 dg9 2m l ewa2 3 et9 6rp esel i c,e t tde0 0 wd i. .mi n8 7sn e6 7 gcs4 6o .a t3 0 od hTr be edh ss oi0 0 eae s v. . r9 8t ecl1 5 vc a r0 9h e-o 3 5ro sgn mi acs eei ocrs 0 0 oot o. .n9 8i tnfn 2 4 hu7 0t tg im2 6e ninso gbtf ueen0 01 o\\uffff. .ro0 9 8 ue4 7d0 o cs0 40 ef t4 2 de em cb lie nd e-\\nforedgesandembeddingentriesonbothmodelperformanceand e\\uffffc(iae)nLcigyh.tGFCigNure4sho(bw)cSaGsLestheev(ac)luSiamtGedCLmodelpe(dr)foOrumrsance iwn ri ept che orM mfoA mrDm en.aT dn ahc te ie oe. nvHa plou ew ra fte oiov rn merr a,e nist cu eilst wsna hor eet nepw pre ro usre ntn ih ntye gdt thi hna eTt sae abv mlee en5 p.w orh tie on nasub-\\nsOtabnsetiravlaptioorntsi:oin)TohfetGhNeNG-bNaNsedmCoFdpealraidsirgemmsGovCeCdF,aonudrLPigrhut-neGNN a pF tn rhi edg esu ec 1rro -vem Dat5p ia: ou nE nt gim rn laegb tiseF opdL sa.dO cWiP en es fg po(\\uffffd rreoi Yssa eett nr li pni tbg tdu wp at oi too apinn sreuts tno ,i inp ene sgt trh ia smctei ho a2 en t- desD ud) leas bspc y:ra ao Kcs mes Diav lEdna .r pdi roi uun ns - cG moo dC enf a tN tsi han i ossf g deo te te sr .nm n tTe hta r h alt ay tii l so elymn mobeo pasxn lie onh r yt itvh ba cae i oit tnA nil os tom n rw aaa s sez tuhr io g vin Mg eghed lA esa atDlt se ra nvs tv ihe e nat ell guc .opo e Trfm s e hrsc ip e seoa cn omr oc be p emd sea ot rmro f ve ad met th n iote oodr nG eao hto rti iehw gode hna ur -l nl pa -erfor-\\ningschedulethatremovesfewergraphedgesintheGNN,andan mdaanncceycoormnopisaereindtthoeSAimmaGzoCnLdaantad,wLhigichhtGalCigNns.wThitihstrheeslialiregnercecan lightstheinherentover-smoothingissueinpropagation-based aggorfeisnsfiovrempartuionninognstchheeAdumleaztohnatdaretamseotvceosmmpoarreededtogeths.eBGaoswedalolan b gen raua pmt htbr neibr euuo rft aee ldd eg nteo cs ota dhn eed rsuh .s iie ie )rrs Fa/ oritc rehm thisc eap olr te hKs eeD rn btm ain so etd lh iu ne elAe s,,m wwa ezho oinc bh sd eae rt vffa eseect.tively\\nthedraetsausletts.,Twheisdorabwsertvhaetifoonlloswuginggesotsbstherevparteiosnens:ceofmoreredun- atlhiagtnNsCtLhaenpdrSeGdLicsthioownslowoferthMeADstuvadleunest,imndoicdaetlinwgaitshtrothngoesreofthe\\nPdearnfcoyrmorannociseecihnatnhegeA.mAaszwoneddiastcaa,rwdhaiclahrgaleirgnnsumwibtehrtohfeelmarbgeedr- 4wo.6veellr--psAmenrofototihr-miOngivneeg\\uffffret-ceSta.mTchhoiesorsthmhedoisndlegiglhEtth\\uffffornoeutchgtehSlimtbuiiltdeatvyioenl(RsaolQifgt5nh)emirentand\\n• dniunmgbeenrtroifesedagnedsgarnadpuhseedrsg/eitse,mwseporebsseenrtveinathcoenAtimnauzoounsddaetcalsiente. irmanpdoormtasntcruecdtuisretialluagtmioenn.taAtidodnitmioenthaoldlys,,wthheicihnaterermsuesdceiapttieblKeDlayer\\nToassesstheabilityofPruneGNNtomitigatetheover-smoothing\\ninperformance.However,itisnoteworthythatevenwhenasub- ew\\uffffto eitcthth oesftin Gru\\uffff NucNetun scrdee uo raf iundggamt ta heenno pti ras uetn.ioii nini g)fT purhroetchs euesspr,eewrni eohr ciaotynmco pef asS ri etmhthGeeCrdeL icsa ton rmid bum-enda-\\n4.s6tantAialnptoir-tOiovneorf-tShmeGoNoNthminodgelEis\\uffffreecmtoSvetdu,doyur(PRrQun5e)GNN ttiS oioi nmnuRanebic fiolviratmylid ibta yyte oisnftcohoueri rrpmeo\\uffff oreadctetilin’v sge edmmesobi ergedn deo idf ngp geu sss whsi ian thmg taphlll oee sdm efb ore fod bmd ai snhegilgs inhe-order\\nTocoanssseissstetnhtelyabmilaitiyntoafinPsruanheGigNhNletvoelmoiftirgeacteomthmeeonvdera-tsimonooptehrifnogr- mra eep ltaa htr oit od.I snn .sT.co Thm ihsp eca sor emis fo epn aa, truo isu roer nsP icr su on clloe eG ncdtN iuvN ceta leyc dh cii onev nte tws riof bu udrt tih mee ter ona std ihv oea nn src .oe Wb- uestper-\\ne\\uffffmecatnocefGcoNmNpsadruedrintogSthimeGprCuLnianngdpLriogchetsGs,CwNe.cTohmispraerseiltiheencdeisctrain- eflm oabre mon rt aas tnb ecy tehc eao nn exdst pr reu erc cit moin meg nmtm aele nsa en dti atn itng igofu snl ip nco aAs pi pati pbv eie nlis dta iiem xsAp ol .e 7f.p oa uir rs Pu rs uin ng eGNN. bubteioantturnibifuotremdittyootfhoeuhrimeroadreclh’siceamlbKeDddminogdsuwleit,hwthhoicsheoef\\uffffbeacsteilvineley node-wisesimilarityinembeddingpruning.Thistechniquee\\uffffec-\\nmaeltihgondss.tThheisprceodmicptairoinsosnoifstchoendsutuctdeednitnmtwoodedlimweinthsiotnhsosaesboeflothwe. •EtiVffiveisclyuieaennlihczaaynticcoehnsaponofgsiEetim.vAebrseedtlahdteiionpngrluDeanirsinntirgnibgruainttiiaoonsle.aiFnrrncoarmbelaetshmeesa,enPmnrebure.nde-GNN\\nwell-performingteachermodelthroughbilevelalignmentand • exd hin ibg id tsist ari sb iu gt nio in fis cap nlo ttt de ed ci rn eF ai sg eur ie n5 F, Lw Oe Pca sn .To hbs iser cv oe nth fia rt m:i s)T thh ee effec-\\n• wiV am l ii i tp zs ho iu n sra g ttl rai utnz h cca e tet ui ed ro m ein s b ato i uelf dl ga d mE t iim n eo ngnb t. de aA i td s idd otrd ni in i bt fg ui uo t rD n i to hai ns l elt ry or , fi eb t nohu huet r ai i no Pn cn rt ee u. sr nW m te he Ge edb N rie a N eg t ci e oan mlK ob D n my g ev l sa ni is y d du e e a- r\\n-\\n4.t7ic nvl oeu tns aNt e be so lr ysi in s sog tef re oea\\uffff nnne ghc edt a rno R fob c res ine d Lr g iuv ge hGnd tdN Gi an CNn Nb eco ,ffiyt dh ecI m2 ide- oD en nnc sp y ttl ro i ab\\ufffft ts y ic na a gpn tr td iu hoa ennn i sng e(l vge R erep Q emlo 6 ot b v)s e ei rds -dings\\ntt ih onre ae bb ile is tyt- bp yer if no cr om re pd orC aF tinb gas mel oin rees e, dn ga em sse aly mL pi lg eh dt fG roC mN, hS igG hL -, oa rn ded\\nr\\nInatn shmdisoseotxtrphueic nrit gmu ere\\uffffenest,c. twS rep ee sinucvli tefi isnctgiagl fal rytoe, mooutu hrr ePPritur eunreanGte ivNG eNN e’msNabba eidclidhtyii neignv sepmsruoanon-thF -LOPs\\nrS ei lm atG ioC nsL .. TF ho er st eh fi es av tuis ru ea sl ciz oa llt eio ctn i, vew lye cr oan nd tro ibm ul ty es toel te hc et r2 o0 b0 u0 si tte pm er- inrgeindnoguicspetairaoannddiogremfd9.u0in i%)dTadnoucayrdiindnrgethsfsoetrohwbissaeirrsdvseupder,ioSnpGteaLrgaacanttidioonSnidmwaGtahC.iFlLeiginmucraoeir6npota-ining\\nfn oono rmtd oe aas n2a c-s eDs asa npm dap creele cus os. miT nmh ge te-s nSe dNn aEo tiad one nde cnm aopb rame bd aid lliii tzn ieeg dss uoa sfr ie onugth rthe Pn eriurp n;r 2eo Gnje oNc rt mNed .s. s Nhc 9ooo 5ir ow sam %fets eep wPc maco rhor bn uan iec nlbt dr er iel dnaet pise gnetp .ei grve Fx sfer ia o.gfm Bl ro ue morrpa em trl ihen n6sai ( mgn ano )gn ec si te it ld hmlo uet oo sea idt lnl ar siSnh a rei tga lm xe yn sw hGc titei bowtCh it o tLhLt he i, sh ge iaed ghtnsi s hse td eot Gri rfsia Cbs l un euu NnaetF iri .s fnoL. oTenO rd hmuP ewn is sti e eyfr io ge isr nhd um tu btsi hc sty et ti ao nn tio af\\nl\\n•\\nEN\\uffffexcti,ewnecyescthimanatgeet.hAesdtihsetrpibruutnioenraotfiotshienscerseaamsepsl,eoduermPrbuendedGinNgNs in reWedsutf io cmr taie otd eng dses dinio sn tFrt Lih bOe uPtl ie soft nhs ici gd ohe m, lia pgl ao hrn teg dthw teoith eLffu iges he cr ttGs iv’ Ct ee Nnx e,t swr se iv toi he fw oSs iuma rn Gld\\neCaLrnable\\neuxshinibgitdseanssiigtynie\\uffffsctaimntadtieocnrebaasseeidnoFnLOGPasu.sTsihainsckoenrn\\ufffferlmss(KthDeEe).\\uffffIenc- ratingsforthecorrespondingitemsontherightside.Itisimportant tFivigeunreess5,owfeenphraensecnintgthGeNreNsuel\\ufffftscaisenhceyattmhraopusgihntthheep2r-Dunsipnagcoe,f topnre oux thneiib tnhigt ai tnstgthrs eaottem egxe tys rieunvp iemer wiionsriaimt ny dizd riu anteginto gcosimt ws epl reuests na- ortia ton end xapolm osoepa duetgroamtoeiuon rntas-.\\ntiondesign.iii)ComparedtoSimGCL,ourPruneGNNexhibits\\newmhbeerdeddianrgksearncdolsotrruincdtuicraetse.sShpiegchi\\uffffercaplrlyo,boaubirliPtyr.uAnedGdiNtiNonaacllhyi,ewvees PrDu enivffe eG neNrfeNewnm ecroeddsael ra. kIcn rreot gh ise osnp srde iansettnahtseeed etmcsa.bs eeFdsu, dro intuhgrerPrir nmu gno,e irnGedN,icNiatta iis nss giwg hn ioe grd htehrmen-\\nadnisFpLlaOyPtshereedsuticmtiaotnedofprxoxb%abwilhitiyledmenasiintytawin.rin.tgacnogmlesp.arableper- •lo tw iuow nniie fni og grh mt ts ihtyt ao .tTt oh hue isrin aPdt re vur aa nnc ett ai Go gn Nes Nbb ee cdt ow emme ee osn nmD s3ot1rr0eaa taen psd pbaE re1e7tn0t4et, ria nps trw heee sl eal rna vgs\\nalet-ionof\\nfOorbmsearnvcaetitoonSsi:mi)GTChLe,calunsdtearinngFLe\\uffffOePcstorbedseurcvteiodninobfoxthx%plowtshiilse be rt ew bcae ose men dD mp44elo7n0t,da wan td hioeE r4ne64pt1h. eeI rn flt ooe rwr mes pt ai rn nog cbl eay b, wt ih lihe tis eee nse apd rg ree us mna iul ni cg ghn tcw hloi et sh esraus mte or es t’\\nhpeortion\\npneortfaobrmlyisntgrosnimgeilrafrolyrLtoigLhitgGhCtGNC,Nde.mThonessetrsautibnsgtatnhteiaslerveedruecotvioenr-s negativefeedback,suchaslowratingsandcommentslike\"toosalty.\"\\nisnmFoLoOthPisngheig\\uffffhelcitgrhetsuthlteineg\\ufffffercotmivtehneesitseroaftiovueremlebaernddabinlegspmruonoitnhg- Inotfh hii egnh cfooo nrnmtee xas ttiin oofnP gr rou ann pe htGhCNeFN ,At. hmT eah sezisononeb gds aeatr itvvaeastefi eto encdobsmatr copknaig nrlesy tdai nntocd eitc sha aet re eGsaowalla\\nhigheranti-over-smoothingabilityofourPruneGNN,whichcan\\nsitnrgatpeagryadinigmmi.niii)mTioziandgdcreosmspthuitsaitsisounea,lSoGpLeraantdioSnims.GCLincorpo- consideredasregularuser-iteminteractions,potentiallyimpacting\\nbeascribedtothesparsi\\uffffcatione\\uffffectcausedbyembeddingprun-\\nratecontrastivelearningtoenhancethedistributionuniformity themodelingofuserpreferencesinanadversemanner.Similar\\nDi\\ufffferencesacrossdatasets.Furthermore,itisworthmen- ing,andtheuniformityconstraintinourPruneGNN.\\n•\\ntioningthatourPruneGNNdemonstratesbetterpreservationof\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5 1.0 1.0E0m.5be0d.0din0g.5s 1.0\\n0.4 0.2\\n0.0 2 Ang0les 2\\n(a)LightGCN\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5 1.0 1.0 E0m.5be0d.0din0g.5s 1.0\\n0.2\\n0.0 2 Ang0les 2\\n(b)SGL\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5 1.0 1.0 E0m.5be0d.0din0g.5s 1.0\\n0.2 0.1\\n0.0 2 Ang0les 2\\n(c)SimGCL\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5\\n1.0\\n1.0 E0m.5be0d.0din0g.5s 1.0\\n0.2\\n0.0 2 Ang0les 2\\nFigure4:ComputationalFLOPs(bars)andrecommendation\\nperformance(lines)w.r.tdifferentpreservationratios.\\n4.5 InfluenceofPruningRatios(RQ4)\\nInthisexperiment,weinvestigatetheimpactofpruningratios\\nforedgesandembeddingentriesonbothmodelperformanceand efficiency.Figure4showstheevaluatedmodelperformanceand\\ncomputingFLOPs(floatingpointoperations)duringforwardprop-\\nagationacrossvariouspreservationratios.Wepresenttwopruning\\nschemes:amildpruningschemethatremovesfew(edr)Ogurrasphedges\\nintheGNN,andanaggressivepruningschemethatremovesmore Figure5:Embeddingdistributionsinthe2-Dspaceandin\\nedthgees1.-BDaasendgloenspthaecerefosurlYtse,lpwdeadtraaswet,tehsetifmolalotewdinbgyoKbDsEer.vations:\\nTPabelrefo5r:mMaAnDceamchoannggpeo.pAuslawrendoidsecsarfdroamlaYregleprannudmGboerwoaflleam. bed- • dingentriesandgraphedges,weobserveacontinuousdecline Datasets GCCF LightGCN NCL SGL SimGCL SimRec Ours inperformance.However,itisnoteworthythatevenwhenasub- Yelp 0.8747 0.8819 0.8929 0.8643 0.9103 0.9272 0.9404\\nsGtaownatlilaalp0o.8r2t0i6ono0f.8t2h6e9GN0N.82m36od0e.7l7i6s0rem0.8o5v95ed,o0.u84r0L6igh0.t8G74N2Ncon-\\nsistentlymaintainsahighlevelofrecommendationperformance\\ndataset.Thisobservationsuggeststhepresenceofmoreredun-\\ncomparedtoSimGCLandLightGCN.Thisresiliencecanbeat-\\ndancyornoiseintheAmazondata,whichalignswiththelarger\\ntributedtothehierarchicalKD,whicheffectivelyalignsthepre- numberofedgesandusers/itemspresentintheAmazondataset.\\ndictionsofthestudentmodelwiththoseofthewell-performing\\nteachermodelthroughbilevelalignment,andtheimportancedis- 4.6 Anti-Over-SmoothingEffectStudy(RQ5)\\ntillationthatgivestheoptimaldroppingstrategies.Additionally, ToassesstheabilityofPruneGNNtomitigatetheover-smoothing theintermediateKDlayerwithstructureaugmentationfurther\\neffectofGNNsduringthepruningprocess,wecomparethedistribu-\\nenhances the recommendation ability by incorporating more tionuniformityofourmodel’sembeddingswiththoseofbaseline\\nedgessampledfromhigh-orderrelations.Thesefeaturescollec- methods.Thiscomparisonisconductedintwodimensions.We tivelycontributetotherobustperformanceofLightGNN. elaboratetheexperimentalsettingsinAppendixA.7.\\nEVffiiscuiaelnizcayticohnaonfgEem.AbesdtdhiengprDuinsitnrigburatitoion.inFcrormeasthees,eLmigbehdt-GNN •• exdihnigbidtisstarisbiugtnioinfiscapnlotttdeedcirneFaisgeuirne5F,LwOePcsa.nTohbissercvoentfihramt:si)tThheeeffec-\\nticvleunsteesrsinogfeeffnehctanobcsinergveGdNinNbeoffithc2ie-nDcpylobtysapnrdunainnggleepmlobtesdisdings\\nannodtasbtrlyucstturornegs.erSpfoercLifiigchatlGlyC,Nou,dreLmigohntsGtrNatNingacthheiesveevseraeFoLveOrP-sre-\\ndsumctoiootnhiongf9eff0%ectdruersiunltginfgorfrwomartdhepritoepraatgivaetieomnbwedhdiilnegmsmaoinottahi-ning\\ncoin mg pp aar ra ad bi lg em p. eiir)foTo rmad ad nr ce ess tt ohi Ss ii mss Gue C, LSG ,aL na dnd aS Fim LOG PC sL rin ec do ur cp to i-\\nonof\\nratecontrastivelearningtoenhancethedistributionuniformity 95%whileperformingsimilarlytoLightGCN.Thesesubstantial\\nofembeddings.Bothmethodsexhibithigheruniformityinthe reductionsinFLOPshighlighttheeffectivenessofourlearnable estimateddistributioncomparedtoLightGCN,withSimGCL\\npruningstrategyinminimizingcomputationaloperations. exhibitingsomesuperiorityduetoitsless-randomaugmenta-\\nDtiioffnedreesnigcne.siaiic)rCoosmspdaarteadsteotsS.imFuGrCthLe,romuroPreru,niteiGsNwNoretxhhimbietsntion-\\n• inegvetnhfaetwoeurrdaLrikghretgGioNnNsindethmeoenmsbtreadtdeinsgbreitntge,rinpdriecsaetrinvgathiiognheorfrec-\\noumnmifoernmdiatyt.ioTnhipseardfvoarnmtaagnecbeecwohmeensmprourenianpgpatrheentsianmtheeparnogpleo-rtion\\nobfainsefdorpmloatt,iwonheornetthheelAowmapzroobnadbialtitaiseestacroemmpuacrhedclotosetrhteoGthoewalla\\nhighonesinPruneGNN.Thisobservationstronglyindicatesa dataset.Thisobservationsuggeststhepresenceofmoreredun-\\nhigheranti-over-smoothingabilityofourPruneGNN,whichcan\\ndancyornoiseintheAmazondata,whichalignswiththelarger\\nbeascribedtothesparsificationeffectcausedbyembeddingprun-\\nnumberofedgesandusers/itemspresentintheAmazondataset. ing,andtheuniformityconstraintinourPruneGNN.\\nMeanAverageDistance(MAD)Values.Wefurtherevaluate\\n•\\ntheMADvalues[4,33]inTable5,fromwhichwedrawthefol-\\nlowingobservations:i)TheGNN-basedCFparadigmsGCCFand\\nLightGCNgenerallyexhibitlowerMADvaluescomparedtoother\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5\\n1.0\\n1.0 E0m.5be0d.0din0g.5s 1.0\\n0.4\\n0.2\\n0.0 2 Ang0les 2\\n(a)LightGCN\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5\\n1.0\\n1.0 E0m.5be0d.0din0g.5s 1.0\\n0.2\\n0.0 2 Ang0les 2\\n(b)SGL\\nytisneD\\n1.0\\n0.5\\n0.0\\n0.5\\n1.0\\n1.0 E0m.5be0d.0din0g.5s 1.0\\n0.2 0.1\\n0.0 2 Ang0les 2\\n(c)SimGCL\\nytisneD\\n(d)Ours\\nFigure5:Embeddingdistributionsinthe2-Dspaceandin\\nthe1-DanglespaceforYelpdataset,estimatedbyKDE.\\nTable4:MADamongpopularnodesfromYelpandGowalla.\\nDatasets GCCF LightGCN NCL SGL SimGCL SimRec Ours\\nYelp 0.8747 0.8819 0.8929 0.8643 0.9103 0.9272 0.9404\\nGowalla 0.8206 0.8269 0.8236 0.7760 0.8595 0.8406 0.8742\\n4.6 Anti-Over-SmoothingEffectStudy(RQ5)\\nToassesstheabilityofLightGNNtomitigatetheover-smoothing effectofGNNsduringthepruningprocess,wecomparethedistri-\\nbutionuniformityofourmodel’sembeddingswiththoseofbaseline methods.Thiscomparisonisconductedintwodimensions.\\nVisualizationofEmbeddingDistribution.Fromtheembed-\\n• dingdistributionsplottedinFigure5,wecanobservethat:i)The\\nclusteringeffectobservedinboth2-Dplotsandangleplotsis\\nnotablystrongerforLightGCN,demonstratingthesevereover-\\nsmoothingeffectresultingfromtheiterativeembeddingsmooth- ingparadigm.ii)Toaddressthisissue,SGLandSimGCLincorpo- ratecontrastivelearningtoenhancethedistributionuniformity\\nofembeddings.Bothmethodsexhibithigheruniformityinthe\\nestimateddistributioncomparedtoLightGCN,withSimGCLex-\\nhibitingsomesuperiorityduetoitsless-randomaugmentation\\ndesign.iii)ComparedtoSimGCL,ourLightGNNexhibitseven\\nfewerdarkregionsintheembeddingdistributionring,indicating\\nhigheruniformity.Thisadvantagebecomesmoreapparentinthe\\nangle-basedplot,wherethelowprobabilitiesaremuchcloserto thehighonesinLightGNN.Thisobservationstronglyindicates\\nahigheranti-over-smoothingabilityofourLightGNN,which\\ncanbeascribedtothesparsificationeffectcausedbyembedding pruning,andtheuniformityconstraintinourLightGNN.\\nMeanAverageDistance(MAD)Values.Wefurtherevaluate • theMADvalues[2,29]inTable4,fromwhichwedrawthefol-\\nlowingobservations:i)TheGNN-basedCFparadigmsGCCFand\\nLightGCNgenerallyexhibitlowerMADvaluescomparedtoother\\nmethodsthatemploycontrastivelearning.Thisobservationhigh-\\nlightstheinherentover-smoothingissueinpropagation-based\\ngraphneuralencoders.ii)Fortheotherbaselines,weobserve\\nthatNCLandSGLshowlowerMADvalues,indicatingastronger\\nover-smoothingeffect.Thisshedslightonthelimitationsoftheir\\nrandomstructureaugmentationmethods,whicharesusceptible\\ntotheinfluenceofdatanoise.iii)ThesuperiorityofSimGCLand\\nSimRecvalidatestheireffectivedesignofpushingallembeddings\\napart.Incomparison,ourLightGNNachievesfurtheradvance-\\nmentsbyconstructingmeaningfulpositivesamplepairsusing\\nnode-wisesimilarityinembeddingpruning.Thistechniqueeffec-\\ntivelyenhancespositiverelationlearninginalearnablemanner.WSDM’25,March10–14,2025,Hannover,Germany GuoxuanChen,LianghaoXia,andChaoHuang\\n(a) Review for <U 310 , V 1704>: Honestly, I know a lot of people who withintheGNNencoder,andDGCF[26],whichincorporatesarep-\\nV loves this place. For metheir soup base is just way too salty…she\\n0.84 1704 even found it salty. It burned our tongues… resentationdisentanglementmoduleintograph-basedcollaborative\\n0.90 V 2749 R t so ee w rv vni ie c. w eC … afo mr e < hU e3 r1 e0 a , cV o2 u74 p9 l> e: o O f n tie m o ef s .t .h . e A b me att ze ir n J ga p anan de is me pp el ca cc ae bs li en fi prlt ie or rin grg a. pL hig nh et uG rC alN ar[ c8 h] ia ten cd tuG rC esC aF n[ d4 a] ce hm iep vh ea is miz pe rt oh ve edre pd eu rn fod ra mnc ay ncin e\\nU\\n310 0.93 V 2755 R Ue nv lii ke ew mfo or s t< TU h3 a10 i p, lV ac27 e5 s5 …>: My favorite favoritefavoriteThai place. (a) by Rel ei cm ei nn ta lyti ,n sg elb f-o st uh pn eo rn vi- sli en dea ler aa rn nd inl gine (Sa Sr Lm )a hp ap sin gg as in. ed attention\\nU Review for <U 4470 , V 4641>: ...boyfriend suffered though...They foritsabilitytogeneraterichsupervisionsignalsandaddressthe\\n4470 should have issued a warning on those hot peppers...they were too\\n0.74 datasparsityprobleminrecommendation.Contrastivelearning\\nspicy to eat. He picked them off the last slice, but by then, the\\n1.27 damage was done. (CL)-basedgraphCF(e.g.SGL[27],SimGCL[34],DirectAU[22],\\nU\\n14498 Review for <U 14498 , V 4641>: Warm, welcoming, and wonderful AdaGCL[12])isapopularSSLtechniquethateffectivelylearnsa\\nV 4641 staff...The food was amazing and very fairly priced...\\nU 14631 1.44 R sae nv di wew ic f ho r I e< vU e1 r4 h63 a1 d , . V W4 e64 a1> ls: o R he aa dl l qy u g ao lio tyd sf eo ro vd i. c. e. . Bestchicken u Hn Cif Co Frm [3d 0i ]st ar nib du Ntio Cn Lt [o 1c 5o ]u inn tte ror dth ue ceov ae dr d- is tm ioo no at lh ein ng coe dff ie nc gto vf ieG wN sN tos.\\n(b) U U U enrichgraphCL.Inaddition,graph-basedrecommendationhasalso\\n23 33 216 1.06\\nbeenenhancedwithgenerativeSSLtechniquesbasedonmasked\\n1.22 0.85 0.80 1.12 1.01 0.83 V 2081 autoencoding,suchasAutoCF[28]andDGMAE[17].\\n1.12 1.13 1.02\\nDespitethesubstantialenhancementsinrecommendationperfor-\\nV 181 V 182 V 187 V 52 V 279 V 293 V 2064 V 2068 V 2077 manceduetoGNNadvancements,aninherentlimitationremains\\nCategory:ChineseRestaurants Category: American Bars Category: Bubble Tea (b) intheinefficiencyofGNN’sextensiveinformationpropagationand\\nnode-specificparameters.Inthiscontext,ourLightGNNaimsto\\nFigure6:Investigationonthecapabilityof(a)noisepruning\\neffectivelypruneredundantandnoisycomponentsofGNNswhile\\nand(b)redundancypruningforourLightGNNframework.\\npreservinghighperformancethroughdistillationconstraints.\\n4.7 NoiseandRedundancyIdentification(RQ6) 5.2 ModelCompressionforGraphModels\\nWeexploreLightGNN’scapacitytotrimnoiseandredundancyin ToenhancethescalabilityofGNNs,priorworkshaveutilizedran-\\ninteractiondata.TheresultsaredetailedinFigure6. dom node and edge sampling techniques for large graphs (e.g.,\\nNoise Pruning. In Figure 6(a), two sets of decision weights in PinSAGE[33],HGT[11]).However,theserandomstrategiesdo\\nW¯𝑠\\nforleft-sideedgesaredepictedalongsideusers’textreviews notensurethepreservationofcrucialinformationandmaysignifi-\\nandratingsforcorrespondingitemsontheright.Notably,these cantlyaffectmodelperformance.Inresponse,severalapproaches\\nreviewsandratingswerenotexposedtoourLightGNN.Ourre- haveemergedtobetterretainimportantpatternsfromtheoriginal\\nsultsshowthatLightGNNassignslowweightstointeractionslike model.GLT[5]advocatesforpreservingonlytheessentialedgesby\\n<𝑢 310, 𝑣\\n1704\\n>and<𝑢 4470, 𝑣\\n4641\\n>,aligningwithusers’negative\\nlearningtheirimportancetodownstreamtaskperformance.Other\\nfeedback(e.g.,\"toosalty.\").InthecontextofgraphCF,suchnegative studiesimprovecompressionsupervisionthroughknowledgedis-\\nfeedbackinstancesareviewedasregularuser-iteminteractions, tillation.GLNN[37]andSimRec[29]proposedistillingefficient\\npossiblyadverselyaffectinguserpreferencemodeling.Frequent studentmodelsbasedonMLPfromheavierGNNs.UnKD[3]further\\nsimilarobservationsinourresultsshowthatLightGNNeffectively mitigatesbiasintheKDprocessusingastratifieddistillationstrat-\\nidentifiesandaddressesnoiseinthegraphstructure,therebyim- egy.Additionally,KDhasbeenappliedtocompressrecommenders\\nprovingthepruningeffectofGNN-basedrecommendation. basedonnon-GNNarchitectures(e.g.,[21,31]).\\nRedundancyPruning.InFigure6(b),somerepresentativecases Incontrasttopreviousapproachesthatbroadlyreducemodel\\ndemonstrate the efficacy of redundancy pruning in LightGNN, complexitybysubstitutingGNNswithsimplerarchitectures,our\\nwherethreeusersinteractwithmultiplevenuessharingthesame LightGNN preserves robust topology extraction capabilities of\\ncategorieslikeChineserestaurantsandAmericanbars,reflectingre- GNNs.Itachievesefficiencybyexplicitlyidentifyingandeliminat-\\ndundantuserinterestinformation.Despitebeingcategory-agnostic, ingredundancyandnoisewithinGNNstructuresandembeddings.\\nLightGNN identifies these similarities, assigning lower weights This strategy effectively mitigates misinformation in the graph\\ntosomeoftheredundantitems.Thisencouragesthepruningal- whileenhancinginterpretabilitythroughprunedinformation.\\ngorithmtoeliminatetheredundancy,therebyenhancingmodel\\nefficiency.Moreover,thankstothelearnableedgeweightsinthe 6 Conclusion\\nintermediateKDlayer,LightGNNpreservespreferencestrengthfor Thispaperintroducesanovelpruningframework,LightGNN,aimed\\neachinterest,ratherthanrelyingonitemcountsofeachinterest. ataddressingscalabilityandrobustnesschallengesinGNN-based\\ncollaborativefiltering.LightGNNexplicitlymodelstheprobabilities\\n5 RelatedWork ofredundancyandnoiseforeachedgeandembeddingparame-\\nter within the GNN recommender, enabling precise pruning of\\n5.1 GraphNeuralRecommenderSystems\\nmisinformation.Itisdrivenbyinnovativehierarchicaldistillation\\nGraph neural networks (GNNs) have emerged as foundational\\nobjectivesthatleveragehigh-orderrelationsandmulti-leveldistil-\\narchitecturesforrecommendationsystems.Earlyworkssuchas\\nlationtoenhanceperformanceretention.Extensiveexperiments\\nNGCF[25]andGCMC[1]introducedgraphconvolutionalnetworks\\ndemonstratethatLightGNNoutperformsbaselinesinrecommen-\\n(GCNs)forcollaborativerecommendation.Subsequentstudiesin-\\ndationperformance,compressionefficiency,androbustness.\\ncludeSTGCN[36],whichintegratesanautoencodingarchitectureLightGNN:SimpleGraphNeuralNetworkforRecommendation WSDM’25,March10–14,2025,Hannover,Germany\\nReferences [21] J.TangandK.Wang. Rankingdistillation:Learningcompactrankingmodels\\n[1] R.v.d.Berg,T.N.Kipf,andM.Welling.Graphconvolutionalmatrixcompletion. withhighperformanceforrecommendersystem.InACMSIGKDDInternational\\narXivpreprintarXiv:1706.02263,2017. ConferenceonKnowledgeDiscovery&DataMining(KDD),pages2289–2298,2018.\\n[2] D.Chen,Y.Lin,W.Li,P.Li,J.Zhou,andX.Sun.Measuringandrelievingthe [22] C.Wang,Y.Yu,W.Ma,M.Zhang,C.Chen,Y.Liu,andS.Ma. Towardsrepre-\\nover-smoothingproblemforgraphneuralnetworksfromthetopologicalview. sentationalignmentanduniformityincollaborativefiltering.InACMSIGKDD\\nInAAAIConferenceonArtificialIntelligence(AAAI),volume34,pages3438–3445, ConferenceonKnowledgeDiscoveryandDataMining(KDD),pages1816–1825,\\n2020. 2022.\\n[3] G.Chen,J.Chen,F.Feng,S.Zhou,andX.He.Unbiasedknowledgedistillation [23] W.Wang,F.Feng,X.He,L.Nie,andT.-S.Chua. Denoisingimplicitfeedback\\nforrecommendation.InACMInternationalConferenceonWebSearchandData forrecommendation.InACMInternationalConferenceonWebWearchandData\\nMining(WSDM),pages976–984,2023. Mining(WSDM),pages373–381,2021.\\n[4] L.Chen,L.Wu,R.Hong,K.Zhang,andM.Wang. Revisitinggraphbased [24] W.Wang,Y.Xu,F.Feng,X.Lin,X.He,andT.-S.Chua.Diffusionrecommender\\ncollaborativefiltering:Alinearresidualgraphconvolutionalnetworkapproach. model.InternationalACMSIGIRconferenceonresearchanddevelopmentinInfor-\\nInAAAIConferenceonArtificialIntelligence(AAAI),volume34,pages27–34, mationRetrieval(SIGIR),2023.\\n2020. [25] X.Wang,X.He,M.Wang,F.Feng,andT.-S.Chua.Neuralgraphcollaborative\\n[5] T.Chen,Y.Sui,X.Chen,A.Zhang,andZ.Wang.Aunifiedlotterytickethypoth- filtering.InInternationalACMSIGIRConferenceonResearchandDevelopmentin\\nesisforgraphneuralnetworks.InInternationalConferenceonMachineLearning InformationRetrieval(SIGIR),pages165–174,2019.\\n(ICML),pages1695–1706.PMLR,2021. [26] X.Wang,H.Jin,A.Zhang,X.He,T.Xu,andT.-S.Chua. Disentangledgraph\\n[6] J.FrankleandM.Carbin.Thelotterytickethypothesis:Findingsparse,trainable collaborativefiltering. InInternationalACMSIGIRconferenceonresearchand\\nneuralnetworks.InInternationalConferenceonLearningRepresentations(ICLR), developmentininformationretrieval(SIGIR),pages1001–1010,2020.\\n2018. [27] J.Wu,X.Wang,F.Feng,X.He,L.Chen,J.Lian,andX.Xie.Self-supervisedgraph\\n[7] C.Gao,Y.Zheng,N.Li,Y.Li,Y.Qin,J.Piao,Y.Quan,J.Chang,D.Jin,X.He,etal.A learningforrecommendation.InInternationalACMSIGIRConferenceonResearch\\nandDevelopmentinInformationRetrieval(SIGIR),pages726–735,2021.\\nsurveyofgraphneuralnetworksforrecommendersystems:Challenges,methods,\\n[28] L.Xia,C.Huang,C.Huang,K.Lin,T.Yu,andB.Kao.Automatedself-supervised\\nanddirections.ACMTransactionsonRecommenderSystems(TRS),1(1):1–51,2023.\\nlearningforrecommendation. InTheACMWebConference(WWW),pages\\n[8] X.He,K.Deng,X.Wang,Y.Li,Y.Zhang,andM.Wang.Lightgcn:Simplifyingand\\n992–1002,2023.\\npoweringgraphconvolutionnetworkforrecommendation.InInternationalACM\\n[29] L.Xia,C.Huang,J.Shi,andY.Xu.Graph-lesscollaborativefiltering.InTheACM\\nSIGIRconferenceonresearchanddevelopmentinInformationRetrieval(SIGIR),\\nWebConference(WWW),pages17–27,2023.\\npages639–648,2020.\\n[30] L.Xia,C.Huang,Y.Xu,J.Zhao,D.Yin,andJ.Huang.Hypergraphcontrastive\\n[9] X.He,L.Liao,H.Zhang,L.Nie,X.Hu,andT.-S.Chua. Neuralcollaborative\\ncollaborativefiltering.InInternationalACMSIGIRConferenceonResearchand\\nfiltering.InTheACMWebConference(WWW),pages173–182,2017.\\nDevelopmentinInformationRetrieval(SIGIR),pages70–79,2022.\\n[10] G.Hinton,O.Vinyals,andJ.Dean.Distillingtheknowledgeinaneuralnetwork.\\n[31] X.Xia,H.Yin,J.Yu,Q.Wang,G.Xu,andQ.V.H.Nguyen.On-devicenext-item\\narXivpreprintarXiv:1503.02531,2015.\\nrecommendationwithself-supervisedknowledgedistillation.InInternational\\n[11] Z.Hu,Y.Dong,K.Wang,andY.Sun.Heterogeneousgraphtransformer.InThe\\nACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval\\nACMWebConference(WWW),pages2704–2710,2020.\\n(SIGIR),pages546–555,2022.\\n[12] Y.Jiang,C.Huang,andL.Huang. Adaptivegraphcontrastivelearningfor\\n[32] T.Yao,X.Yi,D.Z.Cheng,F.Yu,T.Chen,A.Menon,L.Hong,E.H.Chi,S.Tjoa,\\nrecommendation.InInternationalConferenceonKnowledgeDiscoveryandData\\nJ.Kang,etal.Self-supervisedlearningforlarge-scaleitemrecommendations.In\\nMining(KDD),pages4252–4261,2023.\\nACMInternationalConferenceonInformation&KnowledgeManagement(CIKM),\\n[13] Y.Koren,R.Bell,andC.Volinsky. Matrixfactorizationtechniquesforrecom-\\npages4321–4330,2021.\\nmendersystems.Computer,42(8):30–37,2009.\\n[33] R.Ying,R.He,K.Chen,P.Eksombatchai,W.L.Hamilton,andJ.Leskovec.Graph\\n[14] Y.Koren,S.Rendle,andR.Bell.Advancesincollaborativefiltering.Recommender\\nconvolutionalneuralnetworksforweb-scalerecommendersystems. InACM\\nsystemshandbook,pages91–142,2021.\\nSIGKDDInternationalConferenceonKnowledgeDiscovery&DataMining(KDD),\\n[15] Z.Lin,C.Tian,Y.Hou,andW.X.Zhao.Improvinggraphcollaborativefiltering\\npages974–983,2018.\\nwithneighborhood-enrichedcontrastivelearning.InTheACMWebConference\\n[34] J.Yu,H.Yin,X.Xia,T.Chen,L.Cui,andQ.V.H.Nguyen.Aregraphaugmen-\\n(WWW),pages2320–2329,2022.\\ntationsnecessary?simplegraphcontrastivelearningforrecommendation.In\\n[16] A.v.d.Oord,Y.Li,andO.Vinyals. Representationlearningwithcontrastive\\nInternationalACMSIGIRConferenceonResearchandDevelopmentinInformation\\npredictivecoding.arXivpreprintarXiv:1807.03748,2018.\\nRetrieval(SIGIR),pages1294–1303,2022.\\n[17] Y.Ren,Z.Haonan,L.Fu,X.Wang,andC.Zhou. Distillation-enhancedgraph\\n[35] A.Zhang,W.Ma,X.Wang,andT.-S.Chua.Incorporatingbias-awaremargins\\nmaskedautoencodersforbundlerecommendation.InInternationalACMSIGIR\\nintocontrastivelossforcollaborativefiltering.AdvancesinNeuralInformation\\nConferenceonResearchandDevelopmentinInformationRetrieval(SIGIR),pages\\nProcessingSystems(NeurIPS),35:7866–7878,2022.\\n1660–1669,2023.\\n[36] J.Zhang,X.Shi,S.Zhao,andI.King. Star-gcn:stackedandreconstructed\\n[18] S.Rendle,C.Freudenthaler,Z.Gantner,andL.Schmidt-Thieme.Bpr:Bayesian\\ngraphconvolutionalnetworksforrecommendersystems.InInternationalJoint\\npersonalizedrankingfromimplicitfeedback.arXivpreprintarXiv:1205.2618,2012.\\nConferenceonArtificialIntelligence(IJCAI),pages4264–4270,2019.\\n[19] S.Sedhain,A.K.Menon,S.Sanner,andL.Xie. Autorec:Autoencodersmeet\\n[37] S.Zhang,Y.Liu,Y.Sun,andN.Shah. Graph-lessneuralnetworks:Teaching\\ncollaborativefiltering. InTheACMWebConference(WWW),pages111–112,\\noldmlpsnewtricksviadistillation. InInternationalConferenceonLearning\\n2015.\\nRepresentations(ICLR),2021.\\n[20] X.SuandT.M.Khoshgoftaar. Asurveyofcollaborativefilteringtechniques.\\n[38] S.Zhang,L.Yao,A.Sun,andY.Tay.Deeplearningbasedrecommendersystem:A\\nAdvancesinArtificialIntelligence,2009,2009.\\nsurveyandnewperspectives.ACMcomputingsurveys(CSUR),52(1):1–38,2019.WSDM’25,March10–14,2025,Hannover,Germany GuoxuanChen,LianghaoXia,andChaoHuang\\nA EthicalConsiderations toachievehighcompressionratesmightcompromisetherobust-\\nnessoftheGNNmodel,makingitmoresusceptibletoadversarial\\nA.1 EthicalImplications\\nattacksorunexpectedbehaviors.\\nThe proposed research on LightGNN, a distillation-based GNN\\npruningframework,introducesinnovativetechniquesformodel A.2 MitigationStrategies\\ncompressioninGraphNeuralNetworks(GNNs)toreducemodel\\nBelow,weintroducesomepossiblemitigationstrategies.\\ncomplexitywhilepreservingrecommendationaccuracy.Whilethe\\nadvancementsinthisfieldarepromising,thereareethicalimplica- •\\nPrivacy-PreservingTechniques.Implementencryptionand\\nanonymizationmethodstoprotectuserdatawhileensuringthat\\ntionsthatneedtobeconsideredsincegraph-basedrecommendation\\nthepruningprocessdoesnotcompromiseindividualprivacy.\\nsystemsoftenrelyonsensitiveuserinteractiondata.\\nPrivacyConsiderations.GNN’sutilizationofuserinteraction Security Audits. Conduct thorough security assessments to\\n• •\\ndataraisesconcernsaboutprivacy.Thepruningprocessmust identifyandaddresspotentialvulnerabilitiesintroducedbythe\\nsafeguardagainstunauthorizedaccesstosensitiveuserinfor- pruningframework,ensuringdataintegrityandsystemsecurity.\\nmationcontainedwithinthegraphdata.Besides,theremoval TransparencyandAccountability.Maintaintransparencyin\\n•\\nofedgesandembeddingentriesduringcompressionshouldbe thepruningprocess,providingclearexplanationsofhowcompo-\\nconductedinamannerthatdoesnotinadvertentlyexposeor nentsareprunedandenablinguserstounderstandandchallenge\\nretainidentifiableuserinformation. therecommendationsmadebythesystem.\\nInconclusion,whileLightGNNshowspromiseinreducingmodel\\nSecurityandSafety.Pruningcomponentsbasedonlearnable\\n• complexitywhileretainingrecommendationperformance,itisim-\\nalgorithmsmayintroducevulnerabilitiesthatcouldcompromise\\nportantforresearchersanddeveloperstoprioritizeethicalconsid-\\ntheintegrityoftherecommendationsystem,potentiallyleading\\nerationstomitigatepotentialnegativesocietalimpactsanduphold\\ntodatabreachesormanipulation.Moreover,aggressivepruning\\ntheintegrityandfairnessofAIsystemsinrecommendation.',\n",
       " 'Lived Experience Not Found LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use.pdf': 'Lived Experience Not Found: LLMs Struggle to Align with Experts on\\nAddressing Adverse Drug Reactions from Psychiatric Medication Use\\nMohitChandra1,SiddharthSriraman1,GauravVerma1,HarneetSinghKhanuja1,\\nJoseSuarezCampayo2,ZihangLi3,MichaelL.Birnbaum4,MunmunDeChoudhury1\\n1CollegeofComputing,GeorgiaInstituteofTechnology\\n2HospitalGeneralUniversitarioGregorioMarañón\\n3HofstraUniversity,4ColumbiaUniversity\\n{mchandra9, sidsr, gverma, hkhanuja3}@gatech.edu; jsuarezc@salud.madrid.org\\nzli56@pride.hofstra.edu; michael.birnbaum@nyspi.columbia.edu; munmun.choudhury@cc.gatech.edu\\nAbstract\\nAdverseDrugReactions(ADRs)frompsychi-\\natricmedicationsaretheleadingcauseofhospi-\\ntalizationsamongmentalhealthpatients. With\\nhealthcaresystemsandonlinecommunitiesfac-\\ninglimitationsinresolvingADR-relatedissues,\\nLargeLanguageModels(LLMs)havethepo-\\ntentialtofillthisgap. Despitetheincreasing\\ncapabilitiesofLLMs,pastresearchhasnotex-\\nFigure1: Overviewofwork; wepresenttwotasksin\\nploredtheircapabilitiesindetectingADRsre-\\nthiswork–ADRdetectionandmulticlassclassification\\nlated to psychiatric medications or in provid-\\n(RQ1),andExpert-LLMresponsealignment(RQ2).\\ningeffectiveharmreductionstrategies. Toad-\\ndressthis,weintroducethePsych-ADRbench- individualsworldwidehavinglimitedornoaccess\\nmarkandtheAdverseDrugReactionResponse\\ntomentalhealthprofessionals(KazdinandRabbitt,\\nAssessment(ADRA)frameworktosystemati-\\n2013),manypatientsincreasinglyturntosocialme-\\ncallyevaluateLLMperformanceindetecting\\ndiaplatformssuchasReddittoshareexperiences\\nADRexpressionsanddeliveringexpert-aligned\\nmitigationstrategies. Ouranalysesshowthat andseekadvice(Leeetal.,2017;DeChoudhury\\nLLMsstrugglewithunderstandingthenuances etal.,2014). Yet,around35%ofpostsonmental\\nofADRsanddifferentiatingbetweentypesof health-relatedsubredditsgounanswered,leaving\\nADRs.WhileLLMsalignwithexpertsinterms manywithoutadequatesupport(Guimarãesetal.,\\nofexpressedemotionsandtoneofthetext,their\\n2021). Further, while social media offers a plat-\\nresponses are more complex, harder to read,\\nform for seeking assistance with resolving ADR\\nandonly70.86%alignedwithexpertstrategies.\\nqueries,responsesarefrequentlyprovidedbyindi-\\nFurthermore,theyprovidelessactionablead-\\nviduals lacking expertise, raising concerns about\\nvicebyamarginof12.32%onaverage. Our\\nworkprovidesacomprehensivebenchmarkand thereliabilityoftheinformationshared(Vosoughi\\nevaluation framework for assessing LLMs in et al., 2018; Wang et al., 2019). Hence, as con-\\nstrategy-driventaskswithinhigh-riskdomains. versationalAIplatforms(suchasChatGPT)gain\\nprominence,moreindividualsareturningtothese\\n1 Introduction\\nsystems for healthcare-related queries, including\\nthoseaboutpsychiatricmedicationandADRs.\\nAdverse Drug Reactions (ADRs)1 caused due to\\npsychiatricmedicationsarealeadingcauseofhos- Giventhecurrentlimitationsofhealthcaresys-\\npitalizationsamongindividualswithmentalhealth tems and social media platforms, alongside the\\nconditions,accountingfor51.9%to91.8%ofcases, growing capabilities of LLMs in mental health-\\nasreportedinpreviousstudies(AngadiandMathur, relatedtasks(Yangetal.,2023,2024;Singhaletal.,\\n2020;Ejetaetal.,2021). Withnearly70%of 2023b),LLMshavethepotentialtobridgethegap\\nin online discussions by providing high-quality,\\n1AnAdverseDrugReaction(ADR)isdefinedasanap-\\ncontextualresponsestoADRqueriesrelatedtopsy-\\npreciablyharmfulorunpleasantreaction,resultingfroman\\ninterventionrelatedtotheuseofamedicinalproduct,which chiatricmedications. Whilepreviousstudieshave\\npredictshazardfromfutureadministrationandwarrantspre- focused on detecting ADRs using deep learning\\nventionorspecifictreatment,oralterationofthedosagereg-\\nmethods, these efforts have primarily addressed\\nimen,orwithdrawaloftheproduct.(EdwardsandAronson,\\n2000). non-mental health-related ADRs (Mesbah et al.,\\n5202\\nnaJ\\n7\\n]LC.sc[\\n3v55191.0142:viXra2019a; Sarker and Gonzalez, 2015; Karimi et al., RQ1resultsshowthatbothADRdetectionand\\n2015). DetectingADRsrelatedtopsychiatricmed- ADRmulticlassclassificationarechallengingtasks,\\nicationsandevaluationoffeedbackresponsesfrom withthetopmodelinafew-shotsettingachieving\\nLLMstowardsADR-relatedqueries,remainsunex- F1 scores of 75.38 and 76.69 in respective tasks.\\nplored. Thisgapisparticularlysignificantbecause We observed that all models exhibited a “risk-\\naddressing ADRs caused by psychiatric medica- averse” nature, leading to a false-positive rate of\\ntions presents unique challenges, given the com- over70%. Additionally,modelsstruggledwithnon-\\nplex interplay between mental health conditions, dose-relatedandtime-relatedADRs,withGPT-4\\ntheir symptoms, and the potential for psychiatric Turbo misclassifying 51% and 50% of these in-\\nmedicationstoeitheralleviateorexacerbatethose stances, highlighting difficulties in grasping nu-\\nissues. Furthermore, for LLMs to meaningfully anced ADR types. For RQ2, LLM-generated\\ncontributetoonlinediscussionsandeffectivelyad- responses were significantly harder to read than\\ndressADR-relatedqueries,itisessentialtorigor- expert-written responses. In contrast, there was\\nously evaluate the quality of their long-form text no observed significant difference in emotional\\nresponsesandtheiralignmentwithexpertknowl- or tone alignment between LLM and expert re-\\nedge in specialized domains such as psychiatry. sponses. However,thebestmodel(OpenBioLLM-\\nThisevaluationmustconsidertheLLMs’abilityto 70B) achieved only 70.86% alignment with ex-\\ngrasp the complexities of psychiatric medication pertharm-reductionstrategies,andLLMsprovided\\nADRsanddeliverresponsesthatarecontextually 12.32%lessactionableadviceonaverage. Given\\nnuanced. Additionally,thereisaneedtoevaluate theobservations,ourresearchhasimportantreal-\\ntheabilityofLLMstoaccuratelyportraythelived worldimplications. Theproposedbenchmarkpro-\\nexperiences2 ofhealthcareprovidersinaddressing videsaresourceforevaluatingLLMsontasksin-\\nADR-related queries which has been considered volvingtheinteractionbetweenmentalhealthcon-\\nasanimportantfactorinprovidingeffectivemen- ditionsandpsychiatricmedications. Theproposed\\ntalhealthsupport. Inresponsetotheseneedsand frameworkholdpracticalutilityforpolicymakers,\\nchallenges,weaddressthefollowingresearchques- practitioners,andhealthcareprofessionalstoassess\\ntions: LLM performance, especially in strategy-driven\\ntasksinhigh-riskdomains. Thecoderepositoryfor\\nRQ1: HoweffectivelydoLLMsdetectconcernsof\\nthisworkcanbefoundhere3.\\nADRsassociatedwithabroadrangeofpsychiatric\\nmedications? Additionally,howaccurateareLLMs\\n2 DataCollectionandCuration\\ninclassifyingdifferenttypesofADRs?\\nRQ2: TowhatextentdotheresponsesfromLLMs Webeginbyprovidingthedetailsofthedatacol-\\nalign with those from clinicians across different lection and filtering pipeline. We used publicly\\naspectswhenaddressingADRqueries? availabledatainEnglishfromRedditspanning a\\none-yearperiod(January2019-December2019)\\nTo answer the above stated research\\nobtained from Pushshift Reddit Dataset (Baum-\\nquestions, we present Psych-ADR bench-\\ngartner et al., 2020). While the broad timeframe\\nmark and Adverse Drug Reaction Response\\nensureslargeenoughdatabeforefiltering,thespe-\\nAssessment (ADRA) framework. The proposed\\ncificperiodalso(a)predatestheuseofgenerative\\nPsych-ADRbenchmarkincludes239Redditposts,\\nAIinday-to-daylivesand(b)theknowledgecutoff\\nlabeled across two hierarchical levels for ADR\\nfor all LLMs used in our evaluation. This allows\\ndetectionandmulticlassclassificationalongwith\\nfor a fairer comparison between human experts\\nexpert-writtenresponsestoqueries. Theproposed\\nand LLMs and also ensures minimal presence of\\nframework evaluates LLM-generated responses\\nmachine-generatedcontentonReddit.\\nagainst those of medical experts, focusing on\\nFollowingthepastwork(Mesbahetal.,2019b;\\nfour assessment axes: (a) text readability, (b)\\nSahaetal.,2019;Chancelloretal.,2019),wese-\\nemotion and tone expression, (c) alignment of\\nlected 10 subreddits that focus on mental health-\\nharm-reductionstrategies,and(d)actionability\\nrelated issues or provide a platform for users to\\nofsuggestedstrategies.\\nask medical queries (such as r/depression and\\n2Personalknowledgeabouttheworldgainedthroughdi-\\nrect, first-handinvolvementineverydayeventsratherthan 3https://github.com/mohit3011/\\nthroughrepresentationsconstructedbyotherpeople. Lived-Experience-Not-Foundr/askdocs; see Appendix A for the complete list). of ADR it belonged to along with providing rea-\\nToextractrelevantposts,wecompiledasetof297 soningforit(detailsrelatedtotheannotationtool\\nFDA-approved psychiatric medications provided inAppendixD).\\nbySahaetal.(2019). Further,todetectexpressions The annotation task proved to be challenging\\nofadversesymptomsinposttitlesandtexts,weem- for the annotators, with an average time of ∼7.2\\nployedHealthE(Gattoetal.,2023),aspecialized minutestakentoannotateeachpostduetothecom-\\nnamedentityrecognizerforidentifyinghealthcare plexity and subjectivity inherent in detecting ad-\\nand medical entities. By combining the psychi- verse drug reactions. All three annotators agreed\\natricmedicationnameswiththeentitiesgivenby onthelabelsfor48%oftheposts. Toaddressthe\\nHealthE,weobtained19,252Redditposts. disagreements, we conducted a second round of\\nFilteringbasedonmentionsofpsychiatricmed- annotationsinwhichallthreeannotatorscollabora-\\nications and adverse symptoms provides a rich tivelyresolveddisagreements,resultinginthefinal\\nsampletoextractpoststhatstrictlydiscusssymp- set of labels (details in Appendix D). Finally, 11\\ntomscausedbypsychiatricmedications,whichis postswerediscardedduetotheirlackofrelevance\\nthe focus of our study. To specifically filter out toADRs,resultinginafinalbenchmarkcomprising\\nposts expressing concerns of adverse drug reac- 239annotatedposts. Table1presentsthestatistics\\ntions (ADRs), we prompted GPT-3.5 using def- forthePsych-ADRbenchmark.\\ninitions and specific conditions identified in pre-\\nviousresearchwhilealsoincludinginsightsfrom ClassLabel #Examples\\nco-authorswhoaremedicalexperts(Edwardsand\\nNo-AdverseDrugReaction 106(44.4%)\\nAronson, 2000); see Appendix B and C for com-\\nAdverseDrugReaction(ADR) 133(55.6%)\\npletelistofcriteriaandexactprompts. Basedonthe\\nNon-DoseADR 93(38.6%)\\nannotationsbyGPT-3.5,weobtained6,108Reddit\\nWithdrawalADR 22(9.2%)\\nposts expressing ADR and 11,999 expressing no\\nDoseRelatedADR 13(5.4%)\\nADR(restweredeleted). Next,wediscusshuman\\nTimeRelatedADR 4(1.7%)\\nvalidationofthelabelsforconstructingthePsych-\\nDoseandTimeRelatedADR 1(0.4%)\\nADRbenchmark.\\nTable 1: Class-wise distribution of examples in\\n3 ThePsych-ADRBenchmark thePsych-ADRbenchmarkdataset;%w.r.t. N =239.\\nExpertresponsestoADRposts: Akeyaspectof\\nLLM-assistedexpertannotations: Weconducted\\nPsych-ADRbenchmarkistheinclusionofexpert-\\nexpert-ledannotationstovalidatetheADRlabels\\nwritten responses to queries in the ADR labeled\\ngeneratedbyGPT-3.5andtocategorizethespecific\\nposts. ForeachpostthatexpressedanADRrelated\\ntypeofADRdescribedineachpost,ifapplicable.\\nquery,themostexperiencedannotator(Doctor)pro-\\nGiventhecomplexityandtime-intensivenatureof\\nvidedresponsesaddressingthequeries. Tofacili-\\nthe human annotation process, we randomly se-\\ntate this, we identified and articulated the logical\\nlected250posts—consistingofbothADR-labeled\\nstructureoftheresponsestypicallyseeninclinical\\nand no-ADR-labeled posts as identified by GPT-\\nsettingswhileworkingwiththemedicalexperts. In\\n3.5 for experts to annotate. Based on our discus-\\naccordancetothisstructure,eachresponseinour\\nsions with the collaborating medical experts and\\ndataset begins with empathizing with the patient,\\ndrawingontheclassificationprovidedbyEdwards\\nfollowedbyinformationondiagnosis,requestfor\\nand Aronson (2000), we categorized the ADRs\\nadditionalinformation,proposingharmreduction\\nintofivegranulartypes–1)dose-relatedADR,2)\\nstrategies to mitigate the ADR, and concluding\\nnon-doseADR,3)dose-andtime-relatedADR,4)\\nwithafinalsetofquestions. Anexampleresponse\\ntime-related ADR, and 5) withdrawal ADR. We\\nisshowninFigure5intheAppendix.\\ncollaborated with three expert annotators — two\\ndoctors, and one medical student, all with back-\\n4 ModelSelection&Implementation\\ngroundsinpsychiatrywithhighproficiencyinEn-\\nglish. Basedonthecriteriaprovidedforclassifying We conduct our analysis for the research ques-\\na post as expressing ADR (Appendix B and C), tions with a total of 9 proprietary and open-\\ntheyannotatedeachposttodeterminewhetherthe weights LLMs. For proprietary models, we eval-\\npostdescribedanADR,andifso,whichcategory uate GPT-4o (OpenAI-GPT-4o, 2024), GPT-4ADRDetection ADRMulticlassClassification\\nZero-Shot 5-Shot-MostSimilar 5-Shot-LeastSimilar Zero-Shot 5-Shot-MostSimilar 5-Shot-LeastSimilar\\nModel Acc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1\\nGPT-4Turbo 72.03 68.55 72.46 69.52 72.46 70.05 57.58 62.16 65.91 69.36 60.61 64.42\\nGPT-4o 72.03 69.67 71.19 67.60 69.92 66.71 45.46 47.92 59.85 64.06 58.33 62.23\\nLlama3.1-70BInstruct 69.88 65.34 71.97 69.11 71.97 69.29 48.87 52.55 64.66 69.15 62.41 66.88\\nLlama3.1-405BInstruct 71.55 68.16 69.88 65.83 73.22 70.91 46.62 50.31 74.44 76.69 65.41 69.15\\nClaude3Haiku 56.49 42.34 64.02 56.91 65.27 60.74 32.33 34.34 70.68 76.41 54.14 62.00\\nClaude3Opus 77.41 76.44 76.57 75.38 75.73 74.39 42.11 44.68 69.93 73.79 63.16 68.28\\nClaude3.5Sonnet 68.62 63.48 71.13 68.18 75.73 73.49 51.13 55.45 70.68 73.87 66.92 72.66\\nOpenBioLLM-Llama3-70B 61.09 50.92 70.71 67.43 69.04 66.17 37.59 37.08 71.43 73.88 67.67 71.02\\nLlama3-Med42v2-70B 60.25 49.34 64.02 56.53 64.02 56.53 56.40 60.32 72.18 75.16 68.42 71.45\\nTable2: PerformanceofdifferentmodelsonBinaryDetectionandMulticlassClassificationtasksunderZero-Shot\\nand 5-Shot scenarios. We report the accuracy score (Acc.) and weighted F score as (F ) with the best and\\n1 1\\nsecond-bestperformingmodelmetricsineachscenariohighlightedinboldandunderline,respectively.\\nTurbo (Achiam et al., 2023), Claude 3.5 Sonnet, areprovidedinAppendixBandC.\\nClaude 3 Opus, and Claude 3 Haiku (Anthropic- Due to the wide variety of medications and\\nClaude, 2024). For open-weights models, we symptoms in Psych-ADR benchmark, we eval-\\nevaluateLLama-3.1405BInstruct-Turbo,LLama- uated two different example sampling strategies\\n3.1 70B Instruct-Turbo (Meta-LLama3.1, 2024) for few-shot prompting. For this, we generated\\nandspecializedmedicalLLMs–Llama3-Med42- textembeddingsforeachReddittitleandpostus-\\nv2 70B (Christophe et al., 2024) and Llama3- ingText-embedding-3-large(OpenAI-TextEmb-3-\\nOpenBioLLM70B(AnkitPal,2024). Thechoice Large,2024). Usingcosinesimilarity,weretrieved\\nofthesemodelsstemsfromtheirreportedperfor- the five most-similar and five least-similar posts\\nmance in different general-purpose and medical for each example. Table 2 presents the accuracy\\nbenchmarks(Abbasetal.,2024;Norietal.,2023b; and weighted F scores for models in the ADR\\n1\\nChenetal.,2023;Anthropic-Claude,2024). detectionandADRmulticlassclassificationtasks.\\nPreviousstudieshaverecommendedlowertem-\\nperaturesfordetectionandlabelingtaskstoensure 5.1 Zero-shotpromptingonPsych-ADR\\nmoreconsistentoutputs,whilehighertemperature Larger models typically perform better for\\nvalues aid in more flexible generation (Jin et al., ADR detection tasks, but this trend does not\\n2024; Achiam et al., 2023). Accordingly, for the hold for ADR multiclass classification. As ex-\\nADRdetectionandmulticlassclassificationtasks pected, larger models (by parameter size) outper-\\nwe set the temperature t = 0 and use t = 0.6 for formedtheirsmallercounterpartsintheADRde-\\nthe response generation tasks. Beyond the task- tection task within their respective families, with\\nspecific temperature variations, the settings were Claude 3 Opus achieving the highest accuracy at\\nkept consistent across all the LLMs. Additional 77.41%, followed by GPT-4o and GPT-4 Turbo\\ndetailsregardingthemodels,evaluationsetup,and at 72.03%. Interestingly, specialized medical\\ncomputeareprovidedinAppendixE. models(OpenBioLLM-Llama3-70BandLlama3-\\nMed42v2-70B) struggled in this task. However,\\n5 RQ1: DetectingAdverseDrugReaction\\nfor ADR multiclass classification, we did not ob-\\nFor this task, we evaluated LLMs on detecting serve any clear pattern between model size and\\nexpressions of adverse drug reactions using the performance. GPT-4Turbowasthebestperform-\\nPsych-ADRbenchmark. Theevaluationinvolved ingmodelwithanaccuracyof57.58%, followed\\ntwoseparatetasks: (1)identifyingthepresenceor by Llama3-Med42v2-70B at 56.40%. All mod-\\nabsence of concerns realted to ADRs in the 239 elsstruggledwithmulticlassclassification,likely\\nRedditposts,and(2)classifyingthetypeofADR due to the complexity of distinguishing between\\nintooneoffivepre-definedcategoriesforthe133 ADR types. Additionally, aligning with prior re-\\ninstances labeled as expressing ADRs in Psych- search,observedresultsinthemulticlassclassifica-\\nADRbenchmark. Inbothtasksweevaluatedmod- tionshowedthatlargermodelsdonotalwaysexcel\\nels using the zero-shot and few-shot variants of inspecializedtasks(Kanithietal.,2024).\\nthechain-of-thought(CoT)prompting(Weietal., Modelsexhibiteda“risk-averse”tendency,and\\n2022). Detailedpromptsandclassificationcriteria prone to commit false-positive errors. In bothADRdetectionandmulticlassclassificationtasks, Thiswasthemajorreasonbehindmodelsfailingto\\nallmodelsdisplayed“risk-averse\"behavior,often achievetheexpectedgainsindetectingADR.\\nmislabeling posts without ADRs as positive for Impactofchoosingsimilarordiverseexamples\\nADRs (see Appendix G for qualitative analysis). depends upon the task. While the performance\\nIn zero-shot settings, Claude 3 Opus had a false- boost in the ADR multiclass classification task\\npositive rate of 42% for ‘ADR-No’ labels, while could be attributed to the predominance of non-\\nClaude3Haiku’sfalsepositiveratewasashighas dose-relatedADRs,thecomparativelysmallerper-\\n97% (see Appendix F). Similarly, in ADR multi- formance gains observed when models were pre-\\nclassclassification,modelsstruggledtodistinguish sentedwiththefiveleastsimilarexamplessuggest\\nbetweennon-dose-related,dose-related,andtime- thatmodelswereabletograspthecontextualinfor-\\nrelatedADRs. GPT-4Turbomisclassified51%of mationpresentedthroughtheexamplesandcapture\\nnon-dose-relatedand50%oftime-relatedADRsin the nuances of various ADR types. However, no\\nzero-shotsettings. Thisrisk-aversetendencyindi- such pattern was observed in the ADR detection\\ncatesalackofnuancedunderstandingofADRcom- task,with3modelsshowingincreaseinF ≥ 1%\\n1\\nplexities,whichcouldleadto(a)patientsdiscontin- withfiveleastsimilarexamplesbasedprompting.\\nuingtreatment(HorneandWeinman,1999;Horne Thisshowedthatdiversityinexamplesratherthan\\netal.,2005), (b)increasedfearabouttheircondi- stochasticityimpactedmodelperformance.\\ntions (Starcevic and Berle, 2013), and (c) “alert-\\nfatigue” among healthcare providers (Phansalkar 6 RQ2: Alignmentbetweenhumanand\\netal.,2013). AIfeedback\\n5.2 Few-shotpromptingonPsych-ADR Evaluationoflong-formtextgenerationisanopen\\nIn-context learning enhances model perfor- problemandinvolvesmanychallengeslikeisolat-\\nmancebutnotineverycase. Weobservedthein- ing the stylistics from the semantics. However,\\ncontextlearningingeneralimprovedperformance in the context of responses to ADR queries, we\\nofmodelsforbothADRdetectionandmulticlass proposeabstractingouttheLLMgenerationsand\\nclassificationtasks,withamoresignificantimpact ground-truthexpertresponsestofourkeycompo-\\nonthelattertask. Formulticlassclassification,we nents–(1)emotionandtone, (2)textreadability,\\nobserved an average increase of 18.14 and 23.06 (3) harm reduction strategy, and (4) actionability\\npointsinweightedF scoreamongmodelperfor- ofproposedstrategies. Viathisabstractiontokey\\n1\\nmanceusingleast-similarandmost-similarexam- components, our alignment evaluations focus on\\nplepromptingrespectively. However,thispattern specificaspectsthatcontributetowardsanidealre-\\nwasnotobservedinADRdetectiontask. Claude sponsetoADRqueries. Weexplaintheimportance\\n3OpusoutperformedothermodelsintheADRde- ofthesecomponentsbelowandthemethodology\\ntection,achievinganF scoreof76.44withzero- forevaluation.\\n1\\nshotprompting. InADRmulticlassclassification, Emotional and tone alignment: Emotional in-\\nLlama-3.5-405Bperformedbestwithmost-similar telligence is regarded as a key factor in health-\\nexamples (F 76.69). For analyzing the impact care,fosteringstrongtherapeuticrelationshipsthat\\n1\\nofprovidingexamplesintheADRdetectiontask, drive meaningful change (King Jr, 2011). There-\\nweobservedthatsomemodels, suchasClaude3 fore,LLM-generatedresponsesshouldalignwith\\nHaikushowedanaverageimprovementofF score expert-written responses in terms of tone and ex-\\n1\\n(16.49points),whereaswedidnotobservesucha pressed emotion. To assess this, we used Em-\\ntrendformodelssuchasGPT-4o,Claude3Opus path (Fast et al., 2016), a widely-used lexicon-\\ninfew-shotsettings. ThestochasticnatureofLLM basedtool,focusingspecificallyon8relevantemo-\\ngeneration,coupledwiththeinabilitytolearnnu- tional and tonal categories identified from prior\\nancesfromexamplesinthe\"ADR-No\"class,may literature(RiessandKraft-Todd,2014;Mechanic\\nbeacontributingfactortothisissue. Thiswasfur- and Meyer, 2000). We analyzed the distribu-\\nther confirmed as we noted that even in few-shot tionofthesecategoriesinLLM-generatedandex-\\nsettings, modelsexhibited\"risk-averse\"behavior pertresponses,andquantifiedtheirdifferencesus-\\nwithhighfalse-positiverates, indicatingthatpro- ingKullback-Leibler(KL)divergencetomeasure\\nvidingexamplescouldnoteffectivelycompensate alignment of expressed emotions and tone in the\\nfor the lack of “lived-experience” in the models. LLMandexpertresponses.Text readability alignment: Past studies have Second,foramoreinterpretablealignmentscore,\\nshown that health literacy is strongly correlated wepromptedGPT-4owithin-contextexamplesto\\nwith patient outcomes (Wolf et al., 2005). A ma- reason and classify if a strategy is aligned with\\njor factor contributing to lower health literacy is the expert’s response. We computed a response-\\nthe communication barrier between patients and levelGPT-4oscorebycomputingthepercentageof\\nhealthcareproviders,whichoftenarisesfromthe alignedHRSovertotalnumberofHRS.Thesetwo\\ncomplexityofmedicaltext,includingthewriting approaches ensured robustness by covering both\\nstyle and choice of terminology (DuBay, 2004). a continuous alignment score and one based on\\nHence, the responses produced by LLMs should reasoned binary alignment labels. We conducted\\nbeeasilyreadableandbeofcomparabletothatof another round of human evaluation for the GPT-\\nthe expert-written responses. To assess this, we 4o score, where four annotators annotated 40 re-\\nusedSMOGindex(McLaughlin,1969),apopular sponses, achieving a 95% correlation with GPT-\\nreadabilityindextoassesshealthliteracymaterial. 4o’sscoreandreasoning. PromptsforLLM-based\\ntasksarepresentedinTable13, 14&15, andhu-\\nHarmreductionstrategyalignment: Incasesof\\nmanevaluationdetailsarepresentedinAppendix\\nadversereactionstopsychiatricmedications,sug-\\nI.1.\\ngestingsafemedicalinterventionsiscrucialtopre-\\nvent further harm. We operationalized these in- Actionability alignment: Prior work in health\\nterventionsusingharmreductionstrategies(HRS) communicationhasrecognizedtheimportanceof\\n(Single,1995), aimedatminimizingthenegative actionabilityintheresponsesofhealthcareprofes-\\neffectsofmedicationsthatoneisrelianton. Ideally, sionalstoenablegreaterengagementandencour-\\nLLMsshouldproposestrategiesthatalignwiththe ageincreasedactionfrompatients(Sharmaetal.,\\nexpert’sresponses. 2023). To this end, we designed an approach to\\nTo compare the harm reduction strategies sug- measure the alignment between LLM responses\\ngestedbyLLMsandexperts,wetookinspiration and expert responses along the actionability di-\\nfrom methods for entailment and factuality eval- mension. We first decomposed actionability into\\nuation in long-form texts (Min et al., 2023; Wei specificsub-dimensionswhileworkingwithclin-\\netal.,2024;Kamoietal.,2023). First,weextracted icalexpertsandusingtheguidelinespresentedin\\natomic HRS from LLM responses by prompting thePatientEducationMaterialsAssessmentTool\\nGPT-4o(OpenAI-GPT-4o,2024). Sincesomeex- (PEMAT;AHRQ).Harmreductionstrategiesrec-\\ntractedstrategieswereredundant,weusedafew- ommended by experts and LLMs should be: (i)\\nshotapproachtocombinethosethatsuggestedthe practical, (ii) contextually relevant, (iii) specific,\\nsameoverallapproachbutdifferedinspecificde- and(iv)clear. Wepresentconcretedefinitionsfor\\ntailstogetthefinalsetofHRSforeachresponse eachofthesub-dimensionsinAppendixJ.\\n(examples in Table 11). To check for the robust-\\nTo operationalize the quantification of action-\\nnessoftheextractionandcombinationmethod,we\\nabilityalignment,wepromptedtheGPT-4omodel\\nconductedaroundofhumanevaluationwith4an-\\nusingcarefullyselectedin-contextlearningexam-\\nnotators. Usingarandomsampleof40responses\\nples and chain-of-thought prompting. The GPT-\\nforeachtask, weevaluated193strategiesforthe\\n4o model considers the ADR post made by the\\nextractionand174strategiesforcombination,and\\nuserandassignsabinarylabeltoeachharmreduc-\\nobtained a correlation score of 92% and 90% re-\\ntions strategy based on whether or not the target\\nspectivelywithLLMevaluation.\\nsub-dimension of actionability is present in the\\nWe then evaluated alignment of HRS for each strategy (0: absent; 1: present). To validate the\\nLLM-expert response pair using two methods. labelsassignedbytheGPT-4omodel,themedical\\nFirst, we used AlignScore (Zha et al., 2023), a experts reviewed the rationales generated for de-\\nwidely-used text alignment method providing a tectingeachofthesub-dimensionsofactionability\\nscore between 0 and 1 based using a fine-tuned in100harmreductionstrategies,andagreedwith\\nRoBERTa-large model (Liu et al., 2019). We 91ofthemforpracticality,94forrelevance,82and\\ncomputed AlignScore for each strategy from the 89 for specificity and clarity, respectively. Over-\\nLLM response against the expert response. We all, the extent of the agreement between experts\\nobtained a response-level AlignScore by averag- and GPT-4o rationales reinforced the validity of\\ning the scores across all HRS for the response. thelabelsassignedtothe4sub-dimensionsofac-tionability. Followingthis,forresponsesgenerated\\nGPT-4-Turbo\\nby the LLMs, we computed the fraction of harm\\nGPT-4o\\nreductionstrategiesthatarealignedwiththeHRS\\nLlama 3.1-70B Instruct\\nand also demonstrate presence of a certain sub-\\nLlama 3.1-405B Instruct\\ndimension of actionability. For instance, for the\\nClaude 3 Haiku\\npracticality dimension, the LLM-generated HRS\\nClaude 3 Opus\\narescoredas:\\n#aligned&practicalHRS\\nPracticality = Claude 3.5 Sonnet\\nLLM #totalHRS\\nOpenBioLLM-Llama3-70B\\nIt is worth emphasizing that the constraint of\\nLlama3-Med42v2-70B\\nonly considering aligned HRS within the LLM-\\n0 2 4 6 8 10\\ngeneratedresponsesenforcesapenaltyforgener- Mean KL Divergence Score\\natingunalignedHRSwhilecomputingactionabil- Figure 2: Mean KL Divergence score for the empath\\nity. Since expert responses are inherently always categoriesdistributionbetweenmodelsandtheexpertre-\\naligned, their HRS do not undergo such a penal- sponsesinthePsych-ADRbenchmarkdataset. (Lower\\nization. We present the average scores for the 4 scoreisbetter).\\nsub-dimensionsandtheiraggregateastheoverall\\nactionabilityscoreinTable4. 20\\n18\\n6.1 Results\\n16\\nEmotionalandtonealignment. Figure2presents 14\\nthemeanKL-divergencescoreforthedistribution 12\\no a dn uf d c8 teeE dxm p toep r aa t s-t sh w er sc i sa ttt tee hng eo drr e ii fse fps eo rb en ne st cew e. se Ae inn cχL a2 tL etM ge ost rr ye ws dap isso tn rc is o be n us -\\n-\\n10 Expert GPT-4-Turbo GP LT l- a4 mo a 3. L1 l- a7 m0 aB 3In .1s -t 4. C0 l5 aB u dIn es 3t. CH la ai uk du e C3\\nl\\naO up du Oes p3 e. n5 BS io on LLn LMe lt a-L mla am 3-a M3 e-7 d0 4B 2v2-70B\\ntions,andthep-valueswerenon-significantacross\\nall models, indicating that the models’ responses\\nwere not significantly different from the expert-\\nwrittenresponsesintermsofemotionsexpressed\\nandthetoneused. Further,weobservedthatlarger\\nand more capable models from the Llama and\\nClaudefamiliesshowedgreateralignmentwithex-\\npertresponsesacrossdifferentemotionalandtone\\nrelatedcategories. Interestingly,Llama-3Med42v2\\n70Bperformedtheworst. Thiscouldbeattributed\\ntothefactthatamajorportionofdatasetusedfor\\ninstructionfine-tuningforthismodelwasobtained\\nfromthemedicalandbiomedicalliterature,which\\nmaynotprioritizeemotionalcommunicationwhile\\nprovidingresponses(Christopheetal.,2024).\\nUpon closer examination of the individual cat-\\negories (Figure 8), we found that the expert re-\\nsponsesonaverageshowedhigherlevelsofantic-\\nipation and affection in the category distribution\\ncomparedtoLLMs. Similarly,ahelpingtonewas\\nmoreprominentintheexpertresponsesin6outof\\n9comparisons. However,LLMsexhibitedhigher\\nuse of optimistic and cheerful tones in their re-\\nsponsesonaverage. Additionally,6outof9LLMs\\nproduced responses that used a more polite tone,\\nincorporatingmoretrust-basedemotions.\\nText readability alignment. Figure 3 presents\\ntheboxplotforLLMandexpertresponseSMOG\\nerocs\\nGOMS\\nFigure 3: Mean SMOG Scores and 95% Confidence\\nIntervalsforVariousModels(lowervaluesarebetter).\\nscores. As observed, LLM-generated responses\\ntend to be more complex, reflected in higher\\nSMOG scores compared to those written by ex-\\nperts(SMOG 11.02)inthePsych-ADRbench- mean\\nmark. Welch’st-test(Welch,1947)furtherrevealed\\nthattheSMOGscoresofexpert-writtenresponses\\nwere significantly lower than those of any LLM-\\ngeneratedresponses. Wealsoobservedthatmore\\ncapablemodelsproducedmorereadableresponses\\n(withClaude3Opusbeinganexception). Similar\\nto the findings on emotional alignment, Llama3-\\nMed42v2-70Bshowedthelowestalignmentwith\\nthe expert-written responses, producing the most\\ncomplex responses, likely dueto amajor portion\\nof instruction-tuning data coming from medical\\nand biomedical scientific literature. In contrast,\\nOpenBioLLM-Llama3-70B outperformed many\\nproprietarymodels,likelyduetothecustomdataset\\nusedforfine-tuning.\\nHarm reduction strategy alignment. Table 3\\npresentsthemeanresponse-levelAlignScoresand\\nGPT-4o scores for alignment of harm reduction\\nstrategiesofLLMswiththeexpert’sresponses. In\\nlinewithresultsfromzero-shotADRclassification\\ninRQ1,morecapablemodelsLlama3.1-405BIn-struct and Claude 3.5 Sonnet in their respective relevant, considering the users’ personal circum-\\nfamiliestendedtoproducestrategieslessaligned stances,suchasphysicalability,financialresources,\\nwiththeexpertthantheirsmallercounterparts,vali- andtimeconstraints. Thisobservationfurtherrein-\\ndatingapreviouslyobservedpatternofLLMperfor- forcestheneedofencodingandreflectingonlived\\nmanceinrespondingtoopen-endedclinicalques- experiences(DeChoudhuryetal.,2023;Lawrence\\ntions(Kanithietal.,2024). Whiletheopen-weights etal.,2024)aspartofADRresponsestoaddress\\nmodelsperformedonparorbetterthanproprietary contextual cues, a dimension along which LLMs\\nmodels across both alignment metrics, the best- needtoimprovefurther.\\nperformingmedicalmodel(OpenBioLLM-Llama3-\\n70B)alignedwithexpertharmreductionstrategies Model Practical Relevant Specific Clear Actionable\\nExpertResponses 0.83 0.73 0.17 0.13 0.46\\nfor70.86%ofthecases,highlightingtheneedfor OpenBioLLM-Llama3-70B 0.68 0.70 0.17 0.22 0.44\\nfurther fine-tuning for specialized domains such Llama3-Med42v2-70B 0.60 0.61 0.26 0.29 0.44\\nClaude3Haiku 0.64 0.64 0.21 0.24 0.43\\naspsychiatry. Qualitativeanalysisofnon-aligned Claude3.5Sonnet 0.63 0.61 0.20 0.22 0.42\\nGPT-4Turbo 0.63 0.62 0.17 0.21 0.41\\nHRSrevealedthatmostfocusedongenerallifestyle Llama3.1-70BInstruct 0.62 0.64 0.17 0.18 0.40\\nGPT-4o 0.59 0.57 0.15 0.19 0.38\\nadvice,suchasmaintainingahealthydietandsleep Claude3Opus 0.57 0.54 0.16 0.17 0.36\\nLlama3.1-405BInstruct 0.58 0.56 0.13 0.14 0.35\\nroutine, rather than addressing actions related to\\ntheinvolvedmedication(detailsinAppendixI). Table4: MeanactionabilityalignmentscoresofHRS\\n(lastcolumn),computedasaverageofpracticality,rele-\\nvance,specificity,andclarityscores.\\nAlignScore GPT-4oScore\\nModel Mean Std.dev. Mean Std.dev.\\n7 RelatedWork\\nGPT-4Turbo 46.49 22.80 65.28 27.22\\nGPT-4o 42.06 23.10 62.72 27.66 Largelanguagemodelsinhealthcare: Withthe\\nLlama3.1-70BInstruct 46.91 24.22 63.57 31.50\\ngrowing capabilities of LLMs, past studies have\\nLlama3.1-405BInstruct 39.96 20.70 54.71 32.30\\nClaude3Haiku 41.71 25.32 61.96 31.81 explored their potential to assist stakeholders in\\nClaude3Opus 42.42 21.27 59.16 30.21\\nhealthcaredomain. ProprietarymodelslikeGPT-4\\nClaude3.5Sonnet 36.83 22.74 59.48 31.63\\nOpenBioLLM-Llama3-70B 56.55 24.81 70.86 30.46 andMedPalmhaveshownstrongperformanceon\\nLlama3-Med42v2-70B 42.59 22.47 61.61 28.19\\nmultiple-choice benchmarks and even passed ex-\\namssuchastheUSMLE(Singhaletal.,2023a,b;\\nTable3: Alignmentofharmreductionstrategiesofvar-\\niousmodelswiththeexpert’sresponse. Wereportthe Norietal.,2023a;AnkitPal,2024;Kanithietal.,\\nmeanandstandarddeviationfortheAlignScoremetric 2024). LLMshavealsobeenevaluatedformental\\nGPT-4oscore,withthebest(bold)andsecond-best(un- health support queries (Yang et al., 2023). How-\\nderline)performingmodelineachmetrichighlighted. ever, previous research has also highlighted chal-\\nlenges for LLMs in these settings, highlighting\\nActionability alignment. In Table 4, we noted cross-lingualdisparities(Jinetal.,2024), gender\\nthatexpertresponsesscoredthehighestonoverall andgeographicbiases(Restrepoetal.,2024),and\\nactionabilityincomparisontoalltheLLMs(0.46). limitations in clinical competency tests for both\\nNonetheless,medicalmodelslikeOpenBioLLM- generalandmentalhealth(Thirunavukarasuetal.,\\nLlama3-70B and Llama3-Med42v2-70B demon- 2023;Jinetal.,2023).\\nstrate reasonable actionability scores (0.44), fol- ADRdetectionandpharmacovigilance: Pastre-\\nlowedbyotherproprietaryandopen-weightsmod- searchhaslookedintoADRdetectionthroughso-\\nels(0.35to0.43). Beyondtheaggregateactionabil- cialmediaplatforms(Mesbahetal.,2019a;Sarker\\nityscore,thescoresforthesub-dimensionsprovide andGonzalez,2015;Karimietal.,2015). However,\\ninteresting insights on alignment between expert thesestudieshavepredominantlyfocusedonnon-\\nandLLMresponses. Whileexpertresponseswere mentalhealthrelatedcases,relyingonbinaryclas-\\nratedconsiderablybetterthanallLLMresponsesin sificationtaskswithlimitedmedicationdatasets. In\\ntermsofthepracticality(0.83)andcontextualrele- contrast,medicalstudiesonADRsrelatedtopsy-\\nvance(0.73)oftheharmreductionstrategies,their chiatric medications (Angadi and Mathur, 2020;\\nspecificity (0.17) and clarity (0.13) are relatively Ejeta et al., 2021) are typically hospital-based,\\nlacking. This indicates that while LLMs tend to small-scale, and not focused on detecting ADRs\\ndemonstrategreaterspecificityandclarityintheir withinonlinecommunities.\\nharmreductionstrategy,therecommendedstrate- Importanceoflivedexperience: Theimportance\\ngies may often not be feasible and contextually of lived experience has been studied in variousworks across the field of mental health research, revealingnuancedpatternsthathighlighttheintri-\\npsychology, and education. Understanding lived caciesinvolved,andhencefindingsfromthiswork\\nexperiencesprovidesinsightintoindividuals’per- haveseveralkeyimplications:\\nsonal realities and preferences, contributing to-\\nwardsadeeperunderstandingoftheirexperiences, Goingbeyondthechoice-basedmedicalbench-\\nexpectationsandrequirements. Inmentalhealthre- marks. LLMs have achieved near-perfect scores\\nsearch,previousstudieshavehighlightedtheimpor- onpopularmedicalbenchmarks(Norietal.,2023a;\\ntanceofunderstandingtheexperiencesandrealities Singhal et al., 2023b), however, these evalua-\\nofindividualslivingwithmentalhealthconditions tions typically focus on multiple-choice or case-\\nfor providing better treatment (Gilbert and Stick- based questions,which don’t reflect the nuanced\\nley, 2012; Repper and Carter, 2011). Byrne et al. understanding required in real-world scenarios\\n(2013) further highlighted that students showed like mental health. Despite their strong perfor-\\npositiveattitudesandincreasedself-awarenessto- mance on medical tasks, Llama3-Med42v2-70B\\nwardstheimpactofmentalillnessonindividuals andOpenBioLLM-Llama3-70Bstruggledwithde-\\nwhentheyweretaughtbypeoplewithlivedexperi- tectingADRsandprovidingalignedandactionable\\nenceofmentalhealthchallenges. Pastresearchin HRS,highlightingtheneedtomovebeyondstan-\\npsychologyhasalsostressedontheunderstanding dardbenchmarkstowardsmoreholisticalignment\\nof the lived experience of individuals belonging evaluationparadigms.\\nto different backgrounds. Previous studies have Focusingonempoweringexpertsratherthanre-\\nalso highlighted the importance of lived experi- placingthem. WhileLLMsdidnotmatchexpert\\nenceintheformofexperientialknowledgeamong performance in our analysis, they showed a po-\\nthehealthcareproviderformakingdecisions(Lyu tentialtoenhancehealthcarebyprovidingclearer,\\net al., 2023; Palukka et al., 2021). In summary, moreactionableresponses. Giventheglobalshort-\\npreviousresearchinmentalhealthandpsychology age of mental health professionals (Kazdin and\\nhasemphasizedonthemultifacetedimportanceof Rabbitt,2013),LLMscouldexpandaccesstomen-\\nlivedexperienceamongthepatients,educatorsand talhealthcareandsupportexpertswithfurtherfine-\\nhealthcareproviders. tuningandalignmentwithexpertreasoning.\\nDisentanglinginclusionofhumanisticfeatures\\n8 ConclusionandFutureWork in LLMs and advocacy for inclusion of lived\\nexperience. While our work provides evidence\\nInthiswork,weproposedthePsych-ADRbench-\\nofthelackoflivedexperience,whichisessential\\nmark and ADRA framework for evaluating the\\nfor understanding the nuances of a complex task\\nalignment of LLMs with experts on responding\\nsuchasADRdetectionandforproposingmitiga-\\nADRqueriescausedduetopsychiatricmedication\\ntionstrategiesinmodelresponses,wedonotadvo-\\nuse. In our RQ1 analysis, even the best models\\ncate for increasing human-like features in LLMs.\\nachievedonly77.41%accuracyindetectingADR\\nPrevious studies have suggested that heightened\\nand74.44%accuracyindetectingthetypeofADR.\\nanthropomorphism,independentofwhetheritisac-\\nOurRQ2analysisfurtherrevealedthatwhilemod-\\ncompaniedbyenhancedcapabilities,canincrease\\nelsalignwithexpertsonexpressedemotionsand\\ntrustamongindividuals(NatarajanandGombolay,\\ntoneofthetext,theystruggleinimportantareaslike\\n2020; Chen and Park, 2021). Hence, developers\\nreadability,alignmentofharmreductionstrategies\\nand researchers need to be cautious before intro-\\nwithexpertknowledge,andsuggestingactionable\\nducingsuchfeaturesasindividualsmaytrustLLM\\ninterventions. Our work can inspire future work\\nresponsesevenwhentheyprovideincorrectorin-\\nto adopt a more holistic approach for evaluating\\nconsistentinformationwhichcanbehazardousin\\nmodels,emphasizingtheintegrationof“livedex-\\nhigh-riskdomainssuchashealthcare. Incontrast,\\nperience\"alongsideexpertknowledge.\\nweadvocateforapproachesthatalignwithprevi-\\nousresearch,whichhasshownthattheefficacyof\\n9 BroaderImplications\\nLLMs in the healthcare domain can be enhanced\\nRespondingtoADRqueriesischallengingdueto through fine-tuning on specialized data or by in-\\nthecomplexityofmentalhealthconditions,symp- corporatingusefulfeaturesintothemodel,without\\ntoms,andmedicationeffects. Theresultsfromthe introducing human-like features (Belyaeva et al.,\\nanalysesofRQ1andRQ2surfacethesechallenges, 2023;Lietal.,2023).10 Limitations data,asrecommendedintheliterature(Wellerand\\nKinder-Kurlanda, 2016, 2015). In line with Red-\\nWhile novel, it is important to acknowledge the\\ndit’sdata-sharingguidelinesandrelevantdata-use\\nlimitationsofourwork. WhiletheproposedPsych-\\nagreements, we will provide access to the bench-\\nADR benchmark is the first to focus exclusively\\nmark exclusively comprising Post IDs and anno-\\non ADRs related to psychiatric medications, the\\ntations,tointerestedresearchersuponacceptance.\\nnumberofexamplesusedforevaluatingLLMsis\\nFurther, wewillmakethecodeusedinthiswork\\nlimited, which may not capture the full range of\\npublicly available on a GitHub repository upon\\nADRsassociatedwiththesemedications. Wealso\\nacceptance.\\nacknowledgethatexpandingabenchmarklikeours\\nOur study presents a systematic approach for\\npresentschallengesduetothetime-intensivenature\\nevaluating LLMs for addressing ADR related\\nofannotationandresponsewriting,compounded\\nqueriesfrompsychiatricmedicationuse,andhence\\nbythesubjectivityandcomplexityinherentinthis\\ndoesnotinherentlyposedirectrisks. However,itis\\ndomain. Additionally, while the responses were\\nimportanttoemphasizethatbetterperformanceon\\nprovided by a highly experienced doctor, varia-\\nPsych-ADRbenchmarkshouldnotbeinterpreted\\ntions in clinical opinions are possible given the\\nas an indication of increased capabilities in real-\\nsubjectivenatureofADRassessmentinpsychiatric\\nworldapplications. Instead,theseresultsshouldbe\\nmedicationcontexts. Despitetheselimitations,we\\ncomplementedwiththoroughhumanevaluationto\\nbelievethattheproposedPsych-ADRbenchmark\\nensurethereliabilityandsafetyofmodels.\\nprovides a valuable resource for further research,\\noffering a robust starting point for the study of 12 Acknowledgment\\nADRsinpsychiatricmedications.\\nWe also acknowledge certain limitations in ChandraandDeChoudhurywerepartlysupported\\nthe ADRA framework. Although we aimed to throughNationalScienceFoundation(NSF)grant\\ncompare responses across a set of relevant emo- #2230692,agrantfromtheAmericanFoundation\\ntionsandtones, ourapproachreliesonalexicon- for Suicide Prevention (AFSP). Further, this re-\\nbasedmethod,whichmaysometimesmissseman- search project has benefitted from the Microsoft\\ntic meaning of the responses. Additionally, the AccelerateFoundationModelsResearch(AFMR)\\nharm reduction strategy alignment in our frame- grantprogram. Thefindings,interpretations,and\\nworkexcludesstrategiessuggestedbyLLMsthat conclusionsofthispaperarethoseoftheauthors\\narenotpresentintheexpertresponses. However, and do not represent the official views of NSF,\\ntheremaybecaseswheretheLLM’sproposedstrat- AFSP or Microsoft. We further acknowledge the\\negyisaviableoptionaccordingtootherclinicians, contributions from Dr. Santiago Alvarez Lesmes\\nbutduetotheopen-domainnatureoftheproblem towardsdataannotationandassessment.\\nand the lack of a verified data source, we were\\nunable to evaluate the correctness of such strate-\\nReferences\\ngies. Despitethesechallenges,ourworkprovides\\na robust framework for assessing the capabilities Ali Abbas, Mahad S Rehman, and Syed S Rehman.\\nofLLMsinhigh-riskstrategy-drivendomains. 2024. Comparingtheperformanceofpopularlarge\\nlanguage models on the national board of medical\\nexaminerssamplequestions. Cureus,16(3).\\n11 EthicalConsiderations\\nJoshAchiam,StevenAdler,SandhiniAgarwal,Lama\\nWecollectedpublicdomainsocialmediadatafrom\\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\\napubliclyavailabledatasetwhichallowedustouse\\nDiogoAlmeida,JankoAltenschmidt,SamAltman,\\ntheresourcefornon-commercialpurposes. Wefur- ShyamalAnadkat,etal.2023. Gpt-4technicalreport.\\nther ensured that all data used was de-identified arXivpreprintarXiv:2303.08774.\\nand did not contain any offensive content. As\\nAHRQ. 2020. The patient education materi-\\nourstudyinvolvedworkingwithretrospectivedata\\nals assessment tool (pemat) and user’s guide.\\nwithout direct interaction with the authors of the https://www.ahrq.gov/health-literacy/\\nposts,theInstitutionalReviewBoard(IRB)classi- patient-education/pemat9.html. [Accessed\\n30-08-2024].\\nfieditasnon-humansubjectsresearch,exempting\\nit from IRB approval. Still, we adhered to estab-\\nNetravathiBasavarajAngadiandChhaviMathur.2020.\\nlishedbestpracticesforworkingwithsocialmedia Prevalence and severity of adverse drug reactionsamongpatientsreceivingantipsychoticdrugsinater- MunmunDeChoudhury,SachinRPendse,andNeha\\ntiarycarehospital. InternationalJournalofNutrition, Kumar.2023. Benefitsandharmsoflargelanguage\\nPharmacology, Neurological Diseases, 10(3):144– models in digital mental health. arXiv preprint\\n148. arXiv:2311.14693.\\nMalaikannan Sankarasubbu Ankit Pal. 2024. William DuBay. 2004. The principles of readability.\\nOpenbiollms: Advancing open-source large ImpactInformation.\\nlanguage models for healthcare and life sci-\\nences. https://huggingface.co/aaditya/ IRalphEdwardsandJeffreyKAronson.2000. Adverse\\nOpenBioLLM-Llama3-70B. drugreactions: definitions,diagnosis,andmanage-\\nment. Thelancet,356(9237):1255–1259.\\nAnthropic-Claude.2024. IntroducingClaude3.5Son-\\nFikaduEjeta,TemesgenAferu,DiribaFeyisa,Oliyad\\nnet — anthropic.com. https://www.anthropic.\\nKebede, Jafer Siraj, Workineh Woldeselassie\\ncom/news/claude-3-5-sonnet. [Accessed07-09-\\nHammeso, Esayas Tadesse, and Alemayehu Tin-\\n2024].\\nishku.2021. Adversedrugreactionanditspredictors\\nJasonBaumgartner,SavvasZannettou,BrianKeegan, amongpsychiatricpatientstakingpsychotropicmed-\\nMegan Squire, and Jeremy Blackburn. 2020. The icationsatthemizan-tepiuniversityteachinghospi-\\npushshiftredditdataset. InProceedingsoftheinter- tal. NeuropsychiatricDiseaseandTreatment,pages\\nnationalAAAIconferenceonwebandsocialmedia, 3827–3835.\\nvolume14,pages830–839.\\nEthanFast,BinbinChen,andMichaelSBernstein.2016.\\nEmpath: Understandingtopicsignalsinlarge-scale\\nAnastasiyaBelyaeva,JustinCosentino,FarhadHormoz-\\ntext. InProceedingsofthe2016CHIconferenceon\\ndiari,KrishEswaran,ShravyaShetty,GregCorrado,\\nhuman factors in computing systems, pages 4647–\\nAndrew Carroll, Cory Y McLean, and Nicholas A\\n4657.\\nFurlotte.2023. Multimodalllmsforhealthgrounded\\ninindividual-specificdata. InWorkshoponMachine\\nJosephGatto, ParkerSeegmiller, GarrettMJohnston,\\nLearningforMultimodalHealthcareData,pages86–\\nMadhusudanBasak,andSarahMasudPreum.2023.\\n102.Springer.\\nHealthe: Recognizing health advice & entities in\\nonline health communities. In Proceedings of the\\nLouise Byrne, Brenda Happell, Tony Welch, and\\nInternationalAAAIConferenceonWebandSocial\\nLornaJaneMoxham.2013. ‘thingsyoucan’tlearn\\nMedia,volume17,pages1024–1033.\\nfrombooks’: Teachingrecoveryfromalivedexpe-\\nrienceperspective. Internationaljournalofmental\\nPeterGilbertandTheodoreStickley.2012. “wounded\\nhealthnursing,22(3):195–204.\\nhealers”:theroleoflived-experienceinmentalhealth\\neducationandpractice. TheJournalofMentalHealth\\nStevieChancellor,GeorgeNitzburg,AndreaHu,Fran-\\nTraining,EducationandPractice,7(1):33–41.\\nciscoZampieri,andMunmunDeChoudhury.2019.\\nDiscoveringalternativetreatmentsforopioidusere-\\nAnnaGuimarães,ErisaTerolli,andGerhardWeikum.\\ncovery using social media. In Proceedings of the\\n2021. Comparinghealthforums: Userengagement,\\n2019CHIconferenceonhumanfactorsincomputing\\nsaliententities,medicaldetail. InCompanionPubli-\\nsystems,pages1–15.\\ncation of the 2021 Conference on Computer Sup-\\nported Cooperative Work and Social Computing,\\nQianQianChenandHyunJungPark.2021. Howan-\\npages57–61.\\nthropomorphismaffectstrustinintelligentpersonal\\nassistants. IndustrialManagement&DataSystems, Rob Horne, John Weinman, Nick Barber, Rachel El-\\n121(12):2722–2737. liott,MyfanwyMorgan,ACribb,andIKellar.2005.\\nConcordance,adherenceandcomplianceinmedicine\\nZeming Chen, Alejandro Hernández Cano, Angelika\\ntaking. London: NCCSDO,2005(40):6.\\nRomanou,AntoineBonnet,KyleMatoba,Francesco\\nSalvi,MatteoPagliardini,SiminFan,AndreasKöpf, RobertHorneandJohnWeinman.1999. Patients’be-\\nAmirkeivanMohtashami,etal.2023. Meditron-70b: liefs about prescribed medicines and their role in\\nScalingmedicalpretrainingforlargelanguagemod- adherence to treatment in chronic physical illness.\\nels. arXivpreprintarXiv:2311.16079. Journalofpsychosomaticresearch,47(6):555–567.\\nClément Christophe, Praveen K Kanithi, Tathagata HaoanJin,SiyuanChen,MengyueWu,andKennyQ\\nRaha,ShadabKhan,andMarcoAFPimentel.2024. Zhu.2023. Psyeval:Acomprehensivelargelanguage\\nMed42-v2: Asuiteofclinicalllms. modelevaluationbenchmarkformentalhealth. arXiv\\npreprintarXiv:2311.09189.\\nMunmunDeChoudhury,MeredithRingelMorris,and\\nRyen W White. 2014. Seeking and sharing health Yiqiao Jin, Mohit Chandra, Gaurav Verma, Yibo Hu,\\ninformationonline: comparingsearchenginesand Munmun De Choudhury, and Srijan Kumar. 2024.\\nsocialmedia. InProceedingsoftheSIGCHIconfer- Bettertoaskinenglish: Cross-lingualevaluationof\\nenceonhumanfactorsincomputingsystems,pages largelanguagemodelsforhealthcarequeries. InPro-\\n1365–1376. ceedingsoftheACMWebConference2024,WWW’24,page2627–2638,NewYork,NY,USA.Associa- YangLyu,HanYu,FengliGao,XinhuaHe,andJulia\\ntionforComputingMachinery. Crilly. 2023. The lived experiences of health care\\nprofessionals regarding visiting restrictions in the\\nRyoKamoi,TanyaGoyal,JuanDiegoRodriguez,and emergencydepartmentduringthecovid-19pandemic:\\nGregDurrett.2023. WiCE:Real-worldentailment Amulti-perspectivequalitativestudy. NursingOpen,\\nforclaimsinWikipedia. InProceedingsofthe2023 10(5):3243–3252.\\nConference on Empirical Methods in Natural Lan-\\nguageProcessing,pages7561–7583,Singapore.As- GHarryMcLaughlin.1969. Smoggrading-anewread-\\nsociationforComputationalLinguistics. abilityformula. Journalofreading,12(8):639–646.\\nPraveenKKanithi,ClémentChristophe,MarcoAFPi- David Mechanic and Sharon Meyer. 2000. Concepts\\nmentel,TathagataRaha,NadaSaadi,HamzaJaved, oftrustamongpatientswithseriousillness. Social\\nSvetlana Maslenkova, Nasir Hayat, Ronnie Rajan, science&medicine,51(5):657–668.\\nand Shadab Khan. 2024. Medic: Towards a com-\\nprehensiveframeworkforevaluatingllmsinclinical Sepideh Mesbah, Jie Yang, Robert-Jan Sips,\\napplications. arXivpreprintarXiv:2409.07314. Manuel Valle Torre, Christoph Lofi, Alessan-\\ndroBozzon,andGeert-JanHouben.2019a. Training\\nSarvnazKarimi,ChenWang,AlejandroMetke-Jimenez, data augmentation for detecting adverse drug\\nRaj Gaire, and Cecile Paris. 2015. Text and data reactionsinuser-generatedcontent. InProceedings\\nminingtechniquesinadversedrugreactiondetection. of the 2019 Conference on Empirical Methods\\nACMComputingSurveys(CSUR),47(4):1–39. in Natural Language Processing and the 9th\\nInternationalJointConferenceonNaturalLanguage\\nMarzena Karpinska, Nader Akoury, and Mohit Iyyer. Processing(EMNLP-IJCNLP),pages2349–2359.\\n2021. The perils of using mechanical turk to eval-\\nuate open-ended text generation. arXiv preprint Sepideh Mesbah, Jie Yang, Robert-Jan Sips, Manuel\\narXiv:2109.06835. ValleTorre,ChristophLofi,AlessandroBozzon,and\\nGeert-Jan Houben. 2019b. Training data augmen-\\nAlanEKazdinandSarahMRabbitt.2013. Novelmod- tation for detecting adverse drug reactions in user-\\nelsfordeliveringmentalhealthservicesandreducing generatedcontent. InProceedingsofthe2019Con-\\ntheburdensofmentalillness. ClinicalPsychological ferenceonEmpiricalMethodsinNaturalLanguage\\nScience,1(2):170–191. Processing and the 9th International Joint Confer-\\nence on Natural Language Processing (EMNLP-\\nSteve H King Jr. 2011. The structure of empathy in IJCNLP),pages2349–2359,HongKong,China.As-\\nsocialworkpractice. JournalofHumanBehaviorin sociationforComputationalLinguistics.\\ntheSocialEnvironment,21(6):679–695.\\nMeta-LLama3.1. 2024. Introducing llama 3.1: Our\\nGG Landis JRKoch. 1977. The measurement of ob- most capable models to date. https://ai.meta.\\nserver agreement for categorical data. Biometrics, com/blog/meta-llama-3-1/. [Accessed 07-09-\\n33(1):159174. 2024].\\nHannah R Lawrence, Renee A Schneider, Susan B SewonMin,KalpeshKrishna,XinxiLyu,MikeLewis,\\nRubin, Maja J Mataric´, Daniel J McDuff, and Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle-\\nMeganJonesBell.2024. Theopportunitiesandrisks moyer,andHannanehHajishirzi.2023. FActScore:\\nof large language models in mental health. JMIR Fine-grainedatomicevaluationoffactualprecision\\nMentalHealth,11(1):e59479. inlongformtextgeneration. InProceedingsofthe\\n2023ConferenceonEmpiricalMethodsinNatural\\nKathyLee,AshequlQadir,SadidAHasan,VivekDatla, Language Processing, pages 12076–12100, Singa-\\nAadityaPrakash,JoeyLiu,andOladimejiFarri.2017. pore.AssociationforComputationalLinguistics.\\nAdverse drug event detection in tweets with semi-\\nsupervised convolutional neural networks. In Pro- InesMontani,MatthewHonnibal,MatthewHonnibal,\\nceedings of the 26th international conference on AdrianeBoyd,SofieVanLandeghem,andHenning\\nworldwideweb,pages705–714. Peters. 2023. explosion/spaCy: v3.7.2: Fixes for\\nAPIsandrequirements.\\nYunxiangLi,ZihanLi,KaiZhang,RuilongDan,Steve\\nJiang,andYouZhang.2023. Chatdoctor: Amedical ManishaNatarajanandMatthewGombolay.2020. Ef-\\nchat model fine-tuned on a large language model fects of anthropomorphism and accountability on\\nmeta-ai (llama) using medical domain knowledge. trust in human robot interaction. In Proceedings\\nCureus,15(6). ofthe2020ACM/IEEEinternationalconferenceon\\nhuman-robotinteraction,pages33–42.\\nYinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-\\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis, HarshaNori, NicholasKing, ScottMayerMcKinney,\\nLuke Zettlemoyer, and Veselin Stoyanov. 2019. DeanCarignan,andEricHorvitz.2023a. Capabili-\\nRoberta: A robustly optimized bert pretraining ap- tiesofgpt-4onmedicalchallengeproblems. arXiv\\nproach. Preprint,arXiv:1907.11692. preprintarXiv:2303.13375.HarshaNori,YinTatLee,ShengZhang,DeanCarig- Ashish Sharma, Kevin Rushton, Inna Wanyin Lin,\\nnan, Richard Edgar, Nicolo Fusi, Nicholas King, David Wadden, Khendra G Lucas, Adam S Miner,\\nJonathan Larson, Yuanzhi Li, Weishung Liu, et al. Theresa Nguyen, and Tim Althoff. 2023. Cog-\\n2023b. Can generalist foundation models outcom- nitive reframing of negative thoughts through\\npetespecial-purposetuning? casestudyinmedicine. human-languagemodelinteraction. arXivpreprint\\narXivpreprintarXiv:2311.16452. arXiv:2305.02466.\\nOpenAI-GPT-4o. 2024. Hello gpt-4o. https:// KaranSinghal,ShekoofehAzizi,TaoTu,SSaraMah-\\nopenai.com/index/hello-gpt-4o/. [Accessed davi,JasonWei,HyungWonChung,NathanScales,\\n07-09-2024]. AjayTanwani,HeatherCole-Lewis,StephenPfohl,\\netal.2023a. Largelanguagemodelsencodeclinical\\nOpenAI-TextEmb-3-Large. 2024. New knowledge. Nature,620(7972):172–180.\\nembedding models and api up-\\ndates. https://openai.com/index/ Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\\nnew-embedding-models-and-api-updates/. Ellery Wulczyn, Le Hou, Kevin Clark, Stephen\\n[Accessed24-09-2024]. Pfohl, Heather Cole-Lewis, Darlene Neal, et al.\\n2023b. Towards expert-level medical question an-\\nHannelePalukka,ArjaHaapakorpi,PetraAuvinen,and sweringwithlargelanguagemodels. arXivpreprint\\nJaana Parviainen. 2021. Outlining the role of ex- arXiv:2305.09617.\\nperiential expertise in professional work in health\\ncare service co-production. International Journal EricSingle.1995. Definingharmreduction. Drugand\\nof Qualitative Studies on Health and Well-being, AlcoholReview,14(3):287–290.\\n16(1):1954744.\\nVladanStarcevicandDavidBerle.2013. Cyberchon-\\ndria: towards a better understanding of excessive\\nShobha Phansalkar, Heleen Van der Sijs, Alisha D\\nhealth-related internet use. Expert review of neu-\\nTucker,AmritaADesai,DouglasSBell,JonathanM\\nrotherapeutics,13(2):205–213.\\nTeich, Blackford Middleton, and David W Bates.\\n2013. Drug—druginteractionsthatshouldbenon-\\nArunJamesThirunavukarasu,RefaatHassan,Shathar\\ninterruptiveinordertoreducealertfatigueinelec-\\nMahmood, Rohan Sanghera, Kara Barzangi, Mo-\\ntronichealthrecords. JournaloftheAmericanMedi-\\nhanned El Mukashfi, and Sachin Shah. 2023. Tri-\\ncalInformaticsAssociation,20(3):489–493.\\nalling a large language model (chatgpt) in general\\npractice with the applied knowledge test: observa-\\nJulie Repper and Tim Carter. 2011. A review of the\\ntional study demonstrating opportunities and limi-\\nliteratureonpeersupportinmentalhealthservices.\\ntations in primary care. JMIR Medical Education,\\nJournalofmentalhealth,20(4):392–411.\\n9(1):e46599.\\nDavid Restrepo, Chenwei Wu, Constanza Vásquez-\\nSoroush Vosoughi, Deb Roy, and Sinan Aral. 2018.\\nVenegas, João Matos, Jack Gallifant, Leo An-\\nThe spread of true and false news online. science,\\nthony Celi, Danielle S Bitterman, and Luis Filipe\\n359(6380):1146–1151.\\nNakayama.2024. Analyzingdiversityinhealthcare\\nllmresearch: Ascientometricperspective. medRxiv,\\nYuxi Wang, Martin McKee, Aleksandra Torbica, and\\npages2024–06.\\nDavidStuckler.2019. Systematicliteraturereviewon\\nthespreadofhealth-relatedmisinformationonsocial\\nHelenRiessandGordonKraft-Todd.2014. Empathy: a\\nmedia. Socialscience&medicine,240:112552.\\ntooltoenhancenonverbalcommunicationbetween\\nclinicians and their patients. Academic Medicine, JasonWei,XuezhiWang,DaleSchuurmans,Maarten\\n89(8):1108–1112. Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,\\netal.2022. Chain-of-thoughtpromptingelicitsrea-\\nKoustuv Saha, Benjamin Sugar, John Torous, Bruno\\nsoninginlargelanguagemodels. Advancesinneural\\nAbrahao, EmreKıcıman, andMunmunDeChoud-\\ninformationprocessingsystems,35:24824–24837.\\nhury.2019. Asocialmediastudyontheeffectsof\\npsychiatric medication use. In Proceedings of the JerryWei,ChengrunYang,XinyingSong,YifengLu,\\nInternationalAAAIConferenceonWebandSocial Nathan Hu, Jie Huang, Dustin Tran, Daiyi Peng,\\nMedia,volume13,pages440–451. RuiboLiu,DaHuang,CosmoDu,andQuocV.Le.\\n2024. Long-formfactualityinlargelanguagemodels.\\nPunyajoySaha,BinnyMathew,KiranGarimella,and Preprint,arXiv:2403.18802.\\nAnimesh Mukherjee. 2021. “short is the road that\\nleadsfromfeartohate”: Fearspeechinindianwhat- Bernard L Welch. 1947. The generalization of ‘stu-\\nsappgroups. InProceedingsoftheWebconference dent’s’problemwhenseveraldifferentpopulationvar-\\n2021,pages1110–1121. lancesareinvolved. Biometrika,34(1-2):28–35.\\nAbeedSarkerandGracielaGonzalez.2015. Portable Katrin Weller and Katharina Kinder-Kurlanda. 2015.\\nautomatic text classification for adverse drug reac- Uncoveringthechallengesincollection,sharingand\\ntiondetectionviamulti-corpustraining. Journalof documentation: Thehiddendataofsocialmediare-\\nbiomedicalinformatics,53:196–207. search? In Proceedings of the International AAAIConference on Web and Social Media, volume 9,\\npages28–37.\\nKatrinWellerandKatharinaEKinder-Kurlanda.2016.\\nAmanifestofordatasharinginsocialmediaresearch.\\nInProceedingsofthe8thACMConferenceonWeb\\nScience,pages166–172.\\nMichael S Wolf, Julie A Gazmararian, and David W\\nBaker.2005. Healthliteracy andfunctionalhealth\\nstatus among older adults. Archives of internal\\nmedicine,165(17):1946–1952.\\nKailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian\\nXie,ZiyanKuang,andSophiaAnaniadou.2023. To-\\nwardsinterpretablementalhealthanalysiswithlarge\\nlanguagemodels. InProceedingsofthe2023Con-\\nferenceonEmpiricalMethodsinNaturalLanguage\\nProcessing,pages6056–6077,Singapore.Associa-\\ntionforComputationalLinguistics.\\nKailaiYang,TianlinZhang,ZiyanKuang,QianqianXie,\\nJiminHuang,andSophiaAnaniadou.2024. Mental-\\nlama: interpretablementalhealthanalysisonsocial\\nmediawithlargelanguagemodels. InProceedings\\noftheACMonWebConference2024,pages4489–\\n4500.\\nYuhengZha,YichiYang,RuichenLi,andZhitingHu.\\n2023. AlignScore: Evaluating factual consistency\\nwith a unified alignment function. In Proceedings\\nof the 61st Annual Meeting of the Association for\\nComputationalLinguistics(Volume1: LongPapers),\\npages11328–11348,Toronto,Canada.Association\\nforComputationalLinguistics.A Listofsubreddits isenoughtotriggeranadversereaction.\\n• Time-related: Thesearethereactionsthatare\\nWe use the following list of subreddit to collect\\nrelatedduetoprolongeduseinapsychiatric\\ndataforfurtherfiltering: ‘r/depression’,‘r/anxiety’,\\nmedicationwhichdoesn’ttendtoaccumulate.\\n‘r/bipolar’,‘r/BPD’,‘r/schizophrenia’,‘r/autism’,\\n• Dose-and-time-related: These are the reac-\\n‘r/mentalhealth’, ‘r/askdocs’, ‘r/diagnoseme’,\\ntionsthatarerelatedduetodoseaccumulation,\\n‘r/medical_advice’.\\norwithprolongeduseofthepsychiatricmedi-\\nThechoiceforthesesubredditsstemsfrompast\\ncation.\\nworks (Mesbah et al., 2019b; Saha et al., 2019;\\n• Withdrawal: Thesearethereactionsthatare\\nChancelloretal.,2019).\\nrelatedtotheundesiredeffectsofceasingor\\nstoppingtheintakeofthepsychiatricmedica-\\nB ADRDetectionScenariosandPrompts\\ntion.\\nPostsonsocialmediaplatformsdiscussingadverse\\nTable8and9presenttheLLMpromptsusedfor\\ndrug reactions related to psychiatric medications\\nzero-andfew-shotADRmulticlassclassification.\\nare often written by individuals with limited or\\nno medical knowledge. As a result, the level of D AnnotationTaskDetails\\ncertainty in expressing concerns about potential\\nsideeffectscanvarysignificantly. Somepostsare We collaborated with a team of four medical ex-\\nmore assertive, while others express uncertainty. perts(threedoctorsandonemedicalstudent), all\\nForexample,individualsmayreportexperiencing of whom are co-authors of this work. Hence, we\\nadversesymptomsaftertakingpsychiatricmedica- did not provide any additional compensation for\\ntions, beunsureifthesesymptomsarecausedby theannotationtask. Furthermore,InstitutionalRe-\\nthemedication,orinquirewhethertheirsymptoms view Board (IRB) approval was obtained before\\ncouldberelatedtothedrugstheyaretaking. Ad- the annotation task. To facilitate the annotation\\nditionally,somepostsmayexpressconcernsabout process, we developed a custom web-based tool\\npossible future side effects of starting a new psy- specificallyforannotatingthePsych-ADRbench-\\nchiatricmedication. Thesescenarioswereusedas mark. Figure 4 presents the interface of the an-\\nexamples to guide both annotators and language notationtoolusedforthedataannotationpurpose.\\nmodels. Atlast,bothLLMsandexpertswereasked Weconductedapreliminaryroundoftestannota-\\ntodeterminewhethertheconcerncouldberelated tions to familiarize the annotators with both the\\ntoADRornotbasedontheirexperience. Table6 criteria and the annotation tool. For the further\\nandTable7presentpromptsusedwithLLMsfor rounds, the average Fleiss’ kappa inter-annotator\\ndetectingcasesofADRfrompsychiatricmedica- agreementwas∼ κ =0.33,withallthreeannota-\\ntion. torsagreeingonthelabelsfor48%oftheposts,in-\\ndicatingafairlevelofagreement(LandisJRKoch,\\nC ADRMulticlassClassification 1977). Theseresultsareconsistentwithprevious\\nDefinitionsandPrompts research,whichhasreportedsimilarinter-annotator\\nagreement scores for tasks of comparable diffi-\\nWeprovidedthesamedefinitionstoboththeLLMs\\nculty(Karpinskaetal.,2021;Sahaetal.,2021).\\nand expert annotators for the annotation task. To\\nindependentlyevaluatetheLLMs,wefocusedonly D.1 ADRPostReplyAnnotationand\\nonpostsannotatedasexpressingADR-relatedcon- Generation\\ncerns (N =133) in the Psych-ADR benchmark. Figure5presentsthesampleofstructureoftheex-\\nAdverse drug reactions (ADRs) related to a psy- pertresponsesprovidedinthePsych-ADRbench-\\nchiatricmedicationscanbeclassifiedinoneofthe mark. Themostexperienceddoctoronthecollabo-\\nfollowingclasses: ratingteamprovidedtheresponses,witheachtak-\\ning∼8minutestoansweronaverage. Weprovided\\n• Dose-related: Thesearethereactionsthatare\\nthe same set of instructions to the domain expert\\ndirectlyrelatedtothedosageofthepsychiatric\\nandtheLLMsforwritingtheresponsetoanADR\\nmedication.\\nrelatedquery. BoththeexpertsandtheLLMswere\\n• Non-dose-related: These are the reactions prompted to write responses that follow a strict\\nwhereanyexposureofpsychiatricmedication logicalstructuretypicallyseeninclinicalsettings:Figure4: AnnotationinterfaceforthePsych-ADRbenchmarkusedintheannotationprocess. Theinterfacedisplays\\ntheposttitleandcontent,alongwithaccesstoannotationguidelines. Intheleftimagescreenshot,theannotator\\nidentifiesanadversedrugreaction(ADR)relatedtopsychiatricmedication,thenprovidesabriefrationaleand\\nselectstheclassofADR.Intherightimagescreenshot,theannotatorindicatesthatnoADRispresent,inwhich\\ncaseonlyarationaleforthisdecisionisrequired.\\nLLM Version ParameterSize\\nGPT-4o 2024-08-06(OpenAI-GPT-4o,2024) (undisclosed)\\nGPT-4Turbo turbo-2024-04-09(Achiametal.,2023) (undisclosed)\\nClaude3.5Sonnet 2024-06-20 (undisclosed)\\nClaude3Opus 2024-02-29 (undisclosed)\\nClaude3Haiku 2024-03-07(Anthropic-Claude,2024) (undisclosed)\\nLLama-3.1405BInstruct-Turbo (Meta-LLama3.1,2024) 405billion\\nLLama-3.170BInstruct-Turbo (Meta-LLama3.1,2024) 70billion\\nLlama3-Med42-v270B (Christopheetal.,2024) 70billion\\nLlama3-OpenBioLLM70B (AnkitPal,2024) 70billion\\nTable5: Modelsandtheircorrespondingversiondates\\nthe adverse drug reaction which is available\\ninthepostandprovideabriefreasoningfor\\nproposingaharmreductionstrategy.\\n• As step 4, ask potential questions to get\\nadditional information that might help in\\nprovidingabetterresponse.\\nFigure5: Sampleanswerrepresentingthestructureof\\nanswersprovidedinthePsych-ADRbenchmarkdataset.\\n• Asstep5, provideabriefexplanationofthe\\n• Start with empathizing with the post writer harmreductionstrategythatthepostershould\\nandacknowledgingtheirconcern. followtogetrelief.\\n• As step 2, provide a brief explanation for\\n• Finally,askthepostwriterabouthowtheyfeel\\nthe potential diagnosis as an adverse drug\\nabouttheproposedharmreductionstrategy.\\nreaction.\\nTable 10 presents the prompt for ADR reply\\n• As step 3, talk briefly about the evidence of promptgeneration.Type Prompt\\nSystem Youareanexpertpsychiatristandpsychologist,andyouhelppeoplewiththeirmentalhealthandadverse\\nPrompt drugreaction(ADR)relatedqueries. Youprovideadvice,andguidancetopeoplewhoareexperiencing\\nmentalhealthissues.Givenbelowaredifferentevents/waysinwhichconcernsrelatedtoapotentialcaseof\\nadversedrugreaction(ADR)canbeexpressed(PresentedasADVERSE_DRUG_REACTION_EVENTS),\\ntheRedditposttitle(PresentedasPOST_TITLE),andtheRedditposttext(PresentedasPOST_TEXT)with\\nmentionsofpsychiatricmedicinesandsymptoms.\\nADVERSE_DRUG_REACTION_EVENTS:Aneventcanpotentiallyexpressconcernsforanadversedrug\\nreaction(ADR)relatedtopsychiatricmedicationsinoneormoreofthefollowingfour(4)ways:\\n1)Thepersonisexperiencingsomeadversesymptomsaftertakingpsychiatricmedicine(s).\\n2)Thepersonisunsureiftheadversesymptomsarecausedduetopsychiatricmedication(s).\\n3)Thepersonisinquiringwhethertheadversesymptomswerepotentiallycausedduetoanypsychiatric\\nmedicinetakenbytheperson.\\n4)Personisnottakingpsychiatricmedicationandisconcernediftakinganewpsychiatricmedicationwould\\nhaveside-effectsinthefuture.\\nAND\\nThepostasksaquestionthatisrelevanttotheadversedrugreaction.\\nKeepingthecontextofthePOST_TITLEandPOST_TEXTinviewandusingthedifferentwaysofpotential\\nexpressionsprovidedinADVERSE_DRUG_REACTION_EVENTS,yourtaskistodeterminewhetherthe\\npostactuallyexpressesaboutanadversedrugreaction(ADR)relatedtoapsychiatricmedicationandasksa\\nquestionabouttheADRrelatedtothepsychiatricmedicationornot.\\nYoushouldthinkstepbystepandprovidearationaleforyouranswer.Youshouldfirstprovideyourrationale\\nandatlastyoushouldexplicitlyprovidealabelas‘ADR-Yes’or‘ADR-No’determiningwhetherthepost\\ntalksaboutadversedrugreactionornotrespectively.Exactlyprovideoneofclasslabelandalwaysprovide\\ntheexactclasslabelintheformat-ClassLabel:<ADR-YesorADR-No>\\nUser POST_TITLE:<post_title>\\nPrompt\\nPOST_TEXT:<post_text>\\nTable6: PromptusedfortheADRdetectiontaskinzero-shotsetting.Type Prompt\\nSystem Youareanexpertpsychiatristandpsychologist,andyouhelppeoplewiththeirmentalhealthandadverse\\nPrompt drugreaction(ADR)relatedqueries. Youprovideadvice,andguidancetopeoplewhoareexperiencing\\nmentalhealthissues.Givenbelowaredifferentevents/waysinwhichconcernsrelatedtoapotentialcaseof\\nadversedrugreaction(ADR)canbeexpressed(PresentedasADVERSE_DRUG_REACTION_EVENTS),\\n5examplesofRedditposttitle,posttextandclasslabel(PresentedasEXAMPLE_POST_TITLE,EXAM-\\nPLE_POST_TEXT,EXAMPLE_CLASS_LABEL),theRedditposttitle(PresentedasPOST_TITLE),and\\ntheRedditposttext(PresentedasPOST_TEXT)withmentionsofpsychiatricmedicinesandsymptoms.\\nADVERSE_DRUG_REACTION_EVENTS:Aneventcanpotentiallyexpressconcernsforanadversedrug\\nreaction(ADR)relatedtopsychiatricmedicationsinoneormoreofthefollowingfour(4)ways:\\n1)Thepersonisexperiencingsomeadversesymptomsaftertakingpsychiatricmedicine(s).\\n2)Thepersonisunsureiftheadversesymptomsarecausedduetopsychiatricmedication(s).\\n3)Thepersonisinquiringwhethertheadversesymptomswerepotentiallycausedduetoanypsychiatric\\nmedicinetakenbytheperson.\\n4)Personisnottakingpsychiatricmedicationandisconcernediftakinganewpsychiatricmedicationwould\\nhaveside-effectsinthefuture.\\nAND\\nThepostasksaquestionthatisrelevanttotheadversedrugreaction.\\nSetofExamples:\\n1.EXAMPLE_POST_TITLE:<example_post_title_1>\\nEXAMPLE_POST_TEXT:<example_post_text_1>\\nEXAMPLE_CLASS_LABEL:<example_class_label_1>\\n...\\n...\\nEXAMPLE_CLASS_LABEL:<example_class_label_5>\\nKeepingthecontextofthePOST_TITLEandPOST_TEXTinviewandandusingthe5examples(EXAM-\\nPLE_POST_TITLE,EXAMPLE_POST_TEXT,EXAMPLE_CLASS_LABEL)andusingthedifferentways\\nofpotentialexpressionsprovidedinADVERSE_DRUG_REACTION_EVENTS,yourtaskistodetermine\\nwhetherthepostactuallyexpressesaboutanadversedrugreaction(ADR)relatedtoapsychiatricmedication\\nandasksaquestionabouttheADRrelatedtothepsychiatricmedicationornot.\\nYoushouldthinkstepbystepandprovidearationaleforyouranswer.Youshouldfirstprovideyourrationale\\nandatlastyoushouldexplicitlyprovidealabelas‘ADR-Yes’or‘ADR-No’determiningwhetherthepost\\ntalksaboutadversedrugreactionornotrespectively.Exactlyprovideoneofclasslabelandalwaysprovide\\ntheexactclasslabelintheformat-ClassLabel:<ADR-YesorADR-No>\\nUser POST_TITLE:<post_title>\\nPrompt\\nPOST_TEXT:<post_text>\\nTable7: PromptusedfortheADRdetectiontaskin5-shotsetting.Type Prompt\\nSystem Youareanexpertpsychiatristandpsychologist,andyouhelppeoplewiththeirmentalhealthandadverse\\nPrompt drugreaction(ADR)relatedqueries. Youprovideadvice,andguidancetopeoplewhoareexperiencing\\nmentalhealthissues. Givenbelowisthelistofclassnamesanddefinitionsforeachclassofadversedrug\\nreaction(ADR)(PresentedasADR_CLASS_NAMES_DEFINITION),theRedditposttitle(Presentedas\\nPOST_TITLE),andtheRedditposttext(PresentedasPOST_TEXT)expressingadversedrugreaction(ADR)\\nrelatedtoapsychiatricmedication/s.\\nADR_CLASS_NAMES_DEFINITION:Adversedrugreactions(ADRs)relatedtoapsychiatricmedications\\ncanbeclassifiedinoneofthefollowingclasses:\\n1)Dose-related-adr-reactions:Thesearethereactionsthataredirectlyrelatedtothedosageofthepsychiatric\\nmedication.\\n2)Non-dose-adr-reactions:Thesearethereactionswhereanyexposureofpsychiatricmedicationisenough\\ntotriggeranadversereaction.\\n3)Dose-and-time-adr-reactions:Thesearethereactionsthatarerelatedduetodoseaccumulation,orwith\\nprolongeduseofthepsychiatricmedication.\\n4)Time-related-adr-reactions:Thesearethereactionsthatarerelatedduetoprolongeduseinapsychiatric\\nmedicationwhichdoesn’ttendtoaccumulate.\\n5)Withdrawal-adr-reactions:Thesearethereactionsthatarerelatedtotheundesiredeffectsofceasingor\\nstoppingtheintakeofthepsychiatricmedication.\\nKeepingthecontextofthePOST_TITLEandPOST_TEXTinviewandusingthedefinitionsprovidedin\\nADR_CLASS_NAMES_DEFINITION,yourtaskistodeterminetheclassofadversedrugreaction(ADR)\\nrelatedtoapsychiatricmedication/sexpressedinthepost.\\nYoushouldthinkstepbystepandprovidearationaleforyouranswer.Youshouldfirstprovideyourrationale\\nandatlastyoushouldexplicitlyprovidetheclasslabelfromADR_CLASS_NAMES_DEFINITIONwhichis\\nmostappropriateandapplicableforthepost.Onlyprovideoneofclasslabelandalwaysprovidetheexact\\nclasslabelintheformat-ClassLabel:<labelname>\\nUser POST_TITLE:<post_title>\\nPrompt\\nPOST_TEXT:<post_text>\\nTable8: PromptusedfortheADRmulticlassclassificationtaskinzero-shotsetting.Type Prompt\\nSystem Youareanexpertpsychiatristandpsychologist,andyouhelppeoplewiththeirmentalhealthandadverse\\nPrompt drugreaction(ADR)relatedqueries. Youprovideadvice,andguidancetopeoplewhoareexperiencing\\nmental health issues. Given below is the list of class names and definitions for each class of adverse\\ndrug reaction (ADR) (Presented as ADR_CLASS_NAMES_DEFINITION), 2 examples of reddit post\\ntitle,posttextandclasslabel(PresentedasEXAMPLE_POST_TITLE,EXAMPLE_POST_TEXT,EXAM-\\nPLE_CLASS_LABEL),theRedditposttitle(PresentedasPOST_TITLE),andtheRedditposttext(Presented\\nasPOST_TEXT)expressingadversedrugreaction(ADR)relatedtoapsychiatricmedication/s.\\nADR_CLASS_NAMES_DEFINITION:Adversedrugreactions(ADRs)relatedtoapsychiatricmedications\\ncanbeclassifiedinoneofthefollowingclasses:\\n1)Dose-related-adr-reactions:Thesearethereactionsthataredirectlyrelatedtothedosageofthepsychiatric\\nmedication.\\n2)Non-dose-adr-reactions:Thesearethereactionswhereanyexposureofpsychiatricmedicationisenough\\ntotriggeranadversereaction.\\n3)Dose-and-time-adr-reactions:Thesearethereactionsthatarerelatedduetodoseaccumulation,orwith\\nprolongeduseofthepsychiatricmedication.\\n4)Time-related-adr-reactions:Thesearethereactionsthatarerelatedduetoprolongeduseinapsychiatric\\nmedicationwhichdoesn’ttendtoaccumulate.\\n5)Withdrawal-adr-reactions:Thesearethereactionsthatarerelatedtotheundesiredeffectsofceasingor\\nstoppingtheintakeofthepsychiatricmedication.\\nSetofExamples:\\n1)EXAMPLE_POST_TITLE:<example_title_1>\\nEXAMPLE_POST_TEXT:<example_text_1>\\nEXAMPLE_CLASS_LABEL:<example_class_label_1>\\n...\\nEXAMPLE_CLASS_LABEL:<example_class_label_5>\\nKeepingthecontextofthePOST_TITLEandPOST_TEXTinviewandusingthe2examples(EXAM-\\nPLE_POST_TITLE,EXAMPLE_POST_TEXT,EXAMPLE_CLASS_LABEL)anddefinitionsprovidedin\\nADR_CLASS_NAMES_DEFINITION,yourtaskistodeterminetheclassofadversedrugreaction(ADR)\\nrelatedtoapsychiatricmedication/sexpressedinthepost. Youshouldthinkstepbystepandprovidea\\nrationaleforyouranswer.Youshouldfirstprovideyourrationaleandatlastyoushouldexplicitlyprovidethe\\nclasslabelfromADR_CLASS_NAMES_DEFINITIONwhichismostappropriateandapplicableforthe\\npost. Onlyprovideoneofclasslabelandalwaysprovidetheexactclasslabelintheformat-ClassLabel:\\n<labelname>\\nUser POST_TITLE:<post_title>\\nPrompt\\nPOST_TEXT:<post_text>\\nTable9: PromptusedfortheADRmulticlassclassificationtaskin5-shotsetting.Type Prompt\\nSystem You are an expert psychiatrist and psychologist, and you help people with their mental health and ad-\\nPrompt verse drug reaction (ADR) related queries. You provide advice, and guidance to people who are expe-\\nriencing mental health issues. Given below is the guideline for generating an ideal reply (Presented as\\nIDEAL_REPLY_TEMPLATE),theredditposttitle(PresentedasPOST_TITLE),andtheredditposttext\\n(PresentedasPOST_TEXT)expressingadversedrugreaction(ADR)relatedtoapsychiatricmedication/s.\\nIDEAL_REPLY_TEMPLATE:An\"idealreply\"followsthebelowsteps:\\n1.Startwithempathizingwiththepostwriterandacknowledgingtheirconcern.\\n2.Asstep2,provideabriefexplanationforthepotentialdiagnosisasanadversedrugreaction.\\n3.Asstep3,talkbrieflyabouttheevidenceoftheadversedrugreactionwhichisavailableinthepostand\\nprovideabriefreasoningforproposingaharmreductionstrategy.\\n4. Asstep4, askpotentialquestionstogetadditionalinformationthatmighthelpinprovidingabetter\\nresponse.\\n5.Asstep5,provideabriefexplanationoftheharmreductionstrategythatthepostershouldfollowtoget\\nrelief.\\n6.Finally,askthepostwriterabouthowtheyfeelabouttheproposedharmreductionstrategy.\\nBelowaresomeadditionalguidelines:\\n1.Donotwordslikedearposter,dearuser,bestregards,etc.intheresponse.\\n2.Someofthestepsofan\"idealanswer\"areoptionalandyoucanskipthoseifthatmakesmoresense,butit\\nisrecommendedtoincludethem.\\n3.Theresponseshouldbeconciseandtothepointandwiththewordlimitof225wordsor300token.Never\\nexceedthisword/tokenlimit.\\nKeepingthecontextofthePOST_TITLEandPOST_TEXTinviewandusingtheguidelineprovidedin\\nIDEAL_REPLY_TEMPLATE,yourtaskistogenerateareplytothepost.Yourresponseshouldbehelpful\\nandaimtoprovideasolutiontotheissues/problemsmentionedinthepost.\\nUser POST_TITLE:<post_title>\\nPrompt\\nPOST_TEXT:<post_text>\\nTable10: PromptusedforgeneratingthereplyforpostexpressingADRrelatedconcerns.E ModelDetails,Hyperparameters,and Opus) misclassifying 42% examples. This quali-\\nCompute tativelyimpliedthatmodelsshowedlackoflived\\nexperienceanda“risk-averse”behavior. Analyz-\\nWe use API-based model inference for GPT4-\\ning the ADR multiclass classification results in\\nTurbo, GPT-4o, Llama 3.1-70B Instruct, Llama\\nzero-shotsetting(Figure7),weobservedthatWith-\\n3.1-405B Instruct, Claude 3 Haiku, Claude 3\\ndrawalADRswerecorrectlyclassifiedmorethan\\nOpus,Claude3.5Sonnet. WeusedAzureOpenAI\\n90%timesbyallmodels. However,allLLMsstrug-\\nservice for accessing GPT4-Turbo & GPT-4o\\ngledbetweentheDoseandNon-DoserelatedADRs\\nmodels,Together.aiforaccessingLlama3.1-70B\\nandfailedtounderstandthenuancesbetweenthe\\nInstruct & Llama 3.1-405B Instruct, and the\\ntwotypesofADRs.\\nAnthropic platform for accessing the Claude\\nseries models. For OpenBioLLM-Llama3-70B\\nG ADRDetectionandMulticlass\\nand Llama3-Med42v2-70B, we did GPU-based\\nClassificationErrorAnalysis\\ninferenceusingan8xNVIDIAL40SGPUcluster.\\nThe hyperparameters for API-based inference\\nWeconductedaqualitativeerroranalysisformis-\\nmodels and GPU-based inference models are\\nclassifiedexamplesintheADRdetectionandmul-\\npresented below. Table 5 presents the details\\nticlass classification tasks, focusing on Claude 3\\nregardingthemodelsizesandversions.\\nOpus and Llama 3.1 405B in few-shot settings.\\nUpontheanalysis,twomajorthemesemerged: (a)\\nHyperparameters for GPT, Llama 3.1 and\\nlackoflivedexperienceand(b)incorrectassump-\\nClaude series models: temperature t = 0 (for\\ntionsaboutpotentialADRqueries. Inthefirstsetof\\nADR detection and multiclass classification) &\\nerrors,modelsadheredtoorigidlytopromptrules,\\nt = 0.6 (for response generation), top_p= 1,\\nmissingotherpossiblesymptomexplanations. In\\nfrequency_penalty= 0, presence_penalty= 0,\\nthe second set of errors, models often confused\\nmax_tokens= 600 (for ADR detection and\\npostsseekingemotionalsupportwithADR-related\\nmulticlassclassification)&max_tokens= 340(for\\nqueries. The model misjudged a person’s use of\\nresponsegeneration),numberofcompletions= 1,\\nsocial media to share their feelings as a potential\\ntop_k= 50(forClaudeseriesmodels)\\nADR-relatedquery.\\nForcaseswherethemodeldemonstratesalack\\nHyperparameters for OpenBioLLM-Llama3-\\noflivedexperience,weobserveexpertquotessuch\\n70BandLlama3-Med42v2-70B:temperaturet =\\nas“Patientishavingswallowingdifficultieswhich\\n0 (for ADR detection and multiclass classifica-\\nseemstobeduetoGIissuesratherthanmedication”\\ntion)&t = 0.6(forresponsegeneration),top_p=\\nand“WecannotsayshehasanADRsincesheis\\n1, frequency_penalty= 0, presence_penalty= 0,\\nactually sleep deprived, plus slightly (minimally)\\nmax_tokens= 600(forADRdetectionandmulti-\\noverweight,soweshouldneedtoassessifsheactu-\\nclass classification) & max_tokens= 340 (for re-\\nallyhassleepapnea.”. Thesequotesindicatethat\\nsponse generation), number of completions= 1,\\nthemodelisquicktolabelapostasADRandcan\\ntop_k= 50.\\noverlook some other contributing factors for the\\nsymptoms,whiletheexpertsarecautiouswhilela-\\nF ADRdetectionandmulticlass\\nbelingapostasADR.GettingadiagnosisofADR\\nclassificationresults\\nbypsychiatricmedicationcanbeoverwhelmingfor\\nWe analyzed the class-wise distribution of pre- patientsalreadysufferingfromanxiety,depression,\\ndictedlabelsfortheADRdetectionandADRmul- andotherailments,andeliminatingotherpotential\\nticlass classification task. Figure 6 and Figure 7 causesfirstisasmarterapproach.\\npresenttheconfusionmatricesfortheADRdetec- Redditisasocialmediaspacewherepeoplenot\\ntionandADRmulticlassclassificationtaskinzero- onlyaskqueriesbutoftensharetheirfeelingsand\\nshotsetting. AnalyzingFigure6weobservedthat thoughts. Themodelconfusespostsofpeopleshar-\\nallmodelsperformedexceptionallywellincases ing what they are going through and their expe-\\nofADRswith4outof9modelscorrectlydetect- riencesaspeopleseekingADR-relatedhelpeven\\ningallexamplesinthe‘ADR-Yes’class. However, if no explicit question has been asked. There are\\nallmodelsstruggledincorrectlyclassifyingcases also cases where the question being asked in the\\nof‘ADR-No’classwiththebestmodel(Claude3 post is about the workings of a particular drug,ADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nGPT-4-Turbo\\n0.38 0.62\\n0.0076 0.99\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nGPT-4o\\n0.43 0.57\\n0.053 0.95\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nLlama 3.1-70B Instruct\\n0.32 0.68\\n0 1\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nLlama 3.1-405B Instruct\\n0.38 0.62\\n0.015 0.98\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nClaude 3 Haiku\\n0.028 0.97\\n0.0075 0.99\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nClaude 3 Opus\\n0.58 0.42\\n0.068 0.93\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nClaude 3.5 Sonnet\\n0.29 0.71\\n0 1\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\nOpenBioLLM-Llama3-70B\\n0.12 0.88\\n0 1\\nADR-No ADR-Yes\\nPredicted\\nlautcA\\noN-RDA\\nseY-RDA\\n1.0\\n0.9\\n0.8 0.8 0.8\\n0.7\\n0.6 0.6 0.6\\n0.5\\n0.4 0.4 0.4\\n0.3\\n0.2 0.2 0.2\\n0.1\\n0.0\\n0.9\\n0.8\\n0.8 0.8\\n0.7\\n0.6 0.6 0.6\\n0.5\\n0.4 0.4 0.4\\n0.3\\n0.2 0.2\\n0.2\\n0.1\\nLlama3-Med42v2-70B\\n1.0 1.0 1.0\\n0.8 0.8 0.1 0.9 0.8\\n0.6 0.6 0.6\\n0.4 0.4 0.4\\n0 1\\n0.2 0.2 0.2\\n0.0 0.0 0.0\\nFigure6: ConfusionMatrixforADRDetectiontaskinzero-shotsetting. Thevaluesrepresentstheratioofexamples\\ninthepredictedclassovertotalnumberofexamplesintheactualclass.\\nlifestyle,orsomethingelseunrelatedtoADRbut modelonSpaCy(Montanietal.,2023). Thispre-\\nthemodelgetsconfused. Expertsareabletoiden- processingstepensuredconsistencyincomparing\\ntifythesecorrectlyandgivevalidreasoningsuch thelinguisticfeaturesacrosstheresponseswiththe\\nas“Althoughtheposthasadetaileddescriptionof Empathcategories.\\nanADR(Serotoninsyndrome),thepatientdoesn’t\\nhaveanyexplicitquestionsandinsteadjustseems I HarmReductionStrategyAlignment\\nto be sharing her situation.” and “No ADR, just QualitativeAnalysis\\nquestionsonhowthedrugworks.” forthesecases.\\nWequalitativelyanalyzedalignmentbetweenthe\\nLLM’s harm reduction strategies and those sug-\\nH MethodologicalDetailsforEmotional\\ngested by the expert. One pattern observed\\nandToneAlignment\\nacross all LLMs was that in addition to their\\nTocomputetheemotionalandtonalalignment,we main response to the issue, they suggested non-\\nlemmatizedtheEmpathlexicon,expertresponses pharmacologicaladviceonlifestylechangesinvolv-\\nand LLM responses using ‘en_core_web_sm’ ing sleep hygiene (“Prioritize adequate sleep.”),Dose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nGPT-4-Turbo\\n0.69 0.15 0 0.077 0.077\\n0.15 0.49 0.033 0.22 0.11\\n0 0 0 1 0\\n0.25 0.25 0 0.5 0\\n0.045 0.045 0 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nGPT-4o\\n0.77 0.077 0 0.077 0.077\\n0.32 0.3 0.054 0.2 0.13\\n1 0 0 0 0\\n0.25 0.25 0 0.5 0\\n0.045 0.045 0 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nLlama 3.1-70B Instruct\\n0.69 0.077 0 0.15 0.077\\n0.28 0.35 0.022 0.23 0.12\\n0 0 1 0 0\\n0.25 0.25 0 0.5 0\\n0.091 0 0 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nLlama 3.1-405B Instruct\\n0.62 0.23 0.077 0 0.077\\n0.38 0.34 0.065 0.11 0.11\\n1 0 0 0 0\\n0 0.5 0 0.5 0\\n0.091 0 0 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nClaude 3 Haiku\\n0.38 0 0.46 0 0.15\\n0.19 0.16 0.37 0.15 0.13\\n0 0 1 0 0\\n0 0.25 0.25 0.5 0\\n0.045 0 0.045 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nClaude 3 Opus\\n0.85 0.077 0 0 0.077\\n0.45 0.25 0.13 0.11 0.065\\n1 0 0 0 0\\n0 0 0.5 0.5 0\\n0 0.045 0 0.045 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nClaude 3.5 Sonnet\\n0.62 0.077 0.15 0 0.15\\n0.35 0.39 0.054 0.13 0.075\\n0 0 1 0 0\\n0 0 0 1 0\\n0.091 0 0.045 0 0.86\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\nOpenBioLLM-Llama3-70B\\n0.92 0 0 0 0.077\\n0.72 0.16 0.022 0.032 0.065\\n0 0 1 0 0\\n0.5 0 0 0.5 0\\n0.091 0 0 0 0.91\\nDose Non-DoseDose-Time Time Withdrawal\\nPredicted\\nlautcA\\nesoD\\nesoD-noNemiT-esoD\\nemiT\\nlawardhtiW\\n1.0 1.0 1.0\\n0.8 0.8 0.8\\n0.6 0.6 0.6\\n0.4 0.4 0.4\\n0.2 0.2 0.2\\n0.0 0.0 0.0\\n1.0 1.0 1.0\\n0.8 0.8 0.8\\n0.6 0.6 0.6\\n0.4 0.4 0.4\\n0.2 0.2 0.2\\n0.0 0.0 0.0\\nLlama3-Med42v2-70B\\n1.0 1.0 1.0\\n0.69 0.15 0 0.077 0.077\\n0.8 0.8 0.8\\n0.17 0.46 0.086 0.17 0.11\\n0.6 0.6 0.6\\n0 0 1 0 0\\n0.4 0.4 0.4\\n0 0.5 0 0.5 0\\n0.2 0.2 0.2\\n0.045 0.045 0 0 0.91\\n0.0 0.0 0.0\\nFigure7: ConfusionMatrixforADRMulticlassclassificationtaskinzero-shotsetting. Thevaluesrepresentsthe\\nratioofnumberofexamplesinthepredictedclassoverthetotalnumberofexamplesintheactual(groundtruth)\\nclass.\\ndiet(“Maintainabalanceddiet.”) andmindfulness I.1 HumanEvaluationonLLM-basedtasks\\ntechniques such as meditation (“Practice stress- forHRS\\nmanagementtechniqueslikedeepbreathing.”) and\\nForcorrelationonHRSextractionandalignment\\njournaling(“Keepajournalofyoursymptoms.”).\\nbetweenLLMsandhumans,wereportedtheper-\\nOntheotherhand,expertanswerstendedtofocus\\ncentage of HRS where the annotator agreed with\\non addressing the symptoms or questions involv-\\ntheLLM’sextractionandalignmentclassification.\\ningthemedication. Harmreductionstrategiessug-\\nFor combination, since there could be multiple\\ngestedbyLLMsrelatedtomedicationwereoften\\ngroupsformedfromdifferentHRS,wereportedthe\\npairedwithanactiontodiscusswithadoctorabout\\npercentageofanswerswheretheannotatoragreed\\ntherecommendationsbeforecommittingtothem\\nwiththecombinedHRSthatweregenerated.\\n(“Consideradjustingthedosagewithyourdoctor’s\\nguidance.”,“GraduallytaperoffTrintellixunder J ActionabilityCriteria\\nmedicalsupervision.”). Examplesofalignmentin\\nWepresenttheconcretedefinitionsforeachofthe\\nthesecasesarepresentedinTable12.\\nsub-dimensionsofactionability.\\n• Practicality: The proposed strategy shouldpleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nGPT-4-Turbo Answer Empath Category Distribution\\nExpert Answer\\n0.25 GPT-4-Turbo Answer\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nGPT-4o Answer Empath Category Distribution\\n0.30 Expert Answer\\nGPT-4o Answer\\n0.25\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nLlama 3.1-70B Instruct Answer Empath Category Distribution\\nExpert Answer\\n0.25 Llama 3.1-70B Instruct Answer\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00\\npleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nLlama 3.1-405B Instruct Answer Empath Category Distribution\\n0.25 Expert Answer\\nLlama 3.1-405B Instruct Answer\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nClaude 3 Haiku Answer Empath Category Distribution\\nExpert Answer\\nClaude 3 Haiku Answer\\n0.25\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nClaude 3 Opus Answer Empath Category Distribution\\n0.25 Expert Answer\\nClaude 3 Opus Answer\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00\\npleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nClaude 3.5 Sonnet Answer Empath Category Distribution\\n0.25 Expert Answer\\nClaude 3.5 Sonnet Answer\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nOpenBioLLM-Llama3-70B Answer Empath Category Distribution\\nExpert Answer\\nOpenBioLLM-Llama3-70B Answer\\n0.25\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00 pleh ssenlufreehc noitapicitna msimitpo yhtapmys tsurt ssenetilop noitceffa\\nLlama3-Med42v2-70B Answer Empath Category Distribution\\n0.30 Expert Answer\\nLlama3-Med42v2-70B Answer\\n0.25\\n0.20\\n0.15\\n0.10\\n0.05\\n0.00\\nFigure8: AverageDistributionofEmotionandTonecategoriesfromEmpathacrossLLMandExpertresponses.AtomicStrategies CombinedStrategies\\n1.Consultyourhealthcareproviderbeforealteringyourmedica- 1.Consultyourhealthcareproviderbeforealteringyourmedi-\\ntiondosage. cationdosage.Discusssymptomsandtaperingplanswithyour\\n2.Discusssymptomsandtaperingplanswithyourdoctor. doctor.\\n3.Avoidactivitiesthatcouldbedangerousduetovisionissues, 2.Avoidactivitiesthatcouldbedangerousduetovisionissues,\\nsuchasdriving. suchasdriving.\\n1.Taperoffthemedicationverygradually.\\n1.Taperoffthemedicationverygradually.Extendthetapering\\n2.Extendthetaperingperiod.\\nperiod.Makesmallerdosagereductions.\\n3.Makesmallerdosagereductions.\\n2.Discussthepossibilityofusingothersupportivemedications\\n4.Discussthepossibilityofusingothersupportivemedications\\northerapieswithyourhealthcareprovider.\\northerapieswithyourhealthcareprovider.\\n1.Discussmedicationconcernswithyourpsychiatrist. 1.Discussmedicationconcernswithyourpsychiatrist.\\n2.Graduallyswitchtoanotherantidepressantundersupervision. 2.Graduallyswitchtoanotherantidepressantundersupervision.\\n3.Consideralternativeantidepressantslikebupropion. Consideralternativeantidepressantslikebupropion.\\n1.Reviewthetiminganddosageofmedicationsundertheguid-\\nanceofapsychiatricpractitioner. 1.Reviewthetiminganddosageofmedicationsundertheguid-\\n2.AdjustthetimeyoutakeAdderallXR. ance of a psychiatric practitioner. Adjust the time you take\\n3.Maintainasleeproutine. AdderallXR.ConsideradjustingtheLamotraginedosageifit’s\\n4.Useasleepmask. foundtobethecause.\\n5.Discusswithyourpsychiatristthepossibilityofusingadiffer- 2.Maintainasleeproutine.Useasleepmask.\\nentsleepaid. 3.Discusswithyourpsychiatristthepossibilityofusingadiffer-\\n6.ConsideradjustingtheLamotraginedosageifit’sfoundtobe entsleepaid.\\nthecause.\\n1.Switchtoanothermedicationifneeded. 1.Switchtoanothermedicationifneeded.\\n2.Practicemindfulnesstechniques. 2.Practicemindfulnesstechniques.Userelaxationtechniques\\n3.Userelaxationtechniquestomanagerestlessness. tomanagerestlessness.\\nTable11: ExamplesofharmreductionstrategiesthatwerecombinedbyGPT-4o(groupshighlightedindifferent\\ncolors). The combination was performed for strategies which suggest the same overall approach with minor\\ndifferencesinspecificdetails.\\nclearly identify at least one action the user\\ncan take. Further, it should be contextually\\nfeasible/practical,consideringtheirpersonal\\ncircumstances,suchasphysicalability,finan-\\ncialresources,andtimeconstraints.\\n• Contextualrelevance: Theprovidedstrategy\\nshould be relevant and should contribute to\\naddressingtheconcernofthepatient.\\n• Specificity: Thedetailsandinstructionspro-\\nvided in the harm reduction strategy should\\nnotbevagueandshouldleavenotolittleroom\\nforriskyinterpretation.\\n• Clarity: Thestrategyprovidedcanbebroken\\nupintoclear,manageableandexplicitsteps.\\nTable16presentstheLLMpromptsusedtogetthe\\nactionabilityscoreforeachharmreductionstrategy.LLM’sHarm\\nExpert’sResponse\\nReductionStrategies\\n1. Consult a healthcare professional\\n\"Firstofall,Iunderstandhowdifficultlivingwiththisexperience...Itisalwaysimportant\\nfamiliarwithpsychiatricmedications\\ntomakeallmedicationadjustmentwithclosemonitorizationfromyourmainprovider.\\nandwithdrawalsymptoms.\\nTherefore,themainrecommendationwouldbetoseekforprofessionalhelp,eitherby\\n2.Prioritizeadequatesleep.Focuson\\nmakinganappointmentwithyourmainprovider(ifpossible)orgoingtoapsychiatry\\nnutrition.\\nemergency department (if symptoms become severe). There are many strategies for\\n3.Implementstressmanagementtech-\\ntaperingantidepressantmedication...”\\nniques.\\n\"Iunderstandhowfrustratinglivingwiththisfeelingmightbe... Italwaysdependson 1.Discusswithyourdoctoraboutad-\\neachpatient’sperceptionandfeelingsaboutit.Howisyourownexperienceaboutit?Do justingthedosage.\\nyouthinkthatitisbeinghelpfulorisitworseningyourhealingprocess?Ifyouarehaving 2.Consideralternativemedications.\\ndifficultiestohandlewithitwecouldswitchtoadifferentantidepressanttotrytoavoid 3. Combinemedicationwiththerapy,\\nthissideeffect.Howdoyoufeelwiththis?Doyoufeelmoreconfidentwithany...” suchascognitive-behavioraltherapy.\\nTable12: ExamplesofharmreductionstrategiesfromLLMsandtheiralignmentwiththeexpert’sresponse(aligned\\nstrategiesareshowninteal,non-alignedstrategiesinred).\\nType Prompt\\nSystem Aharmreductionstrategyisdefinedasameasuretobetakenbyanindividualtoreducethenegativeeffects\\nPrompt ofconsumingapsychiatricmedication.Thiscouldincludechangingthedosage(frequencyortimeoftaking\\nit)ofamedication,doingexercises,avoidingcertainfooditems,takingalternativemedicationortreatment,\\nconsultingahealthcareprovideretc.\\nInstructions:\\n1.YouaregivenaRESPONSEfromahealthexpert.Yourtaskistoextractasalistofatomicharmreduction\\nstrategiesfromtheRESPONSE.\\n2.Anatomicharmreductionstrategyshouldcontainanactionverbandcontainasinglepieceofadvice.\\n3.AnatomicharmreductionstrategyshouldbeextractedfromastatementintheRESPONSEandnotfroma\\nquestion.\\n4. Eachatomicharmreductionstrategyshouldcarryanentirelydifferentpieceofadvice,andshouldbe\\nindependentofotheratomicharmreductionstrategiesinthelist.\\n5.Youshouldonlyoutputtheatomicharmreductionstrategiesasalist,witheachitemstartingwith\"-\".Do\\nnotincludeotherformatting.\\nUser RESPONSE:<response>\\nPrompt\\nTable13: Promptusedfortheharmreductionstrategyextractiontask.Type Prompt\\nSystem Aharmreductionstrategyisdefinedasameasuretobetakenbyanindividualtoreducethenegativeeffects\\nPrompt ofconsumingapsychiatricmedication.Thiscouldincludechangingthedosage(frequencyortimeoftaking\\nit)ofamedication,doingexercises,avoidingcertainfooditems,takingalternativemedicationortreatment,\\nconsultingahealthcareprovideretc.\\nInstructions:\\n1.Youaregivenalistofharmreductionstrategiesfromahealthexpert.\\n2.Yourtaskistocombinesimilarharmreductionstrategiesbylogicallygroupingthembasedonthesimilarity\\noftheadvice.\\n3.Twoharmreductionstrategiesaresimilariftheysuggestthesameoverallapproachwithdifferencesonly\\ninthespecificdetails.\\n4.Donotalterthewordingofanyoftheharmreductionstrategies,onlygroupthemasmultiplesentencesin\\nasinglecombinedharmreductionstrategy.\\n5.Youshouldonlyoutputthecombinedharmreductionstrategiesasalist,witheachitemstartingwith\"-\".\\nDonotincludeotherformatting.\\nYoushouldcombinestrategiesbasedongroupssuchas:\\n1.Lifestylechangessuchassleepingpatterns,diet,physicalexercise.\\n2.Mindfulness-basedexercises.\\n3.Adjustingdosageofexistingmedication.\\n4.Tryingoutnewmedications.\\n5.Consultingpeoplefordifferentopinions.\\nYoushouldNOT:\\n1.Combinestrategiespurelybasedonthepersoninvolvedinthesuggestion(e.g:doctor).\\n2.Combinestrategiesthatsuggestfull-fledgedtherapyapproacheswiththosethatsuggestsimpleself-imposed\\nmindfulnessexercises.\\nDothisfortheharmreductionstrategiesunder\"YourTask:\".\\nConsiderthefollowingexamples:\\nHarmReductionStrategies:\\n<example_1_harm_reduction_strategies_list>\\nReasoning:\\n<example_1_reasoning>\\nCombinedHarmReductionStrategies:\\n<example_1_combined_harm_reduction_strategies_list>\\n...\\n...\\n<example_5_combined_harm_reduction_strategies_list>\\nUser YourTask:\\nPrompt\\nHarmReductionStrategies:\\n<harm_reduction_strategies_list>\\nTable14: Promptusedfortheharmreductionstrategycombinationtaskin5-shotsetting.Type Prompt\\nSystem YouareanintelligentagentwhoisgivenaRESPONSEfromapsychiatristtoapatient,andaLISTOF\\nPrompt STATEMENTSthatareharmreductionstrategies.ASTATEMENTisconsidered’Suggestion-Present’ifit\\ncanbebroadlyinferredimplicitlyORexplicitlyasaharmreductionstrategysuggestedintheRESPONSE,or\\nelseitis’Suggestion-NotPresent’.A’Suggestion-Present’STATEMENTcanbeaspecificinstantiationofa\\nbroadharmreductionstrategymentionedintheRESPONSEorvice-versa.\\nTheRESPONSEmaycontaingenericnamesofmedication,whileaSTATEMENTmayuseabrandnamefor\\nthesamemedication,notethattheseareconsideredtheSAME.\\nInstructions:\\n1.ThefollowingLISTOFSTATEMENTSisrelatedtothecontextofthegivenRESPONSE.\\n2. Your task is to analyze if EACH STATEMENT is considered ’Suggestion-Present’ or ’Suggestion-\\nNotPresent’,basedonthegivendefinitionandtheRESPONSE.\\n3. Onebyone, foreachSTATEMENT,mentionstep-by-stepreasoningbehindtheclassification, along\\nwiththelabel. ThereasoningandclassificationforeachSTATEMENTshouldbeindependentofother\\nSTATEMENTS.\\n4.AfterdoingthisforeachSTATEMENT,statethetotalNUMBERof’Suggestion-Present’STATEMENTS,\\ninanewlinestartingwith\"Numberof’Suggestion-Present’statementsintotal:\".\\n5.AnswerONLYinplaintext(withoutMarkdownformatting)fortheRESPONSEandLISTOFSTATE-\\nMENTSunder\"YourTask\".\\nConsiderthefollowingexamples:\\nRESPONSE:<example_1_response>\\nLISTOFSTATEMENTS:\\n<example_1_harm_reduction_strategies_list>\\nSOLUTION:\\n<example_1_solution>\\n...\\n...\\n<example_5_solution>\\nUser YourTask:\\nPrompt\\nRESPONSE:<response>\\nLISTOFSTATEMENTS:\\n<harm_reduction_strategies_list>\\nTable15: Promptusedfortheharmreductionstrategyalignmenttaskin5-shotsetting.Type Prompt\\nSystem You are an expert psychiatrist and psychologist. You are also an expert in identifying the practicality,\\nPrompt contextual relevance, specificity, and clarity of harm reduction strategies. You will be provided with\\nthe original query posed by the health advice seeker (presented as ORIGINAL_QUERY) and asked to\\nthedetectwhetherornottheharmreductionstrategysuggestedbythehealthcareprovider(presentedas\\nHARM_REDUCTION_STRATEGY)meetsthecriteriaforbeingpractical,contextuallyrelevant,specific,\\nandclear.Wedefineeachofthedimensionsasfollows:\\nPracticality:Theproposedstrategyshouldclearlyidentifyatleastoneactiontheusercantake.Further,it\\nshouldbecontextuallyfeasible/practical,consideringtheirpersonalcircumstances,suchasphysicalability,\\nfinancialresources,andtimeconstraints.\\nContextualrelevance: Theprovidedstrategyshouldberelevantandshouldcontributetoaddressingthe\\nconcernofthepatient.\\nSpecificity: Thedetailsandinstructionsprovidedintheharmreductionstrategyshouldnotbevagueand\\nshouldleavenotolittleroomforriskyinterpretation.\\nClarity:Thestrategyprovidedcanbebrokenupintoclear,manageableandexplicitsteps.\\nMakesurethatyououtputtheresultsstrictlyinthefollowingformat: {’rationale_to_assess_practicality’:\\n’<yourrationalegoeshere>’,’practicality_decision’:’<0or1>’,’rationale_to_assess_contextual_relevance’:\\n’<yourrationalegoeshere>’,’contextual_relevance_decision’:’<0or1>’,’rationale_to_assess_specificity’:\\n’<yourrationalegoeshere>’,’specificity_decision’:’<0or1>’,’rationale_to_assess_clarity’:’<yourrationale\\ngoeshere>’,’clarity_decision’:’<0or1>’}where0indicatesthatthestrategydoesnotmeetthecriteriaand\\n1indicatesthatitdoes.\\nConsiderthefollowingexamples:\\nORIGINAL_QUERY:<example_1_query>\\nHARM_REDUCTION_STRATEGY:<example_1_hrs>\\nOUTPUT:{’rationale_to_assess_practicality’:<example_1_practicality_rationale>,’practicality_decision’:\\n<example_1_practicality_decision>,\\n’rationale_to_contextual_relevance’:<example_1_contextual_relevance>,’contextual_relevance_decision’:\\n<example_1_contextual_relevance_decision>,\\n’rationale_to_assess_specificity’:<example_1_specificity_rationale>,’specificity_decision’:\\n<example_1_specificity_decision>,\\n’rationale_to_assess_clarity’:<example_1_clarity_rationale>,’clarity_decision’:<example_1_clarity_decision>}\\n...\\n...\\n’rationale_to_assess_clarity’:<example_3_clarity_rationale>,’clarity_decision’:<example_3_clarity_decision>}\\nUser ORIGINAL_QUERY:<query>\\nPrompt\\nHARM_REDUCTION_STRATEGY:<harm_reduction_strategy>\\nTable16: Promptusedforthedecompositionofactionabilityinharmreductionstrategies.',\n",
       " 'Mathematical Definition and Systematization of Puzzle Rules.pdf': '5202\\nnaJ\\n8\\n]IA.sc[\\n2v33410.1052:viXra\\nMATHEMATICAL DEFINITION AND SYSTEMATIZATION OF\\nPUZZLE RULES\\nA PREPRINT\\nItsukiMaeda YasuhiroInoue\\nDepartmentofMicroEngineering, DepartmentofMicroEngineering,\\nKyotoUniversity KyotoUniversity\\nKyotocity,Kyoto615-8540JAPAN Kyotocity,Kyoto615-8540JAPAN\\nmaeda.itsuki.b27@kyoto-u.jp inoue.yasuhiro.4n@kyoto-u.ac.jp\\nJanuary9,2025\\nABSTRACT\\nWhile logic puzzles have engaged individuals through problem-solving and critical thinking, the\\ncreationof new puzzle ruleshas largelyrelied on ad-hocprocesses. Pencilpuzzles, such as Slith-\\nerlink and Sudoku, represent a prominent subset of these games, celebrated for their intellectual\\nchallengesrootedincombinatoriallogicandspatialreasoning.Despiteextensiveresearchintosolv-\\ningtechniquesandautomatedproblemgeneration,aunifiedframeworkforsystematicandscalable\\nruledesignhasbeenlacking.Here,weintroduceamathematicalframeworkfordefiningandsystem-\\natizingpencilpuzzlerules. Thisframeworkformalizesgridelements,theirpositionalrelationships,\\nand iterative composition operations, allowing for the incremental construction of structures that\\nformthe basis ofpuzzle rules. Furthermore,we establish a formalmethodto describeconstraints\\nanddomainsforeachstructure, ensuringsolvabilityandcoherence. Applyingthisframework,we\\nsuccessfullyformalizedthe rulesofwell-knownNikolipuzzles, includingSlitherlinkandSudoku,\\ndemonstratingthe formal representationof a significant portion (approximatelyone-fourth)of ex-\\nisting puzzles. These results validate the potential of the framework to systematize and innovate\\npuzzleruledesign,establishingapathwaytoautomatedrulegeneration. Byprovidingamathemat-\\nical foundationfor puzzle rule creation, this framework opens avenues for computers, potentially\\nenhanced by AI, to design novel puzzle rules tailored to player preferences, expanding the scope\\nofpuzzlediversity. Beyonditsdirectapplicationtopencilpuzzles,thisworkillustrateshowmathe-\\nmaticalframeworkscanbridgerecreationalmathematicsandalgorithmicdesign,offeringtoolsfor\\nbroaderexplorationinlogic-basedsystems,withpotentialapplicationsineducationalgamedesign,\\npersonalizedlearning,andcomputationalcreativity.\\n1 Introduction\\nPuzzleshavelongbeenasourceofintellectualengagementandentertainment,captivatingpeopleworldwidethrough\\ntheir ability to foster problem-solvingand criticalthinkingskills. Amongthe diversegenresof puzzles, pencilpuz-\\nzles,suchasSlitherlinkandSudoku,areparticularlycelebratedfortheirlogicaldepthandrelianceoncombinatorial\\nreasoningandspatialintuition.Thesepuzzles,asdeterministicgameswithperfectinformation,havebeenextensively\\nstudiedintermsoftheircomputationalcomplexity,solvingalgorithms,andautomatedproblemgeneration. However,\\ndespitetheseadvances,thecreationofnewpuzzleruleshasremainedalargelyad-hocprocess,lackingaunifiedand\\nsystematicapproach.\\nTheneedforautomatingpuzzlerulecreationarisesfrompracticalchallengesinmaintainingengagementanddiversity\\ninpuzzle-basedgames. DeKegelandHaahrobservedthat: “Playerstendtofeelasenseofmonotonyfromrepetitive\\ngameplay.However,thiscanbemitigatedbyintroducingpuzzles.”(DeKegelandHaahr2020).\\nOffering a variety of puzzles, particularly those with novel rules, is widely regarded as an effective way to sustain\\nplayerengagement.Whilespecificstudiesdirectlysupportingthisnotionarelimited,TangandKirmandemonstratedMathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nthat curiosity-driven design, including the introduction of uncertainty and novel challenges, plays a critical role in\\nmaintaining player interest across diverse gaming contexts (TangandKirman 2024). Their findings emphasize the\\nimportance of catering to multiple dimensions of curiosity, such as epistemic and perceptual curiosity, to enhance\\nengagementandfosterloyaltyinplayers.However,designingawidevarietyofpuzzlerulesofteninvolvessignificant\\nproductioncosts,makingitchallengingtoachievediversityefficiently.Toaddresstheseissues,thereisacleardemand\\nforframeworksthatenabletheautomaticgenerationofpuzzlerules,whichcouldfacilitatethecreationofdiverseand\\ninnovativechallenges.\\nDuring our literature review, we found no studies that generated puzzle rules entirely from scratch. A closely re-\\nlatedstudyexploredthegenerationoftwo-playerfinitedeterministicperfectinformationgamesbycombiningexist-\\ning games (BrowneandMaire 2010). However, this approach focused on combining pre-existing rules rather than\\ncreating new ones, and it relied on engineering methods instead of a mathematical framework. Other researches\\n(MantereandKoljonen 2007; Yoshinakaetal. 2012) have concentrated on generating specific puzzle instances that\\nadheretoestablishedrules,ratherthandefiningnewrulesthemselves. Hertingproposedamathematicalformulation\\nfortheboardandconditionsoftheSlitherlinkpuzzle,employingarule-basedapproachforefficientproblem-solving,\\nbutthisworkdidnotaddressthegenerationofnewrules(Herting2004).Whileexistingstudieshaveaddressedpuzzle\\nsolvingandproblemgeneration,thesystematiccreationofnovelpencilpuzzlerulesfromamathematicalframework\\nhasnotbeenextensivelyinvestigated,tothebestofourknowledge.\\nInthisstudy,weaddressthelackofsystematicmethodsforcreatingpencilpuzzlerulesbyintroducingacomprehen-\\nsivemathematicalframework. Ourframeworkformalizesgridelements(e.g.,points,edges,cells)andtheirrelation-\\nships(e.g.,adjacency)anditerativelycomposesthemintostructuresthatformthefoundationofpuzzlerules. Addi-\\ntionally,itprovidesaformalmethodfordefiningconstraintsandsolutiondomains,ensuringsolvabilityandcoherence\\nofthepuzzles. Thissystematicapproachenablesthemathematicaldescriptionandcomputationalimplementationof\\npuzzlerules,offeringaunifiedfoundationforrulecreationacrossdiversepuzzletypes.\\nThisframeworkhasbroadimplicationsbeyondpencilpuzzledesign. Automatedrulegenerationcouldenhancecom-\\nmercial games, personalize learning experiences, and contribute to fields like network security, where logic-based\\nsystems play a crucial role (LiangandXiao 2013). Additionally, the framework opens avenues for future research\\nintoAI-drivenrulegenerationandpersonalizedpuzzledesigntailoredtoplayerpreferences.Bybridgingrecreational\\nmathematics and algorithmic design, this work establishes a foundation for innovations in both entertainment and\\nacademiccontexts.\\nIn this paper, we beginby definingkey terms and conceptsrelated to pencil puzzlesand their rulesin In Section 2.\\nUsingthesedefinitions,wedemonstratetheframework’svalidityinSection3byapplyingittowell-knownpuzzlesand\\nverifyingitseffectivenessthroughcomputationalimplementation.InSection4,wesummarizethisstudybyrevisiting\\nthekeyresultsanddiscussingtheirimplications,includingthepotentialforsystematicpuzzleruledesign.\\n2 Mathematical Definitions ofBasicConcepts Related to Pencil Puzzles\\nFirst,consideratwo-dimensionalgridofsizem×n(m,n∈N). Inthiscase,wecanassigncoordinates(i,j)toeach\\ngridpointfromthe top-leftcorner(1 ≤ i ≤ m+1,,1 ≤ j ≤ n+1). Similarly, wecan assigncoordinates(i′,j′)\\nto each cell from the top-left(1 ≤ i′ ≤ m,,1 ≤ j′ ≤ n). Then, we can give annotationswith variablesi,j,i′,j′\\ntogridpoints,cells, horizontaledgesconnectinggridpoints,verticaledgesconnectinggridpoints, horizontaledges\\nconnectingcells,andverticaledgesconnectingcellsinthetwo-dimensionalgrid.\\nWe definetheseannotationsasgridpointp(i,j), cellc(i′,j′), gridpointhorizontaledgeh (i,j), gridpointver-\\np\\nticaledgev (i,j), cellhorizontaledgeh (i′,j′), andcellverticaledgev (i′,j′), andcollectivelyrefertotheseas\\np c c\\nelementsInthisstudy.Furthermore,wewillrefertosequencescontainingtheseasgridpointsequence,cellsequence,\\ngridpointhorizontaledgesequence,gridpointverticaledgesequence,cellhorizontaledgesequence,andcellvertical\\nedgesequence.\\nDefinition2.1(GridpointsequenceP,CellsequenceC,GridpointhorizontaledgesequenceH ,Gridpointvertical\\np\\nedgesequenceV ,CellsequenceC,CellhorizontaledgesequenceH ,CellverticaledgesequenceV ,Gridpoint\\np c c\\nedgesequenceE , Cell edge sequenceE , ElementsequenceE). Given a planegrid ofsize m×n, we definethe\\np c\\ngridpointsequencePas\\nP:= p(1,1),...,p(m+1,n+1)\\n(cid:0) (cid:1)\\nSimilarly,wedefinegridpointhorizontaledgesequenceH ,gridpointverticaledgesequenceV ,cellsequenceC,\\np p\\ncellhorizontaledgesequenceH ,cellverticaledgesequenceV ,gridpointedgesequenceE ,celledgesequence\\nc c p\\n2MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nE as\\nc\\nC := c(1,1),...,c(m,n)\\nH := (cid:0) h (1,1),...,h (m+(cid:1) 1,n)\\np p p\\nV := (cid:0)v (1,1),...,v (m,n+1) (cid:1)\\np p p\\nH := (cid:0)h (1,1),...,h (m,n−1)(cid:1)\\nc c c\\nV := (cid:0)v (1,1),...,v (m−1,n) (cid:1)\\nc c c\\nE := H(cid:0) ∪V (cid:1)\\np p p\\nE := H ∪V\\nc c c\\nAlso,wedefinetheelementsequenceEcomposedofthesesequencesas\\nE:=(P,E ,C,E )\\np c\\nNext,weintroducerelationshipswhentwoarbitraryelementsaretakenfromthetwo-dimensionalgrid. Thisdefines\\npositionalrelationshipsforannotationsfromboardinformationto variablesas definedearlier. Here, positionalrela-\\ntionshipsarebinarypredicatesinthecontextofmathematicallogicthattakeanyelementincludedinEasarguments.\\nWedefineandintroducetheserelationshipsashorizontaladjacency,verticaladjacency,diagonaladjacency,andcoin-\\ncidencebelow.\\nDefinition2.2(HorizontaladjacencyH(x,y), VerticaladjacencyV(x,y), DiagonaladjacencyD(x,y), Coincidence\\nM(x,y)). WedefinehorizontaladjacencyH(x,y)as\\ni=i′∧|j−j′|=1 if x=p(i,j)∧y =p(i′,j′)\\n\\uf8f1(cid:2)∨ (cid:3)\\nH(x,y):=\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2(cid:2)∨\\n(cid:2)∨\\n(cid:2)∨i\\ni\\ni\\ni=\\n=\\n=\\n=i\\ni\\ni\\ni′\\n′\\n′\\n′∧\\n∧\\n∧\\n∧|\\n|\\n|\\njj\\nj\\nj\\n−−\\n−\\n−\\njj\\nj\\nj\\n′′\\n′\\n′|\\n|\\n|\\n∈=\\n=\\n=\\n{1\\n1\\n1\\n0,1i\\ni\\nif\\nf\\nf\\n}\\nx\\nx\\nx\\nif=\\n=\\n=c\\nh\\nh\\nx(\\np\\nci =((, iij\\n,,\\np)\\njj\\n()∧\\n)\\ni,∧∧y j)yy= ∧==c y( hhi =c′ p, ((j\\ni\\nhi\\n′′\\n′\\n,)\\n,\\nj\\n(j(cid:3)\\ni′′\\n)\\n′)\\n,(cid:3)(cid:3)\\nj′)\\np\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4(cid:2)∨\\n(cid:2)∨\\n(cid:2)∨i\\ni\\ni=\\n=\\n=i\\ni\\ni′\\n′\\n′∧\\n∧\\n∧j\\nj\\nj−\\n−\\n−j\\nj\\nj′\\n′\\n′\\n∈\\n∈\\n∈{\\n{\\n{\\n0\\n0\\n0,\\n,\\n,−\\n1\\n−1 1}} }ifi if fxx x== =c(h\\nhi,p\\ncj\\n((\\n)\\nii ,,\\n∧\\njj ))\\ny\\n∧∧\\n=\\nyy\\nh\\n==\\nc(\\ncip\\n′\\n((\\n,\\nii\\nj\\n′′ ,,\\n′)\\njj\\n′(cid:3)′(cid:3)\\n))\\n(cid:3)\\n.\\n\\uf8f4\\uf8f4\\uf8f3(cid:2) (cid:3)\\nSimilarly,wedefineverticaladjacencyV(x,y),diagonaladjacencyD(x,y),andcoincidenceM(x,y)as\\n3MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\n|i−i′|=1∧j =j′ if x=p(i,j)∧y =p(i′,j′)\\n\\uf8f1∨(cid:2) (cid:3)\\nV(x,y):=\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2∨∨\\n(cid:2)∨ (cid:2)(cid:2)\\ni||| iii −−−− iiii ′′′′ ∈||| === {111 0,∧∧∧ 1jjj }=== ∧jjj j′′′ =iii jfff\\n′\\nxxx if=== vvc x( cpi =((, iij\\n,,\\npj)\\nj\\n())∧\\ni∧\\n,∧y\\njy\\n)y= ∧==c y( vvi\\nc\\n=p′ (,\\n(\\niij v′′′ ,,)\\njj\\n((cid:3)\\n′\\ni′ ))\\n′,(cid:3)(cid:3)\\nj′)\\np\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3∨\\n(cid:2)∨\\n(cid:2)∨ (cid:2)(cid:2)\\niii −−− iii ′′′ ∈∈∈ {{{ 000 ,,, −1− 11\\n}∧\\n}} ∧∧\\nj =\\njj ==\\nj′\\njj ′′\\nif\\nii ff\\nx\\nxx\\n=\\n==\\nc(\\nvv\\ni,\\ncp\\nj\\n(( i)i ,,\\n∧\\njj ))\\ny\\n∧∧\\n=\\nyy\\nv\\n==\\nc(\\ncip\\n′\\n((\\n,\\nii\\nj\\n′′ ,,\\n′)\\njj\\n′(cid:3)′(cid:3)\\n))\\n(cid:3)(cid:3)\\n|i−i′|=1∧|j−j′|=1 if x=p(i,j)∧y =p(i′,j′)\\n\\uf8f1∨(cid:2) (cid:3)\\nD(x,y):=\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2∨∨\\n(cid:2)(cid:2)\\nii|i −−− iii ′′′ ∈∈|= {{1\\n00\\n,,∧ −1|j 1}−\\n∧\\n}∧jj′\\n−\\nj|= −j′1\\nj∈\\n′\\n∈{if\\n{0,\\n0−x ,11= }}c(i ii, ffj)∧ xxy ===\\nvh\\npc ((( iii ,,′ jj, )j )′ ∧∧)\\n(cid:3)\\nyy == hv\\np\\n(( ii ′′ ,, jj ′′ ))\\n(cid:3)\\np p\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3∨ (cid:2)∨ (cid:2)(cid:2)\\nii −− ii ′′ ∈∈ {{ 00 ,, −1 1}∧ }∧j− j−j′ j∈\\n′\\n∈{ {0, 0− ,11 }} ii ff xx == vh\\ncc\\n(( ii ,, jj )) ∧∧ yy == hv\\ncc\\n(( ii ′′ ,, jj ′′ ))\\n(cid:3)(cid:3)(cid:3)\\nM(x,y):= x=y\\n(cid:2) (cid:3)\\nTheserelationshipsarearbitrarybinarypredicatesinspiredbyexistingpuzzlerules.Intuitively,astheirnamessuggest,\\ntheyarebinarypredicatesthatbecometruewhenfreevariablesareassignedtoelementsthatareadjacenthorizontally,\\nvertically,ordiagonallyontheboard,orcoincide.\\nIn pencil puzzles, in addition to the previously defined elements, there are concepts that combine these elements\\n(e.g., \"rooms\" in Shikaku, \"closed curves\" in Slitherlink). In this study, we will refer to these as structures. To\\nmathematicallyhandlestructures,wedefinethemasanextendedconceptofelements.\\nFurthermore,weintroduceorderrelationsforvariouselementsandsequencesdealtwithInthisstudy.\\nDefinition2.3(OrderRelations). Thisresearchonlydealswithelementsandsequencescomposedofthem.Therefore,\\n• The orderrelation betweenelementsof the same type is determinedby coordinates,andfor differenttypes,\\nwedefinep<c<h <v <h <v .\\np p c c\\n• Theorderrelationbetweensequencesissuchthatdeeperpartialsequencesareconsideredlarger.\\nWedefinesuchorderrelations.Notethatelementscanbedefinedassequencesofdepth0whenthedepthofnon-nested\\nsequencesisconsidered1.\\nExample2.1(OrderRelations). Thefollowinggroupofpropositions\\n• p(1,2)<p(2,1)\\n4MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\n• c(3,3)<h (1,1)\\np\\n• h (2,1)< c(1,1),c(2,3)\\np\\n(cid:0) (cid:1)\\n• c(1,1),c(2,3) < p(1,1)\\n(cid:0) (cid:1)\\n(cid:16)(cid:0) (cid:1)(cid:17)\\n• c(1,1),c(2,3) < c(2,1),c(2,3)\\n(cid:0) (cid:1) (cid:0) (cid:1)\\narealltrue.\\nAs an implicit understanding, all sequences appearing In this study (except for the board solution mentioned later\\ndefinition2.8) are assumedto be in lexicographicascendingorder(meaningthatsequenceswith the same elements\\nareuniquelydeterminedandalwayssortedtobeintheminimallexicographicorder). Therefore,notethatallgeneral\\nsetoperationscanbeperformed. Forexample,Inthisstudy,whentherearesequencesAandS,wedescribe\"Sisa\\nsubsequenceofA\"usingtheoperator⊂asinsettheory,S ⊂ A. Atthistime, theoperationPseq(A) oftakingthe\\npowersequenceofAcanbedefinedas\\nPseq(A)=(S |S ⊂A)\\nDuetothepreviousunderstanding,theorderofthepowersequenceisassumedtobeinlexicographicascendingorder\\nofA.\\nHere,weredefinetheuniversalsetdealtwithInthisstudy.Forthispurpose,wedefineanoperationtoflattensequences\\nas\\ns ifsisanelement\\nflatten(S)=\\n(cid:26)flatten(s) ifsisasequence\\ns[∈S\\nwhereS isanysequence.Atthistime,usingthepreviouslymentionedE,wedefinetheuniversalsetUas\\nU={A|∀x∈A,flatten(x)⊆flatten(E)}\\nNotethatUcannotbeidentifiedwiththeinfinitepowersetP∞ flatten(E) offlatten(E).\\n(cid:0) (cid:1)\\nFurthermore,weredefinethepositionalrelationshipsofstructures(verticaladjacency,horizontaladjacency,diagonal\\nadjacency,coincidence)asfollows.\\nDefinition2.4(PositionalRelationshipsofStructures). WhentherearestructuresX andY,wedefinethepositional\\nrelationshipRas\\nR(X,Y):=∃x∈X,∃y ∈Y,R(x,y)\\nwhereR∈{H,V,D,M}. Notethatthisdefinitionisrecursive.\\nHere,wedefinewhatitmeansforagraphtobeconnected.LetR={H,V,D,M}bethesetcomposedofpositional\\nrelationships.Atthistime,whenthereexistsasequenceSandweintroduceanelementRofP(R),wecandefinean\\nedgesequenceE(S,R)byviewingS asavertexsequence.Also,wecanconsideragraphG S,E(S,R) fromthis.\\n(cid:0) (cid:1)\\nE(S,R)= (si,s )∈S×S |r ∈∀R,r(s ,s )\\nj i j\\nFurthermore,wedefinethatagraphG(S,E((cid:0) S,R))isconnectedas (cid:1)\\ncon G S,E(S,R) = ∀u,v ∈E(S,R),∃P =(u=w0,w1,...,w\\nk\\n=v)\\n(cid:16) (cid:0) (cid:1)(cid:17) (cid:2) (cid:3)\\nwherethepathP satisfiesthefollowingconditions:\\n1. w0 =u∧w\\nk\\n=v\\n2. ∀i∈[0,k−1]∩N,(w ,wi+1)∈E(S,R)\\ni\\nAlso,wedefinethatagraphG′ S′,E(S′,R′) isasubgraphofgraphG S,E(S,R) as\\n′ (cid:0) ′ (cid:1) ′ (cid:0) (cid:1) ′ ′\\nsubgraph(G,G)= [S ⊆S]∧[E(S ,R)⊆E(S,R)]∧[∀(u,v)∈E(S ,R),u,v ∈S ]\\n(cid:2) (cid:3)\\nBased on these, we define structures in pencil puzzles below. However, if we adopt the definition that \"a structure\\nisanyelementincludedin theuniversalsetU,\" wewouldcreatedisorderlyobjectsthatarefarfromexistingpuzzle\\nrules and unrecognizable to humans. Since pencil puzzles should be solvable by humans, we provide a definition\\nthatiseasilyrecognizabletohumans. Forthispurpose,usingtheaforementionedadjacencyrelationships,wedefine\\ncompositionoperationsasaprogressivecomputationalmethodtocreatestructuresfromelements.\\n5MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nDefinition2.5(CompositionOperation). LetR={H,V,D,M}bethesetcomposedofpositionalrelationships. At\\nthistime,whentakinganelementRofP(R)andanelementS ofthestructuresequenceSatthatpoint(definitionto\\nbegivenlater),wedefinetheoperation\\ncombine(R,E) = (S|C ∧ S )\\no g\\n′ ′ ′\\nC = con G S ,E(S ,R)\\no\\n(cid:16) (cid:0) (cid:1)(cid:17)\\n′ ′ ′\\nS = subgraph G S ,E(S ,R),G(S,E(S,R))\\ng\\n(cid:16) (cid:0) (cid:1)(cid:17)\\nasthecompositionoperation.NotethattheveryfirststructuresequenceisE(definition2.1).\\nWecallthesequenceresultingfromthiscombineoperation,oranelementofE,astructure,anddefinethestructure\\nsequence S′ asS′ = S∪(X), where Xisthe structurecreatedby thiscompositionoperationandnewlyaddedas\\nanelementofS. WhatcanbeaddedasinputforthenextcompositionoperationisanelementofS′. Inthissense,it\\nisprogressive,andwhenconsideringthecompositionoperationasamapping,notethatthedomaindifferswitheach\\ncompositionoperation.\\nIntuitively,thecompositionoperationisasequencecomposedofpartialconnectedgraphsofthegraphspannedwhen\\nintroducing the positional relationship R to the structure E. Using these, we can create most of the structures in\\nexistingpencilpuzzles.\\nWe will call the structure sequence S remaining after a finite number of composition operations the structure\\nend\\nsequenceS possessedbyacertainpuzzlerule. NotethatE⊂S .\\nend end\\nSince simply stating \"structure\" can lead to confusion between \"a set containing all of a certain structure\" or \"a\\nspecificstructureexistingontheboard,\"wewillrefertotheformeras\"structure\"andthelatteras\"thestructure\"(the\\nresultofcombineistheformer).\\nExample2.2(StructuresPossessedbySlitherlink). Afterperformingthecompositionoperation\\nR = {H,V,D}\\nE = Ep (∈E)\\nX = combine(R,E) (1)\\n1\\nthe remainingstructure sequence S = E∪(X ) is the structure sequencepossessed by Slitherlink, and X is the\\n1 1\\nstructurepossessedbySlitherlink.NotethatinthecaseofSlitherlink,thereisaconditionthatthestructureisaclosed\\ncurveandthereisonlyoneontheboard,butthisisrestrictedbytheconstraintstobedescribedlater.\\nWhenacertainpuzzleruleexistsanditisdeterminedwhatstructuresitpossesses,wecandefineaboard. Aboardis\\nspecifiedbyindividualpuzzlerulesandthesizeofthetwo-dimensionalgrid.Inotherwords,wedefineaboardasthe\\nunionof elements thatalways exist and a subsetof structurescreated by compositionoperations. Unless otherwise\\nspecified,weassumethesizeofthetwo-dimensionalgridism×n(m,n∈N).\\nDefinition2.6. LettherebeapuzzleruleP,andletitpossessstructuresX ,X ,.... WedefinethatB isaboardof\\n1 2\\nPifthefollowingpropositionistrue:\\nB ∈ E∪(X1)∪(X2)∪···|X1 ∈Pseq(X1),X2 ∈Pseq(X 2),...,\\n(cid:0) (cid:1)\\nInpencilpuzzles,structuresexistingontheboardhavecorrespondingstates. Wedefinethespecificnumericalvalues,\\nconstants,orvectorsassolutions(e.g.,3,x1,(2,3)). ForconvenienceInthisstudy,wespecificallycorrespondedges\\nto1when\"effective\"and0when\"ineffective\".Dependingonthepuzzlerule,theremaybenocorrespondingstatefor\\nacertainstructure,inwhichcasewespeciallydefinethevalueasnull.\\nFrom the above discussion, to define a puzzle rule, we need to define which set the solutions correspondingto the\\nstructurespossessedbythepuzzlerulebelongto. Forthispurpose,wedefinethesetofstatesusingthetermdomain\\nbelow.Notethatwhenthereisacertainboard,notallstructurescontainedinitnecessarilyhaveonlyonesolution.\\nDefinition2.7(domain). Wedefinethesetofpossiblestatescorrespondingtostructurespossessedbyacertainpuzzle\\nruleasthedomain. WhenapuzzlerulePpossessesastructureX ,wewilldescribeitintheformX ↔ S tomean\\n1\\nthedomainSofX .\\n1\\n6MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nExample2.3(Slitherlink’sdomain). ThedomainsofthestructurespossessedbySlitherlinkaredescribedas:\\nP ↔ {null}\\nC ↔ {0,1,2,3,4}\\nE ↔ {0,1}\\np\\nE ↔ {null}\\nc\\nX ↔ {null}\\n1\\nwhereX isgivenbyEquation(1).\\n1\\nBydefiningthedomain,whenacertainboardB exists,wecanconsiderpossiblesolutionsforeachstructureexisting\\ninB. IfwedescribethesolutioncorrespondingtoacertainstructureX assolution(X),whenviewedasasequence\\n(definedasaboardsolution),sincethedomainofthestructureisnotnecessarilyasingleton,weobtainasequenceof\\nboardsolutionscorrespondingtoB. WedefinethisastheboardsolutionsequenceS(B).\\nDefinition 2.8 (Board Solution, Board Solution Sequence S(B)). When a certain board B exists, we define the se-\\nquenceofsolutionscorrespondingtoeachstructurecontainedinBastheboardsolution.Also,wedefinethesequence\\ncomposedofallboardsolutionsinBastheboardsolutionsequenceS(B)ofboardB. Notethatamongthesequences\\ndealtwith Inthisstudy, onlytheboardsolutionisnotinlexicographicascendingorder, butcorrespondsone-to-one\\nwiththeelementsofboardB.\\nRemark2.1. WhenB isaboard,\\n∀S ∈S(B) , s=|B|=|S|\\ni\\n∀i∈[1,s]∩N, |B |=|S |\\ni i\\nholds.(TheelementsofB andS(B)correspondone-to-one.)\\nBydeterminingthestructuresequenceanddomainexistinginpuzzleruleP,thesequencecomposedofallboardsinP\\nandtheelementsofthecorrespondingboardsolutionsequencearedetermined.Wedefinetheseastheboardsequence\\nBandtheboardsequencesolutionsequenceS(B)below,respectively.\\nDefinition2.9(BoardSequenceB,BoardSequenceSolutionSequenceS(B)). WhenacertainpuzzlerulePexists,\\nwedefinethesequencecomposedofallpossibleboardsfromthestructurespossessedbyPastheboardsequenceB.\\nAlso,wedefinethesequenceofboardsolutionsequencescorrespondingtoeachelementoftheboardsequenceasthe\\nboardsequencesolutionsequenceS(B).\\nRemark2.2. |S(B)| =|B|holds(TheelementsofS(B)andBcorrespondone-to-one.).\\nExample2.4. Forconvenience,weconsidertheboardsequenceandboardsequencesolutionsequenceofSlitherlink\\non a very small size (2×2) two-dimensional grid. Note that since we are not considering constraints, the board\\nsequenceincludesboardsthatwouldnotbepossibleingeneralSlitherlink.\\nWhen\\nP = p(1,1),...p(3,3)\\nH = (cid:0)h (1,1),...h (3,(cid:1)2)\\np p p\\nV = (cid:0)v (1,1),...v (2,3) (cid:1)\\np p p\\nC = (cid:0)c(1,1),...c(2,2) (cid:1)\\nH = (cid:0) h (1,1),h (2,1) (cid:1)\\nc c c\\nV = (cid:0)v (1,1),v (1,2) (cid:1)\\nc c c\\nE = (cid:0)h (1,1),...h (3(cid:1),2),v (1,1),...v (2,3)\\np p p p p\\nE = (cid:0)h (1,1),h (2,1),v (1,1),v (1,2) (cid:1)\\nc c c c c\\nE = (cid:0)P,E ,C,E (cid:1)\\np c\\n(cid:0) (cid:1)\\ntheboardsequenceBbecomes\\nB={E∪X1 |X1 ∈P(X 1)}\\n7MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nwhereX isgivenbyEquation(1).Notethat|B|=1doesnothold.Duetospacelimitations,weomitwritingoutthe\\n1\\nentireboardsequencesolutionsequenceS(B)correspondingtothisboardsequenceB. Whenconsideringaboard\\nB(∈B)suchas\\nB = p(1,1),...p(3,3) ,\\n(cid:16)(cid:0) (cid:1)\\nc(1,1),...c(2,2)\\n(cid:0)h (1,1),...h (3,(cid:1)2),v (1,1),...v (2,3)\\np p p p\\n(cid:0)h (1,1),h (2,1),v (1,1),v (1,2) (cid:1)\\nc c c c\\n(cid:0) (cid:1)\\n(h(1,1),h(2,1),v(1,1),v(2,1))\\n(cid:0) (cid:1)(cid:17)\\nacertainboardsolutionS ∈S(B)correspondingtotheelementsofthisB isexpressedas\\nS = null,...,null ,\\n(cid:16)(cid:0) (cid:1)\\n4,1,1,0\\n(cid:0)1,0,1,0,(cid:1)0,0,1,1,0,0,0,0\\n(cid:0)null,null,null,null (cid:1)\\n(cid:0) (cid:1)\\nnull (2)\\n(cid:0) (cid:1)(cid:17)\\nNotethatthereareinfinitelymanyelementsincludedinS(B)otherthanEquation(2).\\nWhen dealing with puzzle rules, simply determiningthe structure sequence and domain results in excessively large\\nboard sequences and board sequence solution sequences, as mentioned earlier. Also, in most existing puzzle rules,\\nsomerestrictionsareplacedonstructuresexistingontheboard.Wemathematicallydefinetheseasconstraints.These\\nessentiallybecomeagroupofpredicatesthatapplytoboardsequencesandboardsequencesolutionsequences.\\nDefinition2.10(constraints). We definea groupofpredicateswith structuresexisting onthe boardandtheircorre-\\nspondingsolutionsas free variablesasconstraints. However, we require thatthetruth set ofthe logicalproductof\\nthis groupofpredicatesis notan empty set. We defer the specific descriptionmethodof constraintsto example2.5\\ndescribedlater.\\nWhen constraints are defined, their essence becomes a restriction mapping applied to board sequences and board\\nsequencesolutionsequences. Here, wedefineboardsequencesandboardsequencesolutionsequencesrestrictedby\\nconstraintsasconstrainedboardsequencesandconstrainedboardsequencesolutionsequences,respectively.\\nDefinition2.11(ConstrainedBoardSequenceBcon,ConstrainedBoardSequenceSolutionSequenceS(Bcon)). We\\ndefineconstrained boardsequenceBcon andconstrained boardsequence solutionsequence S(Bcon) respectively\\nas\\nBcon := B |B ∈B,S(B)∈S(B),constraints,(B,S(B))\\nS(Bcon):= (cid:0)S(B)|B ∈B,S(B)∈S(B),constraints,(B,S(B(cid:1)))\\n(cid:0) (cid:1)\\nThesecorrespondtowhatarecalled\"answers\"or\"solutionboards\"inexistingpencilpuzzles.\\nRemark2.3. |S(Bcon)|=|Bcon|holds. Also,Bcon ⊂BandS(Bcon)⊂S(B)hold.\\nExample2.5. TheconstraintsofSlitherlinkaredescribedasfollows.Notethatweareusingagroupoffunctionsthat\\ncanbeusedinconstraintsasdescribedin.\\n• ∀X1 ∈X 1,∀x1 ∈X1,solution(x1)=1\\n• ∀p∈B(P),cross(p)=2\\n• ∀c∈B(C),solution(c)=cycle(c)\\n• |B(X )|=1\\n1\\n8MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nEachbulletpointbecomesagroupofpredicatesthatrestrictthefreevariablesofboardsequencesandboardsequence\\nsolutionsequenceswiththeexpression\\n∀X1 ∈X 1,∀x1 ∈X1,solution(x1)=1 ∧\\n(cid:2)∀p∈B(P),cross(p)=2 ∧ (cid:3)\\n(cid:2)∀c∈B(C),solution(c)=(cid:3)cycle(c) ∧\\n(cid:2)|B(X )|=1 (cid:3)\\n1\\n(cid:2) (cid:3)\\nWeusedtheaboveexpressionforsimplicity.\\nFurthermore,wealsodefinetheactof\"presentingaproblem\".Asapreliminarystep,wedefinetheconstantundecided\\nandtheoperatorofextendedsubsequence⊂ext.\\nDefinition2.12(undecided,⊂ext). WedefinethatasequenceAcontainssequenceB asanextendedsubsequence\\n(B ⊂extA)if\"foranyelementbiofB,thereexistsacorrespondingelementa inA,andb =a orb =undecided.\"\\ni i i i\\nThiscanbeformallydescribedas\\nB ⊂extA ⇐⇒ ∀i,1≤i≤|B|,bi∈B,a ∈A,[b =a ]∨[b =undecided]\\ni i i i\\nUnlikegeneralsubsequences,\\n1. Elementsmustmatchfromthebeginning.\\n2. Nocomparisonismadeinthecaseofundecided.\\nNotethesepoints.\\nDefinition2.13(PresentationofaProblem). WhenthereexistsapuzzleruleP,wedefineQandS(Q)as\\nQ⊂B,S(Q)= Q|Q∈S(B),S ⊂extQ |S(B)∈S(B)\\nQ\\n(cid:16)(cid:0) (cid:1) (cid:17)\\nwhereSQisanarbitrarysequence(however,itactuallyfollowsdefinition2.14describedlater). Wedefinepresenta-\\ntionofaproblemaspresentingQandS tothesolver(humanormachinesolvingthepuzzle)suchthat\\nQ\\ns=|S(Bcon)|,Q ∈Q,S(B)i∈S(Bcon)\\ni\\n∃!i∈[1,s]∩N,|Q ∩S(B) |=1\\ni i\\nholds.Also,wedefinethecombinationof[Q,S ]asaproblem.\\nQ\\nExisting pencil puzzlesare implicitly requiredto have a unique solution. Therefore, we adopted the definition like\\ndefinition2.13. Bydeterminingthestructuresequence,domain,andconstraints,theconstrainedboardsequenceand\\nconstrainedboardsequencesolutionsequencearedetermined.However,theexistenceofQandS isnotself-evident.\\nQ\\nTheexistenceofQandS isanecessaryconditionforbeingapuzzlerule. Currently,thereisnomethodotherthan\\nQ\\nrelyingoncomputationalmethodsto examinewhetherQ and S existfromthe combinationof structuresequence,\\nQ\\ndomain,andconstraints,sothisremainsafuturetask.\\nRemark2.4(NecessaryConditionforBeingaPuzzleRule). TheexistenceofQandS satisfyingdefinition2.13is\\nQ\\nanecessaryconditionforbeingapuzzlerule.\\nAlthough S is an arbitrary sequence, the index for choosing it depends on the puzzle rule (in Slitherlink, S is\\nQ Q\\npresentedwithallsolutionscorrespondingtogridpointverticaledgesandgridpointhorizontaledgesincludedinthe\\nboard, and all cells set to undecided). Generally, since some solutions corresponding to structures possessed by a\\ncertainpuzzleruleareoftenpresentedasundecided,wedefinethisinformationashidden.\\nDefinition 2.14 (hidden). When there exists a puzzle rule P, the range of solutions correspondingto a structure X\\npossessedbyPisspecifiedbythedomain. WhenthereexistsaboardB,theboardsolutioniscomposedofsolutions\\ndetermined within the range of that domain, but we construct a new S from a board solution with this domain\\nQ\\nmodified.Wedefinehiddenaswhichstructure’sdomaintoaddundecidedto. Wedeferthespecificdescriptionmethod\\ntoexample2.6.\\n9MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nExample2.6(Slitherlink’shidden). Slitherlink’shiddenisdescribedasfollows. Notethatbeinghiddenofacertain\\nstructureX isdescribedasX →S′,meaning\"hiddenS’ofX \",similartothedescriptionofdomain.\\n1 1 1\\nP ↔ {null} → {null}\\nC ↔ {0,1,2,3,4}→ {0,1,2,3,4,undecided}\\nE ↔ {0,1} → {undecided}\\np\\nE ↔ {null} → {null}\\nc\\nX ↔ {null} → {null}\\n1\\nThisisexample2.3withhiddenadded.Forexample,forgridpointedges,hiddenbecomesasingletonconsistingonly\\nofundecided.Inpractice,S canbeconstructedasifhiddenwerethedomain.\\nQ\\nThus,apuzzlerulecanbedefinedbydeterminingthestructuresequenceS,domain,constraints,andhidden.\\nDefinition2.15(PuzzleRule). WedefineapuzzleruleasacombinationofstructuresequenceS,domain,constraints,\\nandhiddenthatsatisfiesremark2.4.\\nUsing this, in Section 3, we evaluate whether existing puzzle rules can be described using the puzzle rules of this\\nresearch.\\n3 Verification ofPuzzleRules\\nInthissection,weexperimentwithdescribingexistingpuzzlerulesusingthemathematicalexpressionsdefinedInthis\\nstudy andverifytheireffectivenessthroughcomputationalimplementation. Theexisting puzzleruleswe dealtwith\\nare theNikoliPuzzlespostedonNikoli[2024], Ltd. website. We computationallyimplementedtheexistingpuzzle\\nrules described using the mathematical expressions defined In this study, verified that the completed boards output\\nfromthemdidnotdifferfromtheexistingpuzzlerules,andtherebycorroboratedthatthedefinitionsInthisstudyare\\ntosomeextentvalid.\\n3.1 Method\\nThe method for verifyingeffectivenesswas carried out in the followingthree steps. The targetpuzzle rules are the\\nNikoliPuzzlespostedonNikoli[2024],Ltd. website.\\n1. Convertedexistingpuzzlerulesintomathematicalexpressionsfollowingdefinition2.15.\\n2. Implementedthe mathematicalexpressionsconvertedin 1. computationally. Specifically, we implemented\\nthegenerationofcompletedboardsaccordingtothemathematicalexpressions.\\n3. Confirmedfromtheoutputwhetherthecompletedboardscreatedusing2.donotdeviatefromthecompleted\\nboardsof existingpuzzle rules. If there is no deviationhere, it suggeststhat at least for that mathematical\\nexpression,itisasufficientconditionfortheexistingpuzzlerule.\\nNotethatwhatisverifiedhereisonlyasufficientcondition,andwecannotconfirmthenecessarycondition.\\n3.2 Results\\nOutofatotalof46,10wereconfirmedtobesufficientconditionsbythemethoddescribedinSection3.1. Specifically,\\nwe confirmed that those listed in Table 1 are sufficient conditions (including \"Inshi no heya\" and \"Sukoro\" which\\nare notposted in Nikoli [2024]. There are 44 puzzles posted in Nikoli [2024].). The mathematicalexpressionsare\\npostedinappendixA.2,andthecomputationalimplementationsarepostedinhttps://github.com/itkmaingit/\\npuzzle_check.\\n3.3 Discussion\\nThosethatwerenotconfirmedwereclassifiedaspuzzlerulesfallingunderanyofthefollowingcategories,or(evenif\\nsuccessfulinmathematicalexpression)difficulttoimplementcomputationally.\\n10MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nTable1: Puzzlesconfirmedtobesufficientconditions\\nName\\nChocoBanana\\nKurotto\\nFillomino\\nInshinoheya\\nHitori\\nSudoku\\nSukoro\\nNorinori\\nShikaku\\nSlitherlink\\n1. Thegraphcontainsdirectionalinformation(directedgraph).\\n2. Elementsthatcannotbeexpressedbygridpoints,cells,gridpointedges,orcelledgesareincluded.\\n3. Informationexistsoutsidetheboard.\\n4. Ithasstructuresthatcannotbecreatedbycompositionoperations.\\nForexample,Nansukefallsunderthelimitationin3.\\n4 Conclusion\\nIn this study, we mathematically defined puzzle rules for pencil puzzles. We demonstrated its capacity to express\\nexisting puzzle rules, successfully representing one-fourth of the analyzed puzzle rules. In addition, we identified\\ncaseswherecertainpuzzlerulescouldnotbeexpressedduetoaninherentlimitationofthedefinitionorcomputational\\nchallenges. Thisstudyhighlightsthepotentialforcreatingnewpuzzlerulesbyreplacingorcombiningmathematical\\nexpressionsofexistingpuzzlerules.Inparticular,whenthestructurespaceswouldmatch,theidenticalheuristicfunc-\\ntionscanbeapplied,makingitpossibletocombineconstraints.Thiscombiningexpression,inturn,enablessystematic\\nrulecreation,broadeningthepotentialapplicationsthatrangefromenhancingengagementinrecreationalpuzzlesto\\nadvancinglogic-basedsystemsineducationalandcomputationalcontexts.Ultimately,thisstudylaysarobustfounda-\\ntionforautomatingpuzzlerulegeneration,supportingboththeoreticalexplorationandpracticalimplementation.\\n5 Acknowledgement\\nThecontributionsofI.M.includedconceptualization,investigation,datacuration,methodology,validation,anddraft-\\ning theinitial versionof thismanuscript. Y.I. contributedto the conceptualization,fundingacquisition, supervision,\\nandthereviewandeditingofthismanuscript.\\nReferences\\nBrowne,CandMaire,F. Evolutionarygamedesign.ComputationalIntelligenceandAIinGames,IEEETransactions\\non,2:1–16,042010. doi:10.1109/TCIAIG.2010.2041928.\\nDeKegel,BandHaahr,M.Proceduralpuzzlegeneration:Asurvey.IEEETransactionsonGames,12(1):21–40,2020.\\ndoi:10.1109/TG.2019.2917792.\\nHerting,S. Arule-basedapproachtothepuzzleofslitherlink. Technicalreport,Univ.Kent,UK,2004.\\nLiang,XandXiao,Y. Gametheoryfornetworksecurity. CommunicationsSurveys&Tutorials,IEEE,15:472–486,\\n012013. doi:10.1109/SURV.2012.062612.00056.\\nMantere, T and Koljonen, J. Solving, rating and generating sudoku puzzles with ga. In 2007 IEEE Congress on\\nEvolutionaryComputation,pages1382–1389,2007. doi:10.1109/CEC.2007.4424632.\\nNikoli. Nikolipuzzle-nikoli. https://www.nikoli.co.jp/en/puzzles/,2024. Accessedon06/14/2024.\\nTang,ZandKirman,B. Exploringcuriosityingames: A frameworkandquestionnairestudyofplayerperspectives.\\nInternational Journal of Human-Computer Interaction, 0(0):1–16, 2024. doi:10.1080/10447318.2024.2325171.\\nURLhttps://doi.org/10.1080/10447318.2024.2325171.\\n11MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nYoshinaka,R,Saitoh,T,Kawahara,J,Tsuruma,K,Iwashita,H,andMinato,S. Findingallsolutionsandinstancesof\\nnumberlinkandslitherlinkbyzdds. Algorithms,5:176–213,122012. doi:10.3390/a5020176.\\nA Appendix\\nA.1 HeuristicFunctionGroup\\nBelowaretheoperationsusedinconstraints,orpredicatesandtheircorrespondences.\\nA.1.1 B\\nA functionthattakesastructureXpossessedbyapuzzleruleasanargumentandreturnsthestructuresincludedin\\ntheboardB.\\nB: B(X) 7−→ {X |X ∈B∩X}.\\nA.1.2 cross\\nA functionthatcalculatesthenumberofgridpointedgesgatheringata certaingridpoint. Whenthecoordinatesof\\nthegridpointare(i,j),withE ={hp(i,j−1),h (i,j),v (i−1,j),v (i,j)},\\np p p\\ncross: P −→ Z\\nsolution(e(k,l)) ife(k,l)∈Ep,\\np(i,j) 7−→ e(k,l)∈E\\n(cid:26)0 ife(k,l)∈/ E .\\np\\nP\\nA.1.3 cycle\\nAfunctionthatcalculatesthenumberofgridpointedgesgatheringaroundacertaincell. Whenthecoordinatesofthe\\ncellare(i,j),withE ={h (i,j),h (i+1,j),v (i,j),v (i,j+1)},\\np p p p\\ncross: C −→ Z\\nsolution(e(k,l)) ife(k,l)∈E ,\\np\\nc(i,j) 7−→ e(k,l)∈E\\n(cid:26)0 ife(k,l)∈/ E p.\\nP\\nA.1.4 all_different\\nApredicatethatbecomestruewhenthesolutionsofthestructuresincludedinthestructuregivenasanargumentare\\nalldifferent.\\nall_different(X)= ∀x,y ∈X,,(x6=y ⇒f(x)6=f(y)) .\\n(cid:2) (cid:3)\\nA.1.5 is_rectangle\\nApredicatethatbecomestruewhenthestructuregivenasanargumentformsarectanglewhenarrangedontheboard.\\nHowever,thestructuresthatcanbegivenasargumentsareonlyelementsincludedinthestructuresequencethathas\\nundergonecompositionoperationonlyonce.\\nis_rectangle(X)= ∀x(i,j)∈X,,∃i,j ∈Z,(minX≤i≤maxX∧minY≤j ≤maxY)\\n∧(cid:2)(maxX−minX)×(maxY−minY)=|X| . (cid:3)\\nHere,minX,maxX,minY,maxY(cid:2)aretheminimumandmaximumvaluesofth(cid:3)ecoordinatesoftheelementsincluded\\ninstructureX.\\nA.1.6 is_square\\nA predicatethatbecomestrue whenthe structuregivenas an argumentformsa squarewhenarrangedon the board.\\nHowever,thestructuresthatcanbegivenasargumentsareonlyelementsincludedinthestructuresequencethathas\\nundergonecompositionoperationonlyonce.\\nis_square(X)= is_rectangle(X)\\n∧(cid:2)(maxX−minX)×(cid:3) (maxY−minY)=|X| .\\nHere,minX,maxX,minY,maxYarethem(cid:2)inimumandmaximumvaluesofthecoordina(cid:3)tesoftheelementsincluded\\ninstructureX.\\n12MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nA.1.7 connect\\nWhenaboardBexists,afunctionthatreturnsstructuresconnectedbythepositionalrelationshipgivenasanargument\\ntothestructuregivenasanargument.WithR⊂R={H,V,D,M},\\nconnect: connect(X,R) 7−→{Xother|(X,Xother)∈E(B(X,R))}.\\nA.1.8 no_overlap\\nWhengivenastructureXpossessedbyapuzzlerule,apredicatethatbecomestruewhentheintersectionisanempty\\nset when the flattening function flatten is applied to all structures belonging to it within a certain board B. When\\nmultiplestructuresaregiven,itistoconstructaunionwithintheboardB.\\nno_overlap(X)= ∀X1,X2 ∈B(X),(X1 6=X2 ⇒flatten(X1)∩flatten(X2)=∅)\\n(cid:2) (cid:3)\\nA.1.9 fill\\nWhengivenastructureXpossessedbyapuzzlerule,apredicatethatbecomestruewhen,withinacertainboardB,\\nwhentheflatteningfunctionflattenisappliedtothatstructure,itmatchesoneoftheelementsequencesandsatisfies\\ntheoverlapfunction.\\nfill(X)= no_overlap(X) ∧ flatten(B(X))∈E .\\n(cid:2) (cid:3) (cid:2) (cid:3)\\nA.2 ConversionofExistingPuzzleRulestoMathematicalExpressions\\nBelow are the existing puzzle rulesconvertedto mathematicalexpressionsas demonstratedby Section 3. However,\\nwefirstdescribecommonlyusedstructures.\\nR= {H,V}\\nE= C (∈E)\\nA= combine(R,E) (A.1)\\nR = {H}\\nE = C (∈E)\\nA = combine(R,E)\\nh\\nR = {V}\\nE = C (∈E)\\nA = combine(R,E)\\nv\\nR = {H,V,D}\\nE = E (∈E)\\np\\nG = combine(R,E)\\np\\nR = {H,V,D}\\nE = E (∈E)\\nc\\nG = combine(R,E).\\nc\\nA.2.1 Slitherlink\\nPossessedstructureisG . domainandhiddenare\\np\\nP ↔ {null} → {null}\\nC ↔ {0,1,2,3,4}→ {0,1,2,3,4,undecided}\\nE ↔ {0,1} → {undecided}\\np\\nE ↔ {null} → {null}\\nc\\nG ↔ {null} → {null}.\\np\\n13MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nconstraintsare\\n∀G ∈G ,∀e ∈G ,solution(e )=1\\np p p p p\\n∀p∈B(P),cross(p)=2\\n∀c∈B(C),solution(c)=cycle(c)\\n|B(G )|=1.\\np\\nA.2.2 Sudoku\\nPossessedstructuresareA ,A ,A. domainandhiddenare\\nh v\\nP ↔ {null} → {null}\\nC ↔ {1,2,3,4,5,6,7,8,9}→ {1,2,3,4,5,6,7,8,9,undecided}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {null} → {null}\\nh\\nA ↔ {null} → {null}\\nv\\nA ↔ {null} → {null}.\\nconstraintsare\\nfill(A )\\nh\\nfill(A )\\nv\\nfill(A)\\n∀A ∈B(A ),|A|=9∧all_different(A )\\nh h h\\n∀A ∈B(A ),|A|=9∧all_different(A )\\nv v v\\n∀A∈B(A),is_square(A)∧|A|=9∧all_different(A)\\nA.2.3 Shikaku\\nPossessedstructureisA. domainandhiddenare\\nP ↔ {null} → {null}\\nC ↔ {null} → {null}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {1,...n×m} → {1,...n×m}.\\nconstraintsare\\nfill(A)\\n∀A∈B(A),is_rectangle(A)∧solution(A)=|A|.\\nA.2.4 ChocoBanana\\nPossessedstructuresareA ,A (bothfromEquation(A.1)). domainandhiddenare\\n1 2\\nP ↔ {null} → {null}\\nC ↔ {null} → {null}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {1,...n×m} → {1,...n×m}.\\n1\\nA ↔ {1,...n×m} → {1,...n×m}.\\n2\\nconstraintsare\\nfill(A ,A )\\n1 2\\n∀A1 ∈B(A 1),¬is_rectangle(A1)∧solution(A1)=|A1|.\\n∀A2 ∈B(A 2),is_rectangle(A2)∧solution(A2)=|A2|.\\n14MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nA.2.5 InshinoHeya\\nPossessedstructuresareA ,A ,A. domainandhiddenare\\nh v\\nP ↔ {null} → {null}\\nC ↔ {null} → {null}\\nE ↔ {null} → {null}\\np\\nEc↔ {null} → {null}\\nA ↔ {null} → {null}\\nh\\nA ↔ {null} → {null}\\nv\\nA ↔ {null} → {1,...,n×n!}.\\nconstraintsare\\nn=m\\nfill(A )\\nh\\nfill(A )\\nv\\nfill(A)\\n∀A ∈B(A ),|A|=9∧all_different(A )\\nh h h\\n∀A ∈B(A ),|A|=9∧all_different(A )\\nv v v\\n∀A∈B(A),is_rectangle(A)∧solution(A)= c∈Asolution(c).\\nY\\nA.2.6 Fillomino\\nPossessedstructureisA. domainandhiddenare\\nP ↔ {null} → {null}\\nC ↔ {1,...n×m} → {1,...n×m,undecided}\\nEp↔ {null} → {null}\\nE ↔ {null} → {null}\\nc\\nA ↔ {1,...n×m} → {1,...n×m,undecided}.\\nconstraintsare\\nfill(A)\\n∀A∈B(A),∀c∈A,solution(A)=solution(c)=|A|\\n∀A∈B(A),∀Aother ∈connect(A,{H,V }),|A|6=|A |\\nother\\nA.2.7 Kurotto\\nPossessedstructureisA. domainandhiddenare\\nP ↔ {null} → {null}\\nC ↔ {null,0,...n×m−1,x} → {null,0,...n×m−1,undecided}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {null} → {null}.\\nconstraintsare\\nno_overlap(A)\\n∀A∈B(A),connect(A,{H,V })=∅\\n∀c∈B(C),solution(c)6=null\\n⇒solution(c)= c ∈connect(c,{H,V })|A|∈{A∈B(A)|c ∈A}\\nother other\\nX\\n∀c∈B(C),solution(c)=x⇔c∈∃A∈B(A)\\n15MathematicalDefinitionandSystematizationofPuzzleRules APREPRINT\\nA.2.8 Sukoro\\nPossessedstructureisA. domainandhiddenare\\nP ↔ {null} → {null}\\nC ↔ {null,1,...4} → {undecided}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {null} → {null}.\\nconstraintsare\\n|B(A)|=1\\n∀c∈B(C),solution(c)∈N⇔c∈∃A∈B(A)\\n∧solution(c)=|{x∈connect(c,{H,V })|solution(x)∈N}|\\n∧∀c ∈connect(c,{H,V }),solution(c )6=solution(c)\\nother other\\nA.2.9 Norinori\\nPossessedstructuresareA ,A (bothfromEquation(A.1)). domainandhiddenare\\n1 2\\nP ↔ {null} → {null}\\nC ↔ {null,x} → {undecided}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {null} → {null}\\n1\\nA ↔ {null} → {null}.\\n2\\nconstraintsare\\nno_overlap(A )\\n1\\nfill(A )\\n2\\n∀c∈B(C),solution(c)=x⇔c∈∃A1 ∈B(A 1)\\n∀A1 ∈B(A 1),|A1|=2\\n∀A2 ∈B(A 2),|{c∈A2 |solution(c)=x}|=2\\nA.2.10 Hitori\\nPossessedstructuresareA ,A ,A. domainandhiddenare\\nh v\\nP ↔ {null} → {null}\\nC ↔ {1...n,x} → {1...n}\\nE ↔ {null} → {null}\\np\\nE ↔ {null} → {null}\\nc\\nA ↔ {null} → {null}.\\nh\\nA ↔ {null} → {null}.\\nv\\nA ↔ {null} → {null}.\\nconstraintsare\\nn=m\\nfill(A )\\nh\\nfill(A )\\nv\\n∀A ∈B(A ),A′ ={c∈A |solution(c)6=x},all_different(A′ )\\nh h h h h\\n∀A ∈B(A ),A′ ={c∈A |solution(c)6=x},all_different(A′ )\\nv v v v v\\n|B(A)|=1\\n∀c∈B(C),solution(c)=x⇔{c∈A|A∈B(A)}=∅\\n∧{y ∈connect(c,{H,V })|solution(y)=x}=∅\\n16',\n",
       " 'MedCoDi-M A Multi-Prompt Foundation Model for Multimodal Medical Data Generation.pdf': 'MedCoDi-M: A Multi-Prompt Foundation Model for\\nMultimodal Medical Data Generation\\nDaniele Molinoa, Francesco Di Feolab, Eliodoro Faiellad,e, Deborah Fazzinic,\\nDomiziana Santuccid, Linlin Shenf, Valerio Guarrasia,1, Paolo Sodaa,b,1,∗\\naResearch Unit of Computer Systems and Bioinformatics, Department of Engineering,\\nUniversit`a Campus Bio-Medico di Roma, Roma, Europe\\nbDepartment of Diagnostics and Intervention, Radiation Physics, Biomedical\\nEngineering, Ume˚a University, Ume˚a, Sweden\\ncDepartment of Diagnostic Imaging and Stereotactic Radiosurgey, Centro Diagnostico\\nItaliano S.p.A., Milano, Italy\\ndDepartment of Radiology and Interventional Radiology, Fondazione Policlinico\\nUniversitario Campus Bio-Medico, Rome, Italy\\neResearch Unit of Radiology and Interventional Radiology, Department of Medicine and\\nSurgery, Universit`a Campus Bio-Medico di Roma, Rome, Italy\\nfCollege of Computer Science and Software Engineering, Shenzhen\\nUniversity, Shenzhen, China\\nAbstract\\nArtificial Intelligence is revolutionizing medical practice, enhancing diagnos-\\ntic accuracy and healthcare delivery. However, its adaptation in medical\\nsettings still faces significant challenges, related to data availability and pri-\\nvacy constraints. Synthetic data has emerged as a promising solution to\\nmitigate these issues, addressing data scarcity while preserving privacy. Re-\\ncently, Latent Diffusion Models have emerged as a powerful tool for gen-\\nerating high-quality synthetic data. Meanwhile, the integration of different\\nmodalities has gained interest, emphasizing the need of models capable of\\nhandle multimodal medical data. Existing approaches struggle to integrate\\n∗Corresponding author: p.soda@unicampus.it, paolo.soda@umu.se\\nEmail addresses: daniele.molino@unicampus.it (Daniele Molino),\\nfrancesco.feola@umu.se (Francesco Di Feola), e.faiella@policlinicocampus.it\\n(Eliodoro Faiella), deborah.fazzini@CDI.it (Deborah Fazzini),\\nd.santucci@policlinicocampus.it (Domiziana Santucci), llshen@szu.edu.cn (Linlin\\nShen), valerio.guarrasi@unicampus.it (Valerio Guarrasi), p.soda@unicampus.it,\\npaolo.soda@umu.se (Paolo Soda)\\n1These authors equally contributed to the work and share senior authorship.\\nPreprint submitted to Information Fusion January 10, 2025\\n5202\\nnaJ\\n9\\n]IA.sc[\\n2v41640.1052:viXracomplementary information and lack the ability to generate modalities si-\\nmultaneously. To address this challenge, we present MedCoDi-M, a 6.77-\\nbillion-parameter model, designed for multimodal medical data generation,\\nthat, following Foundation Model paradigm, exploits contrastive learning\\nand large quantity of data to build a shared latent space which capture the\\nrelationships between different data modalities. Further, we introduce the\\nMulti-Prompt training technique, which significantly boosts MedCoDi-M’s\\ngeneration under different settings. We extensively validate MedCoDi-M:\\nfirst we benchmark it against five competitors on the MIMIC-CXR dataset,\\na state-of-the-art dataset for Chest X-ray and radiological report generation.\\nSecondly, we perform a Visual Turing Test with expert radiologists to assess\\nthe realism and clinical relevance of the generated data, ensuring alignment\\nwith real-world scenarios. Finally, we assess the utility of MedCoDi-M in\\naddressing key challenges in the medical field, such as anonymization, data\\nscarcity and imbalance learning. The results are promising, demonstrating\\nthe applicability of MedCoDi-M in medical contexts. Project page is at\\nhttps://cosbidev.github.io/MedCoDi-M/.\\nKeywords: Diffusion Models, Contrastive Learning, Self-Supervised\\nLearning, Generative AI, Chest X-rays, Radiological Report\\n1. Introduction\\nArtificial Intelligence (AI) is increasingly revolutionizing several fields, in-\\ncludinghealthcare. Today,AIsystemsarecapableofprocessingvastamounts\\nof medical data, revealing patterns often undetectable to the human eye and\\nenabling more accurate diagnostics, personalized treatments, and efficient\\nhealthcare delivery [1]. Moreover, the capability to leverage multimodal data\\nrepresents a disruptive advancement in the medical field, enabling compre-\\nhensive diagnostic insights by integrating different data sources. However,\\ndespitetheseadvancements,theimplementationofAIinhealthcarefacessev-\\neral challenges, primarly caused by data scarcity and privacy concerns [2].\\nThe available datasets for training AI models are often limited in size, di-\\nversity, and scope, making training deep learning (DL) models a significant\\nchallenge, as these models typically require extensive, high-quality data to\\nachieve great performances. Without enough diverse data, models may be-\\ncome biased, prone to overfitting, or unable to generalize well to new, unseen\\ncases, creating a bottleneck in the deployment of AI solutions in real-world\\n2healthcare scenarios. Privacy regulations, such as the General Data Protec-\\ntion Regulation (GDPR) [3] in Europe and the Health Insurance Portability\\nand Accountability Act (HIPAA) [4] in the United States, although crucial\\nfor protecting patient privacy, can hinder the collaborative efforts required\\nto gather large-scale datasets. To address these limitations, a novel stream\\nof research is focusing on multimodal synthetic data generation techniques.\\nThis emerging approach involves creating artificial data that replicate the\\ncomplexity and diversity of real medical data, thus providing a solution to\\nbypass the constraints of real-world data scarcity and privacy concerns.\\n1.1. Generative AI\\nGenerative AI has seen remarkable growth since 2014, when the introduc-\\ntion of Generative Adversarial Networks (GANs) [5] had a groundbreaking\\ninfluence on the research field, enabling the creation of realistic synthetic\\ndata through adversarial training. Despite their early success, GANs face\\ninherent challenges, such as training instability, mode collapse, and diffi-\\nculty in generating fine-grained details, issues that limit their effectiveness\\nin the medical domain. Building on the foundation set by GANs, Diffu-\\nsion Models (DM) [6] have recently emerged as a more robust approach for\\ndata generation. Through a multi-step denoising process, DMs demonstrate\\nan improved capacity for generating diverse, high-fidelity data, capturing\\nsubtle variations and intricate details that are essential in medical imaging\\napplication, where both fidelity and diversity of synthetic data are crucial.\\nLatent diffusion models (LDMs) [7] have gained significant attention: as the\\ndenoising process operates within a low-dimensional latent space [7], LDMs\\nrequire reduced computational resources, making them more practical and\\naccessible for deployment to a wider range of users and systems. Moreover,\\ndue to their advanced conditioning mechanism, LDM allow for fine-grained\\ncontrol over the generation process [8, 9]. The conditioning mechanism lever-\\nages encoders that extract meaningful representations from the input source,\\nenabling the synthesis of targeted features, such as specific anatomical struc-\\ntures or disease characteristics. This controlled generation process not only\\nenhances the model’s flexibility but also its relevance in medical setting, as it\\nallows practitioners to generate synthetic data tailored to unique diagnostic\\nrequirements or research needs. LDMs can be effectively adapted to a wide\\nrange of downstream tasks and, with the appropriate pre-training, have the\\npotential to serve as robust foundation models [10]. However, most of these\\nmodels can only generate one modality from another, which can be a signif-\\n3icant limitation in the healthcare setting, where multiple modalities coexist\\nand interact. Outside the medical domain, significant advancements have\\nbeen made in multimodal data generation. Among these studies, CoDi [11]\\nstands as pivotal work. By enabling the simultaneous generation of multi-\\nple modalities from a shared latent space, CoDi significantly improves the\\nconsistency and coherence of the generated outputs, allowing for any-to-any\\ngeneration, avoiding the pitfalls of a multi-step approach. The adaptation of\\na similar approach for medical data generation could prove highly beneficial,\\nfilling a critical gap in the availability of diverse and high-quality datasets\\nfor research and diagnostic purposes. However, CoDi presents some limita-\\ntions when applied to such a setting: while it demonstrates the feasibility\\nof any-to-any generation in non-medical enviroment, its performance tends\\nto degrade when provided with multiple input modalities or their combina-\\ntions, a limitation that cannot be overlooked in the medical domain, where\\nreliability and consistency across modalities are critical.\\n1.2. Related Works\\nIn recent years, there has been a growing interest in developing generative\\nmodels for X-rays generation, as they can give insight about a wide range\\nof medical conditions. Numerous studies have assessed the task of synthetic\\nChest X-ray (CXR) generation through GANs, where most focused on a\\nspecific pathology, like tubercolosis [12], pneumonia [13] or Covid-19 [14, 15].\\nRecently, LDMs have emerged as a promising approach for CXR generation:\\nRoentGen [16] was the first work to explore the adaptation of a pre-trained\\nLDM, named Stable Diffusion [7], for text-conditioned generation of CXRs\\nbeyond few- or zero-shot setting [17, 18]. In such a work, they showed that\\nfine-tuning the UNet component is necessary in order to effectively adapt the\\nmodel to the medical domain, as it allows to capture the unique features and\\nnuances of medical images, thereby improving the quality and realism of the\\ngenerated CXRs.\\nIn parallel with the rise of LDMs, there has been a growing interest in devel-\\noping techniques to fuse textual and visual data, driving the development of\\nthe first vision-language models, capable of processing and combining both\\nmodalities [19, 20, 21, 22]. In the field of CXR generation, UniXGen [23]\\nleverages the transformer [24, 25] architecture for both X-ray and report gen-\\neration. Theyadoptedavectorquantizationtechnique,namedVQ-GAN[26],\\nto convert an X-ray in a set of discrete tokens, addressing both tasks as a\\nsequence generation problem. Additionally, their work emphasizes the gen-\\n4eration of different X-ray views, as each view contains distinct informative\\ncontent, enhancing the utility of generated data. However, their approach is\\nlimited by its inability to generate multiple outputs simultaneously, requir-\\ning separate processing for each modality, without an explicit mechanism to\\nguarantee coherence between the generated data. Building on this idea, Lee\\net Al. [27] proposed a similar approach for bidirectional X-ray and report\\ngeneration via a fine-tuned large language model, named LLM-CXR. Unlike\\nUniXGen, they only leveraged frontal chest X-rays, focusing on a single view\\nfor their generation tasks, potentially limiting its applicability in more com-\\nprehensive clinical scenarios.\\nThe main limitation of these works is that they overlook the complementary\\nnature of different medical data modalities and lack the ability to gener-\\nate multimodal outputs simultaneously. This independent processing often\\nresults in inconsistencies when modalities are synthesized separately, poten-\\ntially leading to outputs that lack clinical coherence. Such limitations hinder\\ntheir applicability in real-world healthcare settings, where seamless integra-\\ntion of multimodal data is essential to replicate the complexity of patient-\\nspecific information accurately.\\n1.3. Contribution\\nBuilding on the success of CoDi, this work proposes MedCoDi-M, a novel\\nmulti-prompt foundation model for multimodal medical data generation. By\\ntakingadvantageofcontrastivelearningtechniques,usedtobuildFoundation\\nModels [28], MedCoDi-M enable flexible, any-to-any generation across differ-\\nent medical data modalities. Specifically, our generative process ensures that\\nMedCoDi-M can capture the complex interactions between different medi-\\ncal modalities. To this end, we propose a novel training approach, named\\nMulti-Prompt Training, to improve the model’s ability to fuse information\\nfrom multiple modalities, enhancing its capability to generate coherent and\\naccurate medical data.\\nThe main contribution can be summarized as:\\n• We propose MedCoDi-M, a novel generative model that synthesizes\\nmultiple data modalities from a shared multimodal latent space.\\n• WeintroduceaMulti-PrompttrainingapproachthatboostsMedCoDi-\\nM’sgenerationcapabilitieswhenpromptedbymultipledatamodalities.\\n5• We thoroughly evaluate MedCoDi-M against existing state-of-the-art\\nmodels, showing its superior capabilities in terms of quality, realism\\nand clinical accuracy.\\n• We perform a Visual Turing Test, consisting of five evaluation tasks\\nadministrated to three expert radiologists, to assess the clinical realism\\nand diagnostic consistency of the generated data modalities.\\n• We evaluate the utility of synthetic data, by showing its effectiveness in\\ntackling three key challenges in the medical domain, i.e., Anonymiza-\\ntion, Imbalance Learning and Data Scarcity.\\nThis paper is organized as follows: Section 2 presents the methods employed\\ninthiswork, detailingthearchitectureofMedCoDi-M,itstrainingprocedure,\\nand the innovative Multi-Prompt Training strategy. Section 3 describes the\\ndataset and preprocessing steps, emphasizing the characteristics of the medi-\\ncaldataused. Itthenoutlinestheexperimentalsetup, includingthecompeti-\\ntors, evaluation metrics, and configurations adopted to assess MedCoDi-M.\\nSection 5 discusses the results, providing both quantitative and qualitative\\nanalyses, also introducing the findings from the Visual Turing Test. Finally,\\nSection 6 summarizes the main contributions and discusses potential direc-\\ntions for future research.\\n2. Methods\\nAssuming M is the set of our modalities, let I = {I ,I ,...,I } be any subset\\n1 2 n\\nof modalities used to prompt the generation and let O = {O ,O ,...,O }\\n1 2 m\\nbe any subset of modalities to be generated, such that O ∩ I = ∅, with\\nI,O ⊆ M. It is important to note that this distinction is made solely for\\nexpositional clarity; in practice, any modality from the set M can be used\\nboth as an input or as an output, and the model is not restricted to specific\\nmodality pairings.\\nThe overall architecture of MedCoDi-M is depicted in Fig.1, which consists\\nof three blocks, each corresponding to a distinct training phase. In panel\\n(a), we align the feature representations extracted from the input modali-\\nties by modality-specific prompt encoders into a shared latent space using\\ncontrastive learning. In panel (b), we independently train an LDM for each\\noutput modality, using the multi-prompt training approach for condition-\\ning. Finally, in panel (c), we perform cross-modal alignment, enabling the\\n6... ... ... ...\\n... ...\\n(a) (b) (c)\\nFigure 1: Framework of MedCoDi-M - a) Shared Latent Space construction: Input\\nmodalities are processed by modality-specific prompt encoders to extract feature\\nrepresentations, which are aligned using contrastive learning. - b) Single modality\\ngeneration training: Individual LDMs are trained for each output modality using the\\nproposed Multi-prompt training approach. This technique dynamically combines subsets\\nof input modalities to form a conditioning vector, allowing the model to learn from\\nvarious input configurations. - c) Latent Cross-Modal Alignment: This phase enable\\nsimultaneous multimodal generation, enabling mutual conditioning between LDMs.\\nmodel to simultaneously generate any combination of output modalities. In\\nthe following, we provide a rigorous description of each training step in sec-\\ntions 2.1, 2.2 and 2.3.\\n2.1. Building a Shared Latent Space\\nWe propose to align any input modalities within a shared latent space by\\nleveraging contrastive learning. This approach allows the model to be freely\\nconditionedonanyinputcombination, eventhoseabsentinthetrainingdata.\\nInspired by [11], we take advantage of an efficient technique called Bridg-\\ning Alignment to align the representations extracted by modality-specific\\nprompt encoders. Following Fig 1.a, we first extract a feature representa-\\ntion h = P (I ) for every input modality I ∈ I, where P is the prompt\\nIj Ij j j Ij\\nencoder for modality I . The latent space is constructed through a series of\\nj\\npairwise training rounds, ensuring coherent alignment across all modalities\\nwhile reducing the computational complexity. Once the encoders are trained,\\n7multimodalconditioningcanbeachievedbyinterpolatingtherepresentations\\nof each modality h ,h ,...,h .\\nI1 I2 In\\n2.2. A Multi-prompt approach for single-modality generation\\nTraining a multi-input, multi-output generative model requires extensive\\ntraining across diverse data sources, while mantaining high generation qual-\\nity across all synthesis flows. To address these challenges, MedCoDi-M is de-\\nsigned to be both composable and integrative, as it enables the independent\\ndevelopment of modality-specific LDMs, which can then be seamlessly inte-\\ngrated into a unified framework. In the healthcare domain, information often\\nflows concurrently across multiple modalities: to emulate this phenomenon,\\nwedevelopedanoveltrainingapproach, namedMulti-PromptTraining. This\\ntechnique enhances MedCoDi-M’s conditioning capabilities, enabling it to be\\neffectively conditioned on multiple data modalities simultaneously. Let us re-\\nmember that O is an output modality we aim to generate and I is the set\\ni\\nof input modalities used to prompt the LDM. Following Figure 1.b, we first\\nextract the latent representation h = P(I ) for all the I in I using the\\nIj j j\\nprompt encoders now frozen and previously trained as described in Section\\n2.1. Then, at each training iteration, the prompt sampling strategy Ω dy-\\nnamically select and combine a random subset of input modalities I from\\np\\nI into a conditioning vector ω. Given a total number of n modalities, there\\nexists 2n−1−1 possible combinations, making the probability of drawing any\\npossible subset equal to p = 1 . Once a combination is selected, their\\n2(n−1)−1\\nlatent representations are linearly combined to form a conditioning vector\\ndefined as:\\nn n\\n(cid:88) (cid:88)\\nω = Ω(h ...h ) = α h with α = 1 and j ∈ {I }. (1)\\nI1 In j Ij j p\\nj=1 j=1\\nTheresultingvectorω, isthenusedastheconditioningfortrainingthemodel\\nG . Following the reparametrization method proposed in [6], the training\\nOi\\nobjective can be expressed as [7]:\\nL = E (cid:2) ∥ϵ−ϵ (z ,t,ω)∥2(cid:3) (2)\\nD z,ϵ,t θ t 2\\nWhere z is the latent variable of diffusion process, progressively diffused\\nt\\nacross time step t ∼ [1,T], sampled from a uniform distribution, and ϵ is a\\nθ\\ndenoising model with a UNet architecture parameterized by θ.\\n82.3. Multi-output generation via Cross-modal Latent Alignement\\nThe third training stage enables the simultaneous generation of any combi-\\nnation of output modalities, ensuring that each generative flow is aware of\\nthe others. To this end, we incorporate two trainable components into each\\nLDM G : the first is an encoder V , that projects the latent variable of\\nOi Oi\\nthe diffusion process z into a shared latent space; the second is a cross-\\nOi\\nattention layer, that allows each LDM to attend to the generative process of\\nanother model. Formally, let us consider two modalities, O and O , being\\ni i+1\\njointly synthesized by G and G and let z and z denote their la-\\nOi Oi+1 Oi Oi+1\\ntent variables at a generic diffusion step, respectively. Following Fig 1.c, the\\nencoder V first projects z into a shared latent space. Then, in each\\nOi+1 Oi+1\\nlayer of G , the cross-attention layer attends to V (z ).\\nOi Oi+1 Oi+1\\nForthediffusionmodelofmodalityO , thetrainingobjectiveinEq.2become:\\ni\\nLOi = E ∥ϵ−ϵ (z ,V (z ),t,ω)∥2, (3)\\nD z,ϵ,t θc Oi Oi+1 Oi+1 2\\nwhere θ represents the parameters of the cross-attention layer in the UNet.\\nc\\nThe training objective for the joint generation of O and O becomes\\ni i+1\\nL = LOi +LOi+1.\\nCross D D\\nBy training only these two additional components while keeping the rest\\nof the model frozen, MedCoDi-M effectively learns to generate modalities\\nsimultaneously while mantaining high-quality outputs.\\n3. Experimental Configuration\\nThis section provides a comprehensive overview of the experimental setup\\nadopted to evaluate the performance of MedCoDi-M. It begins by describing\\nthe dataset used, including its key characteristics and preprocessing steps,\\nwhich ensure that the data is prepared appropriately for training and evalu-\\nation. Next, the section details the implementation specifics of the proposed\\nframework, such as architectural choices, training configurations, and opti-\\nmization strategies. Additionally, it presents the state-of-the-art competitors\\nused for comparative analysis, highlighting their relevance and limitations in\\nthe context of multimodal medical data generation. Finally, the evaluation\\nmetrics are introduced, encompassing both quantitative and qualitative mea-\\nsures to thoroughly assess the realism, coherence, and clinical utility of the\\ngenerated outputs.\\n93.1. Materials\\nTo achieve our purpose, it is crucial to leverage a multimodal medical dataset\\nthatcapturesthecomplementarynatureofdifferentmodalities,suchasimag-\\ning and textual data. Such datasets are essential for training models capable\\nof synthesizing clinically accurate and coherent outputs across diverse medi-\\ncal data types. We used the MIMIC-CXR [29] dataset that contains 377.110\\nCXR images along with their corresponding radiology reports, for a total of\\n227.827 studies conducted at the Beth Israel Deaconess Medical Center in\\nBoston, MA, USA. In the dataset, images are acquired in frontal and lat-\\neral projection. Due to significant anatomical differences, the two views offer\\ndistinct yet complementary diagnostic information [30]. For example, car-\\ndiovascular structures and the diaphragm can obscure up to 15% of the lung,\\nmaking certain pathologies undetectable in the frontal view alone [31]. The\\nlateral view, by providing a different perspective, enables the visualization\\nof lesions or abnormalities hidden behind these anatomical structures, thus\\nensuring more accurate diagnosis [32]. For those reasons, we treated frontal\\nand lateral CXRs as distinct modalities. Each radiology report in the dataset\\nis divided in two sections: a finding section that provides a detailed descrip-\\ntion of both normal and abnormal features observed in the corresponding\\nCXR, and an impression section, which provides a concise summary of the\\nfindings intended to support medical decision-making. In this work, we fo-\\ncused exclusively on the latter, as it offers a concise yet powerful summary\\nof the patient’s condition and it also complies with our text encoder, which,\\nfollowing [11] implementation, poses a limitation on the length of the report\\nto 77 tokens.\\nFrom the repository, we extracted a total of 154.721 X-rays from 78.584 stud-\\nies, including all the patients for which the radiology report and both frontal\\nand lateral view were present. An explicative example of a triplet is depicted\\nin Fig. 2.\\nFurthermore, we used the original uncompressed X-rays stored in DICOM\\nformat [33] as in medical imaging, subtle details are critical for accurate di-\\nagnosis, and compression can lead to unintended loss of information.\\nThe X-ray’s preprocessing involved several steps to standardize and prepare\\nthe data for model training. First, we examinated the pixel spacing of each\\nimage and resampled those with non-standard spacing to [0.139,0.139], i.e.,\\nthe value observed in 95.76% of the dataset. For the images with a Pho-\\ntometric Intepretation of Monochrome-1, the pixel values were inverted to\\nensure proper representation. Subsequently, we normalized the images by\\n10Figure 2: A sample of our dataset, composed of a Frontal X-ray, a Lateral X-ray and the\\ncorresponding radiology report.\\ndividing every pixel by the maximum pixel value possible given by their bit\\ndepth, bringing the range to [0,1]. Since the original scans are not square, we\\nchose not to modify their proportions through a direct resizing, as this could\\ndistortimportantanatomicalfeatures. Additionally, extractingasquarecrop\\nwas not a viable option, due to the impossibility to select a Region of Interest\\n(ROI) that would be universally applicable. Instead, we added zero-padding\\naround images and then resize them to 256×256, to standardize the input\\nsize while preserving the integrity of the visual content.\\nToensureanunbiasedevaluation, weextractedanholdouttestsetbeforeany\\ntraining procedure. This set consists of 33.588 samples, that were carefully\\nselected to guarantee no patient’s overlapping between training and test set.\\n3.2. Model Architecture and Training\\nWe delve here into the architectural choices made for each component of our\\nframework, with a specific focus on how every part of the model is trained.\\n3.2.1. Prompt Encoders\\nGiven that our three modalities consist of texts and images, we adopt the\\nContrastive Language-Image Pretraining (CLIP) [34] approach to leverage\\na pretrained text-image paired encoder. This approach is composed of an\\nimage and a text encoder, denoted as P and P , jointly trained on large-\\nX R\\nscale datasets of text-image pairs. By doing so, the encoders learn a shared\\nrepresentation space that effectively captures the semantics of both modal-\\nities. In order to reduce the computational overload, we decided to let a\\nsingle image encoder, i.e. a ViT Transformer, be responsible for both frontal\\n11and lateral X-rays feature representations, while we leverage a masked self-\\nattention Transformer for the text encoding.\\nGiven a batch of X-ray images X and their corresponding reports R, we ob-\\ntain the embeddings h = P (X), h = P (R) for both modalities. These\\nX X R R\\nrepresentations are then aligned through contrastive learning, using the In-\\nfoNCE contrastive loss [35]:\\nexp(hi ⊤ hi /τ)\\nL = −log X R (4)\\nX,R exp(hi ⊤ hi /τ)+(cid:80) exp(hi ⊤ hi /τ)\\nX R j̸=i X R\\nwhere τ is the scalar temperature regulating the softness of the softmax\\ndistribution, and i,j refers, respectively, to positive and negative couples.\\nWe adopt the symmetric loss L + L to make the embeddings closer\\nX,R R,X\\ntogether. AnexampleofthegenerictrainingprocedureforCLIPisillustrated\\nin Fig. 3.\\nFigure 3: CLIP training procedure.\\n3.2.2. Latent Diffusion Model\\nX-ray Diffusion Model: The LDM for image generation adopts the same\\narchitecture of Stable Diffusion 1.5 [7], where AutoKL [26] is used as the\\n12variational autoencoder (VAE) to map the input modalities in a lower di-\\nmensional space. As stated in [17], the most effective approach for the adap-\\ntation of an LDM to the medical imaging domain is to fine-tune the UNet\\ncomponent. Therefore, we kept the VAE frozen and only trained the UNet.\\nIn total we trained two LDMs, one for the frontal X-rays and one for the\\nlateral X-rays, using a batch size of 512, a learning rate of 5×10−5, and a\\nweight decay of 1×10−4. Both models were trained for 100 epochs using the\\nAdamW optimizer.\\nReport Diffusion Model: For the text generation, the UNet architec-\\nture is based on [36], which introduced the fully-connected residual blocks\\n(FCResBlock). These expand the 768-dimensional text latent vectors into a\\n320-by-4 hidden feature and follow the residual block paradigm with Group-\\nNorms [37], SiLU [38], and skip connections. We adopt Optimus [39] as the\\ntext VAE, which consist of a BERT [40] text encoder and a GPT-2 [41] text\\ndecoder. Unlike the LDMs used for X-ray images, we decided to fine-tune\\nboth the VAE and the UNet in two separate training rounds. This approach\\nis necessary as the model has to effectively adapt to a completely different\\nvocabulary. Following [39], the training process begins with a reconstruction\\ntask, where the VAE is tasked with accurately reconstructing input radiol-\\nogy reports from their latent representations. Once the first step is fulfilled,\\nthe UNet is trained for report generation using a batch size of 1024 was em-\\nployed, while the learning rate was set to 1 × 10−5. The weight decay, the\\noptimizer configuration and the number of epochs remained consistent with\\nthe X-ray LDMs.\\n3.3. Computational Analysis\\nTo quantify the computational cost of our framework, we provide a detailed\\nbreakdown of the number of parameters for each model component. Specif-\\nically, CLIP model contains 737 million parameters, while AutoKL has 101\\nmillion parameters, with two instances used in our framework. Optimus\\nmodel consists of 241 million parameters, and the X-ray UNet model has\\n1.77 billion parameters, with two instances used. Finally, the Report UNet\\nmodel has 2.04 billion parameters. In total, the number of parameters for\\nall components combined amounts to 6.77 billion. All experiments were con-\\nductedonahigh-performancecomputingclusterequippedwithfourNVIDIA\\nA100 GPUs. The total computational time required across all experiments\\nwas approximately 38.354 hours.\\n133.4. Competitors\\nTo rigorously compare MedCoDi-M against established approaches for the\\ngeneration of X-rays and radiology report, we include a total of five open\\nsource competitors which, to the best of our knowledge, are the only works\\nwith accessible and reproducible code as well as model weights. It is worth\\nnoting that we selected UniXGen and LLM-CXR [23, 27] because they ad-\\ndress the same problem, i.e., bidirectional generation of CXRs and reports,\\nwith different architectures from us, namely Transformer and LLM. Mean-\\nwhile, despite it lacks of bidirectional capabilities, we selected RoentGen [16]\\nas it was the first work to leverage a fine-tuned LDM for X-ray generation.\\nAll competitors were trained on the MIMIC-CXR dataset, allowing us to use\\nthem directly without requiring additional training.\\n• The original CoDi [11] model, without any adaptation to the medical\\ndomain.\\n• MedCoDi, our same implementation that omits the Multi-Prompt\\ntraining strategy, serving as an ablation of MedCoDi-M. This variant\\nhighlights the importance of the Multi-Prompt training approach in\\nenhancing the model’s conditioning capabilities and generating outputs\\nthat integrate information from multiple input modalities effectively.\\n• UniXGen[23], atransformer-basedarchitectureforbidirectionalCXR\\nand report generation. UniXGen employs a vector quantization tech-\\nnique to convert X-rays into discrete visual tokens, enabling the model\\nto treat both tasks as a sequence generation. UniXGen incorporates\\ntokenstogenerateview-specificX-rays. Additionally, multi-viewCXRs\\ncan be used to condition the report generation.\\n• LLM-CXR [27], a pretrained LLM fine-tuned for CXR understanding\\nand generation. It can perform both CXR-to-report and report-to-\\nCXR generation tasks. It is restricted to frontal chest X-rays and does\\nnot consider multi-view or multimodal relationships, limiting its appli-\\ncability in comprehensive diagnostic workflows.\\n• RoentGen[16],atext-conditionedLDMfine-tunedforgeneratingsyn-\\nthetic frontal CXRs based on textual prompts. RoentGen adapts the\\nStable Diffusion architecture to the medical domain by fine-tuning the\\nUNet component, enabling it to capture the unique characteristics of\\nchest X-rays.\\n143.5. Evaluation Metrics\\nWe conducted both quantitative and qualitative assessments to evaluate the\\nperformance of our approach. The first focuses on the statistical properties\\nof the generated data, while the second ensures that the outputs accurately\\nalign with the expected clinical informations.\\n3.5.1. Quantitative Metrics\\nToobjectivelyevaluatethequalityofthegeneratedoutputs,weemployedtwo\\nwell-established quantitative metrics, the FID Score and the BLEU Score,\\nthat measure the statistical similarity between synthetic and real data, as\\nwell as the linguistic coherence of generated clinical reports.\\nThe Fr´echet Inception Distance (FID) [42] measures the dissimilarity be-\\ntween real and synthetic samples in the feature space of an Inception-V3\\nmodel pre-trained on ImageNet [43], ranging in the interval [0,+∞) with\\nlower values indicating greater similarity. However, because the Inception-\\nNetisnottrainedonamedicaldataset, itmayleadtomisleadingresults[44].\\nTo address this limitation, we computed the FID also with another two back-\\nbones, i.e., XRV-DenseNet [45], an in-domain classification model trained to\\ndetect pathologies in CXR scans, and XRV-Mimic densenet [45], specifically\\ntrained for MIMIC-CXR scans classification. However, to remain coherent\\nwith other works, We decided to report the result obtained using the latter\\nbackbone in Table A1.\\nThe Bilingual Evaluation Understudy (BLEU) compares machine-generated\\ntext to a set of references by calculating the n-gram overlap between the\\ntwo [46], ranging in the interval [0,+∞). Following the literature, here we\\ncomputed the BLEU score for a number of n-grams equal to 1,2,3,4. BLEU-\\n1 and BLEU-2 place greater emphasis on the consistency of the vocabulary\\nused, focusing on single words or word pairs, while BLEU-3 and BLEU-4\\nprovide information about the semantic structure of the reports.\\n3.5.2. Factual Correctness\\nEnsuring the factual correctness of the generated data is a crucial aspect of\\nevaluating the performance of MedCoDi-M. By using well-established classi-\\nficationmodelsandrule-basedtools, weassesshowwellthesyntheticoutputs\\nalign with real-world diagnostic information.\\n15X-rays Classification: To evaluate whether the models are capable of gen-\\nerating images that accurately reflect the information of the corresponding\\nclinicalreports,weclassifiedthegeneratedsamplesusingXRV-DenseNet[45],\\na well-established classifier in the literature for CXR classification. Since\\nsuch a classifier is trained only on a subset of pathologies, we computed\\nthe AUC and F1 scores for the following diseases: Atelectasis (Atl.), Car-\\ndiomegaly (Cmgl.), Consolidation (Cnsl.), Edema (Edm.), Enlarged Car-\\ndiomediastinum (Enl.), Lung Lesion (Les.), Lung Opacity (Opc.), Pleural\\nEffusion (Eff.), Pneumonia (Pnm.) and Pneumothorax (Ptx.), along with\\nmicro, macro, and weighted averages. The micro average aggregates con-\\ntributions from all classes to provide an overall measure, the macro average\\ncomputes the metric independently for each class and averages them, and the\\nweighted average adjusts the macro average by accounting for the number of\\nsamples per class. However, because not all scans have a defined label for\\nevery pathology, we computed the performance for each class only when a\\nground truth was available, Table 1 report the number of samples for every\\npathology in our test set.\\nCondition Samples Positives\\nAtl. 10561 1438\\nCgml. 10305 1146\\nCnsl. 9911 254\\nEdm. 10230 774\\nEnl. 9215 83\\nLes. 9476 342\\nOpc. 11136 1980\\nEff. 10558 1258\\nPnm. 10454 853\\nPtx. 9337 84\\nTable 1: Number of samples of every pathology for the X-rays classification task.\\nReport Classification: For report classification, we leveraged CheXpert-\\nLabeler [47], a rule-based natural language processing tool that reads a text\\nreportandextractswhetheritmentionsthepresenceorabsenceofsignificant\\nradiologic findings. Since a rule-based classifier is used, it is not possible to\\ncompute the AUC; instead, we reported the F1 score for the same subset of\\ndisease previously introduced along with No Finding (No F.) class. To re-\\nmain consistent with the previous setup, we also reported the micro, macro,\\n16and weighted averages for the F1 score. This task quantifies the ability of\\nthe model to generate reports that align with the medical conditions seen in\\nthe X-ray images, ensuring that the synthetic reports accurately reflect the\\ndiagnostic information provided by the images.\\n3.5.3. Visual Turing Test\\nWeperformedaqualitativeassessmentofthedatageneratedbyMedCoDi-M,\\nthrough a Visual Turing Test performed by three expert radiologist. This\\nevaluation consisted of five independent tasks aimed at comparing synthetic\\nand real medical data, with both X-rays and clinical report being assessed.\\nEach task was performed through a web-based platform, where experts eval-\\nuated the data using a 1-to-5 numeric scale. A score of 1 indicated the\\npoorest quality, while a score of 5 represented the highest level of quality\\nand coherence. The tasks are:\\n• General X-ray Realism: Experts rated the overall realism of a series\\nof 20 images, which included a mix of real and synthetic X-rays. A high\\nscore indicates that the synthetic X-rays appear indistinguishable from\\nreal clinical X-rays, with accurate anatomical structures and no visible\\nartifacts that could mislead a clinician in a diagnostic setting.\\n• General Report Realism: Expertsreviewed20clinicalreports, both\\nreal and synthetic, rating their plausibility and realism. A high score\\nin this task implies that the synthetic reports accurately reflect the\\nclinical context, making use of appropriate medical terminology and\\nproviding clinically relevant findings that would be consistent with a\\nreal report.\\n• Report Coherence with Pair of X-rays: Experts evaluated the\\nconsistencybetween20pairsX-rayimagesandtheirassociatedreports.\\nThe images were guaranteed to be real, while the reports were either\\nreal or synthetic, presented in random order. A high score indicates\\nthat the synthetic reports align accurately with the X-ray images, with\\nno contradictions or inconsistencies between the reported findings and\\nthe visual evidence.\\n• Coherence Between Report and X-ray: Experts compared 20\\npairs of X-ray images, both real and synthetic, in random order, with\\nthe real clinical report to assess the plausibility of the X-ray given\\n17Model T→F L→F L+T→F T→L F→L F+T→L\\nv3↓ XRV↓ v3↓ XRV↓ v3↓ XRV↓ v3↓ XRV↓ v3↓ XRV↓ v3↓ XRV↓\\nRoentGen 102.77 5.60 - - - - - - - - - -\\nUniXGen 81.75 7.28 - - 86.21 7.63 128.96 9.76 - - 133.38 10.20\\nLLM-CXR 71.91 6.83 - - - - - - - - - -\\nCoDi 541.44 107.23 520.02 83.12 539.35 107.17 522.00 83.01 540.66 105.63 525.80 82.52\\nMedCoDi 10.56 0.86 34.89 3.31 22.63 1.90 13.90 0.84 43.24 4.95 23.12 1.99\\nMedCoDi-M 10.67 0.93 12.04 0.48 11.51 0.43 14.00 0.96 13.75 0.48 11.97 0.34\\nTable 2: FID score for X-ray generation, with lower values indicating greater similarity.\\nXRV and v3 refers to the two backbones used to compute the score, respectively\\nXRV-Densenet and Inception-v3. The “-” symbol indicates that the respective models\\nare not capable of performing the specified generation task\\nthe report. A high score reflects that the synthetic X-rays match the\\nfindings described in the report, indicating that the generative model\\ncorrectlyunderstoodandtranslatedtheclinicalcontextfromthereport\\ninto the visual representation.\\n• Coherence Between X-ray Pairs: Experts assessed the consistency\\nbetween 20 pairs of frontal and lateral X-rays. One of the view was\\nguaranteed to be real, while the other were either real or synthetic,\\npresented in random order. A high score here indicates that the syn-\\nthetic view accurately represents the same clinical findings as the real\\nview, demonstrating proper anatomical alignment and no conflicting\\nfeatures across different perspectives.\\n4. Results and Discussion\\nThis section presents an in-depth analysis to assess MedCoDi-M’s perfor-\\nmance, providing both quantitative and qualitative evaluations and visual\\nexamples.\\n4.1. X-ray Generation\\nTable 2 presents the FID scores on the test set for generating frontal (F) and\\nlateral (L) X-rays. The first column lists the models used for generation,\\nwhile the remaining columns show the performance achieved for different\\ngeneration settings using different prompts combination: from clinical report\\n(T) to frontal or lateral CXR (T→F, T→L), from lateral or frontal CXR to\\nthe other view (L→F, F→L) and a combination of a clinical report and a\\nCXR image to the other view (L+T→F, F+T→L). The results in Table 2\\n18show that MedCoDi-M consistently outperforms all the competitors for X-\\nray generation. It is worth noting that the excessively high FID values for\\nCoDi highlight how crucial is the finetuning step of a LDM. This observation\\nis further supported by Figure 4, which show one example of generation by\\nCoDi and MedCoDi-M with the same textual prompt, where the former fails\\nto generate any resemblance of an X-ray.\\nFigure 4: Generation comparison between CoDi and MedCoDi-M using the same textual\\nprompt, i.e., “No acute cardiopulmonary process”.\\nOn the other side, the Multi-Prompt training technique shows its effective-\\nness,asMedCoDi-MconsistentlyoutperformMedCoDiinfourconfigurations\\n(L→F, L+T→F, F→L, F+T→F), showing that the possibility to merge in-\\nformation in the shared latent space improves the generation results. How-\\never, since this approach leverages two image modalities alongside a single\\ntextual modality, it tends to prioritize learning from visual prompts over\\ntextual ones. As a result, we observe a slight drop in performance when\\ngeneration is based solely on clinical reports (T→F, T→L), although this\\ndegradation is minimal compared to the significant boost the model gains in\\nother generation settings. In Fig. 5 and Fig. 6 several examples of synthetic\\nimages from the different models are displayed. While at first glance the\\nsynthetic X-rays may appear visually similar, the FID values reveal a clearer\\nresemblance of MedCoDi-M’s outputs to real samples, highlighting the effec-\\ntiveness of our approach.\\nTo further assess the generation capabilities of MedCoDi-M we analyzed\\nthe factual correctness by performing a classification task on the patient’s\\npathology (Section 3.5.2). Specifically, for each sample in the test set, we\\n19Figure 5: Frontal Synthetic Samples generated by different baselines with the same input\\nprompt, i.e., “No acute cardiopulmonary process”.\\ngenerated a corresponding synthetic X-ray and evaluated it with the XRV\\nclassifier [45]. The results are presented in Table 3. Again, MedCoDi-M\\nachieves the highest performance in both AUC and F1 scores, demonstrating\\nits ability to effectively capture and represent the relevant clinical features\\nspecified in the inputs. It is important to highlight that F1 scores for some\\nclasses are notably low, likely due to the scarcity of positive samples for these\\nspecific pathologies in the dataset, as showed in Table 1, however, MedCoDi-\\nM outperforms its competitors also for less represented classes. Moreover, it\\nis worth to notice that our synthetic data achieves better results than real\\ndata. Weattributethisresulttothemodel’sstrongunderstandingofthespe-\\ncific characteristics of the diseases, which makes the generated samples more\\neasily classifiable by the pre-trained densenet. This hypothesis is further\\nsupported by the results of the Visual Turing Test, which will be presented\\nin Section 4.4, where the synthetic data demonstrated a high level of clinical\\nrealism. Both this results indicates that MedCoDi-M not only produces vi-\\nsually realistic X-rays but also accurately reflects the clinical features of the\\nreal images.\\n20Figure 6: Lateral Synthetic Samples generated by different baselines with the same input\\nprompt, i.e., “No acute cardiopulmonary process”.\\n4.2. Report Generation\\nTable 4 presents the BLEU score on the test set for report generation across\\nthree different generation settings: frontal CXR to report (F→T), lateral\\nCXRtoreport(L→T)andbothfrontalandlateralCXRtoreport(F+L→T).\\nThese scores highlight the ability of each method to generate reports in com-\\nparison to reference ones, with higher BLEU scores indicating better per-\\nformances. The results show that MedCoDi-M outperforms the competitors\\nacross all BLEU score metrics. Results suggest that not only MedCoDi-M\\nutilize the same terminology as real clinical reports, as indicated by the best\\nBLEU-1 and BLEU-2, but it also generates sentences whose structure is con-\\nsistent with that of actual reports, as demonstrated by the better BLEU-3\\nand BLEU-4. This highlights a high degree of linguistic coherence and fi-\\ndelity in reproducing both the content and phrasing of real-world medical\\ntexts. Moreover, we computed BLEU scores for reports generated across\\n21Task Model Atl. Cmgl. Cnsl. Edm. Enl. Les. Opc. Eff. Pnm. Ptx. Micro Macro Weighted\\n- RealData .84 .91 .91 .93 .81 .78 .85 .95 .78 .86 .87 .86 .87\\nRoentGen .87 .93 .82 .80 .50 .59 .68 .94 .48 .58 .78 .72 .78\\nUniXGen .75 .78 .69 .81 .67 .67 .69 .76 .66 .66 .74 .71 .71\\nT→F LLM-CXR .89 .92 .87 .96 .80 .78 .85 .95 .80 .85 .89 .87 .87\\nMedCoDi .91 .95 .93 .96 .84 .82 .91 .97 .84 .88 .90 .90 .91\\nMedCoDi-M .86 .95 .91 .94 .82 .75 .86 .97 .86 .85 .88 .89 .90\\nMedCoDi .84 .88 .90 .91 .81 .76 .85 .95 .76 .82 .83 .85 .90\\nL→F\\nMedCoDi-M .86 .92 .93 .94 .83 .80 .89 .97 .80 .90 .87 .88 .90\\nUniXGen .75 .79 .65 .81 .66 .63 .68 .77 .63 .70 .73 .71 .71\\nT+L→F MedCoDi .89 .91 .92 .91 .82 .80 .86 .97 .77 .85 .88 .89 .90\\nMedCoDi-M .92 .96 .95 .97 .87 .85 .92 .98 .85 .93 .91 .92 .92\\nTask Model Atl. Cmgl. Cnsl. Edm. Enl. Les. Opc. Eff. Pnm. Ptx. Micro Macro Weighted\\n- RealData .49 .49 .35 .60 .09 .12 .60 .73 .35 .21 .49 .40 .53\\nRoentGen .31 .40 .00 .25 .00 .02 .40 .74 .04 .04 .36 .25 .43\\nUniXGen .25 .31 .05 .29 .06 .05 .37 .41 .00 .04 .24 .17 .34\\nT→F LLM-CXR .51 .53 .19 .60 .08 .07 .60 .74 .38 .16 .47 .39 .51\\nMedCoDi .60 .60 .33 .66 .10 .05 .64 .78 .38 .17 .53 .43 .59\\nMedCoDi-M .51 .60 .25 .59 .08 .11 .60 .78 .33 .12 .50 .41 .54\\nMedCoDi .51 .45 .32 .42 .06 .07 .59 .73 .27 .10 .43 .35 .49\\nL→F\\nMedCoDi-M .51 .46 .39 .57 .09 .13 .64 .79 .36 .17 .50 .41 .54\\nUniXGen .20 .31 .06 .27 .06 .07 .34 .43 .04 .07 .24 .19 .33\\nT+L→F MedCoDi .54 .55 .32 .64 .09 .06 .63 .75 .38 .17 .53 .44 .58\\nMedCoDi-M .58 .59 .39 .68 .13 .18 .68 .81 .40 .26 .57 .47 .60\\nTable 3: CXR classification with XRV - AUC and F1.\\nmultiple scans of the same study. This evaluation assesses the model’s con-\\nsistency in generating coherent and reliable reports when presented with\\nscans from the same clinical case. The goal was to ensure that the model not\\nonly excels in generating high-quality individual reports but also maintains\\nconsistency across multiple related images. We report numerical results for\\nthis evaluation in Table A2.\\nAs we did for the synthetic X-rays, we performed a classification task on the\\ngenerated reports, to assess whether they capture the relevant clinical infor-\\nmation used to prompt MedCoDi-M. In terms of classification performance,\\nas shown in Table 5, MedCoDi-M also demonstrates superior capabilities.\\nFor instance, it achieves the highest F1-score in most categories, including\\nMicro, Macro and Weighted average for all the three input combinations.\\nThe results shows that our approach not only excels in generating realistic\\nreports but also in accurately representing the patient’s condition provided\\nin the prompt. It is worth noting that the best performances are achieved\\n22F→T L→T F+L→T\\nMethods\\nBLEU-1↑ BLEU-2↑ BLEU-3↑ BLEU-4↑ BLEU-1↑ BLEU-2↑ BLEU-3↑ BLEU-4↑ BLEU-1↑ BLEU-2↑ BLEU-3↑ BLEU-4↑\\nUniXGen .25 .16 .12 .09 .26 .16 .11 .07 .26 .17 .12 .09\\nLLM-CXR .25 .15 .10 .07 - - - - - - - -\\nMedCoDi .38 .27 .22 .18 .38 .28 .23 .18 .42 .32 .27 .22\\nMedCoDi-M .41 .30 .25 0.20 .42 .32 .26 .21 .44 .34 .29 .24\\nTable 4: BLEU Score for Report Generation, with higher values indicating greater\\nsimilarity. The “-” symbol indicates that the respective models are not capable of\\nperforming the specified generation task.\\nwhen both views are given as conditioning (F+L→T), demonstrating that\\ncombining information from multiple perspectives enables the model to ex-\\ntract more comprehensive insights of the clinical picture. This integration\\nallows for a more accurate and detailed diagnosis, highlighting the model’s\\ncapability to leverage diverse data to enhance diagnostic performance.\\nTask Model Atl.Cmgl.Cnsl.Edm.Enl.Les.Opc.Eff.Pnm.Ptx.NoF.MicroMacroWeighted\\nUniXGen .18 .17 .03 .28 .01 .01 .01 .13 .10 .03 .74 .49 .15 .42\\nLLM-CXR .25 .23 .07 .40 .02 .03 .21 .36 .24 .02 .74 .46 .20 .44\\nF→T\\nMedCoDi .56 .56 .15 .67 .10 .26 .47 .71 .52 .37 .88 .67 .44 .67\\nMedCoDi-M .62 .61 .14 .70 .15 .27 .52 .79 .59 .34 .90 .71 .46 .73\\nUniXGen .23 .23 .05 .36 .04 .02 .20 .36 .16 .05 .73 .45 .19 .43\\nL→T MedCoDi .54 .58 .14 .65 .07 .23 .45 .75 .51 .30 .89 .68 .41 .68\\nMedCoDi-M .62 .61 .16 .70 .09 .26 .51 .78 .57 .32 .91 .71 .45 .73\\nUniXGen .22 .16 .06 .30 .01 .00 .17 .33 .17 .02 .75 .49 .16 .45\\nF+L→TMedCoDi .61 .60 .17 .70 .09 .31 .51 .78 .58 .27 .90 .72 .45 .72\\nMedCoDi-M .62 .61 .17 .70 .12 .27 .53 .79 .58 .37 .91 .73 .46 .73\\nTable 5: Report classification with CheXPert-Labeler.\\n4.3. Multi-Output Generation\\nThankstothetrainingproceduredescribedinSection2.3,MedCoDi-Mlearns\\nto jointly generate two or more modalities while ensuring their coherence.\\nSincethereisnoestablishedquantitativemetrictoassesswhetherthemodali-\\ntiessimultaneouslygeneratedarecoherent, wecomputedthecosinesimilarity\\nbetween the two generated modalities M and M [11]:\\ni j\\ncos(P (M ),P (M )) (5)\\ni i j j\\nwhere P , P are the prompt encoders which projects modalities in the shared\\ni j\\nlatent space. Intuitively, the closer is the metric to 1, the higher the align-\\nmentbetweenthetwomodalities. Becausenoneofthecompetitorsiscapable\\nof jointly generate more than one modality, we compared the multi-output\\n23generation of MedCoDi-M with a multi-step approach, where every modal-\\nity is synthesized independently by MedCoDi-M. As shown in Table 6, the\\njoint generation shows higher similarity between the generated samples. To\\nInput Independent Gen. Multi-Output Gen.\\nT→F+L .61 .65\\nL→F+T .12 .22\\nF→L+T .19 .21\\nTable 6: Similarity Scores for Multi-Output Generation.\\nfurther assess whether this improvement in similarity is also reflected in the\\nclinical correctness of the two jointly generated modalities, we conducted an\\nevaluation between the frontal X-rays and the report generated through in-\\ndependent generation, i.e., L→F + L→T, and Multi-Output generation, i.e.,\\nL→F+T. Specifically, we aimed to assess whether the two modalities gener-\\nated were aligned in terms of clinical content. To do so, we classified both the\\ngenerated X-ray images and reports, obtaining two classification vectors for\\neach instance. To quantify the alignment, we computed the Hamming Dis-\\ntance[48],measuringthediscrepancybetweentheclassificationlabelsderived\\nfrom the two outputs. In this context, smaller Hamming Distance values in-\\ndicate greater similarity between the labels and, therefore, better alignment\\nof the clinical information conveyed by the generated modalities. The re-\\nsult of this evaluation is illustrated in Figure 7, where the x-axis represents\\nthe Hamming Distance, i.e., the number of differing labels, while the y-axis\\nshows the frequency of occurrences for each distance value. As shown in the\\nfigure, the red curve (joint generation) peaks at lower Hamming Distance\\nvalues compared to the blue curve (independent generation). Specifically,\\na large proportion of the samples generated via the joint approach exhibit\\na Hamming Distance equal to zero, meaning the generated modalities are\\nhighly aligned. Additionally, the fact that the red curve is lower than the\\nblue one at distances 1 and 2 further highlights how the jointly generated\\nmodalities are clinically closer. Subsequently, both curves reach a plateau,\\ndemonstrating that neither approach generates modalities that are entirely\\nincoherent. This suggests that generating the X-ray and the report simulta-\\nneously ensures better consistency in terms of clinical content, highlighting\\nthe advantages of the Multi-Output approach.\\n24\\x00ŝ\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00Ŝ\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00ś\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00Ś\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00ř\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00Ř\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00ŗ\\x00Ŗ\\x00Ŗ\\x00Ŗ\\n\\x00Ŗ\\n\\x00Ŗ \\x00Ř \\x00Ś \\x00Ŝ \\x00Ş \\x00ŗ\\x00Ŗ \\x00ŗ\\x00Ř\\n\\x00\\n\\x00\\x8a\\x00\\x96\\x00\\x96\\x00\\x92\\x00\\x97\\x00\\x90\\x00ȱ\\x00\\x06\\x00\\x92\\x00\\x9c\\x00\\x9d\\x00\\x8a\\x00\\x97\\x00\\x8c\\x00\\x8e\\n\\x00\\x9c\\x00\\x8e\\x00\\x95\\x00\\x99\\x00\\x96\\x00\\x8a\\x00\\x15\\x00ȱ\\x00\\x8f\\x00\\x98\\x00ȱ\\x00Ǜ\\n\\x00\\x0b\\x00\\x97\\x00\\x8d\\x00\\x8e\\x00\\x99\\x00\\x8e\\x00\\x97\\x00\\x8d\\x00\\x8e\\x00\\x97\\x00\\x9d\\x00ȱ\\x00\\t\\x00\\x8e\\x00\\x97\\x00\\x8e\\x00\\x9b\\x00\\x8a\\x00\\x9d\\x00\\x92\\x00\\x98\\x00\\x97\\n\\x00\\x0c\\x00\\x98\\x00\\x92\\x00\\x97\\x00\\x9d\\x00ȱ\\x00\\t\\x00\\x8e\\x00\\x97\\x00\\x8e\\x00\\x9b\\x00\\x8a\\x00\\x9d\\x00\\x92\\x00\\x98\\x00\\x97\\nFigure 7: Hamming Distance for joint generation.\\n4.4. Visual Turing Test\\nTable 7 presents the results of the Visual Turing Test conducted to as-\\nsess the quality and coherence of the synthetic medical data generated by\\nMedCoDi-M. The evaluation involved three expert radiologists, each with\\n10+ years of experience.\\nGeneral X-ray Realism.\\nThe average rating for real X-rays was 4.1±0.9, demonstrating the radiolo-\\ngists’ high level of confidence in recognizing and evaluating authentic clinical\\nimages. This result highlights the robustness of the evaluation process and\\nthe expertise ofthe participants. Synthetic images generatedby MedCoDi-M\\nscored 3.7±0.8, which, while slightly lower, still represents a strong perfor-\\nmance, indicating the overall quality of MedCoDi-M’s outputs.\\nGeneral Report Realism.\\nReal clinical reports received an average rating of 3.5±0.9, highlighting\\nthat even authentic reports are not always perceived as perfect. This may\\nbe due to occasional discrepancies in interpretation between radiologists or\\nvariability in the detail and clarity of the reports, which are often influenced\\nby stylistic differences among clinicians. In contrast, synthetic reports gen-\\nerated by MedCoDi-M achieved a higher average rating of 4.0±0.9. This\\n25Task Data Type Score\\nGeneral X-ray Realism Real X-rays 4.1 ± 0.9\\nSynthetic X-rays 3.7 ± 0.8\\nGeneral Report Realism Real Reports 3.5 ± 0.9\\nSynthetic Reports 4.0 ± 0.9\\nReport Coherence with X-ray Pair Real Reports 3.4 ± 1.3\\nSynthetic Reports 3.3 ± 1.1\\nCoherence Between Report and X-ray Real X-rays 3.7 ± 0.9\\nSynthetic X-rays 3.9 ± 0.8\\nCoherence Between X-ray Pairs Real X-rays 3.8 ± 0.7\\nSynthetic X-rays 3.6 ± 0.8\\nTable 7: Evaluation results for different tasks in the Visual Turing Test, comparing real\\nand synthetic data generated by MedCoDi-M. The scores range from 0 to 5, with higher\\nvalues indicating better performance.\\nresult underscores the model’s ability to consistently use accurate medical\\nterminology and construct coherent and contextually appropriate narratives.\\nReport Coherence with Pair of X-rays.\\nThe average score for real reports was 3.4±1.3, while synthetic reports\\nachieved a comparable score of 3.3±1.1. These relatively modest ratings\\nreflect the inherent difficulty of this task, which requires precise alignment\\nbetween diagnostic findings described in the report and the visual evidence\\nprovidedbytheX-raypair. Despitethechallenge, MedCoDi-Mdemonstrates\\nthe ability to generate diagnostic reports that are closely aligned with those\\nwritten by radiologists, highlighting the model’s capability to produce coher-\\nent and contextually relevant reports, even in a highly demanding evaluation\\nscenario.\\nCoherence Between Report and X-ray. The average score for real X-rays\\npaired with their corresponding reports was 3.7±0.9, while synthetic pairs\\ngeneratedbyMedCoDi-Machievedaslightlyhigherscoreof3.9±0.8. These\\nresults highlight the strong capabilities of MedCoDi-M in generating X-rays\\nthat align closely with the diagnostic context described in the corresponding\\nreports. Additionally, while the model’s robust understanding of pathologies\\n26contributes to producing samples where disease features are prominently and\\nclearly represented, this characteristic might also pose a limitation. By gen-\\nerating images with overly evident pathological signs, the synthetic data may\\nfail to capture more subtle or ambiguous cases that often challenge radiolo-\\ngists in real-world clinical practice.\\nCoherence Between X-ray Pairs. The average score for real X-ray pairs was\\n3.8±0.7,whilesyntheticpairsscored3.6±0.8. ThissuggeststhatMedCoDi-\\nM is able to guarantee anatomical consistency between frontal and lateral\\nviews of the same subject, approaching the realism of real X-ray data.\\n4.5. About the utility of Synthetic Data in the Medical Field\\nTo gain more insight into the generation performance of MedCoDi-M, we\\ninvestigate the use of synthetic data to address three key challenges in the\\nmedical field, i.e., Anonymization, Imbalance Learning and Data Scarcity.\\nThese issues are critical when working in real-world scenarios, where privacy\\nconcerns, unevenclassdistributionsandlimitedaccesstolargedatasetsoften\\nhinder the development of robust models. For this evaluation, we conducted\\nexperiments using both Frontal and Lateral synthetic X-rays. However, to\\nmaintain clarity and conciseness, we present only the results for Frontal X-\\nrayshere,neverthelesstheresultsforLateralX-raysarereportedinappendix,\\nin Tables A3, A4, A5.\\nAnonymization. Medical data is subject to stringent privacy regulations.\\nHowever, traditional anonymization methods can lead to information loss.\\nBy generating synthetic data that mimics real patients, it is possible to\\nmitigate privacy risks while preserving data quality. To assess whether\\nMedCoDi-M can tackle this challenge, we trained two DenseNet-121 classi-\\nfier from scratch on two data splits: one composed of synthetic images only,\\nwhile the other includes solely real data. Subsequently, both models were\\nevaluated on the real test set to assess whether training solely on synthetic\\ndata would lead to a degradation in model performance. As shown in Ta-\\nble 8, both classifiers achieve comparable results. The classifier trained with\\nsynthetic data achieves slightly lower AUC which is however compensated\\nby an improvement in the F1-Score, suggesting that synthetic data can effec-\\ntively replace real data for training purposes without significant degradation\\nin model performance.\\n27TrainingData AUROC F1-Score\\nMicro Macro Weighted Micro Macro Weighted\\nReal .75 .74 .74 .30 .20 .21\\nReal+Synthetic .74 .73 .73 .34 .23 .23\\nTable 8: Classification metrics for Anonymization task.\\nImbalance Learning. Imbalancelearningisawell-knownchallengeinmachine\\nlearning, many classifier tend to be biased towards majority classes, result-\\ning in poor sensitivity to rare but critical conditions. One possible solution\\nis to artificially augment minority classes using synthetic data, thus helping\\nmodels to generalize better on imbalanced datasets. To assess MedCoDi-M’s\\ncapabilities to tackle this challenge, we focused on a 5-class classification\\ntask, selecting the five most represented classes from our dataset, which are\\nlisted in Table 9 along with the respective percentage of positive samples.\\nThis choice was made to avoid excessive imbalance that would have required\\ngenerating an impractical number of synthetic samples. For this experiment,\\nwe generated synthetic samples to build a training split that ensured a bal-\\nanced distribution of positive samples across all five classes.\\nCondition Positive (%)\\nAtelectasis 15.6%\\nCardiomegaly 13.5%\\nConsolidation 2.99%\\nEdema 10.4%\\nEffusion 14.1%\\nTable 9: Percentage of positive samples inthe training set for the condition used for Data\\nImbalance task.\\nToevaluatetheeffectivenessofthisstrategy,wetrainedtwoseparateDenseNet-\\n121 from scratch: one on the original dataset, which maintained the natural\\nimbalance, and the other on the augmented split, where synthetic samples\\nwere added to create a balanced partition. Both models were trained us-\\ning the same hyperparameters to ensure a fair comparison. In Table 10, we\\ncompare the two classifiers’ F1-score on the real test set: the results show\\nan improvement for all classes after synthetic data augmentation, indicating\\nthat synthetic data can enhance the classifier’s ability to generalize across\\nall conditions, ensuring better overall performance and sensitivity to rare,\\n28Training Data F1-Score\\nAtl. Cmgl. Cnsl. Edm. Eff. Micro Macro Weighted\\nReal .34 .42 .17 .67 .64 .50 .45 .45\\nSynthetic .48 .48 .33 .69 .72 .58 .54 .54\\nTable 10: Classification metrics for Imbalance Learning task.\\nclinically important cases.\\nData Scarcity. The collection of large and well-annotated medical datasets\\nposes a significant challenge, especially when dealing with rare diseases or\\nnewly emerging conditions. The scarcity of data hinders the development\\nand training of robust machine learning, as these models often require sub-\\nstantial amounts of high-quality data to generalize effectively. One promising\\napproach to address this issue is the augmentation of real datasets with syn-\\nthetic data, while preserving the real distributions. By generating synthetic\\nsamplesthatcapturetheunderlyingstatisticalpropertiesoftheoriginaldata,\\nwe can allow models to train on a more comprehensive range of samples,\\nmitigating the problem of data scarcity while preserving the real-world vari-\\nability and clinical relevance. To assess whether MedCoDi-M could take\\nthis challenge, we conducted a series of experiments training from scratch a\\nDenseNet-121 on several data splits, gradually increasing the number of syn-\\nthetic data generated by our model. Specifically, we expanded the training\\nset by incorporating synthetic data at the following proportions: 25%, 50%,\\n75%, 90%, and 95% of the total training data. Subsequently, all models were\\nevaluated on the real test set, allowing us to assess the impact of progres-\\nsively increasing amounts of synthetic data on the model’s performance. As\\nshown in Table 11, our findings confirm that synthetic data can expand the\\nsize of existing medical datasets, positively affecting the model performance\\nand learning outcome.\\n5. Conclusions\\nThis work presents MedCoDi-M, a novel foundation model specifically de-\\nsigned for multimodal medical data generation, leveraging diffusion models\\nand contrastive learning. The results demonstrate that MedCoDi-M excels\\nin generating both realistic chest X-rays and high-quality radiology reports,\\nconsistently outperforming state-of-the-art models across both quantitative\\n29Syn % AUROC F1-Score\\nMicro Macro Weighted Micro Macro Weighted\\n0% .75 .74 .76 .27 .18 .18\\n25% .68 .75 .68 .34 .24 .25\\n50% .79 .76 .79 .32 .22 .22\\n75% .76 .77 .77 .36 .24 .25\\n90% .70 .75 .70 .38 .26 .27\\n95% .76 .75 .77 .35 .24 .25\\nTable 11: Classification metrics for Data Scarcity task.\\nandfactualcorrectnessmetrics. ThemainnoveltyintroducedbyMedCoDi-M\\nis the Multi-Prompt Training strategy, which plays a pivotal role in enhanc-\\ning cross-modal generation performance, helping the model to capture the\\ncomplex relationships between medical data modalities. This approach al-\\nlows MedCoDi-M to effectively integrate and align information from multiple\\nsources in a shared latent space, thereby improving both the visual fidelity of\\nthe generated images and the clinical accuracy of the corresponding textual\\nreports. The ability of MedCoDi-M to seamlessly fuse diverse inputs ensures\\na more cohesive representation, facilitating more accurate and context-aware\\ngeneration of synthetic medical data, as shown by the results in comparison\\nwith MedCoDi. The Visual Turing Test results demonstrate that MedCoDi-\\nM performs well in generating synthetic medical data that is both realistic\\nand contextually coherent. Across all tasks, synthetic data scored consis-\\ntently between 3.0 and 4.0, indicating a high level of quality and alignment\\nwith real clinical data. The model’s high performance in tasks requiring\\nconsistency between different image views and between reports and images\\nfurther confirms its potential for generating clinically relevant synthetic data.\\nMoreover, the results show that the synthetic data generated by MedCoDi-\\nM hold significant promise for addressing challenges in medical research and\\nhealthcare, such as anonymization, data imbalance, and data scarcity, sug-\\ngesting that synthetic chest X-rays and radiology reports can offer new av-\\nenues for enhancing AI integration in the medical field. Future research\\ncould explore several promising directions to further extend the capabili-\\nties of MedCoDi-M. One area of exploration involves scaling the modular\\nframework of MedCoDi-M to support additional modalities beyond 2D chest\\nX-rays, such as 3D medical images (e.g., CT, MRI) and time series (e.g.,\\nECG, EEG). Additionally, there is significant potential to investigate more\\n30advanced techniques for merging input embeddings, which could enhance the\\nintegration of heterogeneous medical data sources, for a more holistic under-\\nstanding of patient conditions. The inclusion of longitudinal information\\nand temporal dynamics could also play a vital role in temporal data gen-\\neration, allowing MedCoDi-M to model disease progression and treatment\\nresponses over time. This would be particularly beneficial for chronic condi-\\ntions where patient data evolve across multiple time points. Finally, future\\nworkcouldexploretheintegrationofactivelearningandreinforcementlearn-\\ning paradigms into the training process, enabling MedCoDi-M to iteratively\\nrefine its generative capabilities by receiving feedback from expert clinicians\\nor interacting with clinical environments. This would ensure that the model\\ncontinues to improve over time, staying up-to-date with the latest medical\\nknowledge and standards of care. Ultimately, MedCoDi-M represents a sig-\\nnificant step forward in the generation of synthetic medical data, and with\\nfurther research and development, it has the potential to become a key tool\\nin advancing medical AI across a wide range of applications.\\nAuthor Contributions\\nDaniele Molino: Conceptualization, Data curation, Formal analysis, Inves-\\ntigation,Methodology,Software,Validation,Visualization,Writing–original\\ndraft, Writing – review & editing; Francesco Di Feola: Conceptualization,\\nFormal analysis, Investigation, Methodology, Supervision, Validation, Writ-\\ning – original draft, Writing – review & editing; Eliodoro Faiella: Vali-\\ndation; Deborah Fazzini: Validation; Domiziana Santucci: Validation;\\nLinlin Shen: Validation, Writing – review & editing; Valerio Guarrasi:\\nConceptualization, Formal analysis, Investigation, Methodology, Project ad-\\nministration, Resources, Supervision, Validation, Writing – review & edit-\\ning. Paolo Soda Conceptualization, Formal analysis, Funding acquisition,\\nInvestigation, Methodology, Project administration, Resources, Supervision,\\nWriting – review & editing;\\nAcknowledgment\\nDaniele Molino is a Ph.D. student enrolled in the National Ph.D. in Artifi-\\ncial Intelligence, XL cycle, course on Health and life sciences, organized by\\nUniversita` Campus Bio-Medico di Roma.\\nThis work was partially founded by: i) Universita` Campus Bio-Medico di\\n31Roma under the program “University Strategic Projects” within the project\\n“AI-powered Digital Twin for next-generation lung cancEr cAre (IDEA)”;\\nii) PNRR MUR project PE0000013-FAIR. iii) Cancerforskningsfonden Nor-\\nrland project MP23-1122; iv) Kempe Foundation project JCSMK24-0094; v)\\nthe Italian Ministry of Foreign Affairs and International Cooperation, grant\\nnumber PGR01156\\nResources are provided by the National Academic Infrastructure for Super-\\ncomputing in Sweden (NAISS) and the Swedish National Infrastructure for\\nComputing (SNIC) at Alvis @ C3SE, partially funded by the Swedish Re-\\nsearch Council through grant agreements no. 2022-06725 and no. 2018-\\n05973.\\nReferences\\n[1] Shuroug A Alowais, Sahar S Alghamdi, Nada Alsuhebany, Tariq Alqah-\\ntani, Abdulrahman I Alshaya, Sumaya N Almohareb, Atheer Aldairem,\\nMohammed Alrashed, Khalid Bin Saleh, Hisham A Badreldin, et al.\\nRevolutionizing healthcare: the role of artificial intelligence in clinical\\npractice. BMC medical education, 23(1):689, 2023.\\n[2] Laith Alzubaidi, Jinshuai Bai, Aiman Al-Sabaawi, Jose Santamar´ıa,\\nAhmedShihabAlbahri, BasharSamiNayyefAl-dabbagh, MohammedA\\nFadhel, Mohamed Manoufali, Jinglan Zhang, Ali H Al-Timemy, et al.\\nA survey on deep learning tools dealing with data scarcity: defini-\\ntions, challenges, solutions, tips, and applications. Journal of Big Data,\\n10(1):46, 2023.\\n[3] General Data Protection Regulation GDPR. General data protection\\nregulation. Regulation (EU) 2016/679 of the European Parliament and\\nof the Council of 27 April 2016 on the protection of natural persons with\\nregard to the processing of personal data and on the free movement of\\nsuch data, and repealing Directive 95/46/EC, 2016.\\n[4] Accountability Act. Health insurance portability and accountability act\\nof 1996. Public law, 104:191, 1996.\\n[5] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David\\nWarde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Gen-\\nerative adversarial networks. Communications of the ACM, 63(11):139–\\n144, 2020.\\n32[6] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion proba-\\nbilistic models. In Proceedings of the 34th International Conference on\\nNeural Information Processing Systems, NIPS ’20. Curran Associates\\nInc., 2020.\\n[7] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser,\\nand Bjo¨rn Ommer. High-Resolution Image Synthesis With Latent Diffu-\\nsion Models. In Proceedings of the IEEE/CVF Conference on Computer\\nVision and Pattern Recognition (CVPR),pages10684–10695,June2022.\\n[8] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark\\nChen. Hierarchical text-conditional image generation with clip latents.\\narXiv preprint arXiv:2204.06125, 1(2):3, 2022.\\n[9] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang,\\nEmily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu\\nKaragol Ayan, Tim Salimans, et al. Photorealistic text-to-image dif-\\nfusion models with deep language understanding. Advances in neural\\ninformation processing systems, 35:36479–36494, 2022.\\n[10] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran\\nArora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine\\nBosselut, Emma Brunskill, et al. On the opportunities and risks of\\nfoundation models. arXiv preprint arXiv:2108.07258, 2021.\\n[11] Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, and Mohit\\nBansal. Any-to-Any Generation via Composable Diffusion. In Thirty-\\nseventh Conference on Neural Information Processing Systems, 2023.\\n[12] DanielIMor´ıs, JoaquimdeMoura, JorgeNovo, andMarcosOrtega. Un-\\nsupervised contrastive unpaired image generation approach for improv-\\ningtuberculosisscreeningusingchestX-rayimages. Pattern Recognition\\nLetters, 164:60–66, 2022.\\n[13] Devansh Srivastav, Akansha Bajpai, and Prakash Srivastava. Improved\\nclassification for pneumonia detection using transfer learning with GAN\\nbased synthetic image augmentation. In 2021 11th international con-\\nference on cloud computing, data science & engineering (confluence),\\npages 433–437. IEEE, 2021.\\n33[14] Yash Karbhari, Arpan Basu, Zong Woo Geem, Gi-Tae Han, and Ram\\nSarkar. Generation of synthetic chest X-ray images and detection of\\nCOVID-19: A deep learning based approach. Diagnostics, 11(5):895,\\n2021.\\n[15] MY Shams, OM Elzeki, Mohamed Abd Elfattah, T Medhat, and\\nAboul Ella Hassanien. Why are generative adversarial networks vital\\nfor deep neural networks? A case study on COVID-19 chest X-ray im-\\nages. In Big data analytics and artificial intelligence against COVID-19:\\ninnovation vision and approach, pages 147–162. Springer, 2020.\\n[16] Christian Bluethgen, Pierre Chambon, Jean-Benoit Delbrouck, Rogier\\nvan der Sluijs, Ma(cid:32)lgorzata Po(cid:32)lacin, Juan Manuel Zambrano Chaves,\\nTanishq Mathew Abraham, Shivanshu Purohit, Curtis P Langlotz, and\\nAkshay S Chaudhari. A vision–language foundation model for the gen-\\neration of realistic chest x-ray images. Nature Biomedical Engineering,\\npages 1–13, 2024.\\n[17] Pierre Chambon, Christian Bluethgen, Curtis P Langlotz, and Akshay\\nChaudhari. Adapting pretrained vision-language foundational models\\nto medical imaging domains. arXiv preprint arXiv:2210.04133, 2022.\\n[18] Kai Packha¨user, Lukas Folle, Florian Thamm, and Andreas Maier. Gen-\\neration of anonymous chest radiographs using latent diffusion models\\nfor training thoracic abnormality classification systems. In 2023 IEEE\\n20th International Symposium on Biomedical Imaging (ISBI),pages1–5.\\nIEEE, 2023.\\n[19] R OpenAI. Gpt-4 technical report. View in Article, 2(5), 2023.\\n[20] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual\\ninstruction tuning. Advances in neural information processing systems,\\n36, 2024.\\n[21] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain\\nBarr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican,\\nMalcolmReynolds,etal. Flamingo: avisuallanguagemodelforfew-shot\\nlearning. Advances in neural information processing systems, 35:23716–\\n23736, 2022.\\n34[22] Jing Yu Koh, Daniel Fried, and Russ R Salakhutdinov. Generating im-\\nages with multimodal language models. Advances in Neural Information\\nProcessing Systems, 36, 2024.\\n[23] HyungyungLee, WonjaeKim, Jin-HwaKim, TackeunKim, JihangKim,\\nLeonard Sunwoo, and Edward Choi. Unified chest x-ray and radiology\\nreport generation model with multi-view chest x-rays. arXiv preprint\\narXiv:2302.12172, 3(7):8, 2023.\\n[24] A Vaswani. Attention is all you need. Advances in Neural Information\\nProcessing Systems, 2017.\\n[25] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou\\nSong, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz\\nMohiuddin, Lukasz Kaiser, et al. Rethinking attention with performers.\\narXiv preprint arXiv:2009.14794, 2020.\\n[26] PatrickEsser, RobinRombach, andBjornOmmer. Tamingtransformers\\nfor high-resolution image synthesis. In Proceedings of the IEEE/CVF\\nconference on computer vision and pattern recognition, pages 12873–\\n12883, 2021.\\n[27] Suhyeon Lee, Won Jun Kim, Jinho Chang, and Jong Chul Ye. LLM-\\nCXR: Instruction-Finetuned LLM for CXR Image Understanding and\\nGeneration. arXiv preprint arXiv:2305.11490, 2023.\\n[28] Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed\\nAmin, Pi-Chuan Chang, Andrew Carroll, Charles Lau, Ryutaro Tanno,\\nIra Ktena, Anil Palepu, Basil Mustafa, Aakanksha Chowdhery, Yun\\nLiu, Simon Kornblith, David Fleet, Philip Mansfield, Sushant Prakash,\\nRenee Wong, Sunny Virmani, Christopher Semturs, S. Sara Mahdavi,\\nBradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Joelle Bar-\\nral, Dale Webster, Greg S. Corrado, Yossi Matias, Karan Singhal, Pete\\nFlorence, Alan Karthikesalingam, and Vivek Natarajan. Towards Gen-\\neralist Biomedical AI. NEJM AI, 1(3):AIoa2300138, 2024.\\n[29] Alistair EW Johnson, Tom J Pollard, Seth J Berkowitz, Nathaniel R\\nGreenbaum, Matthew P Lungren, Chih-ying Deng, Roger G Mark, and\\nSteven Horng. MIMIC-CXR, a de-identified publicly available database\\n35of chest radiographs with free-text reports. Scientific data, 6(1):317,\\n2019.\\n[30] KC Santosh and Laurent Wendling. Angular relational signature-based\\nchest radiograph image view classification. Medical & biological engi-\\nneering & computing, 56:1447–1458, 2018.\\n[31] Suhail Raoof, David Feigin, Arthur Sung, Sabiha Raoof, Lavanya\\nIrugulpati, and Edward C Rosenow III. Interpretation of plain chest\\nroentgenogram. Chest, 141(2):545–558, 2012.\\n[32] Mohammad Hashir, Hadrien Bertrand, and Joseph Paul Cohen. Quan-\\ntifying the value of lateral views in deep learning for chest x-rays. In\\nMedical Imaging with Deep Learning, pages 288–303. PMLR, 2020.\\n[33] W Dean Bidgood Jr, Steven C Horii, Fred W Prior, and Donald E\\nVan Syckle. Understanding and using DICOM, the data interchange\\nstandard for biomedical imaging. Journal of the American Medical In-\\nformatics Association, 4(3):199–212, 1997.\\n[34] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel\\nGoh, SandhiniAgarwal, GirishSastry, AmandaAskell, PamelaMishkin,\\nJack Clark, et al. Learning transferable visual models from natural\\nlanguage supervision. In International conference on machine learning,\\npages 8748–8763. PMLR, 2021.\\n[35] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learn-\\ningwithcontrastivepredictivecoding. arXiv preprint arXiv:1807.03748,\\n2018.\\n[36] XingqianXu,ZhangyangWang,GongZhang,KaiWang,andHumphrey\\nShi. Versatile diffusion: Text, images and variations all in one diffusion\\nmodel. In Proceedings of the IEEE/CVF International Conference on\\nComputer Vision, pages 7754–7765, 2023.\\n[37] Yuxin Wu and Kaiming He. Group normalization. In Proceedings of the\\nEuropean conference on computer vision (ECCV), pages 3–19, 2018.\\n[38] Stefan Elfwing, Eiji Uchibe, and Kenji Doya. Sigmoid-weighted linear\\nunits for neural network function approximation in reinforcement learn-\\ning. Neural networks, 107:3–11, 2018.\\n36[39] Chunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun Li, Yizhe\\nZhang, and Jianfeng Gao. Optimus: Organizing sentences via pre-\\ntrained modeling of a latent space. arXiv preprint arXiv:2004.04092,\\n2020.\\n[40] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova.\\nBert: Pre-trainingofdeepbidirectionaltransformersforlanguageunder-\\nstanding. In Proceedings of naacL-HLT, volume 1, page 2. Minneapolis,\\nMinnesota, 2019.\\n[41] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,\\nIlyaSutskever, etal. Languagemodelsareunsupervisedmultitasklearn-\\ners. OpenAI blog, 1(8):9, 2019.\\n[42] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard\\nNessler, and Sepp Hochreiter. Gans trained by a two time-scale update\\nrule converge to a local nash equilibrium. Advances in neural informa-\\ntion processing systems, 30, 2017.\\n[43] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev\\nSatheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla,\\nMichael Bernstein, et al. Imagenet large scale visual recognition chal-\\nlenge. International journal of computer vision, 115:211–252, 2015.\\n[44] Lorenzo Tronchin, Rosa Sicilia, Ermanno Cordelli, Sara Ramella, and\\nPaolo Soda. Evaluating GANs in medical imaging. In Deep Generative\\nModels, and Data Augmentation, Labelling, and Imperfections: First\\nWorkshop, DGM4MICCAI 2021, and First Workshop, DALI 2021, Held\\nin Conjunction with MICCAI 2021, Strasbourg, France, October 1, 2021,\\nProceedings 1, pages 112–121. Springer, 2021.\\n[45] Joseph Paul Cohen, Joseph D Viviano, Paul Bertin, Paul Morrison,\\nParsa Torabian, Matteo Guarrera, Matthew P Lungren, Akshay Chaud-\\nhari, Rupert Brooks, Mohammad Hashir, et al. TorchXRayVision: A\\nlibrary of chest X-ray datasets and models. In International Conference\\non Medical Imaging with Deep Learning, pages 231–249. PMLR, 2022.\\n[46] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu:\\na method for automatic evaluation of machine translation. In Proceed-\\nings of the 40th annual meeting of the Association for Computational\\nLinguistics, pages 311–318, 2002.\\n37[47] JeremyIrvin, PranavRajpurkar, MichaelKo, YifanYu, SilvianaCiurea-\\nIlcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball,\\nKatie Shpanskaya, et al. Chexpert: A large chest radiograph dataset\\nwith uncertainty labels and expert comparison. In Proceedings of the\\nAAAI conference on artificial intelligence, volume 33, pages 590–597,\\n2019.\\n[48] Richard W Hamming. Error detecting and error correcting codes. The\\nBell system technical journal, 29(2):147–160, 1950.\\n38Appendix\\nA1. FID Score computed with the XRV-mimic backbone\\nModel T→F L→F L+T→F T→L F→L F+T→L\\nXRV-mimic↓ XRV-mimic↓ XRV-mimic↓ XRV-mimic↓ XRV-mimic↓ XRV-mimic↓\\nRoentGen 9.38 - - - - -\\nUniXGen 17.08 - 16.36 22.12 - 23.07\\nLLM-CXR 9.66 - - - - -\\nCoDi 141.79 140.03 141.53 139.92 142.34 139.13\\nMedCoDi 1.63 2.04 2.26 2.56 2.10 1.80\\nMedCoDi-M 1.68 0.45 0.44 2.78 0.48 0.44\\nTable A1: FID score for X-ray generation with XRV-mimic backbone, with lower values\\nindicating greater similarity. The ’-’ symbol indicates that the respective models are not\\ncapable of performing the specified generation task. Results marked in bold denote the\\nbest performance.\\nA2. Intra-study BLEU score evaluation\\nModel BLEU-1 BLEU-2 BLEU-3 BLEU-4\\nUniXGen .45 .35 .27 .23\\nMedCoDi .59 .52 .48 .46\\nMedCoDi-M .60 .53 .49 .47\\nTable A2: BLEU scores for the intra-study evaluation of the clinical report.\\n39A3. Anonymization, Imbalance Learning and Data Scarcity assess-\\nment with Lateral X-rays\\nTraining Data AUROC F1-Score\\nMicro Macro Weighted Micro Macro Weighted\\nReal .77 .73 .73 .34 .23 .24\\nSynthetic .75 .70 .69 .37 .26 .27\\nTable A3: Classification metrics for Anonymization task with Lateral X-rays.\\nTraining Data F1-Score\\nAtl. Cmgl. Cnsl. Edm. Eff. Micro Macro Weighted\\nReal .32 .41 .13 .70 .63 .46 .40 .41\\nSynthetic .34 .43 .15 .65 .63 .48 .42 .43\\nTable A4: Classification metrics for Imbalance Learning task with Lateral X-rays.\\nSyn % AUROC F1-Score\\nMicro Macro Weighted Micro Macro Weighted\\n0% .76 .76 .76 .37 .26 .26\\n25% .71 .77 .72 .38 .27 .28\\n50% .74 .74 .74 .29 .19 .19\\n75% .74 .78 .75 .36 .23 .24\\n90% .73 .76 .73 .32 .20 .20\\n95% .75 .74 .75 .36 .21 .22\\nTable A5: Classification metrics for Data Scarcity task with Lateral X-rays.\\n40',\n",
       " 'Migician Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models.pdf': 'Migician: Revealing the Magic of Free-Form Multi-Image Grounding in\\nMultimodal Large Language Models\\nYouLi1*,HeyuHuang2*,ChiChen3†,KaiyuHuang1†,ChaoHuang1,ZonghaoGuo3,\\nZhiyuanLiu3,JinanXu1,YuhuaLi2,RuixuanLi2,MaosongSun3\\n1 StateKeyLaboratoryofAdvancedRailAutonomousOperation,\\nBeijingJiaotongUniversity,Beijing,China\\n2 HuazhongUniversityofScienceandTechnology,Wuhan,China\\n3 TsinghuaUniversity,Beijing,China\\nReasoning Multi-view\\nGrounding Grounding\\nWhere did I park my car? It is the same type shown in the first image, except it is black in color.\\noT fh te h ec a pr a y rko iu n gp a gr ak re ad g eis al to (c 5a 0te 0d ,5 a 7t 5 t )h ,e (6 e 5n 0t ,r 7a 3n 5c )e . Co Om bm jeo cn t 48.5159 4.4 51 .54 60.07 R Ge rofe ur nri dn ig n g\\n(6Y 5o 3u ,5r\\n9\\nb 8l )a ,c (9k\\n4\\nc 8a ,r\\n8\\ni 4n\\n7\\n)is\\ni\\nnlo Ic mat ae gd\\ne\\na -2t\\n.\\n84.19\\n46.46 34.93\\n202 .2 8. 357 36.4058.57 96.77 Q MMw\\nia\\nnne itn Ci2\\ns\\nP- MVL -V-7 2B\\n.6\\na DiffeS reta nt cic e 65.1546.1227.84 . 18.62 25.95 74.31 R Loeg caio tin n g Im nP teL rnU VG L- 2O -w 76l3 B\\nPlease recognize <ref>the same person appearing in InternVL2-8B\\nall these images</ref> and locate it in all these image. 30.73 17.09 26.50 Qwen2-VL-72B\\n665.583.52 36.73 34.19 LLaVA-OV-7B\\nMigician\\nThe common person appearing in these images(272,200),(608,999). GrouG nr do iu np\\ng\\n70.73 46.8138.30 Correspondence\\n46.81\\nThe same person appearing in all images\\nImage-1: (698,231),(783,487). Image-2: (314,204)(404,552). Image-3: (918,157),(999,618). Image-4: (271,273),(399,633). Object Robust\\nTracking Difference\\nFigure1.Left:Examplesoffree-formmulti-imagegrounding.Thetaskistoidentifyandlocalizerelevantvisualregionsacrossmultiple\\nimagesbasedonafree-formquery.Right:Ourproposedmodel,Migician,significantlyoutperformsotherMLLMsonvariousmulti-image\\ngroundingtasks.\\nAbstract formgroundinginstruction-followingdata. Furthermore,we\\npropose MIG-Bench, a comprehensive benchmark specifi-\\nThe recent advancement of Multimodal Large Language callydesignedforevaluatingmulti-imagegroundingcapa-\\nModels (MLLMs) has significantly improved their fine- bilities. Experimental results demonstrate that our model\\ngrained perception of single images and general compre- achievessignificantlysuperiormulti-imagegroundingcapa-\\nhensionacrossmultipleimages. However,existingMLLMs bilities,outperformingthebestexistingMLLMsby21.61%\\nstillfacechallengesinachievingprecisegroundingincom- and even surpassing much larger 70B models. Our code,\\nplexmulti-imagescenarios. Toaddressthis,wefirstexplore model, dataset, and benchmark are fully open-sourced at\\naChain-of-Thought(CoT)frameworkthatintegratessingle- https://migician-vg.github.io/.\\nimagegroundingwithmulti-imagecomprehension. While\\npartiallyeffective,itremainsunstableandstrugglestocap-\\ntureabstractvisualinformationduetoitsnon-end-to-end\\n1.Introduction\\nnature. Therefore, we introduce Migician, the first multi-\\nimage grounding model capable of performing free-form\\nMultimodalLargeLanguageModels(MLLMs)haveexhib-\\nand accurate grounding across multiple images. To sup-\\nitedsignificantadvancementsrecently,demonstratingexcep-\\nportthis,wepresenttheMGrounding-630kdataset,which\\ntional cross-modal understanding capabilities and achiev-\\ncomprisesdataforseveralmulti-imagegroundingtasksde-\\ning outstanding performance in various vision-language\\nrivedfromexistingdatasets,alongwithnewlygeneratedfree-\\ntasks [1, 7, 12, 15, 20, 28, 46]. As these models continue\\ntoevolve, theircapabilitieshaveexpandedbeyondimage-\\n*Equalcontribution.\\n†Correspondingauthors:ChiChen(chenchithu@gmail.com)andKaiyu levelunderstandingtoincludefine-grainedvisualground-\\nHuang(kyhuang@bjtu.edu.cn). ing [5, 37, 48]. This enables MLLMs to process region-\\n1\\n5202\\nnaJ\\n31\\n]LC.sc[\\n2v76750.1052:viXraspecificinputsandoutputs,unlockingabroaderspectrumof andrevealthepotentialandchallengesofcurrentMLLMs\\nreal-worldmultimodalapplicationscenarios[33]. bythroughaproposedCoTframework.\\nDespite the promising visual grounding capabilities • We introduce Migician, the first MLLM capable of ef-\\ndemonstratedbyexistingMLLMs,theseabilitiesarelargely fectively performing free-form MIG. We also present\\nconfinedtosingle-imagescenarios[19,48]. Thepotential MGrounding-630k,thefirstlarge-scaleMIGinstruction\\nofMLLMsinfree-formmulti-imagegrounding(MIG)re- tuningdatasetfortrainingthismodel.\\nmainsunderexplored. Free-formMIGchallengesthemodel • WeintroduceMIG-Bench,acomprehensivebenchmark\\nto perform grounding across multiple images effectively, for evaluating multi-image grounding capabilities. Ex-\\nwheretheinputqueriesandimagecontextscanbeorganized perimentalresultsdemonstratethatMigiciansignificantly\\nin arbitrary forms, enabling flexible and dynamic interac- outperformsthecurrentbestmethods.\\ntions. Forinstance,asshowninFigure1,themodelmust\\nunderstandthewhitecarinthequeryimageandrelateitto 2.RelatedWork\\nthetextualprompt\"blackincolor\"toidentifythecorrespond-\\nMultimodal Large Language Models Recent develop-\\ningtargetinthetargetimage. Thiscapabilityunlocksawide\\nmentsinmultimodallargelanguagemodels(MLLMs)have\\nrange of applications, such as fine-grained environmental\\nshiftedfromsingleimage-textunderstandingtowardsmore\\nperceptioninautonomousdriving[39],anomalydetectionin\\nversatilecapabilities[3,23,38,45]. Amongtheseefforts,\\nsurveillancesystems[2],andtargetlocalizationforembod-\\nsome focus on enabling models to achieve fine-grained\\niedrobotics[11]. Toaddressthefree-formMIG,themodel\\nvisual grounding, either through simple instruction tun-\\nneedstopossessthecapabilityforvisualgroundingwhile\\ning[5,33]orbyintegratingadditionalauxiliaryvisualcom-\\nachievingcross-imageunderstanding.\\nponents[4,48,51]. However,thesemodelsprimarilyfocus\\nAsaresult,aquestionnaturallyarises:Canweintegrated\\non visual grounding within a single image. Some other\\nthesingle-imagegroundingandmulti-imageunderstanding\\nstudies explore multi-image understanding tasks, such as\\ncapabilitiesofexistingMLLMstotackletheMIGtask? In\\nmulti-imagecomparison,reasoning,andtemporalcompre-\\nthiswork,weproposeaChain-of-Thought(CoT)framework\\nhension[3,17,23,24,45,47]. Nevertheless,fine-grained\\nthatfirstleveragesmulti-imageunderstandingtogeneratea\\nvisualgroundingatthemulti-imagelevelremainsanunder-\\ntextualreferringquery,andthenutilizesitforlocalization\\nexploredarea. Tothebestofourknowledge,ourproposed\\nthroughsingle-imagegrounding. Thisapproachisproven\\nMigician is the first MLLM designed to address the chal-\\nhighly effective for MIG tasks, particularly in simple sce-\\nlengeofmulti-imagegrounding.\\nnarioswheretextualdescriptionsaresufficientlydistinctive,\\nrevealingthepotentialofMLLMsinhandlingsuchtasks.\\nMLLMBenchmarks Mostexistingbenchmarksforeval-\\nHowever, the proposed CoT framework struggles with\\nuatingMLLMsfocusonsingle-imagetasks[9,22]. Afew\\ndescribingabstractvisualsemanticsinmulti-imagescenar-\\nrecentbenchmarkshavestartedassessingtheperformanceof\\nios, and the two-step process results in a doubling of the\\nMLLMsonmulti-imageunderstanding[10,17,27,29,36],\\ninference time. To address this, we further propose Migi-\\nbuttheyprimarilyemphasizeimage-levelcomprehension.\\ncian,acompetitiveMLLMcapableoffree-formandaccurate\\nThemostrelevantbenchmarktoourworkisMC-Bench[42],\\ngroundingacrossmultipleimages,whichisanend-to-endso-\\nacontemporaneousstudy. MC-Benchevaluatesthemulti-\\nlutionforMIG.Toprogressivelyestablishflexiblegrounding\\ncontextgroundingcapabilitiesofMLLMsbyaskingthemto\\ncapabilities,weemployatwo-stagetrainingprocedurebased\\naccuratelylocatethecorrespondingobjectbasedonatext\\non our proposed large-scale MIG dataset (MGrounding-\\nprompt in the correct image from a given pair. However,\\n630k). First,thegroundingabilityofMigicianisenhanced\\nitexhibitslimitationsinthefixednumberofinputimages\\nthrough a combination of data of MIG tasks and general\\nandtherestrictedformsofqueries. Incontrast,theproposed\\ntasks. Then,Migicianisfurtherrefinedusinghigh-quality\\nMIG-Benchinthisworkoffersmoreflexibletaskformats,\\nfree-formMIGinstructiondata. Inaddition,toevaluatethe\\nfocusing on evaluating models’ capabilities in free-form\\nchallengesofthefree-formMIGscenario, weconstructa\\nmulti-imageunderstanding.\\ncomprehensive multi-image grounding benchmark, MIG-\\nbench,comprisingatotalof10differenttasks,5.9kdiverse\\n3.TaskDefinition\\nimages and more than 4.2k test instances. We observe a\\nsignificantgapbetweentheperformanceofexistingmain- Thetaskoffree-formmulti-imagegroundingistoidentify\\nstreamMLLMsandhumanperformanceontheMIG-bench. andlocalizerelevantvisualregionsacrossasetofimages\\nIncontrast,Migiciancaneffectivelyalleviatethisgapand based on a free-form query. Unlike traditional grounding\\nimprovetheperformanceoffree-formMIG. taskswithfixedinputformats,thequeryinfree-formmulti-\\nTosumup,ourcontributionscanbeconcludedasfollows: imagegroundingcanbeanarbitrarycombinationoftext\\n• Weexplorethetaskofmulti-imagegroundingforMLLMs and images, making it highly flexible and versatile. For-\\n2Spontaneous Grounding\\nStatic Diff Grounding Common Object Grounding\\nQuestion:Please ground the Question:Please identify the\\ndifference of these images in the common object all these\\nsecond image. images share and ground it\\nAnswer:(157,503),(493,759) irrespectively.\\nRobust Diff Grounding Answer:The commom object\\nall these images share is “dog”.\\nQuestion:Please recognize the Their exact positions: Image-1\\nmain difference of these two images (0,487),(521,889). Image-2\\nand ground it in the second image. (297,383),(794,999)...\\nAnswer:(427,483),(623,589)\\nReferential Grounding\\nVisual Reference Textual Reference Textual + Visual\\n(1) Multi-View Grounding (2) Object Tracking (1) Group Grounding (1) Reasoning Grounding\\nQuestion:For the object marked Question:For the target marked with Question:For these unrelated Question:Which object on Image-\\nwith green box in Image-1, please green box in Image-1, please locate it images, find and locate the 2’s the table could alleivate the\\nlocate it in Image-2. in Image-2. “electronic scales”. situation presented in Image-1?\\nAnswer:The huge window in Answer:The black puppey in Image- Answer:It’s in Image-2, (182, Answer:The red rose located at\\nImage-2 is at (202,27),(613,499). 2 is located at (202,27),(613,499). 527),(23,319). (672,140),(836,549).\\n(3) Referring Grounding (4) Region Locating (2) Correspondence\\nQuestion: For the object Question: Please locate these regions Question:For the region in Image1,\\npresented in Image-1, please pictures in the source image. ground the semantically/functionally\\nlocate it in the second image. corresponding region in Image-2.\\nA b do en t ss t klw e\\n,\\nae isr\\nt\\n: p (7T la 0h c 2e e\\n,\\n2dtr\\n7\\na o )n n ,(s 9tp h 1a e 3r ,e w 2n 7ot\\n3\\nog )d .la es ns A ( lo2n c2 as 1 tw , e3 de 4 r ) a: ,( tT 2 ..h 9 .e 8 ,t 7o 1w 3e ),r ti hs elo wca ht ite ed b a ot a t is A (5n 1s 2w ,0e ),r (: 9T 2h 9e ,4 l 4o 5n )g . tail located at\\nFigure 2. An illustration of the multi-image grounding tasks included in MIG-Bench. These tasks are divided into two categories:\\nspontaneousgroundingandreferentialgrounding,dependingonthewhetherthereareexplicitreferentialrequirements.\\nmally, let the query Q consist of a natural language de- SpontaneousGroundingtypicallyutilizestherelationships\\nscription, reference images {R ,R ,...,R } or a hybrid betweenmultipleimagesascontextualcuestoautonomously\\n1 2 k\\ncombinationof both(e.g., “[awhitecarimage] findacar identifyandlocalizetheobjectstobegrounded(e.g.,find-\\nlike this image except it is black”). Given a set of target ingandlocatingdifferencesbetweenimages). Referential\\nimages{I ,I ,...,I },thetaskistoidentifyasetofvisual Grounding,ontheotherhand,requiresanexplicitreference\\n1 2 n\\nregions {G ,G ,...,G } where G is the target region tothetargetobject. Asmentionedearlier,suchreferences\\n1 2 m i\\nwithinanimageI thatsatisfiesthesemanticandcontextual cantaketheformofarbitrarycombinationsofimagesand\\nj\\nconstraintsdefinedbyQ. textualdescriptions.\\nAs shown in Figure 2, based on whether the task in-\\nvolvesexplicitreferencerequirements,multi-imageground- 4.Methods\\ningtaskscanbefurthercategorizedintotwotypes: Sponta-\\nneousGroundingandReferentialGrounding. Spontaneous Inthissection,wedelveintothemethodsforenablingfree-\\nGrounding refers to recognizing and grounding the target formmulti-imagegroundingcapabilitiesinMLLMs. Since\\nobjectincorrespondingimageswithoutexplicitlypointing free-formMIGrequirestheabilitytoperformvisualground-\\nitout. UnliketheconventionalReferenceExpressionCom- ingwhilesimultaneouslyunderstandingmultipleimages,we\\nprehensiontask[19]thatexplicitlyrefertothetargetobject, beginbyinvestigatingaChain-of-Thought(CoT)framework\\n3Direct Question:Locate the common\\nobject all these images share.\\nIt’s the bird. Task-2: Now ground <ref>a wooden bucket with pink\\nflowers on it</ref> in this Singleimage.\\nThere are messy woods (0,0),\\n(999,999) in the back in Image-1, a\\nbird cage located at (681, 168),\\n(854,902) in Image-3 and orange\\ncat(0,29), (629,999)...\\n...\\n(a) Direct Inference\\ngnilloP\\nTask:Ground the common object all these images share.\\nTask:For the object\\npresented in Image-2,\\nidentify and ground it\\nin the first picture.\\nTask-1: Please describe the content of the second\\n... image.\\nTask-1:Please name\\nthis common object with A wooden bucket with pink flowers on it.\\nsimple phrase.\\nTask-2:Now ground the\\n<ref> bird </ref> in this\\nThe wooden bucket with pink\\nSINGLEimage.\\nflowers on it is located at on the\\nleft , with coordinates as\\n(557,492),(752,786) (67,0),(461,974).\\n(b) The CoT Framework (c) A Failure Case\\nFigure3.IllustrationoftheCoTframeworkanditsfailurecase.Differentfrom(a)directinference,the(b)CoTmethoddecomposesthetask\\nintotwosubtasks,solvingeachtaskdeployingthemodel’sexistingcapabilities. AfailurecaseofCoTisshownin(c)wherethemodel\\nstrugglesathandlingabstractvisualinformation.Greenandredbackgroundcolorsindicatecorrectandincorrectanswers,respectively.\\nObject Tracking (130k) Static Difference (70k)\\nTrackingNet (100k) CLEVR-change (40k)\\nGOT (18k)\\nMagicBrush (10k)\\nLaSOT (10k)\\nImgDiff (10k)\\nMOT17 (2k)\\nSpot-the-diff (10k)\\nReferring Grounding (70k)\\nMGrounding-630k ImageNet (70k) Group Grounding (120k)\\nRegion Locating (70k) GranD REC (80k)\\nGranF REG (40k)\\nObject365 (70k)\\nCommon Object (70k) Free-Form MIG (100k)\\nObject365 (51k) Synthetic_common (32k)\\nImageNet (16k) Synthetic_random (35k)\\nCOCO_train2017 (3k) Synthetic_CLIP (33k)\\nFigure4.StatisticsoftheMGrounding-630kdatasetandMIG-Bench.\\ntocombinethesetwocapabilitieswithinexistingMLLMs tasks as illustrated in Figure 3(b). The model is first\\ntotacklethistask. Furthermore,wedevelopanend-to-end promptedtoengageina\"reasoningprocess\"byperforming\\nMIGmodel, Migician, throughinstructiontuningtoover- multi-imageunderstandingbasedontheinputimagesand\\ncome the limitations of the CoT framework and achieve thegivenprompt,generatingatextualreferringexpression\\nenhancedMIGperformance. thatdescribesthetargetobject. Next,themodelperforms\\nthe visual grounding task, using the referring expression\\n4.1.AChain-of-ThoughtFramework fromtheprevioussteptolocatetheobjectsincorresponding\\nimages. Thisframeworkleadstoanotableperformanceim-\\nAlthoughsomeexistingMLLMssuchasQwen2-VL-7B[38]\\nprovementonMIGtasks,indicatingthatexistingMLLMs\\ndemonstratestrongmulti-imageunderstandingandsingle-\\npossesstheunderlyingcapabilitiesrequiredforsuchtasks\\nimagegroundingcapabilities,wefindthatdirectlyprompting\\nbutneedaneffectivemethodtoelicitthem.\\nthemtoperformMIGtasksoftenleadstosignificantperfor-\\nmance degradation as illustrated in Figure 3(a). To better However, the CoT framework suffers from several in-\\nexplorethepotentialofexistingmodelsforMIGtasks,we herent limitations. On one hand, the multi-step process\\ndesignaChain-of-Thought(CoT)frameworkthatenables introduceserrorpropagationissues[44]andimpactsreason-\\nthemodeltoeffectivelyleverageandcombineitsexitsing ingefficiency. Ontheotherhand,manyscenariosrequire\\nabilitiesduringtheMIGexecution. grounding through abstract visual semantics across multi-\\nSpecifically,wedecomposetheMIGtaskintotwosub- imagecontexts(asshowninFigure3(c)), makingtheuse\\n4Task: Find and locate the different object in the second image. Task: Find and locate the second image in the first picture.\\nPlease describe the difference between these two images. Please identify and describe the content in\\nthe second image.\\nThe girl in pink cloth and her bike have disappeared.\\nThe image is a close-up of a woman\\'s face\\nNow ground <ref>the girl in pink cloth and her bike\\nhave disappeared </ref> in this Singleimage. Now ground <ref>a close-up of a woman\\'s\\nface</ref> in this Singleimage.\\nThere is no person in the first image,\\nso the difference is not applicable. (399,333),(599,666)\\n[Direct Answer](525,524),(775,994). [Direct Answer](606, 0), (796, 276).\\n(a) Multi-Image Format (b) Abstract Visual Information\\nTask: Find and locate the different object in the second image. Task: Recognize and locate the common object they share in the third image.\\nCompare these two images and\\ndescribe the difference in a short phase.\\nThe doll on the left side of the two\\nimages has changed its position.\\nNow ground the object difference <ref> the doll on These images share one object in common. Find\\nthe left side </ref> in the second image. The common object is it and tell me its name in single phrase or words.\\nTuba in all images.\\nIts position is in (83,162),(209,384).\\nPlease locate and ground <ref> the tuba </ref> in the Image-3.\\n[Direct Answer](446, 285), (552, 434). It’s a tuba. [Direct Answer](106, 29), (896, 895).\\n(c) CoT Error Propagation (d)Error inMiddle of Reasoning\\nFigure5.Abovearethefourrepresentativefailurepatternsofthesingle-imageCoT.Fromlefttoright,toptobottom,theyare(a)special\\nmulti-imageformat,(b)abstractvisualinformation,(c)CoTerrorpropagation,(d)step-2inferenceerror.\\nofanintermediatetextualreferringexpressionimpractical. wecollectandorganizedatafromexistingsources,combin-\\nThishighlightstheneedforanend-to-endmodelcapableof ingorautomaticallysynthesizingsingle-imageannotations\\ndirectlyperformingtheMIGtask. tocreatedatasetsfor6typesofMIGtasks. Eachtaskcon-\\nMorefailurepatternsoftheCoTframeworkareillustrated tainsover70kexamples,resultinginatotalof530ktraining\\ninFigure5,categorizedintoperceptualandreasoningflaws. samples. ThedetailsofthesetaskdataareinAppendixC.1.\\nFor the former, the framework falls short when multiple\\nimagesareorganizedinamannerwhereonlyintegratingall\\ntheirvisualinformationcouldtackleMIG(i.e. findingthe\\nSynthesizingFree-formMIGData. Thedataobtained\\nlocationofmissingpeopleinthesecondimage), orwhen\\nthroughtheaforementionedmethodsstilldonotfullymeet\\nthetextualcontentcouldnotsufficientlyrepresentthevisual\\ntherequirementsforfree-formMIG.ToacquireMIGdata\\ninformation. Regardingreasoningerrors,inaccuraciescan\\nwithricherandmorediverseformats,whichwouldenhanc-\\nariseatvariousstagesofthereasoningprocess,undermining\\ningthemodel’sinstruction-followingandflexiblegrounding\\ntheframework’soverallaccuracyandeffectiveness.\\ncapabilities,wedesignaMIGdatasynthesispipeline. This\\npipeline uses the Objects365 [35] images with object an-\\n4.2.DataConstruction\\nnotations,selectmultipleimagesasagroup,andgenerate\\nTheCoTframeworkhasdemonstratedthatanMLLMwith high-qualityinstructionsformulti-imagegrounding. Specif-\\nbothmulti-imageunderstandingandsingle-imagegrounding ically, we first employ Qwen2-VL-72B [38] to generate\\ncapabilitiesinherentlyholdsstrongpotentialforfree-form captions of each individual image and then perform error\\nMIG.Inthefollowingsection,weemployinstructiontuning filtering and refinement on the annotated bounding boxes.\\ntoexplicitlybridgethesecapabilitiesinexistingMLLMsto Next,wepromptQwen2.5-72B[43]toautomaticallygener-\\nachieveMIG.Forthispurpose,wefirstconstructaninstruc- atehigh-quality,free-formMIGquestion-answeringpairsby\\ntion tuning dataset for MIG, named MGrounding-630k, integratinginformationfrommultipleimages. Tooptimize\\nwithitsstatisticspresentedinFigure4. Thisdatasetispri- theselectionofappropriateimagegroups,weadoptdiffer-\\nmarilyconstructedthroughthefollowingtwoways. ent image grouping methods, including random selection,\\nselectionofimageswithcommonobjects,andgroupingim-\\nTransformingExistingData. Byanalyzingthetasksand agesbasedonCLIPsimilaritytoselectsemanticallysimilar\\nannotationtypesofexistingdatasets,weidentifymultiple imagesforeach. Usingthesemethods,wegenerateatotalof\\nmulti-image grounding (MIG) tasks whose data could be 100kFree-FormMIGdata. Formoredetailedinformation\\nderivedthroughtransformationoftheexisting. Specifically, pleaserefertoAppendixC.2.\\n5SpontaneousGrounding ReferentialGrounding\\nModels Difference Similarity VisualReference Textual Visual+Textual AVE\\nStatic Robust Common OT MV Region Refer GG Reason Co-Re\\nHumanPerformance\\nHuman 99.50* 97.87 98.00* 100.00 96.88 100.00* 98.99 91.06* 92.08 97.44 97.18\\n70B-ScaleMLLMs\\nLLaVA-OV-72B 13.26 5.34 26.84 12.91 7.64 2.14 17.83 21.60 11.88 8.55 13.65\\nInternVL2-76B 15.91 10.64 36.40 30.73 20.83 5.74 46.46 41.28 32.67 26.50 26.72\\nQwen2-VL-72B 46.12 46.81 64.46 26.73 22.57 18.62 33.33 62.53 50.50 17.09 38.88\\n7B-ScaleMLLMs\\nMantis 1.52 0.00 3.31 12.18 2.08 1.00 1.01 10.02 0.00 0.85 3.20\\nLLaVA-OV-7B 6.06 3.19 3.43 0.18 1.04 1.08 9.09 15.43 6.93 0.85 4.73\\nMinicpm2.6 14.58 2.13 14.34 9.82 6.25 1.75 11.11 10.02 2.97 2.56 7.55\\nmPLUG-Owl3 18.56 6.38 34.93 8.55 7.64 2.41 7.07 22.85 9.09 5.98 12.35\\nInternVL2-8B 6.92 7.45 25.49 20.73 9.72 3.49 28.28 30.26 17.82 9.40 15.96\\nQwen2-VL-7B 27.84 38.30 19.36 20.73 11.81 25.95 23.23 58.52 48.51 11.97 28.62\\nmPLUG-Owl3 16.29 8.51 55.39 44.36 25.35 19.04 36.36 30.86 18.81 10.26 26.52\\n+CoT\\nInternVL2-8B 14.58 7.45 72.54 40.91 27.78 28.60 67.68 44.49 41.58 11.97 35.76\\n+CoT\\nQwen2-VL-7B 23.48 40.43 63.85 62.73 42.71 24.85 54.55 43.29 51.49 30.77 43.82\\n+CoT\\nMigician 65.15 46.81 84.19 70.73 60.07 74.31 76.77 66.53 59.41 34.19 63.82\\nTable 1. Performance comparison of different models on MIG-Bench. OT, MV, GG and Co-Re respectively means object tracking,\\nmulti-viewgrounding,groupgroundingandcorrespondence.Forvaluesmarkedwith*,werandomlysample20%testingexamplesfor\\nhumanevaluationonthecorrespondingtask.\\n4.3.InstructionTuningforMIG imagegroundingtasks. Tobetterbalancethesetwoaspects,\\nweadoptthemodelmergingtechnique[14],averagingthe\\nUsingtheconstructeddataset,weperforminstructiontuning\\nmodelweightsobtainedfromstage-2withdifferenttraining\\nbasedonQwen2-VL-7B[38]todevelopMigician,enabling\\nsettingsasthefinalweights. Wefindthisapproachmitigates\\nittoachieveend-to-endfree-formMIGcapabilities.\\ntheperformancelossincommonMIGtaskswhilepreserving\\ntheabilitytofollowfree-formMIGinstructionseffectively.\\nTwo-StageTraining. Toeffectivelyequipthemodelwith\\nfree-formMIGcapabilities, weproposeatwo-stagetrain- 5.MIG-Bench\\ning approach. In the first stage, the model learns to per-\\nTothoroughlyassessthemulti-imagegroundingabilitiesof\\nform multi-image grounding by training on the six repre-\\ncurrentMLLMs,wehavemeticulouslycuratedMIG-Bench.\\nsentative MIG tasks of MGrounding-630k, acquiring the\\nThis benchmark consists of 5.9k images and 4.3k testing\\nabilitytosimultaneouslycomprehendmultipleimagesand\\ninstances,covering10tasks. Thedistributionofthesetasks\\nexecute visual grounding. In the second stage, the model\\nisillustratedinFigure4. Thebenchmarktasksaredivided\\nisfurtherfine-tunedonfree-formMIGinstructiondatain\\nintotwocategories:spontaneousandreferentialmulti-image\\nMGrounding-630k,enablingittoadapttomoreflexibleand\\ngrounding. Spontaneousgroundingtasksrequirethemodel\\ndiverseinstructiontypesandtransfertheMIGskillslearned\\nto recognize and ground differences or common objects\\ninthefirststagetoabroaderrangeofscenarios. Toprevent\\nacrossimages,withatotalof1.4ktestinginstances. Refer-\\nthe model from forgetting its existing capabilities during\\nentialgroundingtasks,ontheotherhand,requirethemodel\\ntraining, we also incorporate single-image understanding,\\ntoutilizedifferentformsofreferencequeries(i.e.,textual,\\nmulti-imageunderstanding,andsingle-imagegroundingdata\\nvisual,ormultimodal)tolocatethetargetobjects,compris-\\nintoeachtrainingstage. MoredetailsareinAppendixD.\\ning6distinctivetasksand2.9ktestinginstances. Thedetails\\nofthesetasksareprovidedinFigure2andAppendixA.\\nModel Merging. After the second stage of fine-tuning, Toensurediversity,theimagesaresourcedfromavari-\\nwe observe a trade-off between model performance and etyofsources,existingdatasets,webimagesandmanually\\nflexibility: while the model adapts to the free-form MIG capturedphotos. Forexistingdatasets,weuseexamplesthat\\ninstructions,thereisaperformancedropincommonmulti- exhibitssignificantmovementfromGOT-10k_val[13]for\\n6Model MuirBench BLINKval MIBench Mantis_eval MMIU AVE V*Bench Attribute Spatial Overall\\nClosed-SourceModel HumanLevel 98.26 100.00 98.95\\nRandomGuess 26.73 50.00 35.99\\nGPT-4o 62.31 60.04 71.88 62.67 55.7 62.52\\nGemini-Pro 49.35 45.16 — — 53.4 49.30 Tool-usingPipeline\\nOpen-SourceModel MM-React 34.78 51.31 41.36\\nVisprog 31.30 56.57 41.36\\nLLaVA-1.5 23.46 37.13 26.83 31.34 19.20 27.59\\nSEAL 74.78 76.31 75.39\\nCogVLM 20.85 41.54 — 45.16 23.57 32.78\\nIdefics2-8B 26.08 — 46.39 48.85 27.80 37.28 End-to-endMLLMs\\nmPLUG-Owl3 39.67 50.30 56.66 63.10 21.72 46.29 InternVL2-8B 29.56 56.57 43.07\\nInternVL2-8B 48.70 50.57 52.91 60.37 42.00 50.05 GeminiPro 40.86 59.21 48.16\\nMantis 44.50 49.05 45.09 57.14 45.60 48.28 LLaVA-1.5 43.47 56.57 48.68\\nLLaVA-OV-7B 41.80 48.20 71.29 64.20 44.46 53.99 Minicpm2.6 40.86 64.47 52.67\\nMinicpm2.6 42.65 51.45 71.09 69.12 50.19 56.90 GPT-4V 51.30 60.53 54.97\\nQwen2-VL-7B 42.04 52.35 68.06 70.97 54.36 57.56\\nMigicianzero_shot 59.16 60.53 59.85\\nMigician 53.69 51.53 71.42 69.12 60.32 61.51 Migicianslice 77.49 67.11 72.30\\nTable2.Performancecomparisononvariousmulti-imageunderstandingbenchmarks. Table 3. On V* Bench, Migician generalizes\\nThehighestscoreishighlightedinboldandthesecondhighestscoreisunderlinedfor well to the hyper-resolution single image in a\\nallopen-sourcemodels. zero-shotmanner.\\ntheObjectTrackingtask,andmanuallymodifytheimages ageimprovementof21.61%comparedtothesecond-best\\nfromObjects365[35]forCommonObjecttask. ForMulti- model, Qwen2-VL-72B (38.88%), despite having signifi-\\nview Grounding, we collect 288 examples spanning both cantlyfewerparameters.\\nindoorandoutdoorscenesfromEgo4D[11]. TheStaticDif- Notethatthereisasubstantialgapbetweenhumanperfor-\\nferencetaskissourcedfromtheMagicBrush_devset[50]. manceandthatofallMLLMsacrossalltasks,indicatingthat\\nWealsomanuallycapture97imagepairswithviewdiffer- MLLMshavesignificantpotentialforimprovementinfree-\\nencesinreal-worldsettingsandcollect,onaverage,over100 formMIG.Inparticular,for7B-scalemodels,evenadvanced\\nimagepairsfromGoogleSearchfortasksrelatedtoVisual multi-imagemodelslikeInternVL2-8BandQwen2-VL-7B\\nReferring,Reasoning,andReferringGroundingtasks. struggletoperform,particularlyintaskssuchasmulti-view\\nFor a quantitative and objective evaluation of different grounding,regionlocating,andcorrespondence.\\nMLLMs,weensurethateachtestinginstancecontainsonly Formodelsequippedwithpreliminarygroundingcapabil-\\nonecleartargetregion,eliminatinganypotentialambiguity. ities,suchasmPLUG-Owl3,InternVL2series,andQwen2-\\nOurMIG-Benchoffersacomprehensiveevaluationacross VL series, their inherent localization ability provides an\\nvariousreal-worldscenariosanddomains. Webelievethis implicitadvantageoverotherbaselines. Furthermore, the\\nbenchmarkwillprovidevaluableinsightsintothechallenges proposedsingle-imageCoTmethod(+CoT)effectivelyinte-\\nofMIGandinspirefurtherresearchinrelatedareas. gratesthegroundingandmulti-imageunderstandingcapa-\\nbilitiesoftheMLLMswheredifferentabilitiesassisteach\\n6.Experiments otherindifferentreasoningsteps,achievingcomprehensive\\nimprovementsonmulti-imagegroundingtasks. Moreover,\\n6.1.ImplementationDetails\\nthisapproachiseffectiveforalltheaforementionedmodels.\\nMigicianundergoesdevelopmentbasedontheQwen2-VL-\\n6.3.ResultsonMulti-ImageUnderstandingBench-\\n7B[38]foundationmodelwithaglobalbatchsizeof48,a\\nmarks\\ntotal of 25,000 steps for the two-stage training procedure,\\nandalearningrateof5e-6,using8×A100-80GGPUs. For AsshowninTable2,Migiciannotonlyestablishesitsmulti-\\ntheevaluationinourproposedMIG-Bench,weusethecon- imagegroundingability,butalsoremarkablystimulatesits\\nventionalmetricAcc 0.5inreferringexpressioncomprehen- general multi-image understanding ability. In particular,\\nsion[19]. Thismetricmeasurestheaccuracyofobjectlo- Migicianachievesthebestaverageresultsonthemulti-image\\ncalization,definingapredictionascorrectiftheIntersection understanding benchmarks. It surpasses the second-best\\nover Union (IoU) with the ground truth bounding box is model(Mantis)onMuirBenchby9.77%,achievingSOTA\\ngreaterthan0.5. performanceonMMIUandshowsa1.40%improvementon\\nthelarge-scaleMIBench. Weattributethistothetraining\\n6.2.ResultsonMIG-Bench\\nonamixtureofmulti-imageunderstandingandgrounding\\nAsshowninTable1,Migicanachievesthestate-of-the-art data,whichindicatesthatourproposedMGrounding-630k\\nperformanceacrossalltasksonMIG-bench,withanaver- canenhancegeneralmulti-imagecomprehension.\\n7RefCOCO RefCOCO+ RefCOCOg Models Spontaneous Referential AVE\\nModel AVE\\nval testA testB val testA testB val test mPLUG-Owl3 19.96 9.08 13.04\\nVisionLLMv2[40] 79.20 82.30 77.00 68.90 75.80 61.80 73.30 74.80 74.14\\nmPLUG-Owl3+mCoT 23.78 14.10 17.62\\nShikra[5] 87.00 90.60 80.20 81.60 87.40 72.10 82.30 82.20 82.97\\nmPLUG-Owl3+CoT 26.73 26.43 26.54\\nInternVL2-8B[3] 87.10 91.10 80.70 79.80 87.90 71.40 82.70 82.70 82.94 InternVL2-8B 13.29 17.10 15.71\\nGroundingGPT[25] 88.02 91.55 82.47 81.61 87.18 73.18 81.67 81.99 83.57 InternVL2-8B+mCoT 23.78 21.99 22.64\\nGriffonv2[49] 89.6 91.80 86.50 81.90 85.50 76.20 85.00 86.00 85.30 InternVL2-8B+CoT 31.52 37.57 35.37\\nInternVL2-8B[3] 87.10 91.10 80.70 79.80 87.90 71.40 82.70 82.70 82.94\\nQwen2-VL-7B 19.96 28.67 28.61\\nQwen2-VL-7B[38] 91.70 93.60 87.30 85.80 90.50 79.50 87.30 87.80 87.96\\nQwen2-VL-7B+mCoT 41.83 26.23 31.90\\nMigician 91.62 93.49 87.22 86.13 91.06 79.93 88.06 87.80 88.16 Qwen2-VL-7B+CoT 42.59 44.34 43.70\\nTable4.Theperformanceofdifferentcompetitivesingleimagegroundingmodels Table5. ThecomparisonamongdifferentCoTvari-\\nonRefcoco,Refcoco+andRefcocogbenchmarks.Continualgroundingtraining ants.WecomparethreerepresentativeMLLMsamong\\ninthemulti-imagescenariofurtherenhancestheoverallgroundingabilityofthe direct reference, single-image CoT (+CoT), multi-\\nmodel.Migicianachievestopperformanceamongallgroundingmodels. imageCoT(+mCoT)asdescribedinSection7.1.\\nMulti-imageGeneralBenchmarks Multi-imageGrounding\\nSetting\\nMuirBench BLINK MIBench Mantis MMIU MIG\\nBase 42.04 52.35 68.06 70.97 54.36 28.62\\nFulldata(Stage-1) 53.77 51.27 71.76 66.36 53.31 62.79\\n-w/ogrounding 44.54 51.32 71.68 67.74 52.12 22.43\\n(−9.23) (+0.42) (−0.08) (+1.38) (−1.19) (−40.36)\\n-w/ogeneral 53.62 49.25 65.22 64.52 48.61 62.21\\n(−0.15) (−2.02) (−6.54) (−1.84) (−4.70) (−0.58)\\nTable6.Theablationstudyaboutthecontributionofdifferentdatasubsets.\\n6.4. Results on Single-Image Grounding Bench- Typically, thesetasksinvolveimageswithveryhighreso-\\nmarks lution,wheretherelevantvisualinformationisoftenquite\\nsmall,posingsignificantchallengestothemodel’sgrounding\\nAs presented in Table 4, Migician not only acquires free-\\nability. Inthissection,weanalyzeanddemonstratethatthe\\nform multi-image grounding capabilities but also demon-\\nmulti-imagegroundingcapabilityofMigiciancanbelever-\\nstratescontinualandconsistentperformanceimprovements\\nagedtoefficientlyaddressthistask. Specifically,weslicea\\nontheRefCOCOseriessingle-imagegroundingbenchmark,\\nsinglehigh-resolutionimageintomultiplesub-imagesand\\nsurpassingspecializedgroundingmodelssuchasGriffonv2\\ndirectlytransformtheproblemintoamulti-imagegrounding\\nandGroundingGPTbyalargemargin. Additionally,Migi-\\ntask. ByutilizingtheMIGabilityofMigician,wecanlocate\\ncianoutperformsQwen2-VL-7Bintermsofaveragescores.\\nthe regions relevant to the input question. Afterward, the\\nmodelcombinestheidentifiedregionwiththeoriginalimage\\n7.Analysis\\ntogeneratetheanswerfortheinputquestion.\\n7.1.EffectsofDifferentCoTStrategies WetestthisapproachontheV*Bench[41]andlistthe\\nresults in Table 3. In the table, we refer to the method\\nThe CoT framework in Section 4.1, after obtaining a re-\\nthatdirectlyasksMigiciantoanswerthequestionbasedon\\nferring expression, has the MLLM perform grounding in\\ntheoriginalimageasMigician ,whileMigician\\neach image in a polling manner (denoted as single-image zero_shot slice\\ndenotes the method that transforms this task into a MIG\\nCoT), which incurs significant inference overhead. Here,\\ntaskasmentionedbefore. Itsdetailedimplementationcould\\nweexploremulti-imageCoT,wheretheMLLMdirectlyper-\\nbe found in Appendix E. The results remarkably demon-\\nforms grounding across all images based on the obtained\\nstratetheeffectivenessofusingtheMIGapproachforhigh-\\nreferringexpression. AsshowninTable5,multi-imageCoT\\nresolution image visual search. Notably, on the Attribute\\nachievessomeeffectivenessbutitstillfallssignificantlybe-\\nrecognition task, Migician even surpasses the specialized\\nhindsingle-imageCoT.Incontrast,ourproposedMigician\\nvisualsearchingsystemSEAL[41].\\nisabletoperformend-to-endreasoning,offeringsignificant\\nadvantagesinbothefficiencyandeffectiveness.\\n7.3. Effects of Different Data on Multi-Image Un-\\n7.2.VisualSearchinHigh-ResolutionImages derstanding\\nFindingvisualdetailsinhigh-resolutionimagesisachalleng- As observed in Table 6, Migician shows an improvement\\ningtask,andmanyrecentworkshaveexploredthisarea[41]. in multi-image understanding. We further conduct an ab-\\n8lationstudytoanalyzetheeffectsofdifferentdatasubsets. References\\nSpecifically,wetraintwomodelswitheitherthemulti-image\\n[1] Aida Amini, Saadia Gabriel, Peter Lin, Rik Koncel-\\ngrounding and multi-image understanding data removed\\nKedziorski, Yejin Choi, and Hannaneh Hajishirzi.\\nfromthetrainingset.\\nMathqa: Towards interpretable math word problem\\nTheresultsinTable6revealthatgroundingdatagenerally solving with operation-based formalisms. arXiv preprint\\naidsmulti-imageunderstanding. In4outof5benchmarks, arXiv:1905.13319,2019. 1\\nthefulldatasetachievesthehighestperformancecompared [2] JamesBlack,TimEllis,andPaulRosin. Multiviewimage\\ntomodelstrainedwithanysubsetofdataremoved. Incon- surveillanceandtracking. InWorkshoponMotionandVideo\\ntrast, directly fine-tuning with only general data does not Computing,2002.Proceedings.,pages169–174.IEEE,2002.\\nconsistentlyleadtoaperformanceboost. However,when 2\\ncombinedwithfine-grainedgroundingdata,themodelexpe- [3] ZhengCai,MaosongCao,HaojiongChen,KaiChen,Keyu\\nriencesanotableimprovement. Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei\\nChu, et al. Internlm2 technical report. arXiv preprint\\n8.Conclusion arXiv:2403.17297,2024. 2,8\\n[4] Chi Chen, Ruoyu Qin, Fuwen Luo, Xiaoyue Mi, Peng Li,\\nInthiswork,weexplorethetaskofmulti-imagegrounding MaosongSun,andYangLiu. Position-enhancedvisualin-\\nandproposeMigician,thefirstMLLMtoovercomethebar- structiontuningformultimodallargelanguagemodels. arXiv\\nriersbetweenfine-grainedvisualgroundingandmulti-image preprintarXiv:2308.13437,2023. 2\\ninputs. With our proposed large-scale MGrounding-630k [5] KeqinChen,ZhaoZhang,WeiliZeng,RichongZhang,Feng\\ndataset, Migician seamlessly integrates grounding across Zhu,andRuiZhao. Shikra: Unleashingmultimodalllm’s\\nreferentialdialoguemagic. arXivpreprintarXiv:2306.15195,\\nmultiple images, enabling free-form multi-image ground-\\n2023. 1,2,8\\ning. Tofurtheradvanceresearchinthisarea,weintroduce\\n[6] JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLi\\nMIG-Bench,acomprehensivebenchmarkforevaluatingthe\\nFei-Fei. Imagenet:Alarge-scalehierarchicalimagedatabase.\\nmulti-imagegroundingcapabilitiesofMLLMs. Experimen-\\nIn 2009 IEEE conference on computer vision and pattern\\ntalresultsdemonstratethatourmodelsignificantlyoutper-\\nrecognition,pages248–255.Ieee,2009. 13\\nforms existing methods. We hope this work will inspire\\n[7] Desmond Elliott and Akos Kádár. Imagination improves\\nfurther developments in multi-image grounding and con-\\nmultimodal translation. arXiv preprint arXiv:1705.04350,\\ntributetothecreationofmoreversatilemultimodalmodels\\n2017. 1\\ninthefuture.\\n[8] HengFan,LitingLin,FanYang,PengChu,GeDeng,Sijia\\nYu,HexinBai,YongXu,ChunyuanLiao,andHaibinLing.\\nLimitation Lasot:Ahigh-qualitybenchmarkforlarge-scalesingleobject\\ntracking. In Proceedings of the IEEE/CVF conference on\\nDespiteourcomprehensivediscussionoftheMIGchallenge, computervisionandpatternrecognition,pages5374–5383,\\ntherestillremainseverallimitations. First,duetothecom- 2019. 13\\nputationalbudget,wehaven’tverifiedtheeffectivenessof [9] ChaoyouFu,PeixianChen,YunhangShen,YuleiQin,Meng-\\nourtrainingmethodsonlarger70Bscalemodels. Secondly, dan Zhang, Xu Lin, Jinrui Yang, Xiawu Zheng, Ke Li,\\nin spite of intensive grounding training, our model is still XingSun,etal. Mme: Acomprehensiveevaluationbench-\\nconfronted with inaccurate grounding issue, especially in markformultimodallargelanguagemodels. arXivpreprint\\ncomplicatedormessyscenarios. Lastly,ourtrainingmeth- arXiv:2306.13394,2023. 2\\nodsandbenchmarkconstructionmainlyfocusontheREC [10] XingyuFu,YushiHu,BangzhengLi,YuFeng,HaoyuWang,\\ntask. Although Migician possesses decent REG capacity, XudongLin,DanRoth,NoahASmith,Wei-ChiuMa,and\\nRanjay Krishna. Blink: Multimodal large language mod-\\nthistopicisstillinsufficientlydiscussed.\\nels can see but not perceive. In European Conference on\\nComputerVision,pages148–166.Springer,2025. 2\\nAcknowledgement\\n[11] KristenGrauman,AndrewWestbury,EugeneByrne,Zachary\\nChavis,AntoninoFurnari,RohitGirdhar,JacksonHamburger,\\nThis work is supported by the Fundamental Research\\nHaoJiang,MiaoLiu,XingyuLiu,etal. Ego4d:Aroundthe\\nFunds for the Central Universities of China under Grant\\nworldin3,000hoursofegocentricvideo. InProceedingsof\\n2024JBGP008andtheNationalNaturalScienceFoundation\\ntheIEEE/CVFConferenceonComputerVisionandPattern\\nofChina(No. 62406018).\\nRecognition,pages18995–19012,2022. 2,7\\nWeextendourheartfeltgratitudetothededicatedhuman\\n[12] AnwenHu,HaiyangXu,JiaboYe,MingYan,LiangZhang,\\nvolunteers,MaiSun,PujianZhan,XingyuZhang,Binhao\\nBo Zhang, Chen Li, Ji Zhang, Qin Jin, Fei Huang, et al.\\nLiu,andHuitingPei,fortheirtirelesseffortsinhuman-level mplug-docowl 1.5: Unified structure learning for ocr-free\\nperformance evaluation, for which we extend our whole- documentunderstanding. arXivpreprintarXiv:2403.12895,\\nheartedappreciation. 2024. 1\\n9[13] LianghuaHuang,XinZhao,andKaiqiHuang. Got-10k: A [26] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,\\nlargehigh-diversitybenchmarkforgenericobjecttrackingin PietroPerona,DevaRamanan,PiotrDollár,andCLawrence\\nthewild. IEEEtransactionsonpatternanalysisandmachine Zitnick. Microsoft coco: Common objects in context. In\\nintelligence,43(5):1562–1577,2019. 6,13 ComputerVision–ECCV2014: 13thEuropeanConference,\\n[14] GabrielIlharco, MarcoTulioRibeiro, MitchellWortsman, Zurich,Switzerland,September6-12,2014,Proceedings,Part\\nSuchinGururangan,LudwigSchmidt,HannanehHajishirzi, V13,pages740–755.Springer,2014. 13\\nandAliFarhadi. Editingmodelswithtaskarithmetic. arXiv [27] HaoweiLiu,XiZhang,HaiyangXu,YayaShi,ChaoyaJiang,\\npreprintarXiv:2212.04089,2022. 6,15 MingYan,JiZhang,FeiHuang,ChunfengYuan,BingLi,\\n[15] Julia Ive, Pranava Madhyastha, and Lucia Specia. Dis- etal.Mibench:Evaluatingmultimodallargelanguagemodels\\ntilling translations with visual awareness. arXiv preprint overmultipleimages.arXivpreprintarXiv:2407.15272,2024.\\narXiv:1906.07701,2019. 1 2\\n[16] HarshJhamtaniandTaylorBerg-Kirkpatrick. Learningto [28] PanLu,LiangQiu,JiaqiChen,TonyXia,YizhouZhao,Wei\\ndescribedifferencesbetweenpairsofsimilarimages. arXiv Zhang,ZhouYu,XiaodanLiang,andSong-ChunZhu.Iconqa:\\npreprintarXiv:1808.10584,2018. 12 Anewbenchmarkforabstractdiagramunderstandingand\\n[17] DongfuJiang,XuanHe,HuayeZeng,CongWei,MaxKu, visuallanguagereasoning. arXivpreprintarXiv:2110.13214,\\nQianLiu,andWenhuChen. Mantis:Interleavedmulti-image 2021. 1\\ninstructiontuning. arXivpreprintarXiv:2405.01483,2024. 2 [29] FanqingMeng,JinWang,ChuanhaoLi,QuanfengLu,Hao\\n[18] QiruiJiao,DaoyuanChen,YilunHuang,YaliangLi,andYing Tian, Jiaqi Liao, Xizhou Zhu, Jifeng Dai, Yu Qiao, Ping\\nShen. Img-diff: Contrastivedatasynthesisformultimodal Luo,etal. Mmiu: Multimodalmulti-imageunderstanding\\nlarge language models. arXiv preprint arXiv:2408.04594, forevaluatinglargevision-languagemodels. arXivpreprint\\n2024. 12 arXiv:2408.02718,2024. 2\\n[19] Sahar Kazemzadeh, Vicente Ordonez, Mark Matten, and [30] AntonMilan. Mot16:Abenchmarkformulti-objecttracking.\\nTamara Berg. Referitgame: Referring to objects in pho- arXivpreprintarXiv:1603.00831,2016. 13\\ntographsofnaturalscenes. InProceedingsofthe2014con- [31] MatthiasMuller,AdelBibi,SilvioGiancola,SalmanAlsub-\\nferenceonempiricalmethodsinnaturallanguageprocessing aihi,andBernardGhanem.Trackingnet:Alarge-scaledataset\\n(EMNLP),pages787–798,2014. 2,3,7 andbenchmarkforobjecttrackinginthewild. InProceed-\\n[20] Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, ingsoftheEuropeanconferenceoncomputervision(ECCV),\\nKenjiHata,JoshuaKravitz,StephanieChen,YannisKalan- pages300–317,2018. 13\\ntidis, Li-Jia Li, David A Shamma, et al. Visual genome: [32] DongHukPark,TrevorDarrell,andAnnaRohrbach. Robust\\nConnectinglanguageandvisionusingcrowdsourceddense changecaptioning. InProceedingsoftheIEEE/CVFInter-\\nimageannotations. Internationaljournalofcomputervision, nationalConferenceonComputerVision,pages4624–4633,\\n123:32–73,2017. 1 2019. 12\\n[21] WoosukKwon, Zhuohan Li, Siyuan Zhuang, YingSheng, [33] ZhiliangPeng,WenhuiWang,LiDong,YaruHao,Shaohan\\nLianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Huang, Shuming Ma, and Furu Wei. Kosmos-2: Ground-\\nZhang,andIonStoica. Efficientmemorymanagementfor ingmultimodallargelanguagemodelstotheworld. arXiv\\nlargelanguagemodelservingwithpagedattention. InPro- preprintarXiv:2306.14824,2023. 2\\nceedingsoftheACMSIGOPS29thSymposiumonOperating [34] HanoonaRasheed,MuhammadMaaz,SahalShaji,Abdelrah-\\nSystemsPrinciples,2023. 13 manShaker,SalmanKhan,HishamCholakkal,RaoMAnwer,\\n[22] BohaoLi,YuyingGe,YixiaoGe,GuangzhiWang,RuiWang, EricXing,Ming-HsuanYang,andFahadSKhan. Glamm:\\nRuimaoZhang, andYingShan. Seed-bench: Benchmark- Pixelgroundinglargemultimodalmodel. InProceedingsof\\ningmultimodallargelanguagemodels. InProceedingsof theIEEE/CVFConferenceonComputerVisionandPattern\\ntheIEEE/CVFConferenceonComputerVisionandPattern Recognition,pages13009–13018,2024. 13\\nRecognition,pages13299–13308,2024. 2 [35] ShuaiShao,ZemingLi,TianyuanZhang,ChaoPeng,Gang\\n[23] BoLi,YuanhanZhang,DongGuo,RenruiZhang,FengLi, Yu,XiangyuZhang,JingLi,andJianSun. Objects365: A\\nHaoZhang,KaichenZhang,PeiyuanZhang,YanweiLi,Zi- large-scale,high-qualitydatasetforobjectdetection. InPro-\\nwei Liu, et al. Llava-onevision: Easy visual task transfer. ceedingsoftheIEEE/CVFinternationalconferenceoncom-\\narXivpreprintarXiv:2408.03326,2024. 2 putervision,pages8430–8439,2019. 5,7\\n[24] FengLi,RenruiZhang,HaoZhang,YuanhanZhang,BoLi, [36] FeiWang,XingyuFu,JamesYHuang,ZekunLi,QinLiu,\\nWeiLi,ZejunMa,andChunyuanLi. Llava-next-interleave: XiaogengLiu,MingyuDerekMa,NanXu,WenxuanZhou,\\nTackling multi-image, video, and 3d in large multimodal Kai Zhang, et al. Muirbench: A comprehensive bench-\\nmodels. arXivpreprintarXiv:2407.07895,2024. 2,15 markforrobustmulti-imageunderstanding. arXivpreprint\\n[25] ZhaoweiLi,QiXu,DongZhang,HangSong,YiqingCai,Qi arXiv:2406.09411,2024. 2\\nQi,RanZhou,JuntingPan,ZefengLi,VuTu,etal. Ground- [37] PengWang,ShijieWang,JunyangLin,ShuaiBai,Xiaohuan\\ninggpt: Languageenhancedmulti-modalgroundingmodel. Zhou,JingrenZhou,XinggangWang,andChangZhou. One-\\nInProceedingsofthe62ndAnnualMeetingoftheAssocia- peace: Exploringonegeneralrepresentationmodeltoward\\ntionforComputationalLinguistics(Volume1:LongPapers), unlimitedmodalities.arXivpreprintarXiv:2305.11172,2023.\\npages6657–6678,2024. 8 1\\n10[38] PengWang,ShuaiBai,SinanTan,ShijieWang,ZhihaoFan, [51] ShilongZhang,PeizeSun,ShoufaChen,MinXiao,Wenqi\\nJinzeBai,KeqinChen,XuejingLiu,JialinWang,Wenbin Shao, Wenwei Zhang, Yu Liu, Kai Chen, and Ping Luo.\\nGe, et al. Qwen2-vl: Enhancing vision-language model’s Gpt4roi:Instructiontuninglargelanguagemodelonregion-\\nperception of the world at any resolution. arXiv preprint of-interest. arXivpreprintarXiv:2307.03601,2023. 2\\narXiv:2409.12191,2024. 2,4,5,6,7,8\\n[39] YuqiWang,JiaweiHe,LueFan,HongxinLi,YuntaoChen,\\nandZhaoxiangZhang. Drivingintothefuture: Multiview\\nvisual forecasting and planning with world model for au-\\ntonomous driving. In Proceedings of the IEEE/CVF Con-\\nferenceonComputerVisionandPatternRecognition,pages\\n14749–14759,2024. 2\\n[40] JiannanWu,MuyanZhong,SenXing,ZeqiangLai,Zhaoyang\\nLiu,WenhaiWang,ZheChen,XizhouZhu,LeweiLu,Tong\\nLu,etal. Visionllmv2:Anend-to-endgeneralistmultimodal\\nlargelanguagemodelforhundredsofvision-languagetasks.\\narXivpreprintarXiv:2406.08394,2024. 8\\n[41] PenghaoWuandSainingXie. V?:Guidedvisualsearchas\\na core mechanism in multimodal llms. In Proceedings of\\ntheIEEE/CVFConferenceonComputerVisionandPattern\\nRecognition,pages13084–13094,2024. 8\\n[42] YunqiuXu,LinchaoZhu,andYiYang. Mc-bench:Abench-\\nmarkformulti-contextvisualgroundingintheeraofmllms.\\narXivpreprintarXiv:2410.12332,2024. 2\\n[43] AnYang,BaosongYang,BinyuanHui,BoZheng,Bowen\\nYu,ChangZhou,ChengpengLi,ChengyuanLi,Dayiheng\\nLiu,FeiHuang,etal. Qwen2technicalreport. arXivpreprint\\narXiv:2407.10671,2024. 5\\n[44] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,\\nKarthik Narasimhan, and Yuan Cao. React: Synergizing\\nreasoning and acting in language models. arXiv preprint\\narXiv:2210.03629,2022. 4,12\\n[45] YuanYao,TianyuYu,AoZhang,ChongyiWang,JunboCui,\\nHongjiZhu,TianchiCai,HaoyuLi,WeilinZhao,ZhihuiHe,\\netal. Minicpm-v:Agpt-4vlevelmllmonyourphone. arXiv\\npreprintarXiv:2408.01800,2024. 2\\n[46] JiaboYe,AnwenHu,HaiyangXu,QinghaoYe,MingYan,\\nGuohaiXu,ChenliangLi,JunfengTian,QiQian,JiZhang,\\netal. Ureader:Universalocr-freevisually-situatedlanguage\\nunderstandingwithmultimodallargelanguagemodel. arXiv\\npreprintarXiv:2310.05126,2023. 1\\n[47] JiaboYe,HaiyangXu,HaoweiLiu,AnwenHu,MingYan,Qi\\nQian,JiZhang,FeiHuang,andJingrenZhou. mplug-owl3:\\nTowardslongimage-sequenceunderstandinginmulti-modal\\nlarge language models. arXiv preprint arXiv:2408.04840,\\n2024. 2\\n[48] HaoxuanYou,HaotianZhang,ZheGan,XianzhiDu,Bowen\\nZhang, Zirui Wang, Liangliang Cao, Shih-Fu Chang, and\\nYinfeiYang. Ferret:Referandgroundanythinganywhereat\\nanygranularity. arXivpreprintarXiv:2310.07704,2023. 1,2\\n[49] YufeiZhan,YousongZhu,HongyinZhao,FanYang,Ming\\nTang,andJinqiaoWang. Griffonv2:Advancingmultimodal\\nperceptionwithhigh-resolutionscalingandvisual-language\\nco-referring. arXivpreprintarXiv:2403.09333,2024. 8\\n[50] KaiZhang,LingboMo,WenhuChen,HuanSun,andYuSu.\\nMagicbrush: Amanuallyannotateddatasetforinstruction-\\nguidedimageediting. AdvancesinNeuralInformationPro-\\ncessingSystems,36,2024. 7,12\\n11A.BenchmarkTasksDefinition Visual+TextualReferenceQuery Thesetaskscombine\\ninformationfrombothmodalitiestoassesscross-modalrea-\\nA.1.SpontaneousGrounding\\nsoningabilities.\\nOur benchmark evaluates the spontaneous grounding (1)Correspondence. Themodelmustgroundsemantically\\nthroughthreedistincttasksbelow,whichaimatassessing orfunctionallysimilarregionswithinatargetimage. This\\nmodel’sabilitytoautonomouslydiscoverinsidiousconnec- finer-grainedtaskfocusesonobjectregionsratherthanwhole\\ntionsacrossvariousimagesandaccuratelyrecognizethen objects,demandinganin-depthunderstandingofvisualse-\\nlocatethetarget. mantics.\\n(2) Reasoning. This task requires the model to perform\\nreasoning-based grounding by integrating cross-modality\\nSpottheDifference Giventwosimilarimageswithasin-\\ninformation. SeveralexamplesareshowninFigure2.\\nglesubtledifference, themodelisinstructedtorecognize\\nOurcomprehensivebenchmarkoffersarich,multi-faceted\\nandgroundthisdifferenceinthesecondimage, requiring\\nevaluationacrossvariousreal-worldscenariosanddomains,\\nkeenperceptualskills.\\nextendingbeyondsimpleimagepairstoincludelongerand\\nmorecompleximagecontexts. Byensuringthateachtaskis\\nCommon Object Grounding It refers to automatically well-definedandunambiguous,wefacilitateobjectiveand\\nrecognizingandgroundingthecommonobjectappearingin definitiveassessments..\\nallimageswithinanimagegroup,whichinourbench,each\\nB.Single-ImageCoTFailurePatterns\\nsharesonedefinitecommonobject.\\nAs shown in Figure 5, the four representative failure pat-\\nRobustImageDifferenceGrounding Modelsmustfocus ternsare(a)specialmulti-imageformat,(b)abstractvisual\\non the primary difference between two images captured information,(c)CoTerrorpropagation,(d)step-2inference\\nfrom slightly different perspectives, ignoring other minor error.\\nvariationscausedbyshiftsintheviewpoint. Whenthemultipleimagesareformattedinaspecialpat-\\ntern,whereourtargetobjectismissinginthetargetimage,\\nA.2.ReferenceGrounding like,theinformationinthisimageisinsufficienttoperform\\ngrounding.\\nTextualReferenceQuery Thischallenge,whichmainly\\nTheabstractvisualinformationreferstosituationswhere\\nincludesGroupGrounding,testsamodel’sabilitytolinka\\ntheintricatevisualcannotbeadequatelyconvertedintextual\\ntextualreferencetoatargetobjectwithinitscorresponding\\ndescriptiontoperformaccurategrounding. InFigure5,the\\nspecificimage. Givenasetofimagesandonetextualquery,\\nsimpledescription\"aclose-upofawoman’sface\"cannot\\nthemodelmustidentifythecorrectimagethenaccurately\\ndistinguishwhichfacethetargetisinImage-1.\\ngroundthetargetobjectwithinit.\\nEach reasoning step of CoT could be incorrect, which\\ncouldpotentiallyleadstotheerrorpropagationissue[44]. In\\nVisual Reference Query These tasks examine model’s Figure5,theconclusiondrawfromthefirststepisincorrect,\\nabilitytoeffectivelyutilizevisualreferenceinformationand whichdirectlyleadstothemistakeinthesecondstep.\\nincorporateitintothesearchingprocess. The last failure pattern refers to cases where the erro-\\n(1)VisualReferringGrounding. Inthistask,apairofim- neousreasoningstepappearsatthesecondstep,failingto\\nagesisprovided—asourceimagewithaclearobjectanda accuratelygroundorfollowinstruction.\\ntargetimagecontainingmultipleelements. Themodelmust\\nlocatethereferencedobjectinthetargetimage. C.MGrounding-630kDataCurationDetails\\n(2)RegionLocating. Modelsaretaskedwithidentifying\\nC.1.TransformingExistingData\\nmultipleregionimageswithinasourceimage,whichoften\\nrequiresperceptiveanddiscerningobservationasthemodel Static Diff Describing the differences of the two nearly\\nmayencounterpersonrecognition,similarobjectdistinguish- samepicturesisawelldiscussedtopic,yettheyfocusonthe\\ning,tinyitemsearchingandetc. coarse-grainedsemanticfeature,failingtopreciselyrecog-\\n(3)ObjectTracking. Thistaskinvolvestrackingatarget nizethepartofdifferences. Aftercomprehensivesurveyon\\nobjectacrossasequenceofvideoframes. Theobjectishigh- thisarea,wehavecollectedhigh-qualityandfullylabeled\\nlightedwitharedboundingboxinthefirstframe,andthe imagedifferencedatafromSpot-the-diff[16],Img-diff[18],\\nmodelmustfollowitthroughoutthesequence. MagicBrush[50]andCLEVR-change[32].\\n(4) Multi-view Grounding. Here, the model must locate Duringtheconstructionprocess,weensurethediversity\\nthe same target object across multiple images taken from ofthecontentby(1)incorporatingnumerouspromptformats\\ndistinctviewpoints. generatedbyGPT-4,(2)constructingCoTprocesstoassist\\n12the model gradually and progressively reaching the final advantageofthesingleimageGranDrecandregconversa-\\nanswer,whilealsofullyutilizingtheannotationavailablein tiondata[34]withthequantityof3M.Withfurtherfiltering\\nthedataset. andcombining3-5imagespergroup, wefinallyobtained\\na collection of 12w high-quality training data for stage-1\\ntraining(groundinginjectiontraining),whichiseffectivelyat\\nCommonObjectGrounding Recognizingandgrounding\\nenhancingtheco-referenceandimage-levellocatingability\\nthemaincommonobjectinmultipleimagesisaninterest-\\nofmodels.\\ning yet non-trivial task for models, which firstly requires\\nthemtosimultaneouslookatmultipleimages,disentangle\\nthecommonobject,thenfinallygroundingthetargetobject RegionLocating Regionlocatingreferssplittingseveral\\nineverysingleimage. Wetakediversedatasourcesfrom piecesofsemantic-richregionfromthesourceimageand\\nImageNet[6],COCO[26]andObjects365,wheretheanno- thenrecognizetheexactlocationofthisregionimageinthe\\ntationsareabundantandrich. Throughtheirannotations,we sourcepicture. Toguaranteeextractingmeaningfulregions,\\ngrouptheimagesthatsharethesameobjecttogetherwitha weutilizetheObjects365datasetandextractthebounding\\nthresholdoftheproportionittakesforthewholeimageto boxareaastheregions. Tofurtherimprovequality,weseta\\nfilterouttootinyobjects. Weempiricallyfindsuchthresh- seriesoffilteringmechanism:(1)contentrichness: weselect\\noldeffectiveateliminatingambiguitywheretherecouldbe theimagesthathavemorethan10boundingboxannotations\\nmultiplecommonobjectcandidates,whichresultsinclear to avoid too plain or simple cases. (2) aspect ratio: we\\nanddefinitetrainingexamples. Wefurtherreduceambiguity keeptheaspectratiobetween0.5-2toavoidtheexcessively\\nby skipping inappropriate classes where there are always thinboundingboxareasthatmodelsmayfailtoeffectively\\nmultiple possible candidate such as couch, dinning table, tackle. (3)size: wekeeptheregionratioofthewholeimage\\nkeyboardandetc. between0.2-0.49andanabsolutepixelsabove2000toavoid\\nexcessivelytinyandobscureregionimages. Noticeably,due\\nto ourmeticulously craftedmechanism andthe feature of\\nObjectTracking Theoriginalobjecttrackingemphasize\\nthistask,theresultingtrainingdataencompassesthecases\\nmoreontrackingthetargetobjectinavideosequence,which\\nofpersonrecognitioninthesourceimage,analogousobjects\\nresembleswithmulti-imagesequences. Asawelldiscussed\\ndistinguishingandtinydetailsrecognitionthatarenon-trivial\\ntopic,weselectthelargescaleTrackingNet[31],LaSOT[8],\\nevenforhuman.\\nGOT-10K [13] and MOT-2017 [30] datasets as our data\\nsources. Duringthedatasetconstructionprocess,wehave\\nC.2.SynthesizingFree-formMIGData\\nsimplifiedtheoriginallongsequenceto4-6imagepertrain-\\ningexample,maintainingitsoriginalcorefeaturewhilekeep- ThealgorithmforCLIPadaptivesimilarityimageinputis\\ningefficiency.Foreachimage,weextractthekeyframewith showninAlgorithm1. Wefurtherdisplayourprompttem-\\nanappropriateintervaltoensuretheobviousmovementof plateforimagecaptiongeneration,boundingboxlabelrefine-\\nthekeytarget. Wealsoinvolvesmallproportionoftheor- mentandinstructiontuningdatagenerationinthefollowing\\nderingjudgeforcontinuousimagestoenhancethemodel’s pages.\\ntemporalunderstandingability. Specifically,wedeployQwen2-VL-7Bfordetailedim-\\nagecaptiongenerationandQwen2-VL-72Bforbboxlabel\\nrefinement. The inference process is accelerated through\\nReferring Grounding This part of training data is de-\\nvLLMframework[21].\\nsignedtoimitatefindingtheobjectofthesourceimagein\\nthetargetimage. WemainlyutilizetheImageNet-2012sub-\\nD.DetailsofTwo-StageTraining\\nsettoconstructimagepairs,withthefirstonetakinglarge\\nproportionofthewholeimage,andthesecondonecontain-\\nThissectionoutlinesthedataproportionsandtheirrespec-\\ning smaller target object that may take efforts to spot. In\\ntivesourcesforthetwotrainingstages, assummarizedin\\ntotal,thereferringgroundingdatasetcoversawiderangeof\\nTable10.\\nobjectsthatisbeneficialforthemodeltogeneralize.\\nIn stage 1, we leverage both single-image and multi-\\nimage datasets encompassing general understanding and\\nGroup Grounding Conventional visual grounding is grounding tasks to comprehensively enhance the model’s\\nmostlylimitedtosingleimagecontext,whileinrealworld capabilities. At this stage, the stage-1 subset from\\nscenario,weoftenneedtorecognizethetargetobjectfrom MGrounding-630kconstitutesthelargestportionofthetrain-\\namessypilesofpictures. GroupGrounding,whichlocates ingdata,withatotalof530kexamples. Thetotaltraining\\nthetargetamongagroupofdifferentimages, istheexact examplesforstage-1is1million.\\ntasktofillinsuchgapandenrichtheversatilityoftraditional Instage2,thefocusshiftstostimulatingthemodel’sfree-\\ngrounding. When constructing this part of data, we take formMIGabilitiesbyintegratingallfree-formgrounding\\n13TrainingMethods Referring ObjectTracking GroupGrounding Region StaticDiff CommonObject\\nBase 23.23 20.73 58.52 25.95 27.84 19.36\\nMulti-TaskLearning 60.00 61.65 62.28 57.95 55.68 81.37\\nSeparateLearning 69.70 74.55 63.13 65.42 68.94 79.53\\nModelMerging 60.61 50.00 64.53 18.95 29.92 65.44\\nTable7.Comparisonbetweendifferenttrainingmethods.Wecomparethelearningefficiencybetweenmulti-tasklearning,separatelearning\\nandmergingallthesetask-specializedmodes.Wemainlyfocusonthein-domaintasksthatM-Groundingdatasetcovers.\\nModels Settings CommonObject Multi-viewGrounding ObjectTracking RegionLocating\\n— RandomGuess 26.47 1.04 2.13 0.00\\nQwen2-VL-7B Polling 19.96 11.83 20.73 25.95\\nQwen2-VL-7B All 19.36 6.60 13.09 11.80\\nMigician Polling 81.99 44.44 61.09 59.65\\nMigician All 72.43 43.06 58.55 34.91\\nTable8.Comparisonofdifferentansweringforms.Forrandomguess,wesetthedefaultansweras(0,0),(999,999).\\nAlgorithm1CLIPAdaptiveSimilaritySelection andmostlyunsatisfactoryininstructionfollowing,failingto\\nRequire: Images I, adaptive selection range k, thres ∈ objectivelyreflectingtherealgroundingabilityofthemodel.\\n(0,1) Considering current model’s feeble performance, we\\nEnsure: FinalImageSetF transform from directly generating all answers to polling\\n1: InitializeF←∅ everysingleimage,whichfacilitatesdefiniteandobjective\\n2: ExtractF I ←FeaturesofI evaluation. Empirically,directlygeneratingallthebounding\\n3: whileF I isnotemptydo boxcoordinatesforallimagesresultsinlowerperformance.\\n4: Randomlyselectthres∼Uniform(0.1,1) YetasillustratedinTable8,Migicianstilldemonstratesgreat\\n5: foreachf i ∈F I do robustnesstothevariationofevaluationformat.\\n6: s ij =similarity(f i,f j),∀f j ∈F I,j ̸=i TheperformanceofMigicianispresentedinTable4. Al-\\n7: endfor thoughmainlytargetedatmulti-imagegrounding,Migician\\n8: Sort_S i =Sort(s ij)[1:] stillmaintainswellonconventionalsingle-imagegrounding\\n9: k ←⌊thres×(len(Sort_S i))⌋ task.\\n10: Candidates←Sort_S i[:k]\\n11: Randomlyselectr ∼Uniform(3,5) 70BScaleModels Theperformancesofthreecompetitive\\n12: Selected←Sample(Candidates,r) 70BscalemodelsareillustratedinTable9whenequipped\\n13: Appendf iandSelectedtoF with single-image CoT. The general effectiveness of CoT\\n14: Removef iandSelectedfromF I framework is tremendous, with the average performance\\n15: endwhile boost at 20 points. Yet even competitive and much larger\\n16: return F modellikeQwen2-VL-72B(58.70%)stillcan’tsurpassour\\nMigician(60.49%)inmulti-imagegrounding,demonstrating\\ngreatcompetence.\\ndatafromMGrounding-630k. Asignificantproportionof\\nstage-1dataisalsoreusedtomaintainthepreviouslylearned\\nV*-BenchImplementation Whenadaptingasinglehigh-\\nabilities. Thetotalnumberoftrainingexamplesinthisstage\\nresolution image to a multi-image setting, we require the\\nis200k.\\nmodel to first ground, then judge the attributes. We start\\nE.EvaluationImplementation bydividingtheoriginalimageintofourequallysizedsub-\\nimages. Thistransformsthesingle-imagelocalizationprob-\\nWhendirectlyrequiringthemodeltogenerateboundingbox lemintoagroupgroundingtask,wherethemodelisrequired\\ncoordinatesforeachimage,duetotheirlimitedmulti-image toperformbothimage-levelandobject-levelgrounding. The\\ngroundingabilityandinsufficientinstructionfollowingabil- modelgeneratesoutputssuchas: \"Thetinydogislocatedin\\nity, the answer obtained in this way is largely unfaithful Image-4,(346,763),(431,835).\"\\n14SpontaneousGrounding ReferentialGrounding\\nModels Difference Similarity VisualReference Textual Visual+Textual AVE\\nStatic Robust Common OT MV Region Refer GG Reason Co-Re\\n70BScaleModels\\nLLaVA-OV-72B 13.26 5.34 26.84 12.91 7.64 2.14 17.83 21.60 11.88 8.55 13.65\\nInternVL2-76B 15.91 10.64 36.40 30.73 20.83 5.74 46.46 41.28 32.67 26.50 26.72\\nQwen2-VL-72B 46.12 46.81 64.46 26.73 22.57 18.62 33.33 62.53 50.50 17.09 38.88\\nLLaVA-OV-72B 20.27 21.28 52.57 44.36 20.83 25.60 37.37 35.07 31.68 28.21 31.72\\n+CoT\\nInternVL2-76B 16.86 6.38 70.34 70.55 33.33 27.27 68.69 57.31 52.48 23.08 42.63\\n+CoT\\nQwen2-VL-72B 33.33 47.87 69.24 70.18 60.42 51.04 78.79 70.74 70.30 35.04 58.70\\n+CoT\\nTable9.PerformanceComparisonof70BscalemodelsequippedwithCoT.\\nG.CaseStudy\\nType Source Ratio\\nStage-1 We provide detailed cases comprehensively reflecting the\\nS-Understanding LLaVA-OV-data 17% free-formMIGabilityofMigicianinFigure6,7,aswellas\\nS-Grounding RefCOCOseries,Groma-Instruct 13% ourinstructiontuningdatadetailsexamplesinFigure8.\\nM-Understanding M4-Instruct[24] 16%\\nM-Grounding MGrounding-630k(Stage-1) 54%\\nStage-2\\nS-Understanding LLaVA-OV-data 9%\\nS-Grounding RefCOCOseries,Groma-Instruct 7%\\nM-Understanding M4-Instruct[24] 8%\\nM-Grounding(Stage-1) 27%\\nM-Grounding\\nM-Grounding(Stage-2) 49%\\nTable10.Trainingdataproportionfortwostages.\\nOncetheobjectislocalized,wesendonlytheidentified\\nsub-image and its corresponding region of interest to the\\nmodelforattributerecognitionandrelativerelationshipanal-\\nysis. To ensure contextual completeness, we expand the\\nextractedregionbyslightlyenlargingitswidthandheight,\\naddinganadditional50pixelstoeachdimension.\\nF.Multi-TaskLearning\\nOurwholetrainingprocessinvolvesthelearningprocessof\\nmultiple distinct tasks. How does the actual learning effi-\\nciencyaltercomparedwithlearningthesetasksseparately,\\ncantheycontributetoeachotherorcomprisetosomeextent?\\nWeconductexperimentsthatonlyexposethemodelto\\nomni-taskdatasetandtheresultsareshowninTable7. It\\nclearlyrevealstheconflictsoflearningvarioustasks,with\\nmixesmulti-tasktrainingconsistentlysurpassingomni-task\\nlearning by a huge margin. When we directly merge the\\ncheckpointsofallthesetrainedspecializedmodels[14],the\\nmergedmodelfailatexcellingatmosttasks,withtheaverage\\nperformancefallingbehindsimplemulti-tasklearning.\\n15The Christmas tree in Image-2 is located For the object presented in Image-1,\\nat (188,116),(439,635). please locate it in Image-2.\\nGround the flowers in Image-3 that shares the same color with Image-1.\\nThe purple flowers in Image-3 share the same color with the purple lights on the Christmas tree in\\nImage-1.Coordinates:(30,520),(660,830).\\nFor the object presented in Image-2, For the object presented in Image-1,\\nplease locate it in Image-1. please locate it in Image-2.\\nThe luggage in Image-1 is located The glowering towerin lmage-2 is\\nat (598,580),(844,975). located at (292,30),(406,806).\\nPlease briefly descibethe object in Image-1 at (143,70),(345,930).\\nIce cream cone with pink ice cream.\\nWhat about the object in the third image at (330,333),(667,666)?\\nIt’s sliced turkey.\\nFor the people in Image-1, at their time, which Ground the specific item on Image-1\\'s\\nobject on the table of Image-2 may help them table that can divide and split the item in\\ntravelling around the world? Image-2 into pieces.\\nThe globe on the table in Image-2 may help the The black scissors located at\\npeople in Image-1 traveling around the world. It (292,30),(406,806)could cut the pile of\\nis located at (0,208),(208,468). white paper in Image-2.\\nFigure6.Examplecasesofthefree-formmulti-imagegroundingabilityofMigician.\\n16PromptTemplateforSingle-ImageCoT\\nTask:Staticdiff\\nStep-1:Comparethesetwoimagescarefullyandtellmewheredoestheydiffer.Pleaseanswerbrieflyinsinglephraseorwords.\\nStep-2:Accordingtotheobjectdifference/change:[RESPONCE],pleasegroundthisdifferencewithboundingboxcoordinates.\\nTask:Robustdiff\\nStep-1:Comparethesetwoimagescarefullyanddescribetheprominentdifferentobjectwithreallysimplewordsorphrase.\\nStep-2:Nowgroundtheobjectdifference/change:\"[RESPONCE]\"withboundingboxcoordinates.\\nTask:ReferringGrounding\\nStep-1:WatchcarefullyandbrieflydescribetheobjectintheImage-1.\\nStep-2:Pleasefindandgroundtheobject<|object_ref_start|>[RESPONCE]<|object_ref_end|>withboundingboxcoordinates.\\nTask:CommonObject\\nStep-1:Theseimagesshareoneobjectincommon.Recognizeitandtellmeitsnameinsinglephraseorwords.\\nStep-2:Pleaselocateandgroundthetargetobjectaccordingtothereference:<|object_ref_start|>[RESPONCE]<|object_ref_end|>\\nTask:RegionLocating\\nStep-1:DescribethecontentoftheXXXthpicturewithsimplephraseorwords.\\nStep-2:Pleasegroundtheobject<|object_ref_start|>[RESPONCE]<|object_ref_end|>withboundingboxcoordinates.\\nTask:Multi-View\\nStep-1:Describetheobjectinthefirstimagemarkedwithredboundingbox(<|box_start|>(A,B),(C,D)<|box_end|>)withsimple\\nphraseorword.Youcanrefertootherimagesformorepreciserecognitionanddescription.\\nStep-2:Locateandgroundtheobject<|object_ref_start|>[RESPONCE]<|object_ref_end|>withboundingboxcoordinates.\\nTask:ObjectTracking\\nStep-1:Describetheobjectinthefirstimagemarkedwithredboundingboxwithsimplephrase.\\nStep-2:Nowgroundthetargetmovingobject[RESPONCE]withboundingboxcoordinates.\\nTask:GroupGrounding\\nStep-1:Justrecognizeandtellmewhichimageisitin.Answerfrom:Image1|Image2|Image3...\\nStep-2:[SelectedImage]+[OriginalQuestion]\\nNote:Forgroupgrounding,thesingleimageatstep-2isselectedbymatchingtheanswerfromstep-1.Iftheframeworkfails\\ntoextractthetargetimage,wesendthefirstimagebydefault.\\nTask:Reasoning\\nStep-1:[OriginalQuestion]+NamethisobjectintheImage-2withsimplephrase.\\nStep-2:Pleaselocateandgroundtheobject<|object_ref_start|>[RESPONCE]<|object_ref_end|>withboundingboxcoordinates.\\nTask:Correspondence\\nStep-1: For the first image, describe the semantic/functional feature of the area marked by the red bounding box\\n(<|box_start|>(A,B),(C,D)<|box_end|>).\\nStep-2:Groundtheareathatsharesthesamesemanticorfunctionalmeaningof:[RESPONCE].\\nFormatPrompt\\nFormat:<|box_start|>(x1,y1),(x2,y2)<|box_end|>.Don’tgenerateadditionalwords.\\nNote:wedeploythispromptforbetterinstructionfollowing.\\n17Focus on three objects: Image-1 (500,500),(700,834), Image-2 (0,0),(579,486), Image-3 (283,500),\\n(612,795). Please briefly describe them.\\nImage-1: Ferris wheel in the distance.\\nImage-2: A colorful carousel with people riding on it.\\nImage-3: A large bed in the center of the room with a white comforter.\\nGood, now based on all these objects, please compose a detailed and compelling story about our\\nhappy trip today.\\nWe had a great time at the amusement park today. We started by enjoying the Ferris wheel, which\\noffered a great view of the park and the surrounding area. Then we moved on to the carousel, where\\nwe had a lot of fun. Finally, we go back home to sleep on the cosy bed. Overall, it was a perfect day\\nat the amusement park.\\nIn Image-2, please ground the bottle shares the similar shape\\nwith those in image-1, except its color is dark purple.\\nThe tall wine glass filled with red wine (258,100),(470,838).\\nFor the object marked with red box in Image-1, please locate in the\\nlast image.\\nThe basketabll is located at (695,58),(743,130)\\nGiven a source image followed by its several regions. Please\\nrecognize and ground Image-2 in the first image.\\nBlack gloves (811,629),(951,999).\\nGiven a source image followed by its several regions. Please\\nrecognize and ground Image-1 in the second image.\\nRed chair (398,442),(669,871).\\nFigure7.Examplecasesofthefree-formmulti-imagegroundingabilityofMigician.\\n18Q: In Image-1, the dark-colored classic racing car has a large white circle with the number \"1\" on the front.\\nCan you find a similar numerical marking on any of the cars in Image-2? If so, where is it located?\\nA: In Image-2, the vintage white convertible car has a blue and white rally plaque with the number \"16\" on\\nit. The coordinates for this plaque are (178,302) to (912,776).\\nQ: Image-3 features a white sports car with a sign on the front bumper reading \"911 Carrera S.\" Is there a\\nsimilar sign or label on any of the cars in Image-1? If so, what does it say and where is it located?\\nA: In Image-1, there are no signs or labels on the cars that are explicitly mentioned. However, there are\\ninformational signs and banners around the area, including one prominent banner that reads \"MONTE\\nCARLO RALLY.\" The coordinates for the vintage sports car in the background are (0,255) to (466,598),\\nbut the specific sign is not detailed in the provided information.\\nQ: In Image-2, the vintage white convertible car is being driven by a person wearing glasses and a hat. Can\\nyou identify a person wearing a hat in Image-4? If so, where is the person located?\\nA: In Image-4, there is a person wearing a hat located at coordinates (561,213) to (676,330). The hat itself\\nis located at coordinates (565,211) to (607,284).\\nQ: In Image-1, there is a red bottle on the countertop located at (906,717) to (931,851). Can you find a\\nsimilar object in Image-3, and if so, provide its bounding box coordinates?\\nA: In Image-3, there is no red bottle specifically mentioned. However, there is a stack of papers and books\\non the desk located at (0,753) to (224,932). While it\\'s not a bottle, it is another object that could be\\nconsidered similar in the context of a workspace.\\nQ: In Image-4, there is an old, rusted sedan located at (7,285) to (965,700). Can you find a vehicle in\\nImage-2 that contrasts sharply with the state of this car, and provide its bounding box coordinates?\\nA: In Image-2, there is a large white coach bus with the name \"CARADOC\" on its side and front\\ndestination sign located at (133,186) to (719,821). This bus is clean and well-maintained, contrasting\\nsharply with the neglected and rusted sedan in Image-4.\\nQ: In Image-2, there is a tall building with a modern architectural style featuring large glass windows and\\na sleek facade located in the background. Can you find a building in Image-4 that contrasts with this\\nmodern style, and provide its bounding box coordinates?\\nA: In Image-4, there are several houses in the background at (20,208) to (980,330) with various\\narchitectural styles, including some with gabled roofs and others with flat roofs. These houses, located in\\nthe background, contrast with the modern building in Image-2.\\nFigure8.TrainingExamplesofthefree-forminstructiontuningdata.\\n19PromptTemplateforCaptionandInstructionDataGeneration\\nBboxRefinementTemplate\\nNowI’dlikeyoutoinspecttheoriginalimagecarefully.Thenfilter,refineandenhancetheseannotatedobjects.Finally,justgive\\nmeyourfinalmodifiedannotations.\\n*Filtering*\\nBasedonyouinsightfulobservationoftheimage,pleaseeliminatetheobviouslyinaccurate(object,bbox)pairs,whichinsupposed\\ntobesmallinquantity.\\n*Refine*\\nRefine and enhance the original class/name of each object into a short yet richer caption containing its attributes\\nlike color, position, feature(e.g plane <|box_start|>(x1,y1),(x2,y2)<|box_end|> -> dark gray plane flying in the sky\\n<|box_start|>(x1,y1),(x2,y2)<|box_end|>).\\n*Amplify*\\nIfanyimportantobjectsaremissingfromtheannotations,andyoubelievetheyaresignificantandessential,andyouareconfident\\noftheirlocation,feelfreetoaddthemtothefinalannotations.\\n*OutputFormat*\\nModifiedobjectcaptionfollowedbyitsboundingboxcoordinates.\\nNowtheoriginalboundingboxannotationsIgivetoyouare:\\nCaptionGeneration\\nDescribethisimagethoroughlyinafluentparagraph. Includealltheobjectsandtheirattributes(color,shape,sizeandfeature),\\nrelativepositionandrelationship.\\nMulti-imageGroundingInstructionGeneration\\nTemplate1\\nBased on the following detailed information of multiple images, please compose meaningful and flexible CROSS-IMAGE\\ngroundingquestionsthatlinkdifferentobjectsacrosstheimagesbytheirattributessimilarity/contrast—suchascolor,position,\\nfeatures,gender,size,shape,etc.—orbyotherpotentiallogicalconnectionbetweenthem.\\nSpecifically:\\n1.The questions should include CROSS-IMAGE grounding requests that requires the answer to identify and locate various\\npotentiallyconnectedobjectacrossdifferentimages.Youcanusetheconnectionorsimilaritybetweentheseobjectstoreferthe\\ntargetitem.\\n2.When referring an object in the question, keep the reference description concise and avoid giving away unnecessary\\ninformation(likebboxorover-detailedcaption)thatcouldleadtoansweringtooeasily. Youareencouragedtoreferthetarget\\nobjecttobegroundedbytheconnectionoftheseobjects,insteadofexplicitlypointouttheobject.Forinstance:“groundthecarin\\nimage-2thatcontrastsmostinqualitywiththeshabbyvehicleinimage-4”,ratherthan“groundthefancyredsportscar(explicitly\\npointingout)inimage-2thatcontrastsmostinqualitywiththeshabbyvehicleinimage-4”,bydoingsowecanalsointroduceabit\\nreasoningprocess.\\n3.Includetheboundingboxcoordinatesofreferredobjectintheansweraswellastheexplanation.(Actuallyyoucangetalotof\\ninformationfromthecoordinates,whichareformattedas(x1,y1),(x2,y2))\\n4.StrictlyformattheoutputassimpleQ:A:.Inanswer,followtheformat<ref>object</ref>forobjectsmentioned.\\nBelowarethedetailedimagecaptionsandtheobjectsinthecorrespondingimages:\\n20',\n",
       " 'Model Checking in Medical Imaging for Tumor Detection and Segmentation.pdf': 'Model Checking in Medical Imaging for Tumor\\nDetection and Segmentation\\n1st Elhoucine Elfatimi* 2nd Lahcen El Fatimi\\nDepartment of Pathology Laboratory Medicine Department of Computer and Software Engineering\\nUniversity of California Polytechnique Montreal\\nIrvine, CA, USA University of Montreal, Montreal, QC, Canada\\neelfatim@uci.edu lahcen.elfatimi@polymtl.ca\\nAbstract—Recent advancements in model checking have\\ndemonstrated significant potential across diverse applications,\\nparticularly in signal and image analysis. Medical imaging\\nstands out as a critical domain where model checking can be\\neffectively applied to design and evaluate robust frameworks.\\nThese frameworks facilitate automatic and semi-automatic de-\\nlineation of regions of interest within images, aiding in accurate\\nsegmentation. This paper provides a comprehensive analysis of\\nrecent works leveraging spatial logic to develop operators and\\ntools for identifying regions of interest, including tumorous and\\nnon-tumorous areas. Additionally, we examine the challenges\\ninherent to spatial model-checking techniques, such as variability\\nin ground truth data and the need for streamlined procedures\\nsuitable for routine clinical practice.\\nIndex Terms—Model Checking, Segmentation, medical images,\\ntumor.\\nI. INTRODUCTION\\nModel checking is the process of verifying whether a given\\nstructure satisfies a specified logical formula. This concept is\\ngeneral and applies to a wide range of logics and system\\ndesigns. A fundamental model-checking problem involves\\ndetermining whether a propositional logic equation is satisfied\\nby a given structure. Model checking is most commonly\\napplied to hardware designs. For software systems, due to\\nundecidability, the methodology cannot be fully algorithmic\\nand may fail to either prove or disprove a given property.\\nModel checking plays a critical role across various applica-\\ntions, serving purposes such as ensuring the correctness of\\nsystem properties and minimizing errors in software under Figure 1: A typical model-checking workflow\\ndevelopment. Traditional model checking typically consists of\\nthree major steps: Model checking has numerous applications, particularly in\\n• Formal Model of the System: This step involves creating medical image analysis, such as image segmentation, con-\\na formal representation of the system in a language touring, filtering, and classification. These computations are\\ncompatible with the model checker’s requirements. closely tied to the spatial features of images. For example,\\n• Specification of System Properties: A specific property of computer-aided diagnosis focuses on classifying specific areas\\nthe system is defined for verification. This translates into in an image that may correlate with a disease [1]. Similarly,\\na question about the system’s behavior that the model image segmentation aims to identify regions within an image\\nchecker is expected to answer. that exhibit specific features [2], such as tumors or lesions,\\n• Verification by the Model Checker: The model checker depending on the application. Another approach involves\\nevaluates whether the specified property is satisfied. If the forming contours around target areas corresponding to organs\\nproperty cannot be verified, a counterexample is gener- at risk, commonly used in radiotherapy [3]. Indicator-based\\nated to identify the source of the error in the simulation schemes are also employed to compute metrics from images,\\nmodel. aiding diagnostic procedures and enhancing understanding ofdisease-specific characteristics. These indicators can also be associated algorithms, with an emphasis on their reliability\\nextended to monitor treatments and predict outcomes [4], with and dependability.\\nmean diffusivity serving as one such example [5]. The extensive review in [17] highlights model-checking\\nThis review paper aims to comprehensively understand technology as a powerful approach for the automatic verifica-\\nand assess prior research on model checking in medical tion of hardware systems. The authors identify other applica-\\nimaging, with a primary focus on segmentation-based ap- tion domains, translating verification problems into appropriate\\nproaches. Medical imaging encompasses multiple modalities, model-checking questions. Additionally, [17] introduces a tax-\\nwith magnetic resonance (MR) imaging being qualitatively onomy of models, properties, and model-checking approaches.\\nassessed in clinical and routine settings. Typically, image In [18], the formal verification of statecharts using model\\ncontrast serves as a marker for the presence of hyperintense checking is reviewed. A key observation in this work is the\\ntissue [6]. Manual segmentation of regions of interest is reliance of many statechart approaches on translating hierar-\\nlabor-intensive, time-consuming, error-prone, and subjective. chical structures into flat representations of the input language,\\nTo address these limitations, automatic and semi-automatic which poses scalability challenges due to exponential growth\\nsegmentation algorithms have been developed. These methods in the state space.\\nare more accurate and reliable for isolating tumorous regions Model checking for programmable logic controllers (PLCs)\\nin images, as they are independent of human judgment and is comprehensively reviewed in [19], which highlights the\\nare reproducible [7]. importance of real-time functionality in production settings.\\nBrain segmentation, particularly in neuroimaging, has Verification of PLC software using model checking is deemed\\ngained significant attention and has become an active area of critical in these scenarios. A theoretical overview by [20] ex-\\nresearch [8]–[12]. Segmentation methods are generally cate- amines the practical applications of model-checking schemes\\ngorized into generative models and discriminative models [6]. for verifying multi-threaded software systems, with a focus on\\nGenerative models rely on domain-specific knowledge about the automata-theoretic method of verification and its associ-\\nbrain tissue appearance and anatomy, while discriminative ated challenges. Additionally, [21] surveys automata-theoretic\\nmodels depend on extracting numerous low-level features, approaches, focusing on the verification of probabilistic finite-\\nsuch as local histograms or texture patterns [6]. state systems concerning linear-time properties.\\nThe core principle of segmentation is to exploit intensity Symbolic model checking is the subject of a detailed\\nand texture variations among pixels [13]. This principle un- review in [22], which discusses critical system design and\\nderlies various semi-automatic and fully automatic segmenta- model-checking techniques within the domain of information\\ntion techniques, including thresholding, region-growing, and sciences. The review by [23] explores the verification of web\\nclustering. Hybrid methods that combine these techniques are services using model checking, providing insights into data\\nalso common. Examples of semi-automatic methods include flow, requirements, and quality of service. This systematic\\nsupport vector machines and neural networks, while automated review encompasses fifteen years of literature on web service\\ntechniques represent the current gold standard [6], [11], [14]. verification. Finally, [24] reflects on the authors’ experiences\\nAutomated brain tumor segmentation faces challenges due applying model checking to verify the arbitration logic of a\\nto the reliance on luminosity differences between tumorous vehicle control system, identifying strengths and limitations of\\nand normal tissue pixels. These variations introduce complex- different model-checking techniques and tools.\\nities for automated systems and are further exacerbated by\\nA. Spatio-temporal Model Checking for Medical Imaging\\ninter- and intra-expert variability in manual segmentation [6].\\nAdditionally, differences in imaging modalities and patient The application of model checking frameworks in a spatial\\ndata contribute to these challenges. setting for medical imaging is a relatively new area of research,\\nThe remainder of this paper is organized as follows: Section as evidenced by the limited number of publications in the field.\\nII reviews related work. Section III outlines the methodology. However, the existing works, though few, are comprehensive.\\nResults and discussion are presented in Section IV, followed For tumor detection, machine learning has been utilized to\\nby the conclusion and future work in Section V. extract image features and validate them using spatio-temporal\\nmodels [25], [26].\\nII. RELATED WORK\\nIn [27], spatio-temporal meta-model checking was em-\\nA substantial body of literature explores model checking ployed for analyzing biological processes, with a strong em-\\nas a technique for various applications. In [15], the authors phasis on multi-scale aspects.\\nprovide a comprehensive survey and historical account of When it comes to fully automated approaches, machine\\nalgorithmic requirements for directed model checking. Their learning-based techniques, particularly deep learning, have\\nwork covers a wide range of topics, including bug-hunting had a profound impact. Deep learning is highly effective\\ntechniques to mitigate the state explosion problem, prioritiza- in modeling the non-linearities inherent in data to derive\\ntion of successor selection, and the adaptation of algorithms meaningful insights [28].\\nto time-based automata and probabilistic domains. Similarly, For in vivo images, manual segmentation remains a standard\\n[16] focuses on algorithmic verification in probabilistic model practice [13]. However, it has several disadvantages. Man-\\nchecking, discussing various probabilistic models and their ual segmentation demands significant focus and time fromclinicians, making the process labor-intensive and expensive. characteristics in brightness, color, or size [35]. Texture-based\\nAdditionally, it requires a high level of expertise and is prone schemes are widely used in medical imaging [36], proving\\nto subjectivity, resulting in variability among clinicians and instrumental in diagnosing prostate cancer [37] and analyzing\\nintroducing errors into the pipeline [13]. tumor heterogeneities [38].\\nWhile machine learning and deep learning approaches have\\nB. Techniques used with model checking for analyzing the\\ndemonstrated remarkable success in detection, classification,\\nmedical image\\nand pattern recognition tasks, their effectiveness heavily de-\\npends on the quality and reliability of datasets. These frame- Many techniques are used with Model Checking in the\\nworks often require large datasets capable of capturing suf- analysis of medical images, the most important of which\\nficient variability. The strength of deep learning lies in its is Texture analysis, which has also found its application in\\nability to extract features across multiple layers of raw data dynamic contrast-enhanced MRI of breast imaging for the\\nand make meaningful inferences. However, employing these detection of and segmentation of malignant lesions [39]. In\\ntechniques in a supervised framework necessitates ground truth addition to that, there is extensive work on computer-aided\\nlabeling of the data, which introduces challenges. Ground diagnosis and segmentation using texture-based analysis [40],\\ntruth annotations rely on clinicians’ interpretations, making including diagnosis of pulmonary nodules [41]. Classification\\nthem subjective and variable among annotators. A study [13] and segmentation using texture-primitive features in medical\\nreported intra-expert and inter-expert variability of up to imaging have historically been an area of in-depth exploration.\\n35% and 30%, respectively, in manually segmenting tumor Extensive works of [42], [43], [44] have demonstrated the use\\nregions in brain MRI images [29]. Consequently, there is a of texture analysis for classification.\\nneed for interactive model-checking methods to improve the Texture analysis requires that the image textures be charac-\\nreproducibility and efficiency of ground truth generation. terized by some quantitative measure. For that reason, certain\\nSpatio-temporal model checking is still a nascent area of descriptors are estimated to quantify these textural features\\nresearch with limited literature available. Nonetheless, certain [34]. A typical classification of these types of features includes\\nstudies are noteworthy. For example, [30] implemented a syntactic, spectral and statistical [36].\\nspatial extension of signal temporal logic, which is linear In [34], the authors focused on first order statistical features\\nand time-bounded, to provide a framework for stochastic primarily which entails extracting certain statistical descriptors\\npopulation models. This framework is particularly suitable for from the distributions of features of each voxel. These first-\\nscenarios where agents can move within a discrete spatial order statistical features mainly consisted of statistics based on\\nrepresentation. Signal temporal logic employs a graph-based probability density functions of the intensity of voxels in the\\napproach with finite cost-based weighted connections and a image. These could then be estimated as histograms by binning\\nsingle spatial operator [13], similar to the operator intro- voxels values of the same intensities. Statistical features on the\\nduced in [31]. Subsequent extensions, such as the bounded first order include the mean, variance, skewness, kurtosis, and\\nsurrounded operator, enhanced the framework by adding new entropy [45]. The advantage of using these statistical features,\\nrequirements, building on previous work [32]. In [33], this specifically in medical imaging is that they are invariant to\\noperator was further characterized as a derivation from a basic transformations of the image. By construction, these first-order\\noperator. statistical operators are invariant to affine transformations that\\nIn [34], the author proposed an alternative approach by consist of rotation and scaling. This kind of transformation is\\nintegrating spatial, statistical, and algorithmic frameworks critical in medical applications due to the variance involved\\ninstead of relying solely on spatial logics. This approach in different image acquisition conditions. However, while this\\nintroduced distance and texture operators alongside spatial variance of first-order statistical descriptors is plausible, they\\noperators. Distance operators are often defined using real also have a critical limitation which is their lack of spatial\\nnumbers and specific semantics. One example is the ’doughnut coherence. The features assume a degree of independence\\noperator,’ which meets distance constraints between two limits. by ignoring the relative spatial placement of the voxels in\\n[34] also explored quasi-discrete closure models defined by the image. In the experimentation done in [34], the authors\\nbinary relations on a set of points, proposing the inclusion defined a logical operator to compare the areas of the image\\nof distance operators to address the lack of distance infor- with a degree of statistical similarity to a pre-determined area.\\nmation. In medical imaging, distances are typically based The idea is to search for sub-areas in the image with an\\non Euclidean metrics or symmetric graphs. The concept of empirical distribution similar to the predetermined area. For\\nshortest path distances in weighted graphs is intuitive and that purpose, some surrounding areas are also considered and\\nuseful. Other approaches involve sampling spatial grids, such a threshold is applied so as to obtain a Boolean value that\\nas two-dimensional spaces with four or eight neighboring confirms the voxel’s statistical similarity to the sub-region.\\nconnections. However, variations in voxel dimensions pose A measure for comparison for a statistical distribution used\\ninherent challenges in medical imaging. is cross-correlation [34]. As a result, the authors generalize\\nTexture analysis operators are designed to detect and an- the classical texture analysis making use of some spatial\\nalyze patterns in medical images, many of which are im- information owing to the examination of neighborhood distri-\\nperceptible to the human visual system due to their subtle bution when investigating a particular voxel. The frameworkis implemented by the authors on an MR image slice of a patterns are key in identification of spatial structures of [48].\\nbrain affected by glioblastoma tumor [34]. In [13], the authors The images are conveniently described by their voxels. In [48],\\nproposed an approach for segmentation based on a spatial the authors investigate the feasibility of a technique that is\\nlogic method. The goal was to identify a region of interest based on spatial logic for closure spaces for the analysis of\\nin MR images for the analysis of glioblastoma as well as nevi images from a public data set. The authors show that\\nother tumors. The authors employed a texture-based method despite the in homogeneity in the nature of nevi, ranging\\nalong with local histograms to create a hybrid approach for from variance in shape, color, texture, and size to inclusion\\nsegmentation, maintaining relative spatial information. This is of extraneous elements like rulers, patches, and hair, the\\nprimarily inspired by a topological approach interwoven with authors were able to demonstrate the analytic ability in a\\nspatial logic. semi-automatic way. This is credited to the intrinsic rigor of\\nIn this domain of research, works of [32] and [46] have a logic-based approach, utilizing the efficient implementation\\nbeen significant as they developed the theory to enhance the of spatial model-checking algorithms. The comparison is then\\nuse of arbitrary graphs as models of space, particularly by drawn against the ground truth that is provided along with the\\nutilizing a generalized form of topological spaces model called public dataset. The dataset used is the one provided by the\\n’closure spaces’ [47]. As a consequence of this, the spatial Skin Lesion Analysis toward Melanoma Detection challenge\\nlogic for closure spaces was formally defined along with a 2016 [53]. The composition of the data set includes high-\\nmodel-checking algorithm associated with it. resolution annotated dermoscopic images. The ground truth\\nAnother important application of model checking in medical segmentation data is done manually by the experts and are\\nimaging is the contouring of nevus images. Nevus is a visible, separately available as ground truth mask images.\\ncircumscribed lesion of the skin. Typically, it is small and [48] also reports variance not only in the different nevi but\\nbenign. However, these are very difficult to distinguish from also within one nevus. The change of texture and color within\\nthe malignant counterpart [48] which is medically known as a nevus poses a great segmentation challenge. This is even\\na melanocytic nevus. Melanoma is an advanced form of this more complicated with the presence of any sebaceous follicle.\\nand is a serious form of skin cancer. As with most types of Since the inter and intra variations in the nexus pose a great\\ncancers, this too requires early detection and diagnosis for challenge in segmentation, the approach is then tailored to\\neffective disease management and treatment. In the case that focus primarily on the differentiation between any type of\\nmelanoma is not recognized at an early stage, it can become nevus tissue and skin tissue. This is done with the help of\\nlethal and life-threatening. Reportedly, there are over 20,000 texture analysis as well as spatial operators so as to isolate\\ndeaths due to melanoma in Europe each year [49]. Another the nevus tissue from the skin tissue. To that end, the authors\\ncritical factor that is the number of biopsies needed. This employ a statistical texture analysis operator to approximate a\\nnumber can be cut down if automated systems are present to nevus. This is done by using a statistical heuristics approach\\ndetect and diagnose melanoma. In the work of [48], the authors to distinguish between background skin and likely parts of\\nfocused specifically on the contouring of the 2D images of nevus. There is an underlying assumption that the likely part of\\nnevi. This is generally considered to be a challenging problem nevus is centered in the image so that the area at the periphery\\nsince there is a lot of homogeneity in the texture, size, color, of the image belongs to the background healthy skin cells\\nand shape of the nevi. Adding to the variance of the types [48]. This allows for the algorithm to take a sample of the\\nof nevus, there are often extraneous elements that include background. Here, only the intensities are considered while\\npatches, rulers, or hair. In [48], the authors take up this hue or saturation is ignored. Using these intensities only, a\\nchallenge by leveraging texture similarity operators along with histogram of the distribution of intensities is computed with a\\nspatial logic operators. Altogether, the feasibility of such a suitable number of bins. While there is a global histogram, one\\ntechnique on the dermoscopic images from a public database that takes into account all the pixels in the image, a smaller,\\nis investigated in [48]. Usually, in the diagnosis of melanoma, more localized histogram is also constructed for each pixel\\nsegmentation of nevi is considered a part of the overall bigger where intensities of surrounding pixels in a specific radius\\nproblem. In the literature, [50] [51] [52] [13], there is evidence are considered. Comparison of these local histograms with\\nthat techniques that include automatic contouring with spatial the global histogram in the form of a Pearson correlation\\nmodel checking for brain tumors have in fact shown quality coefficient allows for a comparison of the nature of the\\ncomparable to the current state of the art. However, in the localized areas. This texture operator serves as a good first\\ncase of nevi segmentation and model checking, the additional approximation method to identify the area covered by the\\nchallenges make it relatively complex, largely due to the nevus. However, this is still an approximation and requires\\noptical effects that are associated with it. For instance, the adjustments to be made, which are subsequently performed\\ntype of lesions and contrast and the variance within the types using derived operators with metrics like relative distance\\nof lesions. and similarity indexes. The spatial model checking techniques\\nCertain spatial model checkers essentially utilize high-level can be used with the spatial model checking tool VoxlogicA\\nspecifications written in a logic language in order to describe developed in [51] to efficiently segment nevi. The segmenta-\\ncertain spatial properties so as to identify spatial patterns tion based on dermoscopic images is important in automatic\\nof interest in an automatic and efficient way. These spatial routines for the diagnosis of malign skin tumors includingbut not limited to melanoma. Spatial model checkers make accuracies competitive with the state-of-the-art techniques for\\nuse of high-level logic languages to identify certain spatial glioblastoma segmentation.\\nproperties. In conclusion, [48] presented a novel segmentation The authors build on the image query language(SQL) that\\nmethod to combine spatial operators, that were inspired by was proposed in [13]. This was in turn based on the spatial\\nclosure spaces, and domain-based operators such as the texture logic for closure spaces [46]. It is from [46] that the authors\\nsimilarity operator. As a result, achieving a dice score of 0.9 in [51] derive their kernel for their framework. The work in\\nvalidates the segmentation quality. One of the outcomes of [51] is closely related to the spatial logic for closure spaces\\nemploying such a technique is that it is explainable in its presented in [13], particularly with regard to the distance-\\nmethods and it is mostly high-level [48]. There is room to based operator formed therein. For the digital image analysis,\\nadvance this work by increasing the number of classes of a statistical similarity operator is used that quantifies the\\nimages for which the segmentation has shown remarkable similarity of an area around a point with that of a given region.\\naccuracy. It is pertinent to mention the scale of homogeneity This is achieved by the computation of respective histograms\\nbetween the nevi and within the nevi as well. Such variations and then finding cross-correlation between them. This operator\\nreflect artifacts in the image and pose a tremendous challenge allows checking to what extent the area around a point of\\nfor accurate segmentation. interest is statistically similar to a given region.\\nAnother operator introduced is the percentile operator which\\ntakes a numeric-value-based image and its binary mask in\\nC. The Spatial Logic Framework: VoxlogicA and SQL\\norder to return an image that shows at how each point is\\nOne of the most important frameworks for image analysis associated to the percentile rank of its intensity with respect\\nusing the model Checking is VoxLogic, which is a framework to the population voxels. This allows for the same segmen-\\nfor image processing that incorporates user-oriented expres- tation specification on images that have different intensity\\nsion languages into the logic ImgQL to edit images[51], this distributions. This also allows for avoiding the use of ab-\\ntool takes advantage of the library of computational imaging solute values in constraints on the intensity of points. In\\nalgorithms alongside distinct combinations of the declara- terms of its functionality, the VoxLogicA tool specializes for\\ntive specification to deliver optimized execution inherent to spatial analysis for multidimensional images. The pipeline\\nthe spatial logic model checking. As a consequence, the for VoxLogicA is fairly simple as it interprets a particular\\nmethodology developed is considered to be rapid. Testing this specification that is written in the image query language\\nmethodology on existing brain tumor segmentation benchmark and produces a set of multidimensional images representing\\nimages shows that the accuracy can reach the state of the art. the valuation of user-specified expressions. However, when\\nThe additional advantage is the explainability and replicability it comes to medical images, the images are boolean-valued\\nof the approach [51]. for logical operators, thus, the regions of interest may be\\nThe fundamental idea of Spatio-temporal model checking overlaid on top of the original images for better viewing. On\\nis to use the specifications in a relevant logical language in the other hand, the non-logical operators will yield number-\\norder to describe the spatial characteristics so that patterns and valued images. The tool was used in [51] for evaluation in\\nstructures of key importance can automatically be identified. two ways. First, the evaluation was done for VoxLogicA for\\nIn [51], the main focus is on medical imaging for radiotherapy, the segmentation of Glioblastoma in medical images obtained\\nparticularly, brain tumor segmentation. A challenge in this from MRI scans where the clinical target volume of the whole\\ndomain is that the tumorous regions or lesions are only defined tumor is considered. This is different from the gross tumor\\ndistinctively from the normal tissue, owing to any changes in volume which corresponds to what is actually visible on an\\nthe intensities of the pixels in the gray-scale images. This image. Secondly, the evaluation was done on the BraTS 2017\\nrelativity of pixel intensity as a marker of tumor presence dataset which serves as a quality measure of the proposed\\nmakes it a complex challenge to isolate the lesions from technique. The Dice similarity metric serves as a means to\\nnormal tissue pixels. In addition to that, there is a considerable quantify the segmentation accuracy by computing a numeric\\nvariation in the ground truth images of these segmented value for the overlap between the manually segmented ground\\nimages. This is due to the variance in the manual segmentation truth and the ones achieved by the VoxLogicA tool. The Dice\\nby the experts. When there are intensity gradients between result of 0.9 reflects the tool is sufficiently accurate [51].\\nadjacent tissue structures, the experts have shown significant The evaluation of VoxLogicA involved sets of 3D images\\nsubjectivity in the assessment of ground truth for segmenting of size 240 × 240 × 155 which is about 9 million voxels.\\ntumors [51]. This adds to the already challenging constraint Using a variant of [13] a comparison is made to assess the\\nof isolating tumors from normal tissues in gray-scale images performance of VoxLogicA and another model, topochecker.\\nbased on intensities as a metric. Furthermore, the inconsis- The specifications consist of two human-authored text files\\ntency in the data complicates things further as different MRI of about 30 lines each, identifying the oedema. The machine\\nscanners also show considerable variation in the image quality. used for testing is a desktop computer equipped with a 7th-\\nHowever, for demonstration of the approach, the authors use generation Intel Core I7 processor and 16GB of RAM. In\\nthe publicly available BraTS 2017 dataset [6] where ground the 2D case (image size: 512 × 512), topochecker takes 52\\ntruth data is available for any objective deductions; reporting seconds to complete the analysis, whereas VoxLogicA takes750 milliseconds. In the 3D case (image size: 512 × 512 × 24), tissues that have similar textural characteristics by comparing\\ntopochecker takes about 30 minutes, whereas VoxLogicA takes the similarity of the histograms of relevant regions. This\\n15 seconds. This huge improvement is due to the combination statistical similarity-based operator is a cross-correlation-based\\nof a specialized imaging library, new algorithms such as operator. This operator is also invariant to rotations which\\nstatistical similarity of regions, parallel execution, and other adds to this importance for use in spatial logic in medical\\noptimizations. applications. A demonstration on the benchmark checkerboard\\nIn [52], the focus has largely been on identifying tissues in pattern shows good performance. The authors in [52] illustrate\\nthe healthy brain. For example, the idea is to determine white the brain segmentation on two simulated images of the brain.\\nmatter or gray matter in a healthy brain. Simulated images provide the benefit of conclusive ground\\nThis is different from segmenting and identifying tumorous truths [52]. In this particular application, this is even more\\nregions in the brain as done in other studies. [52] reiterates that critical as the regions of interest in question are perfectly\\nmodel checking in medical imaging is mostly concerned with normal brain tissues; the only difference is in the nature of\\nthe creation of visual representations of parts of the human the brain tissue, such as the gray matter and the white matter.\\nbody for clinical analysis as well as preparedness for medical For quantitatively testing a method, using simulated images is,\\nintervention. A key step in radiotherapy planning includes therefore, very effective.\\ncontouring tissues and organs accurately. This, in conjunction In the above-discussed literature, the works are aimed at\\nwith automatic contouring simplifies diagnostic procedures reviewing model checking as a verification tool set in a\\nand eventually contributes to the reduction of time and cost multitude of domains. However, at the time of writing this\\nas compared to manual contouring. The automated software work, there is no review or survey that explores the specific\\nthat is used for contouring is typically highly specific in its application of medical imaging with model checking as a\\napplication, for instance, having the ability to only contour means of verification, particularly with spatial logic design.\\nthe human brain [52]. Such software offers little flexibility This paper is a first of its kind reviewing different model-\\nand transparency for the users and often does not deliver checking approaches taken to understand segmentation and\\nsatisfactory accuracy [52]. Deep learning-based approaches identification of regions of interest in medical images.\\nhave recently become popular for medical image analysis.\\nThese are computationally efficient and mostly deliver decent\\nIII. METHODOLOGY\\nresults. However, they do require sufficiently large data sets This work reviews recent research papers focusing on the\\nthat are accurately labeled by experts. Such large datasets are application of model checking in medical imaging. A compre-\\noften not available, thus, posing as a limiting factor to these hensive analysis was conducted by compiling a curated list of\\ndeep learning-based techniques. In addition to that, there is relevant studies. To achieve this, multiple web-based scientific\\ninter and intra variability between the labelers who annotate databases were accessed using keywords such as ”model\\nthe data for ground truth. In [52], the focus is on healthy brain checking” and ”medical imaging.” The review highlights key\\nimages to identify the types of tissues. The framework for the methodologies employed in these studies, particularly those\\nspatial logic utilized by [52] involves modeling a digital image utilizing model checking to validate proposed techniques.\\nas an adjacency space. This effectively means that only the Special emphasis is placed on tumor segmentation within\\npixels that share an edge are counted as adjacent. Different medical images, a prominent area of research demonstrating\\ntypes of adjacency exist due to the nature of the rules of significant potential and promise. This study aims to critically\\nadjacency. For example, an orthodiagonal adjacency scheme evaluate and synthesize findings from the most recent works\\nconsiders a pixel adjacent even if a corner is shared. Since each employing model checking for segmentation tasks.\\npixel is associated with color intensities, this can be modeled\\nfor similar pixels by using another metric called attributes. IV. RESULTS AND DISCUSSION\\nThese attributes can be passed onto an attribute function and In this section, we review the findings of some of the\\nbe used for Boolean expressions with threshold parameters. works on model checking in medical imaging and build\\nThis aids in defining a closure space. In effect, the adjacency our discussion on top of these works. An analysis of these\\nspace is a subclass of closure spaces. The closure spaces can works in the form of a compilation is also shown in this\\nbe strengthened using distance metric, thus, leading to distance section so as to discuss these works in detail. While there\\nclosure spaces. are conclusive advantages to using spatial model-checking\\nIn the work of [52], certain new derived operators have methods for medical imaging, it is imperative to understand\\nbeen introduced for the spatial model checking framework. the associated challenges.\\nTouch is a derived operator that guarantees that a starting point Logic-based techniques in model checking have a strong\\nand an ending point meet particular criteria along with all reliance on basic set of logical operators. These logical op-\\nintermediate points in between them. With particular criteria erators allow for the definition of more expressive derived\\nset, a grow operator is also defined. A filter operator functions operators that resonate with the domain-specific reasoning of\\nas a filter, taking a radius of a certain distance into account, the user. The idea is to exploit the compositionality of the\\nultimately resulting in a smoothing operation. Furthermore, a basic operators so as to build more complex operators. A\\nstatistical similarity operator is also defined. It searches for benefit for using very basic building blocks is the underlyingSr Studies Application Innovation/Paper-Type Result Year\\n1 Karmakar et al.[22] System Design Review -Algorithmic verification of probabilistic finite-state 2022\\nsystems with respect to linear-time properties.\\n2 Belmont et al.[48] Nevus Segmentation Spatial MC -Determination of the contour of the two- 2021\\ndimensional images of nevi.\\n3 Gopal et al.[23] Web Service Review -A systematic review of the current research work on 2021\\nweb service validation-based model validation that\\nemerged during the period 2002-2017.\\n4 Jonas et al.[24] Vehicle Control Review -Report on model check application trials to check 2020\\nthe arbitration logic of the vehicle control sys-\\ntem. Identify the pros and cons of different model-\\nchecking techniques and tools\\n5 Vincenzo et al.[51] Glioblastoma VoxLogicA -Automatic segmentation of glioblastoma in MR flair 2019\\nfor radiotherapy\\n6 Massink et al. [52] Glioblastoma Spatial MC Providing an open platform introducing declarative 2019\\nmedical image analysis.\\n7 Buonamici et al. [13] Glioblastoma ImgQL Introducing the logical language ImgQL (”Image 2018\\nQuery Language”). ImgQL extends SLCS with\\nBoolean operators that describe distance and area\\nsimilarity.\\n8 Belmont et al.[50] Glioblastoma Automatic Segmentation -Automatic segmentation of glioblastoma 2017\\n9 Nenzi et al. [30] Reaction Diffusion Spatio-temporal Logic -Introducing the Signal SpatioTemporal Logic 2016\\n(SSTL), a modality that may be utilised to charac-\\nterise the spatiotemporal characteristics of linear time\\nand discrete space models.\\n10 Katoen et al. [16] Probabilistic MC Review Algorithmic verification of probabilistic models, in 2016\\nparticular probabilistic model checking.\\n11 Ovidiu et al.[27] Biological Systems Meta MC A New Approach to Multiscale Spatio-Temporal 2016\\nMeta Model Checking for Multilevel Computational\\nModels of Biological Systems\\n12 Ovatman et al[19] PLC Review Model checking practices on verification of PLC 2016\\nsoftware,” Software and Systems Modeling\\n13 Ciancia et al.[32] Spatial Operator Topological Generaliza- Defining and confirming space attributes 2016\\ntion\\n14 Belmonte et al.[34] Medical Imaging Multiple Operators Presenting a preliminary experiment focusing on 2016\\nspatial model verification applications to MI.\\n15 Edelkamp et al.[15] State-explosion Review Using Histological Image Processing Techniques, 2008\\nChronic Tumor Hypoxia is Quantitatively Character-\\nized\\n16 Gerard et al.[20] Software systems Review Explaining the theoretical underpinnings and prac- 2005\\ntical applications of logic model-checking methods\\nfor the verification of multi-threaded software\\n.\\n17 Bhaduri [18] State-chart models Review Recommending a variety of approaches to deal with 2004\\nthe issue of state space explosion as well as some\\nfuture research topics.\\n18 Vardi et al.[21] Probabilistic MC Review Being able to reduce probabilistic model checking 1999\\nfor ergodic analysis of Markov chains.\\n20 Reif and al.[31] Packet Routing Spatio-temporal Operators spatial and temporal modalities in a multiprocess 1985\\nnetwork logic\\nefficiency for the verification and correctness of the algorithms. be coupled with a particular application. Furthermore, a lot\\nIt is also expected that the approach has some degree of of focus in medical imaging and diagnosis has been on\\nflexibility and generalization so that it does not unnecessarily deep learning-based techniques where hierarchical features areextracted and a model is trained to fit under plenty of hyper- studied focused primarily on segmentation and analysis of\\nparameters to give desired results. However, this requires large medical images. This is to confirm the effectiveness of the\\ndatasets and with significant variability in inter and intra model checking in the analysis of medical images, as the\\nexperts on contours of segmentation, not only is deep learning accuracy of most of these works exceeded 90%, which is\\nimplementation time-consuming for manual segmentation help a percentage that shows the importance of model checking\\nimprove as well. To that end, interactive approaches based on in the analysis of medical images, in order to learn more\\nspatial model checking may be of help in terms of improving about the areas of use of model checking (computer science,\\nthe generation of manual ground truth annotations in a more engineering, Medicine Public Health, medicine ), figure 1\\nefficient, transparent, and reproducible way. The explaining shows the results of the top 5 areas where the model checking\\nability aspect is also an under-explored problem when it comes was applied by relying on Spring Nature statistics.\\nto deep learning methods as deep learning approaches suffer\\nfrom a lack of reasonable explanations on human insight as\\nto why a certain area is classified as a tumor by the model,\\nparticularly when the models do not provide correct results\\nat all times. The results in [52] is obtained by utilizing the\\nVoxLogicA-based model checking approach with the integra-\\ntion of the above-discussed derivative operators.\\nThe quantitative metrics used for evaluation included the\\ndice coefficient, specificity, and sensitivity. Sensitivity quanti-\\nfies the fraction of pixels correctly identified as the ground\\ntruth whereas specificity quantifies the fraction of pixels\\nidentified as true negatives. The dice index encapsulates the\\nsimilarity. The authors were able to achieve dice, sensitivity,\\nand specificity scores as high as 0.90, 0.91, and 0.98, re-\\nspectively for grey matter in the brain MRI image and 0.89,\\n0.85, and 1.0, respectively for white matter. In [48] work on\\nnevus segmentation, the authors achieved dice, sensitivity, and\\nspecificity scores of 0.81, 0.81, and 0.96, respectively. While\\nsome variation on scores is evident owing to the difference Figure 2: Model checking research publications common area\\nin applications, the objectivity in the strong performance of\\nmodel checking as a tool for segmentation, in general, is In order to be more precise, we calculated the percentage\\nappreciable nonetheless. [52] emphasized the importance of for each field in terms of the number of Model Checking\\nenhancing capabilities and ensuring transparency in annotation publications by relying on Spring Nature statistics.\\nprocedures conducted by experts during segmentation. Given\\ntheir extensive experience in marking ground truths, it is\\nvital to encapsulate this expertise in the form of high-level\\noperations with formal specifications. These specifications\\nshould be exchangeable, publishable, and open to discussion\\nwithin the domain expert community, promoting collaboration\\nand driving advancements in the field.\\nFurthermore, ensuring device independence is essential for\\nthe broader adoption of academically significant research in\\nclinical practice. Several factors hinder this transition, includ-\\ning the lack of integration of academic research outcomes with\\nexisting hardware and the reliance on hard-coded execution\\nenvironments. To facilitate successful technology transfer, it\\nis critical to address the fragmentation of academic research\\nand establish open standards and protocols. These measures\\ncan enable intermediaries, such as imaging device vendors, to\\ntransform innovative ideas into practical clinical applications. Figure 3: Model checking research publications common area\\nAdditionally, challenges related to data privacy and procedural\\nconfidentiality underscore the need for open standards that It is clear from the above diagram that the strength of model\\nallow users to exchange analysis procedures and build a foun- checking is the ability to apply it in different areas, unlike\\ndation of shared knowledge. We summarize the contributions some other methods, and it is clear that most applications of\\nof the relevant literature on model checking in Table 1. model checking are in computer engineering sciences due to\\nThe table results show that most of the publications we the need for computer engineering to verify the correctness ofthe characteristics in order to avoid errors in the development REFERENCES\\nof programs.\\nwe used the systematic review to draw the historical publica- [1] B. Halalli and A. Makandar, “Computer aided diagnosis - medical\\nimage analysis techniques,” in Breast Imaging, C. M. Kuzmiak,\\ntion chart of model-checking research publications per year\\nEd. Rijeka: IntechOpen, 2017, ch. 5. [Online]. Available: https:\\n//doi.org/10.5772/intechopen.69792\\n[2] N. Gordillo, E. Montseny, and P. Sobrevilla, “State of the art survey on\\nmri brain tumor segmentation,” Magnetic Resonance Imaging, vol. 31,\\nno. 8, pp. 1426–1438, 2013.\\n[3] K. K. Brock, Image Processing in Radiation Therapy. CRC Press,\\n2013.\\n[4] G. Chetelat and J. C. Baron, “Early diagnosis of alzheimer’s disease:\\ncontribution of structural neuroimaging,” NeuroImage, vol. 18, no. 2,\\npp. 525–541, 2003.\\n[5] A. Toosy, D. Werring, R. Orrell, R. Howard, M. King, G. Barker,\\nD. Miller, and A. Thompson, “Diffusion tensor imaging detects cor-\\nticospinal tract involvement at multiple levels in amyotrophic lateral\\nsclerosis,” Journal of neurology, neurosurgery, and psychiatry, vol. 74,\\nno. 9, p. 1250—1257, September 2003.\\n[6] B. Menze, “The multimodal brain tumor image segmentation benchmark\\n(brats),” IEEE Transactions on Medical Imaging, vol. 34, no. 10, pp.\\n1993–2024, 2015.\\n[7] C. Dupont, N. Betrouni, N. Reyns, and M. Vermandel, “On image\\nsegmentation methods applied to glioblastoma: State of art and new\\ntrends,” IRBM, vol. 37, no. 3, pp. 131–143, 2016.\\n[8] A. E. Lefohn, J. E. Cates, and R. T. Whitaker, “Interactive, gpu-based\\nlevel sets for 3d segmentation,” in International Conference on Medical\\nImage Computing and Computer-Assisted Intervention. Springer, 2003,\\npp. 564–572.\\nFigure 4: Total publications on model checking research [9] S. Ho, E. Bullitt, and G. Gerig, “Level-set evolution with region\\n(2016–2022) competition: automatic 3-d segmentation of brain tumors,” in 2002\\nInternational Conference on Pattern Recognition, vol. 1. IEEE, 2002,\\npp. 532–535.\\nWe note that the importance of model checking in the [10] M. Wels, G. Carneiro, A. Aplas, M. Huber, J. Hornegger, and D. Co-\\nhealth field is being studied due to the ability of the model maniciu, “A discriminative model-constrained graph cuts approach to\\nfully automated pediatric brain tumor segmentation in 3-d mri,” in\\nchecking to identify and avoid errors, in addition to its low\\nInternational Conference on Medical Image Computing and Computer-\\ncost compared to deep learning techniques Assisted Intervention. Springer, 2008, pp. 67–75.\\n[11] S. Bauer, J. Tessier, O. Krieter, L.-P. Nolte, and M. Reyes, “Integrated\\nV. CONCLUSION AND FUTURE WORK spatio-temporal segmentation of longitudinal brain tumor imaging stud-\\nies,” in International MICCAI Workshop on Medical Computer Vision.\\nModel checking in medical imaging remains an active area\\nSpringer, 2013, pp. 74–83.\\nof research. The use of spatial model checking for verifying [12] A. Hamamci, N. Kucuk, K. Karaman, K. Engin, and G. Unal, “Tumor-\\nand validating spatial logic designs plays a critical role in cut: segmentation of brain tumors on contrast enhanced mr images\\nfor radiosurgery applications,” IEEE transactions on medical imaging,\\nidentifying and segmenting various types of tissues in the\\nvol. 31, no. 3, pp. 790–804, 2011.\\nbody. However, significant challenges persist, particularly in [13] F. B. Buonamici, G. Belmonte, V. Ciancia, D. Latella, and M. Massink,\\nthe technical development of frameworks and the explainabil- “Spatial logics and model checking for medical imaging,” 2018.\\n[14] G. Mohan and M. M. Subashini, “Mri based medical image analysis:\\nity and reproducibility of methodologies within the model-\\nSurvey on brain tumor grade classification,” Biomedical Signal Process-\\nchecking domain. The existing literature demonstrates that ing and Control, vol. 39, pp. 139–161, 2018.\\nmodel checking is an effective tool not only for detecting [15] S. Edelkamp, V. Schuppan, D. Bosˇnacˇki, A. Wijs, A. Fehnker, and\\nH. Aljazzar, “Survey on directed model checking,” in Model Checking\\ntumorous tissues but also for distinguishing between different\\nand Artificial Intelligence, D. A. Peled and M. J. Wooldridge, Eds.\\nhealthy tissues with notable accuracy. Despite these achieve- Berlin, Heidelberg: Springer Berlin Heidelberg, 2009, pp. 65–89.\\nments, there remains considerable room for improvement, as [16] J.-P. Katoen, “The probabilistic model checking landscape,” in Proceed-\\nmuch of the existing research focuses on specific applications. ings of the 31st Annual ACM/IEEE Symposium on Logic in Computer\\nScience, ser. LICS ’16. New York, NY, USA: Association for\\nMoving forward, we aim to advance model-checking tech-\\nComputing Machinery, 2016, p. 31–45.\\nniques for medical image analysis, with a particular focus on [17] M. Mu¨ller-Olm, D. Schmidt, and B. Steffen, “Model-checking,” in Static\\napplying these methods to 3D imaging. Analysis, A. Cortesi and G. File´, Eds. Berlin, Heidelberg: Springer\\nBerlin Heidelberg, 1999, pp. 330–354.\\nDECLARATIONS [18] P. Bhaduri and S. Ramesh, “Model checking of statechart models:\\nSurvey and research directions,” 2004.\\n• Funding: This research received no external funding. [19] T. Ovatman, A. Aral, D. Polat, and A. O. U¨nver, “An overview of\\n• Conflict of interest: The authors declare no conflict of model checking practices on verification of PLC software,” Software\\nand Systems Modeling, vol. 15, no. 4, pp. 937–960, oct 2016.\\ninterest.\\n[20] G. J. Holzmann, “Software model checking with spin,” ser. Advances\\n• Informed Consent Statement: Not applicable. in Computers. Elsevier, 2005, vol. 65, pp. 77–108.\\n• Data Availability Statement: Not applicable. [21] M. Y. Vardi, “Probabilistic linear-time model checking: An overview of\\nthe automata-theoretic approach,” in Formal Methods for Real-Time and\\n• Research Involving Human and /or Animals :Not appli- Probabilistic Systems, J.-P. Katoen, Ed. Berlin, Heidelberg: Springer\\ncable Berlin Heidelberg, 1999, pp. 265–276.[22] R. Karmakar, “Symbolic model checking: A comprehensive review for Schlegel, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009,\\ncritical system design,” in Advances in Data and Information Sciences, pp. 274–276.\\nS. Tiwari, M. C. Trivedi, M. L. Kolhe, K. Mishra, and B. K. Singh, [41] F. Han, H. Wang, G. Zhang, H. Han, B. Song, L. Li, W. Moore, H. Lu,\\nEds., 2022, pp. 693–703. H. Zhao, and Z. Liang, “Texture feature analysis for computer-aided\\n[23] G. N. Rai and G. R. Gangadharan, “Model checking based web service diagnosis on pulmonary nodules,” Journal of digital imaging, vol. 28,\\nverification: A systematic literature review,” IEEE Transactions on no. 1, pp. 99–115, feb 2015.\\nServices Computing, vol. 14, no. 3, pp. 747–764, 2021. [42] C.-C. Chen, J. DaPonte, and M. Fox, “Fractal feature analysis and clas-\\n[24] J. Fritzsch, T. Schmid, and S. Wagner, “Experiences from large-scale sification in medical imaging,” IEEE Transactions on Medical Imaging,\\nmodel checking: Verification of a vehicle control system,” CoRR, vol. vol. 8, no. 2, pp. 133–142, 1989.\\nabs/2011.10351, 2020. [43] N. Sharma, A. Ray, S. Sharma, K. Shukla, S. Pradhan, and L. Aggar-\\n[25] A. Sundstrom, E. Grabocka, D. Bar-Sagi, and B. Mishra, “Histological wal, “Segmentation and classification of medical images using texture-\\nImage Processing Features Induce a Quantitative Characterization of primitive features: Application of BAM-type artificial neural network,”\\nChronic Tumor Hypoxia,” PloS one, vol. 11, no. 4, 2016. Journal of Medical Physics / Association of Medical Physicists of India,\\n[26] R. Grosu, E. Bartocci, F. Corradini, E. Entcheva, S. A. Smolka, and vol. 33, no. 3, p. 119, jul 2008.\\nA. Wasilewska, “Learning and detecting emergent behavior in networks [44] F. Tomita and S. Tsuji, Statistical Texture Analysis. Boston, MA:\\nof cardiac myocytes,” in Hybrid Systems: Computation and Control, Springer US, 1990, pp. 13–36.\\nM. Egerstedt and B. Mishra, Eds. Berlin, Heidelberg: Springer Berlin [45] G. N. Srinivasan and G. Shobha, “Statistical texture analysis,”\\nHeidelberg, 2008, pp. 229–243. International Journal of Computer and Information Engineering,\\nvol. 2, no. 12, pp. 4268 – 4273, 2008. [Online]. Available:\\n[27] P. Ovidiu and G. David, “A Novel Method to Verify Multilevel Computa-\\nhttps://publications.waset.org/vol/24\\ntional Models of Biological Systems Using Multiscale Spatio-Temporal\\n[46] V. Ciancia, D. Latella, M. Loreti, and M. Massink, “Spatial logic and\\nMeta Model Checking,” PloS one, vol. 11, no. 5, may 2016.\\nspatial model checking for closure spaces,” Lecture Notes in Computer\\n[28] Z. Akkus, A. Galimzianova, A. Hoogi, D. L. Rubin, and B. J. Erickson,\\nScience (including subseries Lecture Notes in Artificial Intelligence and\\n“Deep Learning for Brain MRI Segmentation: State of the Art and Future\\nLecture Notes in Bioinformatics), vol. 9700, pp. 156–201, 2016.\\nDirections,” Journal of digital imaging, vol. 30, no. 4, pp. 449–459, aug\\n[47] A. Galton, “The mereotopology of discrete space,” Lecture Notes in\\n2017. [Online]. Available: https://pubmed.ncbi.nlm.nih.gov/28577131/\\nComputer Science (including subseries Lecture Notes in Artificial Intel-\\n[29] G. P. Mazzara, R. P. Velthuizen, J. L. Pearlman, H. M. Greenberg,\\nligence and Lecture Notes in Bioinformatics), vol. 1661, pp. 251–266,\\nand H. Wagner, “Brain tumor target volume determination for radiation\\n1999.\\ntreatment planning through automated MRI segmentation,” International\\n[48] G. Belmonte, G. Broccia, V. Ciancia, D. Latella, and M. Massink,\\nJournal of Radiation Oncology Biology Physics, vol. 59, no. 1, pp. 300–\\n“Feasibility of spatial model checking for nevus segmentation,” in 2021\\n312, may 2004.\\nIEEE/ACM 9th International Conference on Formal Methods in Software\\n[30] L. Nenzi, L. Bortolussi, V. Ciancia, M. Loreti, and M. Massink,\\nEngineering (FormaliSE), 2021, pp. 1–12.\\n“Qualitative and Quantitative Monitoring of Spatio-Temporal Properties\\n[49] A. M. Forsea, V. Del Marmol, E. De Vries, E. E. Bailey, and A. C.\\nwith SSTL,” vol. 14, no. 4, pp. 1–38, 2017.\\nGeller, “Melanoma incidence and mortality in Europe: new estimates,\\n[31] J. Reif and A. Sistla, “A multiprocess network logic with temporal and persistent disparities,” British Journal of Dermatology, vol. 167, no. 5,\\nspatial modalities,” Journal of Computer and System Sciences, vol. 30, pp. 1124–1130, nov 2012. [Online]. Available: https://onlinelibrary.\\nno. 1, pp. 41–53, 1985. wiley.com/doi/full/10.1111/j.1365-2133.2012.11125.xhttps:\\n[32] V. Ciancia, D. Latella, M. Loreti, and M. Massink, “Specifying and //onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2133.2012.11125.\\nverifying properties of space,” in Theoretical Computer Science, J. Diaz, xhttps://onlinelibrary.wiley.com/doi/10.1111/j.1365-2133.2012.11125.x\\nI. Lanese, and D. Sangiorgi, Eds. Berlin, Heidelberg: Springer Berlin [50] G. Belmonte, C. Vincenzo, L. Diego, and M. Mieke, “A topological\\nHeidelberg, 2014, pp. 222–235. method for automatic segmentation of glioblastoma in mr flair for\\n[33] E. Bartocci, L. Bortolussi, M. Loreti, and L. Nenzi, “Monitoring mobile radiotherapy,” 2017.\\nand spatially distributed cyber-physical systems,” in Proceedings of [51] G. Belmonte, V. Ciancia, D. Latella, and M. Massink, “Voxlogica: a\\nthe 15th ACM-IEEE International Conference on Formal Methods and spatial model checker for declarative image analysis (extended version),”\\nModels for System Design. ACM, sep 2017. in TACAS, 2019.\\n[34] G. Belmonte, V. Ciancia, D. Latella, and M. Massink, “From collective [52] ——, “Innovating medical image analysis via spatial logics,” in From\\nadaptive systems to human centric computation and back: Spatial model Software Engineering to Formal Methods and Tools, and Back, 2019.\\nchecking for medical imaging,” Electronic Proceedings in Theoretical [53] N. C. F. Codella, Q.-B. Nguyen, S. Pankanti, D. Gutman, B. Helba,\\nComputer Science, vol. 217, pp. 81–92, jul 2016. A. C. Halpern, and J. R. Smith, “Deep learning ensembles for melanoma\\n[35] G. Castellano, L. Bonilha, L. M. Li, and F. Cendes, “Texture analysis recognition in dermoscopy images,” ArXiv, vol. abs/1610.04662, 2017.\\nof medical images,” Clinical radiology, vol. 59, no. 12, pp. 1061–1069,\\ndec 2004.\\n[36] A. Kassner and R. E. Thornhill, “Texture analysis: a review of neurologic\\nMR imaging applications,” AJNR. American journal of neuroradiology,\\nvol. 31, no. 5, pp. 809–816, may 2010.\\n[37] R. Lopes, A. Ayache, N. Makni, P. Puech, A. Villers, S. Mordon, and\\nN. Betrouni, “Prostate cancer characterization on MR images using\\nfractal features,” Medical physics, vol. 38, no. 1, pp. 83–95, 2011.\\n[Online]. Available: https://pubmed.ncbi.nlm.nih.gov/21361178/\\n[38] F. Davnall, C. S. Yip, G. Ljungqvist, M. Selmi, F. Ng, B. Sanghera,\\nB. Ganeshan, K. A. Miles, G. J. Cook, and V. Goh, “Assessment of\\ntumor heterogeneity: an emerging imaging tool for clinical practice?”\\nInsights into imaging, vol. 3, no. 6, pp. 573–589, dec 2012.\\n[39] B. J. Woods, B. D. Clymer, T. Kurc, J. T. Heverhagen, R. Stevens,\\nA. Orsdemir, O. Bulan, and M. V. Knopp, “Malignant-lesion seg-\\nmentation using 4D co-occurrence texture analysis applied to dynamic\\ncontrast-enhanced magnetic resonance breast image data,” Journal of\\nmagnetic resonance imaging : JMRI, vol. 25, no. 3, pp. 495–501, mar\\n2007.\\n[40] T. Heinonen, T. Arola, A. Kalliokoski, P. Dastidar, M. Rossi,\\nS. Soimakallio, J. Hyttinen, and H. Eskola, “Computer aided diagnosis\\ntool for the segmentation and texture analysis of medical images,”\\nin World Congress on Medical Physics and Biomedical Engineering,\\nSeptember 7 - 12, 2009, Munich, Germany, O. Do¨ssel and W. C.',\n",
       " 'More is not always better Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives.pdf': 'More is not always better? Enhancing Many-Shot In-Context Learning\\nwith Differentiated and Reweighting Objectives\\nXiaoqingZhang1,2 AngLv1 YuhanLiu1 FloodSung2\\nWeiLiu3 ShuoShang4 XiuyingChen5* Rui Yan1*\\n1GaolingSchoolofArtificialIntelligence,RenminUniversityofChina 2MoonshotAI\\n3XiaomiAILab 4UniversityofElectronicScienceandTechnologyofChina\\n5MohamedbinZayedUniversityofArtificialIntelligence\\n{xiaoqingz, anglv, yuhan.liu, ruiyan}@ruc.edu.cn {floodsung}@moonshot.cn\\n{liuwei40}@xiaomi.com {jedi.shang}@gmail.com {xy-chen}@pku.edu.cn\\nAbstract 0.9\\n0.8\\n0.7\\nLargelanguagemodels(LLMs)excelatfew-\\nshotin-contextlearning(ICL)withoutrequir- 0.6\\ningparameterupdates.However,asthenumber 0.5\\nofICLdemonstrationsincreasesfromafewto 0.4\\nmany,performancetendstoplateauandeven-\\nk=0 1 3 5 10 20 30 40 50 60 70 80 90 100\\ntuallydecline. Weidentifytwoprimarycauses\\nfor this trend: the suboptimal negative log-\\nlikelihood (NLL) optimization objective and\\nthe incremental data noise. To address these\\nissues,weintroduceDrICL,anoveloptimiza-\\ntionmethodthatenhancesmodelperformance\\nthroughDifferentiatedLearningandadvantage-\\nbasedReweightingobjectives. Globally,DrICL\\nutilizesdifferentiatedlearningtooptimizethe\\nNLL objective, ensuring that many-shot per-\\nformancesurpasseszero-shotlevels. Locally,\\nitdynamicallyadjuststheweightingofmany-\\nshotdemonstrationsbyleveragingcumulative\\nadvantages inspired by reinforcement learn-\\ning, thereby improving generalization. This\\napproachallowsthemodeltohandlevarying\\nnumbers of shots effectively, mitigating the\\nimpact of noisy data. Recognizing the lack\\nofmulti-taskdatasetswithdiversemany-shot\\ndistributions, wedeveloptheMany-ShotICL\\nBenchmark(ICL-50)-alarge-scalebenchmark\\nof50tasksthatcovershotnumbersfrom1to\\n350 within sequences of up to 8,000 tokens-\\nforfine-tuningpurposes. ICL-50facilitatesthe\\nevaluationofmany-shotICLstrategiesacross\\nseven prominent NLP tasks and 50 distinct\\ndatasets. Experimentalresultsdemonstratethat\\nLLMs enhanced with DrICL achieve signifi-\\ncantimprovementsinmany-shotsetupsacross\\nvarious tasks, including both in-domain and\\nout-of-domainscenarios. Wereleasethecode\\nandbenchmarkdatasethopingtofacilitatefur-\\ntherresearchinmany-shotICL1.\\n* Correspondingauthors.\\n1https://github.com/xiaoqzhwhu/DrICL\\nycaruccA\\nMistral-7B-Instruct-v0.2 Mistral-7B-Instruct-v0.2+MetaICL\\nMistral-7B-Instruct-v0.2+DrICL\\nFigure1: TheperformancetrendofLLMsacrossdif-\\nferent k-shots scenarios. k refers to the number of\\ndemonstrationexamplesprovidedtoLLMs,“+MetaICL”\\nusesMetaICLforfine-tuning,while“+DrICL”usesour\\nDrICLstrategy.\\n1 Introduction\\nIn-context learning (Brown et al., 2020) enables\\nmodelstoquicklyadaptandaddressspecificissues\\nbyutilizingcontextualcues,improvingadaptabil-\\nityandgeneralization. Withtheexpansionofthe\\ncontext length in advanced LLMs, the ability to\\nprocesstextlengthsupto1milliontokensallows\\nLLMstoacceptincreasinglymoredemonstrations.\\nTheICLscenarioswithhundredsorthousandsof\\nshotsarecalledmany-shotlearning(Agarwaletal.,\\n2024). However,many-shotdoesnotalwaysresult\\ninbetterperformancethanfew-shot. Somemodels\\nexhibit a linear decrease in ICL capabilities with\\nthe increase in ultra-long text lengths (Liu et al.,\\n2024). AsshowninFigure1,wepresenttheaccu-\\nracyvariationsofMistral-7B-Instruct-v0.2onthe\\nCLSClusteringS2Sdataset(Lietal.,2022). Asthe\\nnumberofICLexamplesincreases,models’perfor-\\nmanceexhibitsatrendofrisingandthenfalling.\\nWesummarizetwopossiblefactorsbasedonour\\npreliminarystudyandpreviousworks. Thefirstfac-\\ntoristhetrainingobjective. As Agarwaletal. high-\\nlights, while the straightforward NLL decreases\\nduring testing with ICL, performance on many\\ndownstream tasks also deteriorates. The second\\nfactoristheincreasingnoisewiththelargenumber\\n1\\n5202\\nnaJ\\n9\\n]GL.sc[\\n2v07040.1052:viXraofdemonstrations. Longetal.;Gaoetal. demon- lion samples. The maximum number of shots\\nstratethattheeffectivenessofICLheavilydepends achievablevariesdependingonthemodel,allowing\\non the quality of the demonstrations. While in for comprehensive investigations into many-shot\\nmany-shot scenarios, utilizing a large number of ICL, including research on fine-tuning and infer-\\nhigh-quality demonstrations presents significant ence. WecategorizeICL-50intodifferentsubsets\\nchallenges,suchasthehugeworkloadofcreating basedontasktypes,includingin-domainandout-\\nthemandthedifficultyofdomainadaptation. Ex- of-domain tasks, to fully assess the model’s ICL\\nistingfew-shotICLmethodsdonotaddressthese capabilitiesinmany-shotscenarios.\\nissues,makingthemunsuitableformany-shotsce- Insummary,thispaperidentifiedtwochallenges\\nnarios(Zhangetal.,2024;Lietal.,2023;Agarwal in avoiding ICL’s decreasing performance under\\netal.,2024;Bertschetal.,2024). Many-shot scenarios: suboptimal training objec-\\nToaddresstheabovefactors,weproposeDrICL, tive, and incremental data noise. We propose\\nenhancing many-shot in-context learning with a “differentiated learning” and “advantaged-based\\nrefined fine-tuning objective. For the first factor, reweighting” to address these challenges, respec-\\nweproposedifferentiatedlearningtodealwiththe tively. We further propose the largest ICL-50 to\\ntrade-offbetweenmany-shotandzero-shotscenar- supportourtraining,evaluationaswellasfurther\\niosfromaglobalperspective. Duringdifferentiated studies. We experiment DrICL on the ICL-50\\nlearning,weensurethattheperformanceonmany- with open-source LLMs, showing the stable per-\\nshot demonstrations surpasses that on zero-shot formancebothin-domainandout-of-domainunder\\ndemonstrations. Thisapproachpromotesmodel’s many-shots. Allthesepointsformthemajorcontri-\\ndeeper understanding of contextual cues, encour- butionofthispaper.\\nagingthemodeltoeffectivelyleveragecontextual\\ninformation. For the second factor, inspired by 2 RelatedWork\\nreinforcementlearning,weproposeanadvantage-\\nbasedreweightingmethodtofilternoiseinmany- In-contextLearning. In-contextlearningallows\\nshot demonstrations from a local perspective. In models to execute downstream tasks without the\\nreinforcementlearning,the“advantagefunction”is need for parameter updates, enabling language\\nessentialforassessingthevalueofactionsbeyond models to serve as a universal tool for a variety\\nthe average expected return, effectively directing of tasks. As the number of examples supplied\\nthe policy to choose actions that are predicted to toLLMsgrows,supplementarystrategiesbecome\\nyieldthehighestfuturerewards(Baird,1994). We essential to bolster the model’s ICL capabilities.\\ndivideeachsequencecontainingK demonstrations For instance, Anil et al. (2024) employ multi-\\nintomultiplereweightingwindows,eachwithW exampleprompts,whichcanaccommodateupto\\ndemonstrations. Foreachdemonstrationx inthe 256demonstrations,toovercometheinherentlimi-\\nk\\nreweightingwindoww,wedesignatethepreceding tationsoflanguagemodels. Haoetal.(2022)pro-\\nwindoww−1asthesamplingwindow. Wecalcu- posethestructuredpromptingmethodtoovercome\\nlatethecumulativeadvantagefromthedatawithin lengthrestrictionsandextendin-contextlearning\\nthesamplingwindoww−1andapplyitdynami- to thousands of examples. Li et al. (2023) use\\ncallyastherewardforx . Then,weintegratethe a customized model architecture to support the\\nk\\ncumulative advantage into the NLL computation expansion of contextual examples to 2,000, and\\nforx andgetanadvantage-basedtrainingobjec- (Agarwal et al., 2024) utilize reinforced ICL and\\nk\\ntive. Wecombinetheglobaldifferentiatedlearning unsupervised ICL to extend the scope of contex-\\nandlocalreweightingasthefinalrefinedtraining tual examples to 8,192. Unlike their work, we\\nobjectiveformaintainingICLundermany-shots. enhance the ICL capability of LLMs by improv-\\nIn addition to the two challenges mentioned ingthemodel’sparametersratherthantheformof\\nabove, another significant obstacle is the lack of contextualexamples.\\nsufficientmulti-tasktrainingdatathatspansawide InstructionTuningofLLMs. Instructiontun-\\nrange of task numbers. Such data is crucial for inghasbecomeaneffectivetechniqueforenhanc-\\nstudyingtheeffectsofICLacrossmany-shotsce- ing the capabilities and controllability of LLMs\\nnarios. We present ICL-50, the largest dataset (Zhangetal.,2023). InthedomainofICL,studies\\nto study many-shot ICL, encompassing 50 tasks likeMetaICL(Minetal.,2022)andPEFT(Bertsch\\nacross 7 task types, and a total of over three mil- et al., 2024) have demonstrated that fine-tuning\\n2LLMs with both small and large demonstration thelearningstrategy.\\nsizes, denoted as k, lead to improved ICL perfor-\\n3.1 GlobalPerspective: Differentiated\\nmance. Despite their studies being confined to a\\nLearning\\nmodestquantityoftuningdata—cappedat10,000\\nentries—there is an evident necessity for deeper Weapplydifferentiatedlearningforthetrade-offof\\nresearch into how ICL performs when scaled up many-shot and zero-shot sequences due to differ-\\nwith more extensive datasets. Consequently, we ingsamplelengths,wherelongersequencesmight\\nintroduceICL-50,asignificantlylargerdataset,de- introduce more noise. We expect that after refin-\\nsigned to delve into the strategies for amplifying ingthelearningobjectives,themodelcanstillper-\\nICL’spotential. formwellinscenarioswithnumerousdemonstra-\\nLLM Data Reweighting. As LLMs rapidly tions,longersamples,andpotentiallynoisyback-\\nadvance, the application of data reweighting in grounds. Ineachiteration,wesampleK pairsof\\ntraining has become increasingly prevalent. In examples(x ,y )fromthetrainingdataset,where\\nk k\\nthepre-trainingstage,SoftDedupsignificantlyim- k ranges from 1 to K. Then, we concatenate\\nprovestrainingefficiencybyselectivelyreducing the examples x and their corresponding labels\\nk\\nthe sampling weight of data with high common- y , and the instruction I generated by GPT-3.5-\\nk\\nness through a soft deduplication method, rather turbo for the current task as the input sequence\\nthanremovingthemtoincreasetheintegrityofthe S = {I;x y x y ...x y }. We train the\\nK 1 1 2 2 K K\\ndataset(Heetal.,2024). ScaleBiOreweightsthe modeltopredictthelabely ofthek-thexample\\nk\\ndataofLLMsbyfilteringirrelevantdatasamples basedontheinstructionandthefeaturesandlabels\\nandselectinginformativesamples,demonstrating ofthepreviousk−1examples. Thetrainingobjec-\\nits effectiveness and scalability across models of tiveofthemodelistominimizetheNLLlossL ,\\nNLL\\ndifferentsizesontaskssuchasdatadenoising,mul- with the previous k −1 examples as the training\\ntilingualtraining,andinstructiontuning(Panetal., examplesandthek-thexampleasthetestexample.\\n2024). IntheICLscenario,Yangetal.(2023)pro- Thistrainingmethodhelpsthemodellearnincon-\\nposeWICLtoenhancetheperformanceofICLby text during the inference stage. We organize the\\nassigning optimal weights to demonstration sam- numberofdemonstrationexamplesaccordingtok.\\nples in the inference. Unlike other works, we set When k > 0, we perform many-shot instruction-\\nthe weights during the training process based on tuning, and when k = 0, we perform zero-shot\\nthepositionsofmultipleexamplesinasequence. instruction-tuning. Duringourtrainingprocess,we\\nexpectthatdifferentexamplesofthesametraining\\n3 DrICL sequenceS k canserveashelpfulcontextsC h for\\neach other. In the absence of context, we define\\nInthiswork,weproposetheDrICLlearningframe- C , so we update the original NLL loss com-\\nnone\\nwork,whichadjuststheweightsofdemonstrations binedwiththeadditionalobjectiveformany-shot\\nandintegratesreweightingwithindifferentiatedob- andzero-shotasfollows:\\njectives, as illustrated in Figure 2. In DrICL, we\\norganizetrainingdatathroughmany-shotandzero- L many-shot = L NLL(LLM(C h,Q;θ),A gt),\\nshot demonstrations. By simultaneously training L = L (LLM(C ,Q;θ),A ),\\nzero-shot NLL none gt\\nthe sequence of many-shot and zero-shot with a\\ndifferentiatedobjective,westrengthenthemodel’s whereQistheinputquestiontothemodel,andA\\ngt\\noverallICLcapability. Atthesametime,tofurther isthecorrespondinggroundtruthanswer. Weuti-\\nreduce the noise of demonstrations in many-shot lizedmany-shotdataasQandtransformeditinto\\nscenarios,weintroduceaweightedtrainingobjec- adegradedzero-shotformatusingtheParallelCon-\\ntive towards different samples in the many-shot textWindows(PCW)method(Ratneretal.,2022).\\ndemonstrations. Bysamplingthemodel’sperfor- PCWworksbymaskingmany-shotsequencesto\\nmanceunderdifferentdemonstrations,wecalculate generateazero-shotsequence,effectivelyenabling\\nthecumulativeadvantagegainedasthenumberof ustoleveragebothformats. Inourimplementation,\\ndemonstrationsincreasesandusethiscumulative PCWwasusedsolelytosimplifytheinputforcod-\\nadvantage to adjust the learning process. Below, ingpurposes. Weaimtosimultaneouslyoptimize\\nweshowthecomponentsoftheDrICLframework these two losses, such that L < L .\\nmany-shot zero-shot\\nfrombothaglobalandlocalperspective,aswellas Alowermany-shotlosssignifiesthatthemodelhas\\n3(a) (b)\\nZero-shot Demonstration\\nPCW\\nAttention\\nSk-1 Sk+2 Sk+4\\n...\\n...\\nSk-1 Sk+1 Sk+3\\nSteps\\nSk-3 Sk+1 Sk+3 NLL Loss\\nM(a�n1,y�-s1h)(o�t2 D,�e2m)(o�n3s,t�r3a)tions index w-1 index w index w+1 Reweighted Loss\\nssoL\\nDifferential Learning Advantage Advantage Advantage\\nminimize\\nnoitadargeD\\nFigure 2: The DrICL Training Framework. (a) The global differentiated learning for many-shot and zero-shot\\ndemonstrations. (b)Thelocaladvantage-basedreweightingmethodassignsdifferentialweightstodemonstrations\\ninwindowwwithwindowsize|W|=3andsamplingsize|S|=1,utilizingthecumulativeadvantagefromthe\\nprecedingwindoww−1.\\nmoreeffectivelymasteredin-contextlearning,thus significance,therebyensuringthatmoreemphasis\\nenhancingitsabilitytoaccuratelypredictA . is placed on the critical instances while reducing\\ngt\\nWehavethefollowingdifferentiatedobjectives: focusonthelessimportantones.\\nTo prevent an undue focus on specific parts of\\nL = (1+α)∗L +(1−α)∗L ,\\ndiff many-shot zero-shot thedata,weintroduceareweightingwindow,de-\\nsignedtosegmentthesequenceintomultipleparts.\\nwhere α is the hyperparameter that controls the\\nEachwindowisintendedtohandleaportionofthe\\ntrade-offbetweenmany-shotandzero-shot.\\nsequencewithatotallengthofK. Thesequenceis\\n3.2 LocalPerspective: Advantage-based\\nsegmentedinto⌊K⌋equalwindows,eachwitha\\nW\\nReweighting sizeofW. Forthek-thdemonstrationwehavethe\\nreweightingwindowindexw asfollows:\\nAfterglobalDifferentialLearning,wenoticedthat\\nloss fluctuates at certain k-shot points instead of (cid:20) k (cid:18) k (cid:19) (cid:21)\\nw = ⌊ ⌋×W : ⌊ ⌋+1 ×W .\\ndecreasingconsistently,suggestingsomesamples W W\\naffect the model’s context significantly, possibly\\nWedesignatetheprecedingwindoww−1asthe\\nintroducingnoise. Toaddressthis,weintroduced\\nsamplingwindow,toselect|S|demonstrationsfor\\nareweightmechanismthatadjustsweightsbased\\nthose in the reweighting window w, compiling\\nonperformancedifferencesbetweenadjacentwin-\\ntheseintoasetS. Thedemonstrationswithinset\\ndows,givinghigherweightstosampleswithlarger\\nS arethenutilizedforfurthertraining,leveraging\\ndifferences, and helping the model adapt to dy-\\naccumulatedbenefitstoenhancelearning.\\nnamiccontexts. Themodeloptimizestheweights\\n(cid:20)(cid:18) (cid:19) (cid:21)\\nofdemonstrationdata,continuouslybalancingex- k k\\nw−1 = ⌊ ⌋−1 ×W : ⌊ ⌋×W .\\nploration and data utilization to achieve a rapid W W\\nandstableICLperformance. Below,wedescribe\\nWedefinea target distributionp(x)andan im-\\ntheoverallprocessfromthreeaspects: importance\\nportance distribution q(x) with their probability\\nsampling,advantagefunctions,andreweighting.\\ndensityfunctionstoachievesetS. Specifically,for\\n3.2.1 ImportanceSampling eachtrainingsampleS andfeaturevectorL of\\nk k\\nImportancesamplingadjuststhesamplingweights the k-th demonstrations, we use the ratio of the\\nto reduce bias and imbalance brought by noisy values of the target distribution p(x) and the im-\\ndata. In this section, we leverage the loss of portancedistributionq(x)tocalculatetheweight\\nsamples on the training dataset evaluated by weight k for the k-th demonstration in S k and se-\\nthe training model to calculate the importance lectthetop|S|sampleswiththehighestweights:\\nweights of these samples. For each training se-\\np(L )\\nquence S = {x y x y ...x y }, we calcu- weight =\\nmany-shotk\\n.\\nK 1 1 2 2 K K k q(L )\\nlatethelossL generatedbythesequence many-shotk\\nmany-shotk\\n{x y x y ...x } at the current k-th position to Through these steps, we calculate the weights of\\n1 1 2 2 k\\nrepresent the features of S . Our objective is to importantsamplesandselectthetop|S|represen-\\nk\\nadjust the weighting of examples based on their tativesamplesfromthegivensampledistribution.\\n4Mistral-7B-Instruct-v0.2 ICL Performance\\n0.8 0.8\\n0.6 0.6\\nNFT\\nIT\\nMetaICL\\n0.4 DrICL 0.4\\n0.2 0.2\\n0.0 0.0\\nk=0 1 3 5 10 20 30 40 50 60 70 80 90100 k=0 1 3 5 10 20 30 40 50 60 70 80 90100\\nycaruccA\\nLlama-2-7b-chat-hf ICL Performance\\nNFT\\nIT\\nMetaICL\\nDrICL\\nFigure 3: The performance with incremental k-shots for Mistral-7B-Instruct-v0.2 and Llama-2-7b-chat-hf on\\nCLSClusteringS2Sunderdifferentstrategies. WefocusonCLSClusteringS2Sforitshighk-shotcount,enablinga\\nbroaderevaluationofDrICL.OurDrICLconsistentlyshowsbetterperformancewithadiverserangeofk.\\nk=0 k=1 k=3 k=5\\nDataset Models\\nD3 R1 B1 D3 R1 B1 D3 R1 B1 D3 R1 B1\\nNFT 0.08 0.14 0.17 0.08 0.17 0.14 0.07 0.09 0.11 0.04 0.12 0.07\\nIT 0.19 0.22 0.31 0.18 0.18 0.29 0.17 0.18 0.27 0.16 0.18 0.28\\nXSUMid MetaICL 0.19 0.23 0.30 0.15 0.22 0.31 0.18 0.23 0.30 0.18 0.22 0.29\\nDrICL 0.20 0.22 0.33 0.19 0.21 0.32 0.20 0.23 0.34 0.20 0.22 0.33\\nNFT 0.07 0.29 0.20 0.06 0.21 0.18 0.04 0.15 0.09 0.05 0.07 0.05\\nIT 0.18 0.34 0.51 0.18 0.32 0.51 0.15 0.27 0.39 0.20 0.11 0.14\\nCNNood MetaICL 0.19 0.34 0.51 0.19 0.35 0.51 0.18 0.34 0.51 0.18 0.33 0.47\\nDrICL 0.19 0.34 0.51 0.19 0.34 0.51 0.19 0.31 0.52 0.19 0.31 0.47\\nTable1: SummarizationresultsonLlama-2-7b-chat-hf,where“id”denotesin-domaindatasetsand“ood”signifies\\nout-of-domaindatasets. Boldindicatesthatourmodelperformsthebest.\\nDataset Models k=0 k=1 k=3 k=5 AVG MAX Here, L represents the performance of\\nsampling\\nw−1\\nNFT 0.19 0.10 0.09 0.01 0.10 0.19 the model on all sampled instances before win-\\nIT 0.93 0.06 0.12 0.19 0.33 0.93\\nEcomRetrievalid MetaICL 0.89 0.85 0.92 0.91 0.89 0.92 dow w. It denotes the model’s performance with\\nDrICL 0.93 0.87 0.94 0.93 0.92 0.94 fewer than k shots, whereas L signifies\\nmany-shotk\\nNFT 0.32 0.39 0.14 0.04 0.22 0.39 the model’s performance with k shots. Next, we\\nIT 1.00 0.18 0.21 0.33 0.43 1.00\\nVideoRetrievalood MetaICL 0.89 0.96 1.00 1.00 0.96 1.00 definetheaccumulatedadvantagestomeasurethe\\nDrICL 1.00 1.00 1.00 1.00 1.00 1.00 strategy’sperformanceindifferentpositionsk:\\nTable2: RetrievalperformanceonLlama-2-7b-chat-hf. A = exp(R /γ),\\nk k\\nBoldindicatesthatourmodelperformsthebest.\\nwhereγ isatemperatureparameterusedtoadjust\\nthe sensitivity of the rewards. The exponential\\n3.2.2 AdvantageFunctions increaseintheadvantagesmetricstrengthenspos-\\nTo assess the model’s cumulative advantages as itiverewardswhilesuppressingnegativerewards,\\nthe k-shots grow, we select the sample set S for guiding the model to select strategies that bring\\nthek-thinstancewithintheweightingwindoww. significantperformanceimprovement.\\nSubsequently,wedeterminetheaveragelossofthe\\n3.2.3 Reweighting\\nsamplingwindoww−1usingtheformula:\\nIntheDrICLframework,weselectimportantsam-\\n1 (cid:88) ples in the previous window and calculate the re-\\nL = L .\\nsampling\\nw−1 |S|\\ninstancei\\nward that measures the model’s performance in\\ninstancei∈S\\ndifferentpositionstoupdatetheNLLlossformany-\\nTherewardisdefinedasthedifferencebetweenthe shot scenarios. We adjust the overall training ob-\\nlossoftheinstanceatthecurrentpositionkandthe jectiveofthemany-shotsequenceasfollows:\\naveragelossoftheinstancesinwindoww−1:\\n1 (cid:88)\\nL = L ∗A .\\nR = L −L\\nmany-shot\\nk\\nmany-shotk k\\nk many-shotk sampling w−1 k\\n5Algorithm 1 Differentiated and Reweighting In- hand,theLongICLBenchdatasetintroducedbyLi\\nContextLearning(DrICL) etal.(2024)significantlyextendsthelengthrang-\\nParameter:α,γ,S,W ingfrom1,000to50,000tokens. Nonetheless,the\\n1: InitializetrainingdataD,totalnumberofiterationsT,set dataset’slimitationtoafewhundredtaskinstances\\ncurrentiterationt=0.\\nrenders it more suitable for inference rather than\\n2: fortinT do\\n3: ford=x ,y ,x ,y ,...,x ,y inDdo extensivetraining. Inlightoftheselimitations,we\\n1 1 2 2 K K\\n4: Letthezero-shotlossL zero-shot =0,many-shotloss havedevelopedtheICL-50dataset. Itencompasses\\nL =0.\\nmany-shot 7tasksofdiversedifficultylevelsandincludes50\\n5: forkinKdo\\n6: Calculatethemany-shotlossL . datasetswithaveragesamplelengthspertaskthat\\nmany-shotk\\n7: Maskthecontextofx byPCWattentiontoget\\nk vary from 10 to 14,000 tokens. With the number\\nthesequencezero-shot .\\nk\\nof samples extending from the hundreds into the\\n8: Calculatethezero-shotlossL .\\nzero-shotk\\n9: Setthewindowindexw=⌊k/W⌋. hundredsofthousands,theICL-50datasetensures\\n10: Sample |S| demonstrations from the window\\na substantial volume of data suitable for training\\nw−1basedonimportancetoformavalidation\\nsetS. and inference. More details can be found in the\\n11: CalculatethesamplinglossL samplingw−1 forthe Appendix.\\ndemonstrationsinS.\\n12: SettheR =L −L .\\nk many-shotk samplingw−1 4.1.2 BaseModels\\n13: Update the cumulative advantage: A =\\nk\\nexp(R k/γ). We perform our experiments using two founda-\\n14: Assign the weighted loss: L =\\nmany-shotk tional models, namely Llama-2-7b-chat-hf and\\nL ×A .\\nmany-shotk k\\n15: L +=L . Mistral-7B-Instruct-v0.2. The base models are\\nmany-shot many-shotk\\n16: L zero-shot +=L zero-shotk. trained by different paradigms: • NFT (Touvron\\n17: endfor\\net al., 2023; Jiang et al., 2023): The founda-\\n18: L =L /K.\\nmany-shot many-shot\\n19: L =L /K. tional models with No Fine-tuning. • IT (Wei\\nzero-shot zero-shot\\n20: UpdateL withhyperparameterα.\\ndiff etal.,2021): InstructionTuningfoundationalmod-\\n21: endfor\\n22: endfor els with zero-shot examples. • MetaICL (Min\\netal.,2022): Fine-tuningfoundationalmodelswith\\nmany-shotexamples.\\nByintroducingthereweightingmechanism,wecan\\nnot only maintain the performance of the current 4.1.3 EvaluationMetrics\\ndemonstrationbutalsofurtheroptimizethemodel\\nInourevaluation,weemployaccuracyforassess-\\nthroughgradientdescent,leadingtoimprovedlong-\\ningtheperformanceofquestionanswering,cluster-\\ntermperformance.\\ning,logicalreasoning,classification,andretrieval\\n3.2.4 LearningStrategy tasks. Forthesummarizationtask,weutilizeDis-\\ntinctoftrigramtokens(D3),ROUGEforunigrams\\nThedetailedprocessoftheDrICLispresentedin\\n(R1),andBLEUforunigrams(B1)asourmetrics.\\nAlgorithm 1. It enables the model to build upon\\nInthecaseofrerankingtasks, weapplystandard\\nprior knowledge at each iteration, avoiding uni-\\nrankingmetrics,includingPrecisionatkP@k,Re-\\nformlearning,therebyachievingprogressiveper-\\ncallatkR@k,andNormalizedDiscountedCumu-\\nformanceenhancementoverlong-termtraining.\\nlativeGainG@k.\\n4 Experiments\\n4.1.4 ImplementationDetails\\n4.1 ExperimentalSetup\\nFortheLlama-2-7b-chat-hfmodel,weconfigured\\n4.1.1 Datasets thehyperparameterαto0.2,whileforMistral-7B-\\nTodelveintotheexplorationofmany-shotICLin Instruct-v0.2,wesetαto0.4. Wesettheparameter\\nLLMs,weneedplentyofdataacrossawiderange γ tocounteracttheeffectsofweightexplosion,and\\nof k-shots. The datasets employed in MetaICL, ourexperimentsidentified11astheoptimalvalue\\nlikeCROSSFIT(Yeetal.,2021)andUNIFIEDQA for this parameter. We determined that the opti-\\n(Khashabietal.,2020),haveanotableconstraint: malsamplingsizeforS is1,withthereweighted\\ntheir task lengths are generally centered around window size W set at 10. For details on the ex-\\n100 tokens. This focus restricts the wide range perimentalhyperparametersettings,pleasereferto\\nofk-shotdistributions, especiallywhenthetrain- AppendixB.1. Foralltrainingandevaluationtasks,\\ning sequence length is constrained. On the other weutilized8A100GPUs.\\n6Dataset Models k=0 k=1 k=3 k=5 k=10 k=20 k=30 k=40 k=50 k=60 k=70 AVG MAX\\nNFT 0.27 0.28 0.30 0.28 0.26 0.22 0.21 0.23 0.19 0.21 0.13 0.23 0.28\\nIT 0.70 0.50 0.57 0.56 0.57 0.59 0.56 0.54 0.54 0.50 0.44 0.55 0.70\\nOpenbookQAid MetaICL 0.59 0.59 0.64 0.63 0.72 0.75 0.77 0.78 0.78 0.79 0.70 0.70 0.79\\nDrICL 0.69 0.72 0.77 0.77 0.78 0.76 0.76 0.76 0.80 0.76 0.76 0.76 0.80\\nNFT 0.65 0.31 0.23 0.16 0.29 0.22 0.25 0.19 0.11 0.10 0.03 0.23 0.65\\nIT 0.71 0.60 0.62 0.62 0.60 0.60 0.60 0.57 0.60 0.30 0.21 0.55 0.71\\nARCood MetaICL 0.67 0.71 0.76 0.78 0.76 0.78 0.78 0.82 0.82 0.78 0.71 0.76 0.82\\nDrICL 0.78 0.78 0.76 0.81 0.80 0.80 0.81 0.78 0.79 0.75 0.67 0.78 0.81\\nNFT 0.16 0.08 0.01 0.00 0.00 0.00 0.02 0.01 0.00 0.02 0.08 0.03 0.16\\nIT 0.86 0.71 0.74 0.73 0.65 0.58 0.57 0.52 0.55 0.58 0.56 0.64 0.86\\nCLSClusteringS2Sid MetaICL 0.81 0.82 0.84 0.83 0.85 0.86 0.86 0.85 0.82 0.82 0.83 0.84 0.86\\nDrICL 0.85 0.85 0.86 0.84 0.87 0.86 0.86 0.86 0.86 0.85 0.89 0.86 0.89\\nNFT 0.04 0.05 0.09 0.11 0.08 0.05 0.01 0.03 0.04 0.06 0.00 0.05 0.11\\nIT 0.39 0.32 0.25 0.29 0.20 0.23 0.22 0.20 0.18 0.21 0.21 0.25 0.39\\nArxivClusteringS2Sood MetaICL 0.35 0.41 0.36 0.33 0.42 0.36 0.37 0.39 0.33 0.37 0.39 0.37 0.42\\nDrICL 0.34 0.35 0.38 0.41 0.36 0.40 0.43 0.36 0.34 0.41 0.35 0.38 0.43\\nNFT 0.29 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.29\\nIT 0.29 0.20 0.16 0.19 0.19 0.12 0.15 0.13 0.18 0.17 0.15 0.18 0.29\\nTenkgnadClusteringS2Sood MetaICL 0.24 0.19 0.23 0.21 0.24 0.23 0.23 0.26 0.27 0.27 0.25 0.24 0.27\\nDrICL 0.23 0.23 0.23 0.25 0.30 0.26 0.27 0.23 0.27 0.26 0.26 0.25 0.30\\nTable3: Theperformanceofquestionanswering,clustering,andclassificationtasksacrossvariousdatasetsonthe\\nLlama-2-7b-chat-hfmodel. Boldindicatesthatourmodelperformsthebest.\\nDataset Models k=0 k=1 k=3 k=5 k=10 k=20 k=30 k=40 k=50 k=60 k=70 k=80 k=90 k=100 k=200 AVG MAX\\nNFT 0.34 0.50 0.40 0.43 0.48 0.66 0.66 0.58 0.52 0.51 0.44 0.55 0.49 0.47 0.00 0.47 0.66\\nIT 0.86 0.71 0.74 0.73 0.65 0.58 0.57 0.52 0.55 0.58 0.56 0.55 0.53 0.54 0.07 0.58 0.86\\nCLSClusteringS2S MetaICL 0.80 0.82 0.80 0.82 0.79 0.81 0.75 0.71 0.73 0.70 0.69 0.74 0.70 0.77 0.73 0.76 0.82\\nDrICL 0.83 0.85 0.85 0.85 0.83 0.83 0.83 0.85 0.86 0.85 0.84 0.82 0.88 0.87 0.71 0.84 0.88\\nNFT 0.43 0.30 0.31 0.36 0.33 0.35 0.34 0.40 0.27 0.27 0.20 0.35 0.39 0.38 0.30 0.33 0.43\\nIT 0.74 0.56 0.67 0.52 0.66 0.65 0.69 0.56 0.64 0.65 0.70 0.68 0.70 0.68 0.69 0.65 0.74\\nTweetSentimentExtraction MetaICL 0.75 0.77 0.80 0.77 0.78 0.79 0.78 0.81 0.73 0.75 0.79 0.76 0.73 0.70 0.51 0.75 0.81\\nDrICL 0.82 0.81 0.81 0.80 0.83 0.80 0.80 0.78 0.83 0.78 0.79 0.76 0.77 0.81 0.76 0.80 0.83\\nTable4: Theperformancevariationofdatasetswiththehighestk-shotsonMistral-7B-Instruct-v0.2. Boldindicates\\nthatourmodelperformsthebest.\\nDataset Models k=0 k=1 k=3 k=5 k=10 k=20 AVG MAX taskswiththehighestk,asdetailedinTable4.\\nNFT 0.28 0.16 0.11 0.07 0.01 0.02 0.11 0.28\\nIT 0.31 0.26 0.26 0.21 0.26 0.16 0.24 0.31\\nGSM8K MetaICL 0.24 0.26 0.26 0.24 0.24 0.26 0.25 0.26\\nDrICL 0.30 0.28 0.31 0.27 0.32 0.26 0.29 0.32 As shown in Tables 1, 2, 3, 5, and 6, DrICL\\nsignificantlyimprovesperformanceacrossvarious\\nTable 5: The reasoning performance on GSM8K for\\ntasks. While MetaICL shows substantial fluctua-\\ntheLlama-2-7b-chat-hfmodel. Boldindicatesthatour\\ntionsink-shotperformanceondatasetslikeOpen-\\nmodelperformsthebest.\\nbookQAandARC,DrICLmaintainsmorestable\\nresults. The slight advantage of our method over\\n4.2 ResultsofTasks Meta-ICLisduetoitsfocusonoptimizingmany-\\nshotloss. IT’sperformancedeclineswithincreas-\\nWevalidateourmethod on12 datasetswith both ingcontextlength,asitreliessolelyonzero-shot,\\nin-domainandout-of-domaintasks. Figure3com- whichislesseffectiveinmany-shotscenarios. Ad-\\npares baseline models on the CLSClusteringS2S ditionally,Llama-2-7b-chat-hf’s4,000-tokenlimit\\ndatasetacrossdifferentk-shotsofLlama-2-7b-chat- causes performance on the ARC dataset to drop\\nhf and Mistral-7B-Instruct-v0.2. Table 1 shows from 0.82 to 0.78 when k exceeds 50. Under the\\nsummarizationperformance,whileTable2details DrICL framework, among the 12 datasets tested,\\nretrievalmetrics. Resultsforquestionanswering, k = 0ledtoaperformancedecreaseon5datasets,\\nclustering, and classification are summarized in no change on 2, and improvement on 5. Overall,\\nTable3,andTable5presentsreasoningtaskperfor- performance improved by 0.5% with k = 0, re-\\nmance. Our reranking experiments are shown in mainingstable. Fork > 0,datasetslikeCLSClus-\\nTable6. GivenMistral-7B-Instruct-v0.2’ssuperior teringS2Sshowedcontinuousimprovement,while\\nperformanceonsequencesover4,000tokens,we DrICLeffectivelymaintainedperformancestability\\ncomparebaselinevariationsacrossk-shotsforthe ask increasedacrossmostdatasets.\\n7k=0 k=1 Llama-2-7b-chat-hfandMistral-7B-Instruct-v0.2.\\ncMedQA P@10 R@10 G@10 P@10 R@10 G@10 Fordetailsofthestudyofhyperparametersplease\\nMetaICL 0.33 0.51 0.53 0.30 0.46 0.52 refertoAppendixB.1.\\nDrICL 0.31 0.48 0.55 0.33 0.51 0.54\\nWinoWhy k=0 k=1 k=3 k=5 k=10 k=20 k=30 k=40 k=50 AVG MAX\\nTable 6: The comparison of ranking performance on DrICL 0.30 0.51 0.5 0.53 0.55 0.57 0.48 0.63 0.52 0.51 0.63\\nDrICLw/W=1 0.47 0.46 0.47 0.51 0.51 0.49 0.45 0.58 0.43 0.49 0.58\\nthecMedQAdatasetfortheLlama-2-7b-chat-hfmodel, DrICLw/oglobal 0.45 0.43 0.46 0.41 0.52 0.51 0.52 0.50 0.43 0.47 0.52\\nDrICLw/olocal 0.43 0.52 0.44 0.47 0.51 0.53 0.33 0.42 0.33 0.44 0.52\\nwithafocusonzero-shotandone-shotsettingsdueto\\nitshandlingofexampleswithanextensivenumberof Table7: Theablationresultswithdifferentsettings.\\ntokens. Boldindicatesthatourmodelperformsthebest.\\n4.4.2 GlobalandLocalContribution\\n4.3 In-ContextLearningAnalysis\\nTable7displaystheoutcomesofDrICLwhenap-\\n4.3.1 PerformanceTradeoff plyingonlyglobalstrategiesorlocalstrategiesex-\\nclusivelytotheWinoWhydataset. Theresultsshow\\nWeobservethatthefoundationmodelsunderper-\\nthatrefininglearningobjectivesviaaglobalhyper-\\nform on both datasets. After fine-tuning, the IT\\nparametertotradeofftheperformanceandthelocal\\nstrategyachievesitsbestinthefew-shot. MetaICL,\\nreweightingofdemonstrationexamplescanboost\\nbenefitingfrommany-shottrainingdata,performs\\nwellatlargerk-shotlevelsbutstillshowssignifi- theLLMs’ICLcapabilities.\\ncantfluctuations. Incontrast,DrICLdeliversmore\\n4.4.3 AnalysisofWindowSize\\nstableresults,withaccuracysteadilyimprovingas\\nTable7showsthatincreasingthewindowsizeim-\\nk increases. DrICLnotonlyoutperformsMetaICL\\nprovesperformance. Asthesequencelengthgrows,\\ninmany-shotscenariosbutalsodemonstratesfaster\\nthenumberofk-shotsalsoincreases. Relyingonly\\nloss convergence, as shown in Figure 6(a) in the\\non data from position k − 1 based on previous\\nAppendixB.1,indicatingitstradeoffofmany-shot\\nk − 1-shot demonstrations can cause significant\\nandzero-shotdemonstrations.\\nvariability, amplifying the impact of data fluctua-\\n4.3.2 PerformanceVariance tions. Expandingthesamplingrangehelpsmitigate\\nthiseffect. Wealsotestedsamplingfrompositions\\nWe track the performance variance across\\n0tok−1, butfoundthemodelpreferentiallyse-\\nall datasets with NFT(6.49E-03), IT(2.71E-02),\\nlectedcertaindatapoints,whichdidn’tfullyreflect\\nMetaICL(2.38E-03), and DrICL(1.56E-03) as k\\nthemodel’soverallperformance. Asaresult, we\\nvaried. Onaverage,DrICLhasthelowestvariance,\\nselectedawindowsizeof10.\\nsuggestingamorestableperformancewithk-shot\\nof demonstration changes. For details of the per-\\n5 Conclusions\\nformancevarianceofeachdatasetpleasereferto\\nTable10inAppendixB.2. To enhance the ICL capacity as context lengths\\ngrowanddemonstrationk-shotsrise,weintroduce\\n4.3.3 DataNoiseSensitivity\\nthe DrICL algorithm to tackle the inaccurate ob-\\nWe compare DrICL with and without local\\njective and noise. This innovative method strate-\\nreweightingbyexamininghowlossvariancetrends\\ngically calibrates global training goals to priori-\\nforeachk-shotdemonstrationduringtraining. The\\ntizemany-shotexamplesoverzero-shotonesand\\nreweighting window in DrICL reduces loss vari-\\nemployslocalreweightingofmany-shotinstances\\nanceandeffectivelybalancestheimpactofnoisy\\nusingcumulativeadvantagesasdynamicrewards,\\ndata by appropriately weighting demonstrations.\\nsteering the model toward effective learning tra-\\nThis reduction in sensitivity to data noise helps\\njectories. Tosubstantiatetheeffectivenessofour\\nmaintain stable performance as the number of\\napproach, we have curated and released the ICL-\\ndemonstrationsincreases. Fordetailsofthenoise\\n50 dataset, characterized by its diverse tasks and\\nvariationpleaserefertoTable11inAppendixB.3.\\na broad spectrum of text lengths and quantities.\\nOur method demonstrates notable enhancements\\n4.4 AblationStudies\\nin both in-domain and out-of-domain tasks. We\\n4.4.1 Hyperparameters anticipate that our research will stimulate further\\nFigure7,8,and6(b)illustratetheimpactofvarying explorationintoICL’spotentialandcontributeto\\nthehyperparametersα,γ,andS onthetrainingof theadvancementofLLMperformance.\\n8References Yang.2024. Softdedup: anefficientdatareweighting\\nmethodforspeedinguplanguagemodelpre-training.\\nRishabh Agarwal, Avi Singh, Lei M Zhang, Bernd\\narXivpreprintarXiv:2407.06654.\\nBohnet,StephanieChan,AnkeshAnand,ZaheerAb-\\nbas,AzadeNova,JohnDCo-Reyes,EricChu,etal.\\nDanHendrycks,CollinBurns,StevenBasart,AndyZou,\\n2024. Many-shotin-contextlearning. arXivpreprint\\nMantasMazeika,DawnSong,andJacobSteinhardt.\\narXiv:2404.11018.\\n2020. Measuringmassivemultitasklanguageunder-\\nstanding. arXivpreprintarXiv:2009.03300.\\nCemAnil,EsinDurmus,MrinankSharma,JoeBenton,\\nSandipanKundu,JoshuaBatson,NinaRimsky,Meg\\nDanHendrycks,CollinBurns,SauravKadavath,Akul\\nTong,JesseMu,DanielFord,etal.2024. Many-shot\\nArora,StevenBasart,EricTang,DawnSong,andJa-\\njailbreaking. Anthropic,April.\\ncobSteinhardt.2021. Measuringmathematicalprob-\\nLeemonCBaird.1994. Reinforcementlearningincon- lem solving with the math dataset. arXiv preprint\\ntinuoustime: Advantageupdating. InProceedings arXiv:2103.03874.\\nof 1994 IEEE International Conference on Neural\\nNetworks(ICNN’94), volume4, pages2448–2453. KarlMoritzHermann,TomasKocisky,EdwardGrefen-\\nIEEE. stette,LasseEspeholt,WillKay,MustafaSuleyman,\\nandPhilBlunsom.2015. Teachingmachinestoread\\nAmandaBertsch,MaorIvgi,UriAlon,JonathanBerant, and comprehend. Advances in neural information\\nMatthewRGormley,andGrahamNeubig.2024. In- processingsystems,28.\\ncontext learning with long-context models: An in-\\ndepthexploration. arXivpreprintarXiv:2405.00200. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-\\nsch,ChrisBamford,DevendraSinghChaplot,Diego\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\\ndelasCasas,FlorianBressand,GiannaLengyel,Guil-\\nSubbiah,JaredDKaplan,PrafullaDhariwal,Arvind\\nlaumeLample,LucileSaulnier,etal.2023. Mistral\\nNeelakantan,PranavShyam,GirishSastry,Amanda\\n7b. arXivpreprintarXiv:2310.06825.\\nAskell,etal.2020. Languagemodelsarefew-shot\\nlearners. Advancesinneuralinformationprocessing\\nDaniel Khashabi, Sewon Min, Tushar Khot, Ashish\\nsystems,33:1877–1901.\\nSabharwal, Oyvind Tafjord, Peter Clark, and Han-\\nnanehHajishirzi.2020. Unifiedqa: Crossingformat\\nEunsolChoi,HeHe,MohitIyyer,MarkYatskar,Wen-\\nboundarieswithasingleqasystem. arXivpreprint\\ntauYih, YejinChoi, PercyLiang, andLukeZettle-\\narXiv:2005.00700.\\nmoyer.2018. Quac: Questionansweringincontext.\\narXivpreprintarXiv:1808.07036.\\nTomášKocˇisky`,JonathanSchwarz,PhilBlunsom,Chris\\nChristopher Clark, Kenton Lee, Ming-Wei Chang, Dyer,KarlMoritzHermann,GáborMelis,andEd-\\nTom Kwiatkowski, Michael Collins, and Kristina ward Grefenstette. 2018. The narrativeqa reading\\nToutanova. 2019. Boolq: Exploring the surprising comprehensionchallenge. TransactionsoftheAsso-\\ndifficultyofnaturalyes/noquestions. arXivpreprint ciationforComputationalLinguistics,6:317–328.\\narXiv:1905.10044.\\nMukaiLi, ShansanGong, JiangtaoFeng, YihengXu,\\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot, JunZhang,ZhiyongWu,andLingpengKong.2023.\\nAshishSabharwal,CarissaSchoenick,andOyvind In-contextlearningwithmanydemonstrationexam-\\nTafjord.2018. Thinkyouhavesolvedquestionan- ples. arXivpreprintarXiv:2302.04931.\\nswering? tryarc,theai2reasoningchallenge. arXiv\\npreprintarXiv:1803.05457. Tianle Li, Ge Zhang, Quy Duc Do, Xiang Yue,\\nand Wenhu Chen. 2024. Long-context llms strug-\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, gle with long in-context learning. arXiv preprint\\nMarkChen,HeewooJun,LukaszKaiser,Matthias arXiv:2404.02060.\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\\nNakano,etal.2021. Trainingverifierstosolvemath\\nYudongLi,YuqingZhang,ZheZhao,LinlinShen,Wei-\\nwordproblems. arXivpreprintarXiv:2110.14168.\\njieLiu,WeiquanMao,andHuiZhang.2022. Csl: A\\nlarge-scalechinesescientificliteraturedataset. arXiv\\nHongfu Gao, Feipeng Zhang, Wenyu Jiang, Jun Shu,\\npreprintarXiv:2209.05034.\\nFengZheng,andHongxinWei.2024. Onthenoise\\nrobustnessofin-contextlearningfortextgeneration.\\nStephanieLin,JacobHilton,andOwainEvans.2021.\\narXivpreprintarXiv:2405.17264.\\nTruthfulqa: Measuring how models mimic human\\nYaru Hao, Yutao Sun, Li Dong, Zhixiong Han, Yux- falsehoods. arXivpreprintarXiv:2109.07958.\\nianGu,andFuruWei.2022. Structuredprompting:\\nScalingin-contextlearningto1,000examples. arXiv NelsonFLiu,KevinLin,JohnHewitt,AshwinParan-\\npreprintarXiv:2212.06713. jape,MicheleBevilacqua,FabioPetroni,andPercy\\nLiang.2024. Lostinthemiddle: Howlanguagemod-\\nNan He, Weichen Xiong, Hanwen Liu, Yi Liao, Lei elsuselongcontexts. TransactionsoftheAssociation\\nDing,KaiZhang,GuohuaTang,XiaoHan,andWei forComputationalLinguistics,12:157–173.\\n9QuanyuLong,YinWu,WenyaWang,andSinnoJialin equally beneficial: Reweighting demonstration ex-\\nPan. 2024. Decomposing label space, format and amples for in-context learning. arXiv preprint\\ndiscrimination: Rethinking how llms respond and arXiv:2310.08309.\\nsolve tasks via in-context learning. arXiv preprint\\narXiv:2404.07546. Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren.\\n2021. Crossfit: A few-shot learning challenge for\\nTodorMihaylov,PeterClark,TusharKhot,andAshish cross-task generalization in nlp. arXiv preprint\\nSabharwal.2018. Canasuitofarmorconductelec- arXiv:2104.08835.\\ntricity? anewdatasetforopenbookquestionanswer-\\ning. arXivpreprintarXiv:1809.02789. Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\\nFarhadi, and Yejin Choi. 2019. Hellaswag: Can a\\nSewonMin,MikeLewis,LukeZettlemoyer,andHan- machinereallyfinishyoursentence? arXivpreprint\\nnanehHajishirzi.2022. Metaicl: Learningtolearn arXiv:1905.07830.\\nincontext. InProceedingsofthe2022Conference\\nHongming Zhang, Xinran Zhao, and Yangqiu Song.\\nof the North American Chapter of the Association\\n2020. Winowhy: A deep diagnosis of essential\\nfor Computational Linguistics: Human Language\\ncommonsense knowledge for answering winograd\\nTechnologies,pages2791–2809.\\nschemachallenge. arXivpreprintarXiv:2005.05763.\\nNiklasMuennighoff,NouamaneTazi,LoïcMagne,and\\nKaiyi Zhang, Ang Lv, Yuhan Chen, Hansen Ha, Tao\\nNilsReimers.2022. Mteb: Massivetextembedding\\nXu, and Rui Yan. 2024. Batch-icl: Effective, effi-\\nbenchmark. arXivpreprintarXiv:2210.07316.\\ncient,andorder-agnosticin-contextlearning. arXiv\\npreprintarXiv:2401.06469.\\nShashi Narayan, Shay B Cohen, and Mirella Lap-\\nata. 2018. Don’t give me the details, just the\\nShengyuZhang,LinfengDong,XiaoyaLi,SenZhang,\\nsummary! topic-aware convolutional neural net-\\nXiaofeiSun,ShuheWang,JiweiLi,RunyiHu,Tian-\\nworks for extreme summarization. arXiv preprint\\nweiZhang,FeiWu,etal.2023. Instructiontuning\\narXiv:1808.08745.\\nforlargelanguagemodels: Asurvey. arXivpreprint\\narXiv:2308.10792.\\nRuiPan, JipengZhang, XingyuanPan, RenjiePi, Xi-\\naoyuWang,andTongZhang.2024. Scalebio: Scal-\\nWanjunZhong,SiyuanWang,DuyuTang,ZenanXu,\\nable bilevel optimization for llm data reweighting.\\nDayaGuo,JiahaiWang,JianYin,MingZhou,and\\narXivpreprintarXiv:2406.19976.\\nNan Duan. 2021. Ar-lsat: Investigating analytical\\nreasoningoftext. arXivpreprintarXiv:2104.06598.\\nNirRatner,YoavLevine,YonatanBelinkov,OriRam,\\nInbal Magar, Omri Abend, Ehud Karpas, Amnon\\nShashua, KevinLeyton-Brown, andYoavShoham.\\n2022. Parallelcontextwindowsforlargelanguage\\nmodels. arXivpreprintarXiv:2212.10947.\\nHugoTouvron,ThibautLavril,GautierIzacard,Xavier\\nMartinet,Marie-AnneLachaux,TimothéeLacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro,\\nFaisal Azhar, et al. 2023. Llama: Open and effi-\\ncient foundation language models. arXiv preprint\\narXiv:2302.13971.\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\\ndrewMDai,andQuocVLe.2021. Finetunedlan-\\nguagemodelsarezero-shotlearners. arXivpreprint\\narXiv:2109.01652.\\nJasonWeston,AntoineBordes,SumitChopra,Alexan-\\nderMRush,BartVanMerriënboer,ArmandJoulin,\\nand Tomas Mikolov. 2015. Towards ai-complete\\nquestionanswering: Asetofprerequisitetoytasks.\\narXivpreprintarXiv:1502.05698.\\nShitao Xiao, Zheng Liu, Peitian Zhang, and Niklas\\nMuennighof.2023. C-pack: Packagedresourcesto\\nadvancegeneralchineseembedding. arXivpreprint\\narXiv:2309.07597.\\nZhe Yang, Damai Dai, Peiyi Wang, and Zhifang\\nSui. 2023. Not all demonstration examples are\\n10A Dataset This provides a solid data foundation for the per-\\nformancestudyofICLinmany-shotscenarios.\\nA.1 Overview\\nICLBdatasetincludesthefollowingtasks: TaskType TaskName Train Test\\n•QA: MMLU (Hendrycks et al., 2020), Hel- MMLU 99834 13985\\nHellaSwag 39905 10042\\nlaSwag(Zellersetal.,2019),BoolQ(Clarketal.,\\nBoolQ 9427 100\\n2019),NarrativeQA(Kocˇisky` etal.,2018),Truth- NarrativeQA 36208 0\\nQA TruthfulQA 22434 0\\nfulQA(Linetal.,2021),OpenbookQA(Mihaylov OpenbookQA 4957 500\\netal.,2018),ARC(Clarketal.,2018),andQUAC QUAC 83568 7354\\nARC 1096 106\\n(Choietal.,2018).\\nAPPS 5000 0\\n•Reasoning: GSM8K (Cobbe et al., 2021), MATH 7500 5000\\nAPPS(Hendrycksetal.,2021),MATH(Hendrycks Reasoning BABI 200000 20000\\nGSM8K 7473 1319\\netal.,2021),BABI(Westonetal.,2015),andAR- AR-LSAT 1630 230\\nLSAT(Zhongetal.,2021). CNN 83321 9258\\n•Summarization: XSUM(Narayanetal.,2018) Summarization DailyMail 197555 21951\\nXSUM 204045 11334\\nandCNN/DailyMail(Hermannetal.,2015).\\nCLSClusteringP2P 81499 8501\\nWerefertotheMTEB(Muennighoffetal.,2022) CLSClusteringS2S 83359 6641\\nThuNewsClusteringS2S 83816 6184\\nandC-MTEB(Xiaoetal.,2023)thatcontainsthe ArxivClusteringP2P 135171 14829\\ndescriptionofthefollowingdataset. ArxivClusteringS2S 133190 16810\\nBiorxivClusteringP2P 58185 6815\\n•Clustering: ArxivClusteringS2S, ArxivClus- BiorxivClusteringS2S 57893 7107\\nBlurbsClusteringP2P 135018 14982\\nteringP2P,BiorxivClusteringS2S,BiorxivCluster- Clustering BlurbsClusteringS2S 132972 17028\\ningP2P,MedrxivClusteringP2P,RedditClustering, MedrxivClusteringP2P 29337 3163\\nRedditClustering 134749 15251\\nRedditClusteringP2P, StackExchangeClustering,\\nRedditClusteringP2P 134391 15609\\nStackExchangeClusteringP2P,CLSClusteringS2S, StackExchangeClustering 132996 17004\\nStackExchangeClusteringP2P 58584 6416\\nCLSClusteringP2P, ThuNewsClusteringS2S, TenkgnadClusteringP2P 38953 4110\\nBlurbsClusteringS2S, BlurbsClusteringP2P, TenkgnadClusteringS2S 39293 3770\\nTenkgnadClusteringS2S,TenkgnadClusteringP2P. JDReview 3468 261\\nMultilingualSentiment 90761 9239\\n•Classification: AmazonPolarity, AmazonRe- OnlineShopping 7675 325\\nAmazonPolarity 89979 10021\\nviews,Emotion,ToxicConversations,TweetSenti-\\nAmazonReviews 90145 9855\\nmentExtraction,JDReview,MultilingualSentiment, Classification Emotion 12124 3876\\nToxicConversations 45823 4177\\nOnlineShopping, Waimai and WinoWhy (Zhang\\nTweetSentimentExtraction 24189 3292\\netal.,2020). Waimai 7697 303\\nWinoWhy 1160 443\\n•Retrieval: cMedQA,TREC-COVID,DuRead-\\ncMedQARetrieval 5898 804\\nerRetrieval,EcomRetrieval,MMarco,MedicalRe- TREC-COVID 803 79\\nDuReaderRetrieval 7996 865\\ntrieval,T2R,andVideoRetrieval.\\nEcomRetrieval 757 139\\n•Reranking: cMedQA and AskUbun- Retrieval MMarco 5944 741\\nMedicalRetrieval 829 78\\ntuDupQuestions.\\nT2R 8958 1042\\nVideoRetrieval 859 28\\nA.2 DataAnalysis\\ncMedQAReranking 806 99\\nReranking AskUbuntuDupQuestions 295 45\\nThestatisticsofdatavolumeforeachtaskcanbe\\nreferredtoinTable8,wherethedatavolumefor50 Table8: Thestatisticsofeachtaskdataset.\\ntasksrangesfromseveralhundredtohundredsof\\nthousandsofentries,providingampledataforthe\\nA.3 DataDeploy\\nmodel’s training and inference. The distribution\\nof the number of tokens for tasks is between 10 Foreachtask,weleverageGPT-3.5-Turbotogener-\\nand14,000,asshowninFigure4. Whenthemany- ateinstructions. Wesegmentourdatasetsintometa-\\nshotfine-tuningsequencelengthisfixed,thek-shot train and meta-test sets, holding back data from\\nnumbervariessignificantly. Figure5illustratesthe onetaskpercategoryforevaluatingourmethod’s\\nk-shotdistributionwithafixedtrainingsequence abilitytogeneralizetonewdata. Foroverallevalua-\\nlengthof8,000,rangingbetween0and350. When tion,wepossessbothin-domainandout-of-domain\\nthetrainingsequencelengthisincreasedto32,000, testsetsincomparisontothemeta-traindata. For\\nthe range of k-shot variation will exceed 1,000. Classification,meta-traindomainsincludeonline\\n11SPPA CRA ytiraloPnozamA sweiveRnozamA P2PgniretsulCvixrA S2SgniretsulCvixrA snoitseuQpuDutnubUksA IBAB QLOOB P2PgniretsulCvixroiB S2SgniretsulCvixroiB P2PgniretsulCsbrulB S2SgniretsulCsbrulB P2PgniretsulCSLC S2SgniretsulCSLC gniknareRAQdeMC laveirteRAQdeMC NNC LIAMYLIAD laveirteRuD laveirteRmocE noitomE K8MSG GAWSALLEH noitacifissalCweiveRDJ HTAM ULMM ocraMM laveirteRlacideM P2PgniretsulCvixrdeM tnemitneSlaugnilitluM AQEVITARRAN gnippohSenilnO AQkoobnepO CAUQ gniretsulCtiddeR P2PgniretsulCtiddeR gniretsulCegnahcxEkcatS P2PgniretsulCegnahcxEkcatS laveirteR2T DIVOC-CERT AQLUFHTURT P2PgniretsulCdangkneT S2SgniretsulCdangkneT S2SgniretsulCsweNuhT snoitasrevnoCcixoT noitcartxEtnemitneSteewT laveirteRoediV iamiaW yhWoniW\\n14000\\n12000\\n10000\\n8000\\n6000\\n4000\\n2000\\n0\\nTask Name\\nsnekoT\\nAvg Tokens Num\\nFigure4: Thetokendistributionsofeachtaskdataset.\\nSPPA ytiraloPnozamA sweiveRnozamA P2PgniretsulCvixrA S2SgniretsulCvixrA snoitseuQpuDutnubUksA IBAB QLOOB P2PgniretsulCvixroiB S2SgniretsulCvixroiB P2PgniretsulCsbrulB S2SgniretsulCsbrulB P2PgniretsulCSLC S2SgniretsulCSLC gniknareRAQdeMC laveirteRAQdeMC NNC LIAMYLIAD laveirteRuD noitomE K8MSG GAWSALLEH noitacifissalCweiveRDJ HTAM ULMM ocraMM laveirteRlacideM P2PgniretsulCvixrdeM tnemitneSlaugnilitluM AQEVITARRAN gnippohSenilnO AQkoobnepO CAUQ gniretsulCtiddeR P2PgniretsulCtiddeR gniretsulCegnahcxEkcatS P2PgniretsulCegnahcxEkcatS laveirteR2T DIVOC-CERT AQLUFHTURT S2SgniretsulCsweNuhT snoitasrevnoCcixoT noitcartxEtnemitneSteewT laveirteRoediV iamiaW\\n300\\n250\\n200\\n150\\n100\\n50\\n0\\nTask Name\\nstohs-K\\nAvg K-shots Num\\nFigure5: Thek-shotsdistributionsofeachtaskdataset.\\nshopping,multilingual,sentimentanalysis,andtox- withvariousk-shotvalues,including0,1,3,5,10,\\nicitydetection,whiletestdomainsextendtodining 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, and 300.\\nandcommonsense. ForReasoning,math-related For reference, Table 9 presents the results from\\ndomains are included in both meta-train and test Table 3 for the total test set. The findings show\\nsets. Whenassemblingthetrainingset,weensure thatperformancetrendsremainconsistentacross\\nanequitabledistributionofdataamongtasks,keep- differentsamplinginstancesfromeachdataset.\\ningthedifferenceindatavolumebetweenanytwo\\ntaskstonomorethantentimes,therebyenhancing B.2 HyperparametersStudy\\nmodelperformance. Wegeneratedemonstrations\\nα playsacrucialroleindetermining themodel’s\\nwith varying k-shots using the training set. For\\nperformance,asillustratedinFigure7,thevariance\\neachtask,weinfer100randomlyselectedtestset\\ninperformancebetweenzero-shotandmany-shot\\nentries per k-shot, assessing the model’s perfor-\\nscenariosismodel-dependent.\\nmancewithdifferentk-shotrangesfrom0to350.\\nγ adjusts the sensitivity of the rewards and\\nB ExperimentDetails makes the training process stable. Figure 8 illus-\\ntratesthatthebestsettingofγ is11.\\nB.1 Evaluation\\nS representsthelosscomputedfromthreeran-\\nWeevaluatedourmethodon12datasets,eachwith domlysampledpositionswithinthesamplingwin-\\n1,600 samples, totaling 19,200 test samples, and dow to calculate the reward. A high value of S\\nsamplingratesrangingfrom2%to100%. Foreach leads to non-representative sampling. From our\\ndataset, we collected 16 types of demonstrations experimentsinFigure6(b),wefoundthatthebest\\n12Dataset Models k=0 k=1 k=3 k=5 k=10 k=20 k=30 k=40 k=50 k=60 k=70 AVG MAX\\nNFT 0.29 0.25 0.24 0.23 0.27 0.26 0.19 0.16 0.2 0.18 0.18 0.22 0.29\\nIT 0.71 0.51 0.58 0.6 0.6 0.64 0.62 0.58 0.58 0.53 0.52 0.59 0.71\\nOpenbookQAid MetaICL 0.63 0.65 0.68 0.69 0.73 0.75 0.76 0.76 0.76 0.76 0.74 0.72 0.76\\nDrICL 0.74 0.74 0.77 0.76 0.77 0.79 0.78 0.79 0.79 0.78 0.77 0.77 0.79\\nNFT 0.17 0.03 0.01 0 0 0 0.02 0.03 0.01 0.02 0.12 0.04 0.17\\nIT 0.86 0.81 0.74 0.71 0.66 0.53 0.52 0.49 0.53 0.52 0.51 0.63 0.86\\nCLSClusteringS2Sid MetaICL 0.82 0.85 0.84 0.86 0.85 0.85 0.83 0.85 0.85 0.84 0.83 0.84 0.86\\nDrICL 0.85 0.86 0.86 0.84 0.87 0.86 0.86 0.87 0.85 0.86 0.88 0.86 0.88\\nNFT 0.02 0.03 0.06 0.06 0.05 0.05 0.03 0.03 0.04 0.06 0.02 0.04 0.06\\nIT 0.36 0.32 0.25 0.29 0.25 0.22 0.22 0.23 0.21 0.19 0.16 0.25 0.36\\nArxivClusteringS2Sood MetaICL 0.35 0.39 0.35 0.35 0.34 0.37 0.37 0.39 0.38 0.36 0.33 0.36 0.39\\nDrICL 0.33 0.34 0.37 0.36 0.36 0.39 0.4 0.38 0.36 0.42 0.34 0.37 0.42\\nTable9: TheevaluationonthewholetestsetofOpenbookQA,CLSClusteringS2S,andArxivClusteringS2S.Bold\\nindicatesthatourmodelperformsthebest.\\n(a) (b)\\nFigure 6: (a) The many-shot training loss of DrICL\\nconvergestoalowerlevelcomparedtoITandMetaICL.\\n(b)TheoptimalperformanceiswhentheparameterS Figure 8: (a) and (b) show the optimal γ settings for\\nissetto1onLlama-2-7b-chat-hf. Llama-2-7b-chat-hfandMistral-7B-Instruct-v0.2,with\\nbothmodelsachievingthebestperformanceatγ =11.\\nDataset NFT IT MetaICL DrICL\\nOpenbookQA 2.20E-03 3.90E-03 5.60E-03 8.00E-04\\nARC 2.41E-02 2.10E-02 2.00E-03 1.40E-03\\nCLSClusteringS2S 2.40E-03 1.00E-02 3.00E-04 2.00E-04\\nArxivClusteringS2S 1.00E-03 3.70E-03 8.00E-04 9.00E-04\\nTengkgnadClusteringS2S 7.00E-03 1.90E-03 5.00E-04 5.00E-04\\nTweetSentimentExtraction 3.30E-03 3.40E-03 4.90E-03 5.00E-04\\nFigure 7: (a) The optimal performance is when the GSM8K 8.50E-03 2.20E-03 1.00E-04 5.00E-04\\nXSUM 1.40E-03 2.20E-03 5.00E-05 5.00E-05\\nparameter α is set to 0.2 on Llama-2-7b-chat-hf. (b)\\nCNN 3.90E-03 2.30E-02 3.00E-03 3.70E-03\\nTheoptimalperformanceonMistral-7B-Instruct-v0.2 EcomRetrieval 4.10E-03 1.20E-01 7.00E-04 8.00E-04\\nVideoRetrieval 2.00E-02 1.10E-01 2.00E-03 0.00E+00\\nisachievedwithαsetto0.4.\\ncMedQA 0.00E+00 2.40E-02 8.60E-03 9.40E-03\\nAverage 6.49E-03 2.71E-02 2.38E-03 1.56E-03\\ntrainingresultswereachievedwithS = 1.\\nTable10:Theperformancevariationofvariousdatasets.\\nB.3 PerformanceVariance\\nTable 10 is the performance variance across the\\nNFT,IT,MetaICL,andDrICLmethods. InTable\\n10, we prove that our method demonstrates the VarianceTrendsAcrossTrainingProgress\\nMethods 20% 40% 60% 80% 100%\\nsmallest deviation, indicating greater stability in\\nperformanceask-shotchanges. DrICLw/oLocal 4.90 1.40 0.93 0.59 1.80\\nDrICL 6.60 1.85 0.55 0.35 0.32\\nB.4 DataNoiseSensitivity\\nTable11: Thelossvarianceduringthewholetraining\\nTable 11 illustrates the loss variance at different\\nprocess.\\ntrainingstageswithandwithoutlocalreweighting.\\n13',\n",
       " 'Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification.pdf': 'Neural network prediction of strong lensing systems\\nwith domain adaptation and uncertainty quantification\\nShrihanAgarwal1 AleksandraC´iprijanovic´1,2\\nshrihan@uchicago.edu aleksand@fnal.gov\\nBrianD.Nord1,2,3\\nnord@fnal.gov\\n1DepartmentofAstronomyandAstrophysics,UniversityofChicago,Chicago,IL60637\\n2FermiNationalAcceleratorLaboratory,Batavia,IL60510\\n3KavliInstituteforCosmologicalPhysics,UniversityofChicago,Chicago,IL60637\\nAbstract\\nModelingstronggravitationallensesiscomputationallyexpensiveforthecomplex\\ndatafrommodernandnext-generationcosmicsurveys. Deeplearninghasemerged\\nas a promising approach for finding lenses and predicting lensing parameters,\\nsuch as the Einstein radius. Mean-variance Estimators (MVEs) are a common\\napproachforobtainingaleatoric(data)uncertaintiesfromaneuralnetworkpredic-\\ntion. However,neuralnetworkshavenotbeendemonstratedtoperformwellon\\nout-of-domaintargetdatasuccessfully—e.g.,whentrainedonsimulateddataand\\nappliedtoreal,observationaldata. Inthiswork,weperformthefirststudyofthe\\nefficacyofMVEsincombinationwithunsuperviseddomainadaptation(UDA)on\\nstronglensingdata. Thesourcedomaindataisnoiseless,andthetargetdomain\\ndatahasnoisemimickingmoderncosmologysurveys. WefindthataddingUDA\\ntoMVEincreasestheaccuracyonthetargetdatabyafactorofabouttwooveran\\nMVEmodelwithoutUDA.IncludingUDAalsopermitsmuchmorewell-calibrated\\naleatoricuncertaintypredictions.Advancementsinthisapproachmayenablefuture\\napplicationsofMVEmodelstorealobservationaldata.\\n1 IntroductionandRelatedWork\\nStronggravitationallensingprovidescriticalinsightsintogalaxyevolution,darkmatter,anddark\\nenergy [4,112,111,72,57,41,110,100]. Moderncosmologicalsurveys[20,35,3,81,24,60,55,\\n32,98,15,29,62,119]areexpectedtocontain103-105lensingsystems[85,102,21]. Traditional\\nlensfindingtechniqueshavereliedheavilyonhuman-intensiveimagereviewing[87,86,94,95,77],\\nandmodelinghasreliedoncomputationally-intensiveanalyticlikelihood-fitting[13,65,58,27,31].\\nThishasmotivatedsuperviseddeeplearning-basedtechniqueslikeneuralnetworkclassificationand\\nregressiontobeappliedtostronglensinginadditiontoawidevarietyofcosmologytopics[80,105,\\n49]. Obtaining uncertainties is important for these areas of study [68]. They can be obtained in\\nnetworkregressionthroughavarietyofmethods—e.g.,MCDropout[36,47,116,64],Bayesian\\nNeuralNetworks[BNNs;19,18,8,114,43],mean-varianceestimation[103,109,25,106],Deep\\nEnsembles[17,40,106,63,28,37,2],DeepEvidentialRegression[124,79,78,6],andSimulation-\\nBasedInference[23,66,67,117]. Oncetrained, thesemethodsaretypicallyveryfastcompared\\ntotraditionalparametricmodelingmethods[68]. However,allofthesemodelsfacethechallenge\\nthat there is insufficient observational data for training and instead rely on realistic simulations\\n[12,82,5,70,91,93,92].\\nMachineLearningandthePhysicalSciencesWorkshop,NeurIPS2024.\\n5202\\nnaJ\\n7\\n]MI.hp-ortsa[\\n3v43330.1142:viXraDespite the realism, simulated data can differ from real, observational data — e.g., the image\\nnoise parameters, the range of astrophysics parameters, or the range of cosmology parameters.\\nSometimes,realdataisuseddirectlyintraining[52,53]oriscombinedwithsimulateddata[125].\\nThe differences between the training data (source domain data) and the real observational data\\n(targetdomaindata)constitutedomainshiftsbetweendatadistributionsthatcausemodelstofavor\\nthe source (training) data [69, 51, 127]. Typically, this problem arises when there are few or\\nno labels for the target data for the model to train on [122, 59]. Domain adaptation (DA) is a\\nclass of deep learning techniques that help neural networks adapt to domain shifts so that the\\nfeature spaces of the source and target data domains align when the domain-adapted model is\\napplied[34,48,30,83,126,128].Unsuperviseddomainadaptation(UDA)isasubclassoftechniques\\nthat useunlabeled target data [33, 123, 73]. Studieshave explored DA in many fields, including\\ncosmology and strong lensing [96, 134, 113, 130, 129, 131, 133, 132, 7, 118]. In this work, we\\ncombineMVEandUDAandcomparetheperformanceofMVE-UDAandMVE-onlymodelson\\nstronglensingdataintwodomainsthataredistinguishedbythenoiseintheimages.\\n2 Methods: Lensing,Mean-varianceNetworks,andDomainAdaptation\\nPhysicsofstronglensing:Galaxy-scalestronglensingoccurswhenaforegroundlensgalaxydeflects\\nlightfromabackgroundgalaxy,creatingamagnifiedandwarpedimageofthebackgroundobject.\\nThisdistortedimageistheprimaryobservable(Fig.1(a))forpredictingphysicsparameters. Multiple\\nkindsofnoisesources—e.g.,atmosphere,skybrightness,CCDreadout,andphotoncounting—can\\nfurtherdistorttheimage. TheEinsteinradiusθ indicatesthespatialscaleofthelensingsystemand\\nE\\ndependsonthelensgalaxymassdistribution,whichiscomplexbutcanoftenbemodeledwitha\\n5-parametersingularisothermalellipsoid(SIE),includingtheEinsteinradius[84]. Wepredictθ .\\nE\\nMean-varianceEstimationNetworks: Mean-varianceEstimators(MVEs)estimatethemeanand\\nvarianceofdatalabels,wherethevarianceisthesquareofthealeatoricuncertaintyσ [103,25,99].\\nal\\nTheMVElossfunctionissettotheβ-negativelog-likelihood: L = L (β ), where\\nMVE β−NLL NLL\\nβ is a hyperparameter. For the NLL loss, the gradient becomes small for high-variance data\\nNLL\\npoints, causing them to be undersampled. The β-NLL approach resolves this by multiplying a\\nvariance-re-weighting term σ2βNLL [99]. For β\\nNLL\\n= 1, the gradient is equivalent to that for the\\nmean-squarederror(MSE)loss. Forβ =0,theoriginalNLLlossisrecovered.\\nNLL\\nUnsupervisedDomainAdaptation(UDA):InUDA,thesourcedatahavelabels,whilethetarget\\ndatadonothavelabels. CommonUDAapproachesincludeadversarialmethods[74,42,38,39]\\nand distance-based methods [44, 61, 107, 122]. We use the distance-based method, Maximum\\nMeanDiscrepancy(MMD),whereinthelossL isamulti-dimensionaldistancebetweenlatent\\nUDA\\nembeddings of the source and target data sets [44, 108]. In minimizing the MMD loss, these\\nembeddingsof thesourceandtargetdatabecomealigned andincludedomain-invariant features,\\nw(cid:44)h(cid:80)ic(cid:68)h(cid:74)a(cid:72)llo(cid:3)(cid:68)w(cid:81)s(cid:71)th(cid:3)(cid:44)e(cid:86)m(cid:82)(cid:80)od(cid:68)e(cid:83)lt(cid:3)o(cid:89)(cid:24)p(cid:29)e(cid:3)r(cid:36)fo(cid:88)r(cid:74)m(cid:3)(cid:22)w(cid:20)e(cid:3)llondomain-shifteddata.\\n(cid:11)(cid:68)(cid:12) (cid:11)(cid:69)(cid:12)\\nFigure1: (a): Examplelensingimagesinthesourcedomain(top)andthetargetdomain(bottom)in\\nbandsg,r,andz. (b): IsomapsofthelatentspaceembeddingswhentheMVE-onlymodel(left)and\\ntheMVE-UDAmodel(right)areappliedtothesource(triplet)andtarget(circle)domaindata.\\nCombiningMVEandUDA:Wecombinethesetwomethodsviatheirlossfunctions. First, the\\nsourceandtargetdataarebothpassedthroughconvolutionallayers. UDAlossisthencalculatedon\\nthesourceandtargetdomainlatentembedding—i.e.,thelayerwhereextractedfeaturesareflattened\\nintoonedimension. Then,thesourcedomainembeddingispassedintodenselayers,andtheMVE\\n2Table1: Priordistributionsofthesimulationparametersfortrainingandtestsets.\\nParameter Prior\\nLenslightprofile\\nEinsteinradius θ (′′) U(1.0,3.0)\\nE\\nSérsicindex n U(2.0,5.0)\\nScaleradius R(′′) U(1.0,2.5)\\nEccentricity {e ,e } U(−0.2,0.2)\\nl,1 l,2\\nExternalshear {γ ,γ } U(−0.05,0.5)\\n1 2\\nSourcelightprofile\\nSérsicindex n U(2.0,4.0)\\nScaleradius R(′′) U(0.5,1.0)\\nEccentricity {e ,e } U(−0.2,0.2)\\ns,1 s,2\\nRelativeangularpositions {x,y}(′′) U(−0.5,0.5)\\nlossiscalculatedonthesourcedataonly. ThetotallossisL =L (β )+α ∗L ,\\nTot β−NLL NLL UDA UDA\\nwhereα determinestheweightoftheUDAlossrelativetotheMVEloss. Thetotallossisused\\nUDA\\ntoupdateallweights.\\n3 Experiments\\nData: Weusethedeeplenstronomy[82,12,14]tosimulateground-basedtelescopeimagesof\\ngalaxy-scalestronglenses. Imageshaveapixelscale0.263′′/pixel,matchingtheDarkEnergySurvey\\n(DES) [1]. The lens galaxy light profile (Sérsic) is assumed to be centered on the lensing mass.\\nWeusetheoreticallyandempiricallyinspireduniformpriorsfortypicalstronglensingparameter\\ndistributions. Forthelensmass,weuseSIEprofile,Einsteinradiusθ ,eccentricity{e ,e },and\\nE l,1 l,2\\nexternalshear{γ ,γ }[84]. Two-dimensionalsourceeccentricityis{e ,e }. Forthelensand\\n1 2 s,1 s,2\\nsourcelightprofiles,weuseSérsicprofileswithdistributionindexn,andscaleradiusR. Therelative\\nangularpositionsbetweenthebackgroundandlensgalaxiesare{x,y}. Priorrangesforallsimulation\\nparameterscanbefoundinTable1.\\nWeusethreephotometricbands(g,r,z)togetrichimagemorphologiesduringtraining. Togenerate\\nrealisticgalaxycolors,eachsimulatedlensgalaxyisassignedaredshiftintherangez <0.7,and\\nl\\neach background galaxy a redshift in the range 1.27 < z < 2 according to the DES Y3 Gold\\ns\\nCatalog [101,125]. Eachgalaxyisrandomlyassignedacolorfromarealgalaxyaccordingtothe\\nassignedredshift[26]. Sothateachlensgalaxyisvisiblebutnotsaturated,weusealowerlimitonthe\\napparentmagnitudeforallbands({m ,m ,m }>17.5)andanupperlimitforanyoneofthebands\\ng r z\\n({m ,m ,m } < 21). For the background galaxy, we use the limits {m ,m ,m } > 17.5 and\\ng r z g r z\\nm <22[125]. Redshiftsareusedsolelyforcolorsandareindependentofthelensingconfiguration.\\ng\\nWeinduceadomainshiftbetweenthesourceandthetargetdomainsintermsofimagenoise. The\\nsourcedatahasnoisecharacteristicsthatrepresentanearlynoiselessimage: readnoiseis0e−;no\\nskybrightnessisadded;theexposuretimeis1000seconds(sethightominimizePoisson/shotnoise);\\nthenumberofexposuresis10; thezero-pointmagnitudeis30; theCCDgainis6.083e−/count;\\nseeingis0.9′′(moderateformodernopticalcosmicsurveys)[1,45,82]. Incontrast,thetargetdata\\nhasnoisethatmimicsDES:thereadnoiseis7.0e−, theexposuretimeis90seconds(typicalof\\nmodernopticalcosmicsurveys)[1,26],andthenumberofexposures,themagnitudezeropoint,the\\nskybrightness,andtheseeingaresampledfromempiricaldistributions[1]. Ourdatasethas100,000\\nobjectseachforthesourceandtargetdata. Weusea70/10/20(training/validation/test)splitforall\\ndata. Thetestsetisusedforallresultsinthispaper. Allimageshaveashapeof40×40pixels. The\\ndatasetuses∼9GB.ProjectdatacanbefoundonZenodo. AnexampleimageisshowninFig.1(a).\\nModelOptimization: WebuildourmodelsusingPyTorch[89]. Thenetworkhasthreeconvolution\\nblocks(eachwithaconvolution,maxpooling,andbatchnormalizationlayer)followedbythreedense\\nlayerswith128,32,andtwonodes,respectively. MVEtechniquespresentchallengesfortraining—\\ne.g.,highlyfluctuatinglossfunctions[99]. Wefoundthatabatchsizeof128,alearningrateof0.001,\\nanddefaultsettingsforAdamWprovidedoptimalmodelperformance[75]. Weconsideredscheduling\\nofthehyperparametersfortheUDAandMVElosses.Wefoundthebestresultswithβ =0.5[99]\\nNLL\\nandα =1.4. Over150epochsoftraining,weselectedthebestmodelastheonethatminimized\\nUDA\\ntheMVElossonsourcedata. Forsomeseeds,theMVE-UDAmodelpathologicallypredictsamean\\n3orvarianceofzeroanddoesnotrecover—furtherinvestigationofthisisoutofscope. AppendixD\\nbrieflydiscussesarchitectureandtrainingdetails. ProjectcodecanbefoundonGithub.\\n(a)\\n(b)\\nFigure2: (a):ThefourleftplotsshowtheresidualsoftheEinsteinradiusinferencefortheMVE-only\\nmodel on the source data (purple, solid), the MVE-only model on the target data (pink, dashed),\\ntheMVE-UDAmodelonthesourcedata(orange,solid),andtheMVE-UDAmodelonthetarget\\ndata(cyan,dashed). Thepointsanderrorbarsaretheresidualsfromthemeansandthealeatoric\\nuncertaintiesforrandomlyselectedobjectsfromthetestsetineachdomain. Thesamplestandard\\ndeviationisshadedwiththecorrespondingcolorforeachplot. Thefifth(right)plotshowsthebinned\\naveragealeatoricuncertaintyσ¯ . (b): UncertaintycoverageontheEinsteinradiusfortheMVE-only\\nal\\nandMVE-UDAmodelsappliedtosourceandtargetdataforfiverandomlyseededmodels. Thebold\\nlineshighlighttheSelectedmodel. Panels(a)and(b)sharethesamecolorsandlinestyles.\\n4Table2: Meanresidual⟨δθ ⟩andmeanaleatoricuncertainty⟨σ ⟩oftheforthe“Selected”Model;\\nE al\\nthe“Median”⟨δθ ⟩ and⟨σ ⟩ acrossfiveMVE-onlyandfiveMVE-UDAmodelfits. The\\nE med al med\\nunitsarearcsec(′′). Calculationsaredescribedin§4. AppendixEbrieflydiscussesquantitiesforthe\\nfourothermodels.\\nSelected Median\\n(a)Residual⟨δθ ⟩ (b)Uncertainty⟨σ ⟩ (c)Residual⟨δθ ⟩ (d)Uncertainty⟨σ ⟩\\nE al E med al med\\nModel Source Target Source Target Source Target Source Target\\nMVE-only 0.0201 0.0818 0.0243 0.0253 0.0164 0.0585 0.0203 0.0205\\nMVE-UDA 0.0358 0.0425 0.0489 0.0503 0.0389 0.0461 0.0628 0.0628\\n4 Results: UDAimprovesMVEperformanceonthetargetdomain\\nWe trained five models that differed in their weight initialization. The median results across ini-\\ntializationsareconsistentwiththe“Selected”model(Table2). Therefore,unlessotherwisestated,\\nwereferonlytoresultsofthe“Selected”modelforclarityofpresentation. Forthemeanresidual\\n⟨δθ ⟩ = ⟨θ −θ ⟩ and aleatoric uncertainty ⟨σ ⟩, we take the mean over all the data\\nE E,pred E,true al\\nfor a single model. Ideally, the successful combination of MVE and UDA (MVE-UDA) would\\nperformcomparablytotheMVE-onlymodelonthesourcedata. Whenappliedtosourcedata,the\\nMVE-UDAmodelhasahighermeanresidual⟨δθ ⟩by∼0.015′′comparedtotheMVE-onlymodel\\nE\\n(Table2(a),Fig.2(a;fourleftplots)).ThemeanuncertaintyoftheMVE-UDAmodelisapproximately\\ntwicethatoftheMVE-onlymodel(Table2(b),Fig.2(a; fifth,rightplot)). Atthesametime,the\\nMVE-UDAmodelisbettercalibrated(lessunderconfident)thantheMVE-onlymodel(Fig.2(b)).\\nFortargetdata,however,theMVE-onlymodelhasahighmeanresidual⟨δθ ⟩ = 0.0818′′,twice\\nE\\ntheMVE-UDAmodel’smeanresidual⟨δθ ⟩ = 0.0425′′ (Table2(a)). Incontrast,theMVE-only\\nE\\nmodelhasalowmeanuncertainty⟨σ ⟩=0.0253′′,halftheMVE-UDAmodel’smeanuncertainty\\nal\\n⟨σ ⟩=0.0503′′(Table2(b)). Commensurately,theMVE-onlymodelissignificantlyoverconfident,\\nal\\nwhiletheMVE-UDAmodelisonlyslightlyoverconfident(Fig.2(b))ontargetdata.\\nTheMVE-UDAmodeluncertaintyishigheratbothlowandhighvaluesofθ (Fig.2(a)andFig.2(a;\\nE\\nfifth,rightplot))). ThehighuncertaintyfortheMVE-UDAmodelatlowθ maybeduetolowimage\\nE\\nresolutionorhighseeing,suchthatsmallerlensingarcscouldbeobscured. Thehighuncertainty\\nathighθ maybecausedbytheimagebeingtoosmalltocontainthelensingarcs. Theresiduals\\nE\\nand uncertainties for both models are slightly larger than uncertainties assumed in some studies\\n∼ 0.01′′ [71]butcomparabletothosefromtraditionalmodelingtechniques∼ 1-5%[97,104]. In\\nFig.1(b),wefindthatthetargetandsourceembeddingsdonotoverlapfortheMVE-onlymodel. In\\ncontrast,theembeddingsoverlapalmostcompletelyfortheMVE-UDAmodel,andthepointsexhibita\\ngradientintheEinsteinradius. Theseitemsindicatethattheembeddingvectorsofbotharecorrelated\\nwithθ ,butonlytheMVE-UDAembeddinghasaccuratealignmentacrossdomains. Lastly,the\\nE\\ncoverageoftheMVE-onlymodelvariessignificantlyonthetargetdataacrossinitializations,but\\nperformanceisstableforMVE-UDA(Fig.2(b)).WefindDAisessentialtoMVEforbettercalibrated,\\nconsistent,andaccurateperformanceondomain-shifteddatasets.\\n5 SummaryandOutlook\\nInthiswork,weprovidethefirstdemonstrationthatunsuperviseddomainadaptation(UDA)signifi-\\ncantlyimprovestheperformanceofmean-varianceestimator(MVE)modelsonunlabeledtargetdata.\\nWepredictedtheEinsteinradiusofstronggravitationallenseswithMVEs(§2).Weincurredadomain\\nshiftbetweenthesourceandtargetdomainssothatthesourceimagesareapproximatelynoiseless,\\nand the target images have noise characteristics similar to DES (§3). When applied to the noisy\\ntargetdata,theMVE-UDAmodelissignificantlybettercalibrated,moreconsistentacrossweight\\ninitialization, and moreaccurate than theMVE-only model(Fig. 2(a) andTable2(c,d)). Similar\\napproachesmayimproveneuralnetworkmodelperformancewhenappliedtoreal,observationaldata.\\n5References\\n[1] T.M.C.Abbott,F.B.Abdalla,S.Allam,A.Amara,J.Annis,J.Asorey,S.Avila,O.Ballester,\\nM. Banerji, W. Barkhouse, L. Baruah, M. Baumer, K. Bechtol, M. R. Becker, A. Benoit-\\nLévy,G.M.Bernstein,E.Bertin,J.Blazek,S.Bocquet,D.Brooks,D.Brout,E.Buckley-\\nGeer,D.L.Burke,V.Busti,R.Campisano,L.Cardiel-Sas,A.CarneroRosell,M.Carrasco\\nKind,J.Carretero,F.J.Castander,R.Cawthon,C.Chang,X.Chen,C.Conselice,G.Costa,\\nM.Crocce, C.E.Cunha, C.B.D’Andrea, L.N.daCosta, R.Das, G.Daues, T.M.Davis,\\nC. Davis, J. De Vicente, D. L. DePoy, J. DeRose, S. Desai, H. T. Diehl, J. P. Dietrich,\\nS.Dodelson,P.Doel,A.Drlica-Wagner,T.F.Eifler,A.E.Elliott,A.E.Evrard,A.Farahi,\\nA.FaustiNeto,E.Fernandez,D.A.Finley,B.Flaugher,R.J.Foley,P.Fosalba,D.N.Friedel,\\nJ.Frieman,J.García-Bellido,E.Gaztanaga,D.W.Gerdes,T.Giannantonio,M.S.S.Gill,\\nK.Glazebrook, D.A.Goldstein, M.Gower, D.Gruen, R.A.Gruendl, J.Gschwend, R.R.\\nGupta,G.Gutierrez,S.Hamilton,W.G.Hartley,S.R.Hinton,J.M.Hislop,D.Hollowood,\\nK.Honscheid,B.Hoyle,D.Huterer,B.Jain,D.J.James,T.Jeltema,M.W.G.Johnson,M.D.\\nJohnson,T.Kacprzak,S.Kent,G.Khullar,M.Klein,A.Kovacs,A.M.G.Koziol,E.Krause,\\nA.Kremin,R.Kron,K.Kuehn,S.Kuhlmann,N.Kuropatkin,O.Lahav,J.Lasker,T.S.Li,\\nR. T. Li, A. R. Liddle, M. Lima, H. Lin, P. López-Reyes, N. MacCrann, M. A. G. Maia,\\nJ.D.Maloney,M.Manera,M.March,J.Marriner,J.L.Marshall,P.Martini,T.McClintock,\\nT.McKay,R.G.McMahon,P.Melchior,F.Menanteau,C.J.Miller,R.Miquel,J.J.Mohr,\\nE.Morganson,J.Mould,E.Neilsen,R.C.Nichol,F.Nogueira,B.Nord,P.Nugent,L.Nunes,\\nR.L.C.Ogando,L.Old,A.B.Pace,A.Palmese,F.Paz-Chinchón,H.V.Peiris,W.J.Percival,\\nD. Petravick, A. A. Plazas, J. Poh, C. Pond, A. Porredon, A. Pujol, A. Refregier, K. Reil,\\nP.M.Ricker,R.P.Rollins,A.K.Romer,A.Roodman,P.Rooney,A.J.Ross,E.S.Rykoff,\\nM.Sako,M.L.Sanchez,E.Sanchez,B.Santiago,A.Saro,V.Scarpine,D.Scolnic,S.Serrano,\\nI.Sevilla-Noarbe,E.Sheldon,N.Shipp,M.L.Silveira,M.Smith,R.C.Smith,J.A.Smith,\\nM.Soares-Santos,F.Sobreira,J.Song,A.Stebbins,E.Suchyta,M.Sullivan,M.E.C.Swanson,\\nG.Tarle,J.Thaler,D.Thomas,R.C.Thomas,M.A.Troxel,D.L.Tucker,V.Vikram,A.K.\\nVivas, A. R. Walker, R. H. Wechsler, J. Weller, W. Wester, R. C. Wolf, H. Wu, B. Yanny,\\nA.Zenteno, Y.Zhang, J.Zuntz, DESCollaboration, S.Juneau, M.Fitzpatrick, R.Nikutta,\\nD.Nidever,K.Olsen,A.Scott,andNOAODataLab. TheDarkEnergySurvey: DataRelease\\n1. ApJS,239(2):18,December2018.\\n[2] TaigaAbe,E.KellyBuchanan,GeoffPleiss,RichardZemel,andJohnP.Cunningham. Deep\\nEnsemblesWork,ButAreTheyNecessary? arXive-prints,pagearXiv:2202.06985,February\\n2022.\\n[3] Hiroaki Aihara, Yusra AlSayyad, Makoto Ando, Robert Armstrong, James Bosch, Eiichi\\nEgami,HisanoriFurusawa,JunkoFurusawa,SumikoHarasawa,YuichiHarikane,Bau-Ching\\nHsieh, HiroyukiIkeda, KeiIto, IkuruIwata, TadayukiKodama, MichitaroKoike, Mitsuru\\nKokubo, Yutaka Komiyama, Xiangchong Li, Yongming Liang, Yen-Ting Lin, Robert H.\\nLupton,NateB.Lust,LaurenA.MacArthur,KenMawatari,SogoMineo,HironaoMiyatake,\\nSatoshiMiyazaki,SurhudMore,TakahiroMorishima,HitoshiMurayama,KimihikoNakajima,\\nFumiaki Nakata, Atsushi J. Nishizawa, Masamune Oguri, Nobuhiro Okabe, Yuki Okura,\\nYoshiakiOno,KenOsato,MasamiOuchi,Yen-ChenPan,AndrésA.PlazasMalagón,PaulA.\\nPrice,SophieL.Reed,EliS.Rykoff,TakatoshiShibuya,MirkoSimunovic,MichaelA.Strauss,\\nKanako Sugimori, Yasushi Suto, Nao Suzuki, Masahiro Takada, Yuhei Takagi, Tadafumi\\nTakata,SatoshiTakita,MasayukiTanaka,ShenliTang,DanS.Taranu,TsuyoshiTerai,Yoshiki\\nToba,EdwinL.Turner,HisakazuUchiyama,BovornpratchVijarnwannaluk,ChristopherZ.\\nWaters,YoshihikoYamada,NaoakiYamamoto,andTakujiYamashita. Thirddatareleaseof\\ntheHyperSuprime-CamSubaruStrategicProgram. PASJ,74(2):247–272,April2022.\\n[4] Andreas Albrecht, Gary Bernstein, Robert Cahn, Wendy L. Freedman, Jacqueline Hewitt,\\nWayneHu,JohnHuth,MarcKamionkowski,EdwardW.Kolb,LloydKnox,JohnC.Mather,\\nSuzanneStaggs,andNicholasB.Suntzeff. ReportoftheDarkEnergyTaskForce,September\\n2006. arXiv:astro-ph/0609591.\\n[5] AdamAmara,R.BentonMetcalf,ThomasJ.Cox,andJeremiahP.Ostriker. Simulationsof\\nstronggravitationallensingwithsubstructure. MNRAS,367(4):1367–1378,April2006.\\n[6] Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep Evidential\\nRegression. arXive-prints,pagearXiv:1910.02600,October2019.\\n6[7] YevonnaelAndrew. GalaxyClassificationUsingTransferLearningandEnsembleofCNNs\\nWithMultipleColourSpaces. arXive-prints,pagearXiv:2305.00002,March2023.\\n[8] Julyan Arbel, Konstantinos Pitas, Mariia Vladimirova, and Vincent Fortuin. A Primer on\\nBayesian Neural Networks: Review and Debates. arXiv e-prints, page arXiv:2309.16314,\\nSeptember2023.\\n[9] AstropyCollaboration,A.M.Price-Whelan,B.M.Sipo˝cz,H.M.Günther,P.L.Lim,S.M.\\nCrawford, S. Conseil, D. L. Shupe, M. W. Craig, N. Dencheva, A. Ginsburg, J. T. Vand\\nerPlas, L. D. Bradley, D. Pérez-Suárez, M. de Val-Borro, T. L. Aldcroft, K. L. Cruz, T. P.\\nRobitaille, E. J. Tollerud, C. Ardelean, T. Babej, Y. P. Bach, M. Bachetti, A. V. Bakanov,\\nS.P.Bamford,G.Barentsen,P.Barmby,A.Baumbach,K.L.Berry,F.Biscani,M.Boquien,\\nK.A.Bostroem,L.G.Bouma,G.B.Brammer,E.M.Bray,H.Breytenbach,H.Buddelmeijer,\\nD.J.Burke,G.Calderone,J.L.CanoRodríguez,M.Cara,J.V.M.Cardoso,S.Cheedella,\\nY.Copin,L.Corrales,D.Crichton,D.D’Avella,C.Deil,É.Depagne,J.P.Dietrich,A.Donath,\\nM. Droettboom, N. Earl, T. Erben, S. Fabbro, L. A. Ferreira, T. Finethy, R. T. Fox, L. H.\\nGarrison,S.L.J.Gibbons,D.A.Goldstein,R.Gommers,J.P.Greco,P.Greenfield,A.M.\\nGroener,F.Grollier,A.Hagen,P.Hirst,D.Homeier,A.J.Horton,G.Hosseinzadeh,L.Hu,\\nJ. S. Hunkeler, Ž. Ivezic´, A. Jain, T. Jenness, G. Kanarek, S. Kendrew, N. S. Kern, W. E.\\nKerzendorf,A.Khvalko,J.King,D.Kirkby,A.M.Kulkarni,A.Kumar,A.Lee,D.Lenz,S.P.\\nLittlefair,Z.Ma,D.M.Macleod,M.Mastropietro,C.McCully,S.Montagnac,B.M.Morris,\\nM.Mueller,S.J.Mumford,D.Muna,N.A.Murphy,S.Nelson,G.H.Nguyen,J.P.Ninan,\\nM.Nöthe, S.Ogaz, S.Oh, J.K.Parejko, N.Parley, S.Pascual, R.Patil, A.A.Patil, A.L.\\nPlunkett, J.X.Prochaska, T.Rastogi, V.ReddyJanga, J.Sabater, P.Sakurikar, M.Seifert,\\nL.E.Sherbert,H.Sherwood-Taylor,A.Y.Shih,J.Sick,M.T.Silbiger,S.Singanamalla,L.P.\\nSinger, P. H. Sladen, K. A. Sooley, S. Sornarajah, O. Streicher, P. Teuben, S. W. Thomas,\\nG.R.Tremblay,J.E.H.Turner,V.Terrón,M.H.vanKerkwijk,A.delaVega,L.L.Watkins,\\nB.A.Weaver,J.B.Whitmore,J.Woillez,V.Zabalza,andAstropyContributors. TheAstropy\\nProject:BuildinganOpen-scienceProjectandStatusofthev2.0CorePackage.AJ,156(3):123,\\nSeptember2018.\\n[10] Astropy Collaboration, Adrian M. Price-Whelan, Pey Lian Lim, Nicholas Earl, Nathaniel\\nStarkman, Larry Bradley, David L. Shupe, Aarya A. Patil, Lia Corrales, C. E. Brasseur,\\nMaximilianN\"othe,AxelDonath,ErikTollerud,BrettM.Morris,AdamGinsburg,EeroVaher,\\nBenjaminA.Weaver,JamesTocknell,WilliamJamieson,MartenH.vanKerkwijk,ThomasP.\\nRobitaille,BruceMerry,MatteoBachetti,H.MoritzG\"unther,ThomasL.Aldcroft,JaimeA.\\nAlvarado-Montes,AnneM.Archibald,AttilaB’odi,ShreyasBapat,GeertBarentsen,Juanjo\\nBaz’an,ManishBiswas,M’ed’ericBoquien,D.J.Burke,DariaCara,MihaiCara,KyleE.\\nConroy, Simon Conseil, Matthew W. Craig, Robert M. Cross, Kelle L. Cruz, Francesco\\nD’Eugenio, Nadia Dencheva, Hadrien A. R. Devillepoix, J\"org P. Dietrich, Arthur Davis\\nEigenbrot, Thomas Erben, Leonardo Ferreira, Daniel Foreman-Mackey, Ryan Fox, Nabil\\nFreij,SuyogGarg,RobelGeda,LaurenGlattly,YashGondhalekar,KarlD.Gordon,David\\nGrant, Perry Greenfield, Austen M. Groener, Steve Guest, Sebastian Gurovich, Rasmus\\nHandberg, Akeem Hart, Zac Hatfield-Dodds, Derek Homeier, Griffin Hosseinzadeh, Tim\\nJenness,CraigK.Jones,PrajwelJoseph,J.BryceKalmbach,EmirKaramehmetoglu,Mikolaj\\nKaluszy’nski,MichaelS.P.Kelley,NicholasKern,WolfgangE.Kerzendorf,EricW.Koch,\\nShankarKulumani,AntonyLee,ChunLy,ZhiyuanMa,ConorMacBride,JakobM.Maljaars,\\nDemitriMuna, N.A.Murphy, HenrikNorman, RichardO’Steen, KyleA.Oman, Camilla\\nPacifici, Sergio Pascual, J. Pascual-Granado, Rohit R. Patil, Gabriel I. Perren, Timothy E.\\nPickering,TanujRastogi,BenjaminR.Roulston,DanielF.Ryan,EliS.Rykoff,JoseSabater,\\nParikshitSakurikar,Jes’usSalgado,AniketSanghi,NicholasSaunders,VolodymyrSavchenko,\\nLudwig Schwardt, Michael Seifert-Eckert, Albert Y. Shih, Anany Shrey Jain, Gyanendra\\nShukla,JonathanSick,ChrisSimpson,SudheeshSinganamalla,LeoP.Singer,JaladhSinghal,\\nManodeep Sinha, Brigitta M. SipHocz, Lee R. Spitler, David Stansby, Ole Streicher, Jani\\nSumak, JohnD. Swinbank, Dan S.Taranu, Nikita Tewary, Grant R. Tremblay, Miguel de\\nVal-Borro,SamuelJ.VanKooten,ZlatanVasovi’c,ShresthVerma,Jos’eVin’iciusdeMiranda\\nCardoso,PeterK.G.Williams,TomJ.Wilson,BenjaminWinkel,W.M.Wood-Vasey,Rui\\nXue, Peter Yoachim, Chen Zhang, Andrea Zonca, and Astropy Project Contributors. The\\nAstropyProject: SustainingandGrowingaCommunity-orientedOpen-sourceProjectandthe\\nLatestMajorRelease(v5.0)oftheCorePackage. ApJ,935(2):167,August2022.\\n7[11] AstropyCollaboration,T.P.Robitaille,E.J.Tollerud,P.Greenfield,M.Droettboom,E.Bray,\\nT. Aldcroft, M. Davis, A. Ginsburg, A. M. Price-Whelan, W. E. Kerzendorf, A. Conley,\\nN.Crighton,K.Barbary,D.Muna,H.Ferguson,F.Grollier,M.M.Parikh,P.H.Nair,H.M.\\nUnther,C.Deil,J.Woillez,S.Conseil,R.Kramer,J.E.H.Turner,L.Singer,R.Fox,B.A.\\nWeaver, V. Zabalza, Z. I. Edwards, K. Azalee Bostroem, D. J. Burke, A. R. Casey, S. M.\\nCrawford,N.Dencheva,J.Ely,T.Jenness,K.Labrie,P.L.Lim,F.Pierfederici,A.Pontzen,\\nA.Ptak,B.Refsdal,M.Servillat,andO.Streicher. Astropy: AcommunityPythonpackage\\nforastronomy. A&A,558:A33,October2013.\\n[12] SimonBirrerandAdamAmara. Lenstronomy: multi-purposegravitationallensmodelling\\nsoftwarepackage,2018.\\n[13] SimonBirrer,AdamAmara,andAlexandreRefregier. Gravitationallensmodelingwithbasis\\nsets. TheAstrophysicalJournal,813(2):102,nov2015.\\n[14] SimonBirrer,AnowarJ.Shajib,DanielGilman,AymericGalan,JelleAalbers,MartinMillon,\\nRobertMorgan,GiuliaPagano,JiWonPark,LucaTeodori,NicolasTessore,MadisonUeland,\\nLyneVandeVyvere,SebastianWagner-Carena,EwoudWempe,LilanYang,XuhengDing,\\nThomas Schmidt, Dominique Sluse, Ming Zhang, and Adam Amara. lenstronomy ii: A\\ngravitationallensingsoftwareecosystem. JournalofOpenSourceSoftware,6(62):3283,2021.\\n[15] CoreyBrummel-Smith,DanielleSkinner,SnigdaaS.Sethuram,JohnH.Wise,BinXia,and\\nKhushiTaori. InferredgalaxypropertiesduringCosmicDawnfromearlyJWSTphotometry\\nresults,August2023. arXiv:2302.04882[astro-ph].\\n[16] LarsBuitinck,GillesLouppe,MathieuBlondel,FabianPedregosa,AndreasMueller,Olivier\\nGrisel,VladNiculae,PeterPrettenhofer,AlexandreGramfort,JaquesGrobler,RobertLayton,\\nJake VanderPlas, Arnaud Joly, Brian Holt, and Gaël Varoquaux. API design for machine\\nlearning software: experiences from the scikit-learn project. In ECML PKDD Workshop:\\nLanguagesforDataMiningandMachineLearning,pages108–122,2013.\\n[17] Jesús Carrete, Hadrián Montes-Campos, Ralf Wanzenböck, Esther Heid, and Georg K. H.\\nMadsen. Deepensemblesvscommitteesforuncertaintyestimationinneural-networkforce\\nfields: Comparison and application to active learning. The Journal of Chemical Physics,\\n158(20):204801,May2023.\\n[18] Daniel T. Chang. Bayesian Neural Networks: Essentials. arXiv e-prints, page\\narXiv:2106.13594,June2021.\\n[19] TomCharnock,LaurencePerreault-Levasseur,andFrançoisLanusse. BayesianNeuralNet-\\nworks. arXive-prints,pagearXiv:2006.01490,June2020.\\n[20] TheDarkEnergySurveyCollaboration. TheDarkEnergySurvey,October2005. arXiv:astro-\\nph/0510346.\\n[21] ThomasE.Collett. ThePopulationofGalaxy-GalaxyStrongLensesinForthcomingOptical\\nImagingSurveys. ApJ,811(1):20,September2015.\\n[22] R.Collobert,K.Kavukcuoglu,andC.Farabet.Torch7:Amatlab-likeenvironmentformachine\\nlearning. InBigLearn,NIPSWorkshop,2011.\\n[23] KyleCranmer,JohannBrehmer,andGillesLouppe.Thefrontierofsimulation-basedinference.\\narXive-prints,pagearXiv:1911.01429,November2019.\\n[24] JelteT.A.deJong,GijsA.VerdoesKleijn,KonradH.Kuijken,andEdwinA.Valentijn. The\\nKilo-DegreeSurvey. ExperimentalAstronomy,35(1-2):25–44,January2013.\\n[25] NickiS.Detlefsen,MartinJørgensen,andSørenHauberg. Reliabletrainingandestimationof\\nvariancenetworks. arXive-prints,pagearXiv:1906.03260,June2019.\\n[26] Arjun Dey, David J. Schlegel, Dustin Lang, Robert Blum, Kaylan Burleigh, Xiaohui Fan,\\nJoseph R. Findlay, Doug Finkbeiner, David Herrera, Stéphanie Juneau, Martin Landriau,\\nMichaelLevi,IanMcGreer,AaronMeisner,AdamD.Myers,JohnMoustakas,PeterNugent,\\n8AnnaPatej,EdwardF.Schlafly,AlistairR.Walker,FranciscoValdes,BenjaminA.Weaver,\\nChristophe Yèche, Hu Zou, Xu Zhou, Behzad Abareshi, T. M. C. Abbott, Bela Abolfathi,\\nC.Aguilera,ShadabAlam,LoriAllen,A.Alvarez,JamesAnnis,BehzadAnsarinejad,Marie\\nAubert,JacquelineBeechert,EricF.Bell,SegevY.BenZvi,FlorianBeutler,RichardM.Bielby,\\nAdamS.Bolton,CésarBriceño,ElizabethJ.Buckley-Geer,KarenButler,AnnalisaCalamida,\\nRaymondG.Carlberg,PaulCarter,RicardCasas,FranciscoJ.Castander,YumiChoi,Johan\\nComparat,ElenaCukanovaite,TimothéeDelubac,KaitlinDeVries,SharmilaDey,Govinda\\nDhungana,MarkDickinson,ZhejieDing,JohnB.Donaldson,YutongDuan,ChristopherJ.\\nDuckworth,SarahEftekharzadeh,DanielJ.Eisenstein,ThomasEtourneau,ParkerA.Fagrelius,\\nJayFarihi,MikeFitzpatrick,AndreuFont-Ribera,LeahFulmer,BorisT.Gänsicke,Enrique\\nGaztanaga,KoshyGeorge,DavidW.Gerdes,SatyaGontchoA.Gontcho,ClaudioGorgoni,\\nGregoryGreen,JulienGuy,DianeHarmer,M.Hernandez,KlausHonscheid,LijuanWendy\\nHuang,DavidJ.James,BuellT.Jannuzi,LinhuaJiang,RichardJoyce,ArminKarcher,Sonia\\nKarkar,RobertKehoe,Jean-PaulKneib,AndreaKueter-Young,Ting-WenLan,TodR.Lauer,\\nLaurentLeGuillou,AugusteLeVanSuu,JaeHyeonLee,MichaelLesser,LaurencePerreault\\nLevasseur,TingS.Li,JustinL.Mann,RobertMarshall,C.E.Martínez-Vázquez,PaulMartini,\\nHélionduMasdesBourboux,SeanMcManus,TobiasGabrielMeier,BriceMénard,Nigel\\nMetcalfe,AndreaMuñoz-Gutiérrez,JoanNajita,KevinNapier,GauthamNarayan,JeffreyA.\\nNewman,JundanNie,BrianNord,DaraJ.Norman,KnutA.G.Olsen,AnthonyPaat,Nathalie\\nPalanque-Delabrouille,XiyanPeng,ClaireL.Poppett,MeganR.Poremba,AbhishekPrakash,\\nDavidRabinowitz,AnandRaichoor,MehdiRezaie,A.N.Robertson,NatalieA.Roe,AshleyJ.\\nRoss,NicholasP.Ross,GregoryRudnick,SashaSafonova,AbhijitSaha,F.JavierSánchez,\\nElodieSavary,HeidiSchweiker,AdamScott,Hee-JongSeo,HuanyuanShan,DavidR.Silva,\\nZacharySlepian,ChristianSoto,DavidSprayberry,RyanStaten,ColeyM.Stillman,RobertJ.\\nStupak,DavidL.Summers,SukSienTie,H.Tirado,MarianaVargas-Magaña,A.Katherina\\nVivas,RisaH.Wechsler,DougWilliams,JinyiYang,QianYang,TolgaYapici,DennisZaritsky,\\nA.Zenteno,KaiZhang,TianmengZhang,RongpuZhou,andZhiminZhou. Overviewofthe\\nDESILegacyImagingSurveys. AJ,157(5):168,May2019.\\n[27] WeiDu,LipingFu,YipingShu,RanLi,ZuhuiFan,andChenggangShu. MassReconstruc-\\ntionofGalaxy-scaleStrongGravitationalLensesUsingaBrokenPower-lawModel. ApJ,\\n953(2):189,August2023.\\n[28] Romain Egele, Romit Maulik, Krishnan Raghavan, Bethany Lusch, Isabelle Guyon, and\\nPrasannaBalaprakash. AutoDEUQ:AutomatedDeepEnsemblewithUncertaintyQuantifica-\\ntion. arXive-prints,pagearXiv:2110.13511,October2021.\\n[29] TimEifler,HironaoMiyatake,ElisabethKrause,ChenHeinrich,VivianMiranda,Christopher\\nHirata,JiachuanXu,ShoubanehHemmati,MelanieSimet,PeterCapak,AmiChoi,Olivier\\nDoré,CyrilleDoux,XiaoFang,RebekahHounsell,EricHuff,Hung-JinHuang,MikeJarvis,\\nJeffreyKruk,DanMasters,EduardoRozo,DanScolnic,DavidN.Spergel,MichaelTroxel,\\nAnjavonderLinden,YunWang,DavidH.Weinberg,LukasWenzl,andHao-YiWu. Cos-\\nmology with the Roman Space Telescope - multiprobe strategies. Monthly Notices of the\\nRoyalAstronomicalSociety,507:1746–1761,October2021. Publisher: OUPADSBibcode:\\n2021MNRAS.507.1746E.\\n[30] LinusEricsson,DaLi,andTimothyM.Hospedales. BetterPracticesforDomainAdaptation.\\narXive-prints,pagearXiv:2309.03879,September2023.\\n[31] AmyEtherington,JamesW.Nightingale,RichardMassey,XiaoYueCao,AndrewRobertson,\\nNicolaC.Amorisco,AristeidisAmvrosiadis,ShaunCole,CarlosS.Frenk,QiuhanHe,Ran\\nLi,andSut-IengTam. Automatedgalaxy-galaxystronglensmodelling: Nolensleftbehind.\\nMNRAS,517(3):3275–3302,December2022.\\n[32] EuclidCollaboration,Y.Mellier,Abdurro’uf,J.A.AcevedoBarroso,A.Achúcarro,J.Adamek,\\nR.Adam,G.E.Addison,N.Aghanim,M.Aguena,V.Ajani,Y.Akrami,A.Al-Bahlawan,\\nA.Alavi,I.S.Albuquerque,G.Alestas,G.Alguero,A.Allaoui,S.W.Allen,V.Allevato,A.V.\\nAlonso-Tetilla,B.Altieri,A.Alvarez-Candal,A.Amara,L.Amendola,J.Amiaux,I.T.Andika,\\nS. Andreon, A. Andrews, G. Angora, R. E. Angulo, F. Annibali, A. Anselmi, S. Anselmi,\\nS.Arcari,M.Archidiacono,G.Aricò,M.Arnaud,S.Arnouts,M.Asgari,J.Asorey,L.Atayde,\\nH.Atek,F.Atrio-Barandela,M.Aubert,E.Aubourg,T.Auphan,N.Auricchio,B.Aussel,\\n9H. Aussel, P. P. Avelino, A. Avgoustidis, S. Avila, S. Awan, R. Azzollini, C. Baccigalupi,\\nE. Bachelet, D. Bacon, M. Baes, M. B. Bagley, B. Bahr-Kalus, A. Balaguera-Antolinez,\\nE. Balbinot, M. Balcells, M. Baldi, I. Baldry, A. Balestra, M. Ballardini, O. Ballester,\\nM. Balogh, E. Bañados, R. Barbier, S. Bardelli, T. Barreiro, J. C. Barriere, B. J. Barros,\\nA.Barthelemy,N.Bartolo,A.Basset,P.Battaglia,A.J.Battisti,C.M.Baugh,L.Baumont,\\nL.Bazzanini,J.P.Beaulieu,V.Beckmann,A.N.Belikov,J.Bel,F.Bellagamba,M.Bella,\\nE.Bellini,K.Benabed,R.Bender,G.Benevento,C.L.Bennett,K.Benson,P.Bergamini,J.R.\\nBermejo-Climent,F.Bernardeau,D.Bertacca,M.Berthe,J.Berthier,M.Bethermin,F.Beutler,\\nC. Bevillon, S. Bhargava, R.Bhatawdekar, L.Bisigello, A. Biviano, R. P. Blake, A.Blan-\\nchard,J.Blazek,L.Blot,A.Bosco,C.Bodendorf,T.Boenke,H.Böhringer,M.Bolzonella,\\nA.Bonchi, M.Bonici, D.Bonino, L.Bonino, C.Bonvin, W.Bon, J.T.Booth, S.Borgani,\\nA.S.Borlaff,E.Borsato,A.Bosco,B.Bose,M.T.Botticella,A.Boucaud,F.Bouche,J.S.\\nBoucher,D.Boutigny,T.Bouvard,H.Bouy,R.A.A.Bowler,V.Bozza,E.Bozzo,E.Bran-\\nchini,S.Brau-Nogue,P.Brekke,M.N.Bremer,M.Brescia,M.A.Breton,J.Brinchmann,\\nT.Brinckmann,C.Brockley-Blatt,M.Brodwin,L.Brouard,M.L.Brown,S.Bruton,J.Bucko,\\nH.Buddelmeijer,G.Buenadicha,F.Buitrago,P.Burger,C.Burigana,V.Busillo,D.Busonero,\\nR.Cabanac,L.Cabayol-Garcia,M.S.Cagliari,A.Caillat,L.Caillat,M.Calabrese,A.Calabro,\\nG.Calderone,F.Calura,B.CamachoQuevedo,S.Camera,L.Campos,G.Canas-Herrera,\\nG. P. Candini, M. Cantiello, V. Capobianco, E. Cappellaro, N. Cappelluti, A. Cappi, K. I.\\nCaputi,C.Cara,C.Carbone,V.F.Cardone,E.Carella,R.G.Carlberg,M.Carle,L.Carminati,\\nF.Caro, J.M.Carrasco, J.Carretero, P.Carrilho, J.CarronDuque, B.Carry, A.Carvalho,\\nC. S. Carvalho, R. Casas, S. Casas, P. Casenove, C. M. Casey, P. Cassata, F. J. Castander,\\nD.Castelao,M.Castellano,L.Castiblanco,G.Castignani,T.Castro,C.Cavet,S.Cavuoti,\\nP.Y.Chabaud,K.C.Chambers,Y.Charles,S.Charlot,N.Chartab,R.Chary,F.Chaumeil,\\nH.Cho,G.Chon,E.Ciancetta,P.Ciliegi,A.Cimatti,M.Cimino,M.R.L.Cioni,R.Claydon,\\nC.Cleland,B.Clément,D.L.Clements,N.Clerc,S.Clesse,S.Codis,F.Cogato,J.Colbert,\\nR.E.Cole,P.Coles,T.E.Collett,R.S.Collins,C.Colodro-Conde,C.Colombo,F.Combes,\\nV.Conforti,G.Congedo,S.Conseil,C.J.Conselice,S.Contarini,T.Contini,L.Conversi,A.R.\\nCooray,Y.Copin,P.S.Corasaniti,P.Corcho-Caballero,L.Corcione,O.Cordes,O.Corpace,\\nM.Correnti,M.Costanzi,A.Costille,F.Courbin,L.CourcoultMifsud,H.M.Courtois,M.C.\\nCousinou,G.Covone,T.Cowell,C.Cragg,G.Cresci,S.Cristiani,M.Crocce,M.Cropper,\\nP.ECrouzet,B.Csizi,J.G.Cuby,E.Cucchetti,O.Cucciati,J.C.Cuillandre,P.A.C.Cunha,\\nV.Cuozzo,E.Daddi,M.D’Addona,C.Dafonte,N.Dagoneau,E.Dalessandro,G.B.Dalton,\\nG.D’Amico,H.Dannerbauer,P.Danto,I.Das,A.DaSilva,R.daSilva,G.Daste,J.E.Davies,\\nS.Davini,T.deBoer,R.Decarli,B.DeCaro,H.Degaudenzi,G.Degni,J.T.A.deJong,L.F.\\ndelaBella,S.delaTorre,F.Delhaise,D.Delley,G.Delucchi,G.DeLucia,J.Denniston,\\nF.DePaolis,M.DePetris,A.Derosa,S.Desai,V.Desjacques,G.Despali,G.Desprez,J.De\\nVicente-Albendea,Y.Deville,J.D.F.Dias,A.Díaz-Sánchez,J.J.Diaz,S.DiDomizio,J.M.\\nDiego, D. Di Ferdinando, A. M. Di Giorgio, P. Dimauro, J. Dinis, K. Dolag, C. Dolding,\\nH.Dole,H.DomínguezSánchez,O.Doré,F.Dournac,M.Douspis,H.Dreihahn,B.Droge,\\nB.Dryer,F.Dubath,P.A.Duc,F.Ducret,C.Duffy,F.Dufresne,C.A.J.Duncan,X.Dupac,\\nV.Duret,R.Durrer,F.Durret,S.Dusini,A.Ealet,A.Eggemeier,P.R.M.Eisenhardt,D.Elbaz,\\nM.Y.Elkhashab,A.Ellien,J.Endicott,A.Enia,T.Erben,J.A.EscartinVigo,S.Escoffier,\\nI.EscuderoSanz,J.Essert,S.Ettori,M.Ezziati,G.Fabbian,M.Fabricius,Y.Fang,A.Farina,\\nM. Farina, R. Farinelli, S. Farrens, F. Faustini, A. Feltre, A. M. N. Ferguson, P. Ferrando,\\nA. G. Ferrari, A. Ferré-Mateu, P. G. Ferreira, I. Ferreras, I. Ferrero, S. Ferriol, P. Ferruit,\\nD.Filleul,F.Finelli,S.L.Finkelstein,A.Finoguenov,B.Fiorini,F.Flentge,P.Focardi,J.Fon-\\nseca,A.Fontana,F.Fontanot,F.Fornari,P.Fosalba,M.Fossati,S.Fotopoulou,D.Fouchez,\\nN.Fourmanoit, M.Frailis, D.Fraix-Burnet, E.Franceschi, A.Franco, P.Franzetti, J.Frei-\\nhoefer, G. Frittoli, P. A. Frugier, N. Frusciante, A. Fumagalli, M. Fumagalli, M. Fumana,\\nY.Fu,L.Gabarra,S.Galeotta,L.Galluccio,K.Ganga,H.Gao,J.García-Bellido,K.Garcia,\\nJ. P. Gardner, B. Garilli, L. M. Gaspar-Venancio, T. Gasparetto, V. Gautard, R. Gavazzi,\\nE.Gaztanaga,L.Genolet,R.GenovaSantos,F.Gentile,K.George,Z.Ghaffari,F.Giacomini,\\nF. Gianotti, G. P. S. Gibb, W. Gillard, B. Gillis, M. Ginolfi, C. Giocoli, M. Girardi, S. K.\\nGiri, L. W. K. Goh, P. Gómez-Alvarez, A. H. Gonzalez, E. J. Gonzalez, J. C. Gonzalez,\\nS.GouyouBeauchamps,G.Gozaliasl,J.Gracia-Carpio,S.Grandis,B.R.Granett,M.Granvik,\\nA.Grazian,A.Gregorio,C.Grenet,C.Grillo,F.Grupp,C.Gruppioni,A.Gruppuso,C.Guer-\\nbuez,S.Guerrini,M.Guidi,P.Guillard,C.M.Gutierrez,P.Guttridge,L.Guzzo,S.Gwyn,\\nJ.Haapala,J.Haase,C.R.Haddow,M.Hailey,A.Hall,D.Hall,N.Hamaus,B.S.Haridasu,\\n10J.Harnois-Déraps,C.Harper,W.G.Hartley,G.Hasinger,F.Hassani,N.A.Hatch,S.V.H.\\nHaugan,B.Häußler,A.Heavens,L.Heisenberg,A.Helmi,G.Helou,S.Hemmati,K.Henares,\\nO.Herent,C.Hernández-Monteagudo,T.Heuberger,P.C.Hewett,S.Heydenreich,H.Hilde-\\nbrandt, M. Hirschmann, J. Hjorth, J. Hoar, H. Hoekstra, A. D. Holland, M. S. Holliman,\\nW.Holmes,I.Hook,B.Horeau,F.Hormuth,A.Hornstrup,S.Hosseini,D.Hu,P.Hudelot,\\nM. J. Hudson, M. Huertas-Company, E. M. Huff, A. C. N. Hughes, A. Humphrey, L. K.\\nHunt,D.D.Huynh,R.Ibata,K.Ichikawa,S.Iglesias-Groth,O.Ilbert,S.Ilic´,L.Ingoglia,\\nE.Iodice, H.Israel, U.E.Israelsson, L.Izzo, P.Jablonka, N.Jackson, J.Jacobson, M.Ja-\\nfariyazani,K.Jahnke,H.Jansen,M.J.Jarvis,J.Jasche,M.Jauzac,N.Jeffrey,M.Jhabvala,\\nY.Jimenez-Teja,A.JimenezMuñoz,B.Joachimi,P.H.Johansson,S.Joudaki,E.Jullo,J.J.E.\\nKajava,Y.Kang,A.Kannawadi,V.Kansal,D.Karagiannis,M.Kärcher,A.Kashlinsky,M.V.\\nKazandjian,F.Keck,E.Keihänen,E.Kerins,S.Kermiche,A.Khalil,A.Kiessling,K.Kiiveri,\\nM.Kilbinger,J.Kim,R.King,C.C.Kirkpatrick,T.Kitching,M.Kluge,M.Knabenhans,J.H.\\nKnapen,A.Knebe,J.P.Kneib,R.Kohley,L.V.E.Koopmans,H.Koskinen,E.Koulouridis,\\nR.Kou,A.Kovács,I.Kova{cˇ}ic´,A.Kowalczyk,K.Koyama,K.Kraljic,O.Krause,S.Kruk,\\nB.Kubik,U.Kuchner,K.Kuijken,M.Kümmel,M.Kunz,H.Kurki-Suonio,F.Lacasa,C.G.\\nLacey,F.LaFranca,N.Lagarde,O.Lahav,C.Laigle,A.LaMarca,O.LaMarle,B.Lamine,\\nM.C.Lam,A.Lançon,H.Landt,M.Langer,A.Lapi,C.Larcheveque,S.S.Larsen,M.Lat-\\ntanzi,F.Laudisio,D.Laugier,R.Laureijs,G.Lavaux,A.Lawrenson,A.Lazanu,T.Lazeyras,\\nQ.LeBoulc’h,A.M.C.LeBrun,V.LeBrun,F.Leclercq,S.Lee,J.LeGraet,L.Legrand,\\nK. N. Leirvik, M. Le Jeune, M. Lembo, D. Le Mignant, M. D. Lepinzan, F. Lepori, G. F.\\nLesci,J.Lesgourgues,L.Leuzzi,M.E.Levi,T.I.Liaudat,G.Libet,P.Liebing,S.Ligori,\\nP.B.Lilje,C.C.Lin,D.Linde,E.Linder,V.Lindholm,L.Linke,S.S.Li,S.J.Liu,I.Lloro,\\nF.S.N.Lobo,N.Lodieu,M.Lombardi,L.Lombriser,P.Lonare,G.Longo,M.López-Caniego,\\nX. Lopez Lopez, J. Lorenzo Alvarez, A. Loureiro, J. Loveday, E. Lusso, J. Macias-Perez,\\nT.Maciaszek,M.Magliocchetti,F.Magnard,E.A.Magnier,A.Magro,G.Mahler,G.Mainetti,\\nD.Maino,E.Maiorano,E.Maiorano,N.Malavasi,G.A.Mamon,C.Mancini,R.Mandelbaum,\\nM.Manera,A.Manjón-García,F.Mannucci,O.Mansutti,M.ManteigaOuteiro,R.Maoli,\\nC.Maraston,S.Marcin,P.Marcos-Arenal,B.Margalef-Bentabol,O.Marggraf,D.Marin-\\nucci,M.Marinucci,K.Markovic,F.R.Marleau,J.Marpaud,J.Martignac,J.Martín-Fleitas,\\nP.Martin-Moruno,E.L.Martin,M.Martinelli,N.Martinet,H.Martin,C.J.A.P.Martins,\\nF.Marulli,D.Massari,R.Massey,D.C.Masters,S.Matarrese,Y.Matsuoka,S.Matthew,\\nB.J.Maughan,N.Mauri,L.Maurin,S.Maurogordato,K.McCarthy,A.W.McConnachie,\\nH.J.McCracken,I.McDonald,J.D.McEwen,C.J.R.McPartland,E.Medinaceli,V.Mehta,\\nS.Mei,M.Melchior,J.B.Melin,B.Ménard,J.Mendes,J.Mendez-Abreu,M.Meneghetti,\\nA. Mercurio, E. Merlin, R. B. Metcalf, G. Meylan, M. Migliaccio, M. Mignoli, L. Miller,\\nM.Miluzio,B.Milvang-Jensen,J.P.Mimoso,R.Miquel,H.Miyatake,B.Mobasher,J.J.\\nMohr,P.Monaco,M.Monguió,A.Montoro,A.Mora,A.MoradinezhadDizgah,M.Moresco,\\nC.Moretti,G.Morgante,N.Morisset,T.J.Moriya,P.W.Morris,D.J.Mortlock,L.Moscar-\\ndini,D.F.Mota,L.A.Moustakas,T.Moutard,T.Müller,E.Munari,G.Murphree,C.Murray,\\nN.Murray,P.Musi,S.Nadathur,B.C.Nagam,T.Nagao,K.Naidoo,R.Nakajima,C.Nally,\\nP. Natoli, A. Navarro-Alsina, D. Navarro Girones, C. Neissner, A. Nersesian, S. Nesseris,\\nH.N.Nguyen-Kim,L.Nicastro,R.C.Nichol,M.Nielbock,S.M.Niemi,S.Nieto,K.Nils-\\nson, J.Noller, P.Norberg, A.Nourizonoz, P.Ntelis, A.A.Nucita, P.Nugent, N.J.Nunes,\\nT.Nutma, I.Ocampo, J.Odier, P.A.Oesch, M.Oguri, D.MagalhaesOliveira, M.Onoue,\\nT.Oosterbroek,F.Oppizzi,C.Ordenovic,K.Osato,F.Pacaud,F.Pace,C.Padilla,K.Paech,\\nL.Pagano,M.J.Page,E.Palazzi,S.Paltani,S.Pamuk,S.Pandolfi,D.Paoletti,M.Paolillo,\\nP. Papaderos, K. Pardede, G. Parimbelli, A. Parmar, C. Partmann, F. Pasian, F. Passalac-\\nqua,K.Paterson,L.Patrizii,C.Pattison,A.Paulino-Afonso,R.Paviot,J.A.Peacock,F.R.\\nPearce,K.Pedersen,A.Peel,R.F.Peletier,M.PellejeroIbanez,R.Pello,M.T.Penny,W.J.\\nPercival,A.Perez-Garrido,L.Perotto,V.Pettorino,A.Pezzotta,S.Pezzuto,A.Philippon,\\nO.Piersanti,M.Pietroni,L.Piga,L.Pilo,S.Pires,A.Pisani,A.Pizzella,L.Pizzuti,C.Plana,\\nG. Polenta, J. E. Pollack, M. Poncet, M. Pöntinen, P. Pool, L. A. Popa, V. Popa, J. Popp,\\nC.Porciani,L.Porth,D.Potter,M.Poulain,A.Pourtsidou,L.Pozzetti,I.Prandoni,G.W.\\nPratt, S. Prezelus, E. Prieto, A. Pugno, S. Quai, L. Quilley, G. D. Racca, A. Raccanelli,\\nG.Rácz,S.Radinovic´,M.Radovich,A.Ragagnin,U.Ragnit,F.Raison,N.Ramos-Chernenko,\\nC.Ranc,N.Raylet,R.Rebolo,A.Refregier,P.Reimberg,T.H.Reiprich,F.Renk,A.Renzi,\\nJ. Retre, Y. Revaz, C. Reylé, L. Reynolds, J. Rhodes, F. Ricci, M. Ricci, G. Riccio, S. O.\\nRicken, S.Rissanen, I.Risso, H.W.Rix, A.C. Robin, B. Rocca-Volmerange, P.F.Rocci,\\n11M.Rodenhuis,G.Rodighiero,M.RodriguezMonroy,R.P.Rollins,M.Romanello,J.Roman,\\nE. Romelli, M. Romero-Gomez, M. Roncarelli, P. Rosati, C. Rosset, E. Rossetti, W. Ros-\\nter,H.J.A.Rottgering,A.Rozas-Fernández,K.Ruane,J.A.Rubino-Martin,A.Rudolph,\\nF. Ruppin, B. Rusholme, S. Sacquegna, I. Sáez-Casares, S. Saga, R. Saglia, M. Sahlén,\\nT.Saifollahi,Z.Sakr,J.Salvalaggio,R.Salvaterra,L.Salvati,M.Salvato,J.C.Salvignol,\\nA. G. Sánchez, E. Sanchez, D. B. Sanders, D. Sapone, M. Saponara, E. Sarpa, F. Sarron,\\nS. Sartori, B. Sassolas, L. Sauniere, M. Sauvage, M. Sawicki, R. Scaramella, C. Scarlata,\\nL. Scharré, J. Schaye, J. A. Schewtschenko, J. T. Schindler, E. Schinnerer, M. Schirmer,\\nF.Schmidt,F.Schmidt,M.Schmidt,A.Schneider,M.Schneider,P.Schneider,N.Schöneberg,\\nT. Schrabback, M. Schultheis, S. Schulz, J. Schwartz, D. Sciotti, M. Scodeggio, D. Scog-\\nnamiglio,D.Scott,V.Scottez,A.Secroun,E.Sefusatti,G.Seidel,M.Seiffert,E.Sellentin,\\nM.Selwood,E.Semboloni,M.Sereno,S.Serjeant,S.Serrano,F.Shankar,R.M.Sharples,\\nA.Short,A.Shulevski,M.Shuntov,M.Sias,G.Sikkema,A.Silvestri,P.Simon,C.Sirignano,\\nG.Sirri,J.Skottfelt,E.Slezak,D.Sluse,G.P.Smith,L.C.Smith,R.E.Smith,S.J.A.Smit,\\nF.Soldano,B.G.B.Solheim,J.G.Sorce,F.Sorrenti,E.Soubrie,L.Spinoglio,A.Spurio\\nMancini,J.Stadel,L.Stagnaro,L.Stanco,S.A.Stanford,J.L.Starck,P.Stassi,J.Steinwagner,\\nD.Stern,C.Stone,P.Strada,F.Strafella,D.Stramaccioni,C.Surace,F.Sureau,S.H.Suyu,\\nI.Swindells,M.Szafraniec,I.Szapudi,S.Taamoli,M.Talia,P.Tallada-Crespí,K.Tanidis,\\nC. Tao, P. Tarrío, D. Tavagnacco, A. N. Taylor, J. E. Taylor, P. L. Taylor, E. M. Teixeira,\\nM.Tenti,P.TeodoroIdiago,H.I.Teplitz,I.Tereno,N.Tessore,V.Testa,G.Testera,M.Tewes,\\nR.Teyssier,N.Theret,C.Thizy,P.D.Thomas,Y.Toba,S.Toft,R.Toledo-Moreo,E.Tolstoy,\\nE.Tommasi,O.Torbaniuk,F.Torradeflot,C.Tortora,S.Tosi,S.Tosti,M.Trifoglio,A.Troja,\\nT.Trombetti,A.Tronconi,M.Tsedrik,A.Tsyganov,M.Tucci,I.Tutusaus,C.Uhlemann,\\nL.Ulivi,M.Urbano,L.Vacher,L.Vaillon,I.Valdes,E.A.Valentijn,L.Valenziano,C.Valieri,\\nJ.Valiviita,M.VandenBroeck,T.Vassallo,R.Vavrek,B.Venemans,A.Venhola,S.Ventura,\\nG.VerdoesKleijn,D.Vergani,A.Verma,F.Vernizzi,A.Veropalumbo,G.Verza,C.Vescovi,\\nD.Vibert,M.Viel,P.Vielzeuf,C.Viglione,A.Viitanen,F.Villaescusa-Navarro,S.Vinciguerra,\\nF.Visticot,K.Voggel,M.vonWietersheim-Kramsta,W.J.Vriend,S.Wachter,M.Walmsley,\\nG.Walth,D.M.Walton,N.A.Walton,M.Wander,L.Wang,Y.Wang,J.R.Weaver,J.Weller,\\nD.J.Whalen, M.Wiesmann, J.Wilde, O.R.Williams, H.A.Winther, A.Wittje, J.H.W.\\nWong, A.H.Wright, V.Yankelevich, H.W.Yeung, S.Youles, L.Y.A.Yung, A.Zacchei,\\nL.Zalesky,G.Zamorani,A.ZamoranoVitorelli,M.ZanoniMarc,M.Zennaro,F.M.Zerbi,\\nI.A.Zinchenko,J.Zoubian,E.Zucca,andM.Zumalacarregui. Euclid.I.Overviewofthe\\nEuclidmission. arXive-prints,pagearXiv:2405.13491,May2024.\\n[33] YuqiFang, Pew-ThianYap, WeiliLin, HongtuZhu, andMingxiaLiu. Source-FreeUnsu-\\npervisedDomainAdaptation: ASurvey. arXive-prints,pagearXiv:2301.00265,December\\n2022.\\n[34] AbolfazlFarahani,SaharVoghoei,KhaledRasheed,andHamidR.Arabnia. ABriefReview\\nofDomainAdaptation. arXive-prints,pagearXiv:2010.03978,October2020.\\n[35] B. Flaugher, H. T. Diehl, K. Honscheid, T. M. C. Abbott, O. Alvarez, R. Angstadt, J. T.\\nAnnis,M.Antonik,O.Ballester,L.Beaufore,G.M.Bernstein,R.A.Bernstein,B.Bigelow,\\nM.Bonati,D.Boprie,D.Brooks,E.J.Buckley-Geer,J.Campa,L.Cardiel-Sas,F.J.Castander,\\nJ.Castilla,H.Cease,J.M.Cela-Ruiz,S.Chappa,E.Chi,C.Cooper,L.N.daCosta,E.Dede,\\nG. Derylo, D. L. DePoy, J. de Vicente, P. Doel, A. Drlica-Wagner, J. Eiting, A. E. Elliott,\\nJ. Emes, J. Estrada, A. Fausti Neto, D. A. Finley, R. Flores, J. Frieman, D. Gerdes, M. D.\\nGladders,B.Gregory,G.R.Gutierrez,J.Hao,S.E.Holland,S.Holm,D.Huffman,C.Jackson,\\nD.J.James,M.Jonas,A.Karcher,I.Karliner,S.Kent,R.Kessler,M.Kozlovsky,R.G.Kron,\\nD.Kubik,K.Kuehn,S.Kuhlmann,K.Kuk,O.Lahav,A.Lathrop,J.Lee,M.E.Levi,P.Lewis,\\nT.S.Li,I.Mandrichenko,J.L.Marshall,G.Martinez,K.W.Merritt,R.Miquel,F.Munoz,\\nE.H.Neilsen,R.C.Nichol,B.Nord,R.Ogando,J.Olsen,N.Palio,K.Patton,J.Peoples,\\nA.A.Plazas,J.Rauch,K.Reil,J.-P.Rheault,N.A.Roe,H.Rogers,A.Roodman,E.Sanchez,\\nV.Scarpine,R.H.Schindler,R.Schmidt,R.Schmitt,M.Schubnell,K.Schultz,P.Schurter,\\nL.Scott,S.Serrano,T.M.Shaw,R.C.Smith,M.Soares-Santos,A.Stefanik,W.Stuermer,\\nE.Suchyta,A.Sypniewski,G.Tarle,J.Thaler,R.Tighe,C.Tran,D.Tucker,A.R.Walker,\\nG.Wang,M.Watson,C.Weaverdyck,W.Wester,R.Woods,andB.Yanny. TheDarkEnergy\\nCamera. TheAstronomicalJournal,150(5):150,October2015. arXiv:1504.02900[astro-ph].\\n12[36] YarinGalandZoubinGhahramani. DropoutasaBayesianApproximation: Representing\\nModelUncertaintyinDeepLearning. arXive-prints,pagearXiv:1506.02142,June2015.\\n[37] M.A.Ganaie,MinghuiHu,A.K.Malik,M.Tanveer,andP.N.Suganthan. Ensembledeep\\nlearning: Areview. arXive-prints,pagearXiv:2104.02395,April2021.\\n[38] YaroslavGaninandVictorLempitsky. Unsuperviseddomainadaptationbybackpropagation.\\nInFrancisBachandDavidBlei,editors,Proceedingsofthe32ndInternationalConference\\non Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages\\n1180–1189,Lille,France,07–09Jul2015.PMLR.\\n[39] YaroslavGanin,EvgeniyaUstinova,HanaAjakan,PascalGermain,HugoLarochelle,François\\nLaviolette,MarioMarchand,andVictorLempitsky. Domain-adversarialtrainingofneural\\nnetworks. J.Mach.Learn.Res.,17(1):2096–2030,jan2016.\\n[40] JakobGawlikowski,CedriqueRovileNjieutcheuTassi,MohsinAli,JongseokLee,Matthias\\nHumt,JianxiangFeng,AnnaKruspe,RudolphTriebel,PeterJung,RibanaRoscher,Muham-\\nmadShahzad,WenYang,RichardBamler,andXiaoXiangZhu. Asurveyofuncertaintyin\\ndeepneuralnetworks. ArtificialIntelligenceReview,56(1):1513–1589,October2023.\\n[41] Daniel Gilman, Simon Birrer, Anna Nierenberg, and Maverick S. H. Oh. Turbocharging\\nconstraintsondarkmattersubstructurethroughasynthesisofstronglensingfluxratiosand\\nextendedlensedarcs. MNRAS,July2024.\\n[42] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale\\nsentimentclassification: adeeplearningapproach. InProceedingsofthe28thInternational\\nConference on International Conference on Machine Learning, ICML’11, page 513–520,\\nMadison,WI,USA,2011.Omnipress.\\n[43] EthanGoanandClintonFookes. BayesianNeuralNetworks: AnIntroductionandSurvey.\\narXive-prints,pagearXiv:2006.12024,June2020.\\n[44] ArthurGretton,KarstenM.Borgwardt,MalteJ.Rasch,BernhardSchölkopf,andAlexander\\nSmola. Akerneltwo-sampletest. JournalofMachineLearningResearch,13(25):723–773,\\n2012.\\n[45] D.Gruen,G.M.Bernstein,M.Jarvis,B.Rowe,V.Vikram,A.A.Plazas,andS.Seitz. Charac-\\nterizationandcorrectionofcharge-inducedpixelshiftsinDECam. JournalofInstrumentation,\\n10(5):C05032,May2015.\\n[46] CharlesR.Harris,K.JarrodMillman,StéfanJ.vanderWalt,RalfGommers,PauliVirtanen,\\nDavidCournapeau,EricWieser,JulianTaylor,SebastianBerg,NathanielJ.Smith,Robert\\nKern,MattiPicus,StephanHoyer,MartenH.vanKerkwijk,MatthewBrett,AllanHaldane,\\nJaime Fernández del Río, Mark Wiebe, Pearu Peterson, Pierre Gérard-Marchant, Kevin\\nSheppard,TylerReddy,WarrenWeckesser,HameerAbbasi,ChristophGohlke,andTravisE.\\nOliphant. ArrayprogrammingwithNumPy. Nature,585(7825):357–362,September2020.\\n[47] MehediHasan,AbbasKhosravi,IbrahimHossain,AshikurRahman,andSaeidNahavandi.\\nControlledDropoutforUncertaintyEstimation,May2022. arXiv:2205.03109[cs].\\n[48] HuanHe,OwenQueen,TeddyKoker,ConsueloCuevas,TheodorosTsiligkaridis,andMarinka\\nZitnik. DomainAdaptationforTimeSeriesUnderFeatureandLabelShifts. arXive-prints,\\npagearXiv:2302.03133,February2023.\\n[49] YasharD.Hezaveh,LaurencePerreaultLevasseur,andPhilipJ.Marshall. Fastautomatedanal-\\nysisofstronggravitationallenseswithconvolutionalneuralnetworks. Nature,548(7669):555–\\n557,August2017.\\n[50] BurtHolzman. WelcometotheFermilabEAFdocumentation,2024.\\n[51] Feng Hou, Jin Yuan, Ying Yang, Yang Liu, Yang Zhang, Cheng Zhong, Zhongchao Shi,\\nJianpingFan,YongRui,andZhiqiangHe. DomainVerse: ABenchmarkTowardsReal-World\\nDistributionShiftsForTuning-FreeAdaptiveDomainGeneralization. arXive-prints,page\\narXiv:2403.02714,March2024.\\n13[52] X. Huang, M. Domingo, A. Pilon, V. Ravi, C. Storfer, D. J. Schlegel, S. Bailey, A. Dey,\\nD.Herrera,S.Juneau,M.Landriau,D.Lang,A.Meisner,J.Moustakas,A.D.Myers,E.F.\\nSchlafly, F. Valdes, B. A. Weaver, J. Yang, and C. Yeche. Finding Strong Gravitational\\nLensesintheDESIDECamLegacySurvey. TheAstrophysicalJournal,894(1):78,May2020.\\narXiv:1906.00970[astro-ph].\\n[53] X.Huang,C.Storfer,A.Gu,V.Ravi,A.Pilon,W.Sheu,R.Venguswamy,S.Banka,A.Dey,\\nM.Landriau,D.Lang,A.Meisner,J.Moustakas,A.D.Myers,R.Sajith,E.F.Schlafly,andD.J.\\nSchlegel. DiscoveringNewStrongGravitationalLensesintheDESILegacyImagingSurveys.\\nTheAstrophysicalJournal,909:27,March2021. ADSBibcode: 2021ApJ...909...27H.\\n[54] J.D.Hunter. Matplotlib: A2dgraphicsenvironment. ComputinginScience&Engineering,\\n9(3):90–95,2007.\\n[55] ŽeljkoIvezic´,StevenM.Kahn,J.AnthonyTyson,BobAbel,EmilyAcosta,RobynAllsman,\\nDavid Alonso, Yusra AlSayyad, Scott F. Anderson, John Andrew, James Roger P. Angel,\\nGeorge Z. Angeli, Reza Ansari, Pierre Antilogus, Constanza Araujo, Robert Armstrong,\\nKirkT.Arndt,PierreAstier,ÉricAubourg,NicoleAuza,TimS.Axelrod,DeborahJ.Bard,\\nJeffD.Barr,AurelianBarrau,JamesG.Bartlett,AmandaE.Bauer,BrianJ.Bauman,Sylvain\\nBaumont,EllenBechtol,KeithBechtol,AndrewC.Becker,JacekBecla,CristinaBeldica,\\nSteveBellavia,FedericaB.Bianco,RahulBiswas,GuillaumeBlanc,JonathanBlazek,RogerD.\\nBlandford, Josh S. Bloom, Joanne Bogart, Tim W. Bond, Michael T. Booth, Anders W.\\nBorgland, Kirk Borne, James F. Bosch, Dominique Boutigny, Craig A. Brackett, Andrew\\nBradshaw,WilliamNielsenBrandt,MichaelE.Brown,JamesS.Bullock,PatriciaBurchat,\\nDavid L. Burke, Gianpietro Cagnoli, Daniel Calabrese, Shawn Callahan, Alice L. Callen,\\nJeffreyL.Carlin,ErinL.Carlson,SrinivasanChandrasekharan,GlenaverCharles-Emerson,\\nSteveChesley,ElliottC.Cheu,Hsin-FangChiang,JamesChiang,CarolChirino,DerekChow,\\nDavidR.Ciardi,CharlesF.Claver,JohannCohen-Tanugi,JosephJ.Cockrum,RebeccaColes,\\nAndrewJ.Connolly,KemH.Cook,AsanthaCooray,KevinR.Covey,ChrisCribbs,WeiCui,\\nRocCutri,PhilipN.Daly,ScottF.Daniel,FelipeDaruich,GuillaumeDaubard,GregDaues,\\nWilliam Dawson, Francisco Delgado, Alfred Dellapenna, Robert De Peyster, Miguel De\\nVal-Borro, Seth W. Digel, Peter Doherty, Richard Dubois, Gregory P. Dubois-Felsmann,\\nJosef Durech, Frossie Economou, Tim Eifler, Michael Eracleous, Benjamin L. Emmons,\\nAngeloFaustiNeto,HenryFerguson,EnriqueFigueroa,MerlinFisher-Levine,WarrenFocke,\\nMichael D. Foss, James Frank, Michael D. Freemon, Emmanuel Gangler, Eric Gawiser,\\nJohn C. Geary, Perry Gee, Marla Geha, Charles J. B. Gessner, Robert R. Gibson, D. Kirk\\nGilmore, Thomas Glanzman, William Glick, Tatiana Goldina, Daniel A. Goldstein, Iain\\nGoodenow,MelissaL.Graham,WilliamJ.Gressler,PhilippeGris,LeanneP.Guy,Augustin\\nGuyonnet,GuntherHaller,RonHarris,PatrickA.Hascall,JustineHaupt,FabioHernandez,\\nSvenHerrmann,EdwardHileman,JoshuaHoblitt,JohnA.Hodgson,CraigHogan,JamesD.\\nHoward, DajunHuang, MichaelE.Huffer, PatrickIngraham, WalterR.Innes, SuzanneH.\\nJacoby,BhuvneshJain,FabriceJammes,M.JamesJee,TimJenness,GarrettJernigan,Darko\\nJevremovic´,KennethJohns,AnthonyS.Johnson,MargaretW.G.Johnson,R.LynneJones,\\nClaireJuramy-Gilles,MarioJuric´,JasonS.Kalirai,NityaJ.Kallivayalil,BryceKalmbach,\\nJeffreyP.Kantor,PierreKarst,MansiM.Kasliwal,HeatherKelly,RichardKessler,Veronica\\nKinnison, David Kirkby, Lloyd Knox, Ivan V. Kotov, Victor L. Krabbendam, K. Simon\\nKrughoff,PetrKubánek,JohnKuczewski,ShriKulkarni,JohnKu,NadineR.Kurita,CraigS.\\nLage,RonLambert,TravisLange,J.BrianLangton,LaurentLeGuillou,DeborahLevine,\\nMingLiang, Kian-TatLim, ChrisJ.Lintott, KevinE.Long, MargauxLopez, PaulJ.Lotz,\\nRobertH.Lupton,NateB.Lust,LaurenA.MacArthur,AshishMahabal,RachelMandelbaum,\\nThomasW.Markiewicz,DarrenS.Marsh,PhilipJ.Marshall,StuartMarshall,MorganMay,\\nRobertMcKercher,MichelleMcQueen,JoshuaMeyers,MyriamMigliore,MichelleMiller,\\nDavidJ.Mills,ConnorMiraval,JoachimMoeyens,FredE.Moolekamp,DavidG.Monet,\\nMarcMoniez,SergeMonkewitz,ChristopherMontgomery,ChristopherB.Morrison,Fritz\\nMueller,GaryP.Muller,FreddyMuñozArancibia,DouglasR.Neill,ScottP.Newbry,Jean-\\nYvesNief,AndreiNomerotski,MartinNordby,PaulO’Connor,JohnOliver,ScotS.Olivier,\\nKnutOlsen,WilliamO’Mullane,SandraOrtiz,ShawnOsier,RussellE.Owen,ReynaldPain,\\nPaul E. Palecek, John K. Parejko, James B. Parsons, Nathan M. Pease, J. Matt Peterson,\\nJohn R. Peterson, Donald L. Petravick, M. E. Libby Petrick, Cathy E. Petry, Francesco\\nPierfederici,StephenPietrowicz,RobPike,PhilipA.Pinto,RaymondPlante,StephenPlate,\\n14JoelP.Plutchak,PaulA.Price,MichaelProuza,VeljkoRadeka,JayadevRajagopal,AndrewP.\\nRasmussen,NicolasRegnault,KevinA.Reil,DavidJ.Reiss,MichaelA.Reuter,StephenT.\\nRidgway,VincentJ.Riot,SteveRitz,SeanRobinson,WilliamRoby,AaronRoodman,Wayne\\nRosing,CecilleRoucelle,MatthewR.Rumore,StefanoRusso,AbhijitSaha,BenoitSassolas,\\nTerry L. Schalk, Pim Schellart, Rafe H. Schindler, Samuel Schmidt, Donald P. Schneider,\\nMichaelD.Schneider,WilliamSchoening,GermanSchumacher,MeganE.Schwamb,Jacques\\nSebag,BrianSelvy,GlennH.Sembroski,LynnG.Seppala,AndrewSerio,EduardoSerrano,\\nRichard A. Shaw, Ian Shipsey, Jonathan Sick, Nicole Silvestri, Colin T. Slater, J. Allyn\\nSmith,R.ChrisSmith,ShahramSobhani,ChristineSoldahl,LisaStorrie-Lombardi,Edward\\nStover,MichaelA.Strauss,RachelA.Street,ChristopherW.Stubbs,IanS.Sullivan,Donald\\nSweeney,JohnD.Swinbank,AlexanderSzalay,PeterTakacs,StephenA.Tether,JonJ.Thaler,\\nJohnGreggThayer, SandrineThomas, AdamJ.Thornton, VaikunthThukral, JeffreyTice,\\nDavidE.Trilling,MaxTurri,RichardVanBerg,DanielVandenBerk,KurtVetter,Francoise\\nVirieux,TomislavVucina,WilliamWahl,LucianneWalkowicz,BrianWalsh,ChristopherW.\\nWalter,DanielL.Wang,Shin-YawnWang,MichaelWarner,OliverWiecha,BethWillman,\\nScott E. Winters, David Wittman, Sidney C. Wolff, W. Michael Wood-Vasey, Xiuqin Wu,\\nBoXin,PeterYoachim,andHuZhan. LSST:FromScienceDriverstoReferenceDesignand\\nAnticipatedDataProducts. TheAstrophysicalJournal,873(2):111,March2019.\\n[56] Eric Jones, TravisOliphant, Pearu Peterson, et al. SciPy: Open sourcescientific toolsfor\\nPython,2001–.\\n[57] RyanE.Keeley,AnnaM.Nierenberg,DanielGilman,SimonBirrer,AndrewBenson,and\\nTommasoTreu.Pushingthelimitsofdetectability:mixeddarkmatterfromstronggravitational\\nlenses. MNRAS,524(4):6159–6166,October2023.\\n[58] CharlesR.Keeton. Onmodelinggalaxy-scalestronglenssystems. GeneralRelativityand\\nGravitation,42(9):2151–2176,September2010.\\n[59] WouterM.KouwandMarcoLoog. Areviewofdomainadaptationwithouttargetlabels. arXiv\\ne-prints,pagearXiv:1901.05335,January2019.\\n[60] K.Kuijken,C.Heymans,A.Dvornik,H.Hildebrandt,J.T.A.deJong,A.H.Wright,T.Erben,\\nM.Bilicki,B.Giblin,H.Y.Shan,F.Getman,A.Grado,H.Hoekstra,L.Miller,N.Napolitano,\\nM.Paolilo,M.Radovich,P.Schneider,W.Sutherland,M.Tewes,C.Tortora,E.A.Valentijn,\\nandG.A.VerdoesKleijn. ThefourthdatareleaseoftheKilo-DegreeSurvey: ugriimaging\\nandnine-bandoptical-IRphotometryover1000squaredegrees. A&A,625:A2,May2019.\\n[61] S.KullbackandR.A.Leibler. OnInformationandSufficiency. TheAnnalsofMathematical\\nStatistics,22(1):79–86,1951.\\n[62] PaulLaPlante,JordanMirocha,AdélieGorce,AdamLidz,andAaronParsons. Prospects\\nfor21cm-GalaxyCross-CorrelationswithHERAandtheRomanHigh-LatitudeSurvey. The\\nAstrophysicalJournal,944(1):59,February2023. arXiv:2205.09770[astro-ph].\\n[63] BalajiLakshminarayanan,AlexanderPritzel,andCharlesBlundell. SimpleandScalablePre-\\ndictiveUncertaintyEstimationusingDeepEnsembles. arXive-prints,pagearXiv:1612.01474,\\nDecember2016.\\n[64] Loic Le Folgoc, Vasileios Baltatzis, Sujal Desai, Anand Devaraj, Sam Ellis, Octavio E.\\nMartinezManzanera,ArjunNair,HuaqiQiu,JuliaSchnabel,andBenGlocker.IsMCDropout\\nBayesian? arXive-prints,pagearXiv:2110.04286,October2021.\\n[65] AlanT.Lefor,ToshifumiFutamase,andMohammadAkhlaghi. Asystematicreviewofstrong\\ngravitationallensmodelingsoftware. NewAstronomyReviews,57(1–2):1–13,July2013.\\n[66] Ronan Legin, Yashar Hezaveh, Laurence Perreault Levasseur, and Benjamin Wandelt.\\nSimulation-Based Inference of Strong Gravitational Lensing Parameters. arXiv e-prints,\\npagearXiv:2112.05278,December2021.\\n[67] Ronan Legin, Yashar Hezaveh, Laurence Perreault-Levasseur, and Benjamin Wandelt. A\\nFrameworkforObtainingAccuratePosteriorsofStrongGravitationalLensingParameterswith\\nFlexiblePriorsandImplicitLikelihoodsUsingDensityEstimation. ApJ,943(1):4,January\\n2023.\\n15[68] LaurencePerreaultLevasseur,YasharD.Hezaveh,andRisaH.Wechsler. Uncertaintiesin\\nParametersEstimatedwithNeuralNetworks: ApplicationtoStrongGravitationalLensing.\\nThe Astrophysical Journal Letters, 850(1):L7, November 2017. Publisher: The American\\nAstronomicalSociety.\\n[69] Jeng-Lin Li, Chih-Fan Hsu, Ming-Ching Chang, and Wei-Chao Chen. A Comprehensive\\nReviewofMachineLearningAdvancesonDataChange: ACross-FieldPerspective. arXiv\\ne-prints,pagearXiv:2402.12627,February2024.\\n[70] NanLi, MichaelD.Gladders, EstebanM.Rangel, MichaelK.Florian, LindseyE.Bleem,\\nKatrinHeitmann,SalmanHabib,andPatriciaFasel. PICS:SimulationsofStrongGravitational\\nLensinginGalaxyClusters. ApJ,828(1):54,September2016.\\n[71] TianLi, ThomasECollett, ColemanMKrawczyk, andWolfgangEnzi. Cosmologyfrom\\nlargepopulationsofgalaxy–galaxystronggravitationallenses. MonthlyNoticesoftheRoyal\\nAstronomicalSociety,527(3):5311–5323,112023.\\n[72] EricV.Linder. Stronggravitationallensinganddarkenergycomplementarity. Phys.Rev.D,\\n70(4):043534,August2004.\\n[73] XiaofengLiu,ChaehwaYoo,FangxuXing,HyejinOh,GeorgesElFakhri,Je-WonKang,and\\nJonghyeWoo. DeepUnsupervisedDomainAdaptation: AReviewofRecentAdvancesand\\nPerspectives. arXive-prints,pagearXiv:2208.07422,August2022.\\n[74] MingshengLong,YueCao,JianminWang,andMichaelJordan. Learningtransferablefeatures\\nwithdeepadaptationnetworks. InFrancisBachandDavidBlei,editors,Proceedingsofthe\\n32ndInternationalConferenceonMachineLearning,volume37ofProceedingsofMachine\\nLearningResearch,pages97–105,Lille,France,07–09Jul2015.PMLR.\\n[75] IlyaLoshchilovandFrankHutter. Decoupledweightdecayregularization,2019.\\n[76] TorchVisionmaintainersandcontributors. Torchvision: Pytorch’scomputervisionlibrary.\\nhttps://github.com/pytorch/vision,2016.\\n[77] Philip J. Marshall, Aprajita Verma, Anupreeta More, Christopher P. Davis, Surhud More,\\nAmitKapadia,MichaelParrish,ChrisSnyder,JulianneWilcox,ElisabethBaeten,Christine\\nMacmillan,ClaudeCornen,MichaelBaumer,EdwinSimpson,ChrisJ.Lintott,DavidMiller,\\nEdwardPaget,RobertSimpson,ArfonM.Smith,RafaelKüng,PrasenjitSaha,andThomasE.\\nCollett. SPACEWARPS-I.Crowdsourcingthediscoveryofgravitationallenses. MNRAS,\\n455(2):1171–1190,January2016.\\n[78] NisMeinert,JakobGawlikowski,andAlexanderLavin. TheUnreasonableEffectivenessof\\nDeepEvidentialRegression. arXive-prints,pagearXiv:2205.10060,May2022.\\n[79] NisMeinertandAlexanderLavin. MultivariateDeepEvidentialRegression. arXive-prints,\\npagearXiv:2104.06135,April2021.\\n[80] R. B. Metcalf, M. Meneghetti, C. Avestruz, F. Bellagamba, C. R. Bom, E. Bertin, R. Ca-\\nbanac,F.Courbin,A.Davies,E.Decencière,R.Flamary,R.Gavazzi,M.Geiger,P.Hartley,\\nM. Huertas-Company, N. Jackson, C. Jacobs, E. Jullo, J. P. Kneib, L. V. E. Koopmans,\\nF. Lanusse, C. L. Li, Q. Ma, M. Makler, N. Li, M. Lightman, C. E. Petrillo, S. Serjeant,\\nC.Schäfer, A.Sonnenfeld,A.Tagore,C.Tortora,D.Tuccillo,M.B.Valentín,S.Velasco-\\nForero,G.A.VerdoesKleijn,andG.Vernardos.Thestronggravitationallensfindingchallenge.\\nA&A,625:A119,May2019.\\n[81] SurhudMore,SunaoSugiyama,HironaoMiyatake,MarkusMichaelRau,MasatoShirasaki,\\nXiangchongLi,AtsushiJ.Nishizawa,KenOsato,TianqingZhang,MasahiroTakada,Takashi\\nHamana,RyuichiTakahashi,RoohiDalal,RachelMandelbaum,MichaelA.Strauss,Yosuke\\nKobayashi,TakahiroNishimichi,MasamuneOguri,WentaoLuo,ArunKannawadi,Bau-Ching\\nHsieh,RobertArmstrong,JamesBosch,YutakaKomiyama,RobertH.Lupton,NateB.Lust,\\nLauren A. MacArthur, Satoshi Miyazaki, Hitoshi Murayama, Yuki Okura, Paul A. Price,\\nPhilipJ.Tait,MasayukiTanaka,andShiang-YuWang. HyperSuprime-CamYear3results:\\nMeasurementsofclusteringofSDSS-BOSSgalaxies,galaxy-galaxylensing,andcosmicshear.\\nPhys.Rev.D,108(12):123520,December2023.\\n16[82] RobertMorgan,BrianNord,SimonBirrer,JoshuaLin,andJasonPoh. deeplenstronomy: A\\ndatasetsimulationpackageforstronggravitationallensing. JournalofOpenSourceSoftware,\\n6(58):2854,February2021.\\n[83] SaeidMotiian,MarcoPiccirilli,DonaldA.Adjeroh,andGianfrancoDoretto. UnifiedDeep\\nSupervisedDomainAdaptationandGeneralization,September2017. arXiv:1709.10190[cs].\\n[84] RameshNarayanandMatthiasBartelmann. LecturesonGravitationalLensing. arXive-prints,\\npagesastro–ph/9606001,June1996.\\n[85] B.Nord,E.Buckley-Geer,H.Lin,H.T.Diehl,J.Helsby,N.Kuropatkin,A.Amara,T.Collett,\\nS. Allam, G. B. Caminha, C. De Bom, S. Desai, H. Dúmet-Montoya, M. Elidaiana da S.\\nPereira,D.A.Finley,B.Flaugher,C.Furlanetto,H.Gaitsch,M.Gill,K.W.Merritt,A.More,\\nD.Tucker,A.Saro,E.S.Rykoff,E.Rozo,S.Birrer,F.B.Abdalla,A.Agnello,M.Auger,R.J.\\nBrunner,M.CarrascoKind,F.J.Castander,C.E.Cunha,L.N.daCosta,R.J.Foley,D.W.\\nGerdes,K.Glazebrook,J.Gschwend,W.Hartley,R.Kessler,D.Lagattuta,G.Lewis,M.A.G.\\nMaia,M.Makler,F.Menanteau,A.Niernberg,D.Scolnic,J.D.Vieira,R.Gramillano,T.M.C.\\nAbbott,M.Banerji,A.Benoit-Lévy,D.Brooks,D.L.Burke,D.Capozzi,A.CarneroRosell,\\nJ.Carretero,C.B.D’Andrea,J.P.Dietrich,P.Doel,A.E.Evrard,J.Frieman,E.Gaztanaga,\\nD.Gruen,K.Honscheid,D.J.James,K.Kuehn,T.S.Li,M.Lima,J.L.Marshall,P.Martini,\\nP. Melchior, R. Miquel, E. Neilsen, R. C. Nichol, R. Ogando, A. A. Plazas, A. K. Romer,\\nM.Sako,E.Sanchez,V.Scarpine,M.Schubnell,I.Sevilla-Noarbe,R.C.Smith,M.Soares-\\nSantos,F.Sobreira,E.Suchyta,M.E.C.Swanson,G.Tarle,J.Thaler,A.R.Walker,W.Wester,\\nY. Zhang, and DES Collaboration. Observation and Confirmation of Six Strong-lensing\\nSystemsintheDarkEnergySurveyScienceVerificationData. ApJ,827(1):51,August2016.\\n[86] B. Nord, E. Buckley-Geer, H. Lin, N. Kuropatkin, T. Collett, D. L. Tucker, H. T. Diehl,\\nA.Agnello,A.Amara,T.M.C.Abbott,S.Allam,J.Annis,S.Avila,K.Bechtol,D.Brooks,\\nD.L.Burke,A.CarneroRosell,M.CarrascoKind,J.Carretero,C.E.Cunha,L.N.daCosta,\\nC.Davis,J.DeVicente,P.Doel,T.F.Eifler,A.E.Evrard,E.Fernandez,B.Flaugher,P.Fosalba,\\nJ.Frieman,J.García-Bellido,E.Gaztanaga,D.Gruen,R.A.Gruendl,G.Gutierrez,W.G.\\nHartley,D.L.Hollowood,K.Honscheid,B.Hoyle,D.J.James,K.Kuehn,O.Lahav,M.Lima,\\nM.A.G.Maia,M.March,J.L.Marshall,P.Melchior,F.Menanteau,R.Miquel,A.A.Plazas,\\nA.K.Romer,A.Roodman,E.S.Rykoff,E.Sanchez,V.Scarpine,R.Schindler,M.Schubnell,\\nI.Sevilla-Noarbe,M.Smith,M.Soares-Santos,F.Sobreira,E.Suchyta,M.E.C.Swanson,\\nG.Tarle,D.Thomas,Y.Zhang,andDESCollaboration. Observationandconfirmationofnine\\nstrong-lensingsystemsinDarkEnergySurveyYear1data. MNRAS,494(1):1308–1322,May\\n2020.\\n[87] J.H.O’Donnell,R.D.Wilkinson,H.T.Diehl,C.Aros-Bunster,K.Bechtol,S.Birrer,E.J.\\nBuckley-Geer,A.CarneroRosell,M.CarrascoKind,L.N.daCosta,S.J.GonzalezLozano,\\nR.A.Gruendl,M.Hilton,H.Lin,K.A.Lindgren,J.Martin,A.Pieres,E.S.Rykoff,I.Sevilla-\\nNoarbe,E.Sheldon,C.Sifón,D.L.Tucker,B.Yanny,T.M.C.Abbott,M.Aguena,S.Allam,\\nF.Andrade-Oliveira,J.Annis,E.Bertin,D.Brooks,D.L.Burke,J.Carretero,M.Costanzi,\\nJ.DeVicente,S.Desai,J.P.Dietrich,K.Eckert,S.Everett,I.Ferrero,B.Flaugher,P.Fosalba,\\nJ.Frieman,J.García-Bellido,E.Gaztanaga,D.W.Gerdes,D.Gruen,J.Gschwend,M.S.S.\\nGill, G.Gutierrez, S.R.Hinton, D.L.Hollowood, K.Honscheid, D.J.James, T.Jeltema,\\nK.Kuehn, O.Lahav, M.Lima, M.A.G.Maia, J.L.Marshall, P.Melchior, F.Menanteau,\\nR.Miquel,R.Morgan,B.Nord,R.L.C.Ogando,F.Paz-Chinchón,M.E.S.Pereira,A.A.\\nPlazasMalagón,M.Rodriguez-Monroy,A.K.Romer,A.Roodman,E.Sanchez,V.Scarpine,\\nM.Schubnell, S.Serrano, M.Smith, E.Suchyta, M.E.C.Swanson, G.Tarle, D.Thomas,\\nC.To,andT.N.Varga. TheDarkEnergySurveyBrightArcsSurvey: CandidateStrongly\\nLensedGalaxySystemsfromtheDarkEnergySurvey5000SquareDegreeFootprint. ApJS,\\n259(1):27,March2022.\\n[88] Thepandasdevelopmentteam. pandas-dev/pandas: Pandas,February2020.\\n[89] AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,GregoryChanan,\\nTrevorKilleen,ZemingLin,NataliaGimelshein,LucaAntiga,AlbanDesmaison,Andreas\\nKöpf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,\\nBenoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style,\\n17high-performancedeeplearninglibrary,2019. citearxiv:1912.01703Comment: 12pages,3\\nfigures,NeurIPS2019.\\n[90] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,\\nP.Prettenhofer,R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,\\nM.Perrot,andE.Duchesnay. Scikit-learn: MachinelearninginPython. JournalofMachine\\nLearningResearch,12:2825–2830,2011.\\n[91] A.A.Plazas,M.Meneghetti,M.Maturi,andJ.Rhodes. Imagesimulationsforgravitational\\nlensingwithSKYLENS. MNRAS,482(2):2823–2832,January2019.\\n[92] AndrésA.PlazasMalagón. ImageSimulationsforStrongandWeakGravitationalLensing.\\nSymmetry,12(4):494,March2020.\\n[93] JackRichings,CarlosFrenk,AdrianJenkins,AndrewRobertson,andMatthieuSchaller. A\\nhigh-resolutioncosmologicalsimulationofastronggravitationallens. MNRAS,501(3):4657–\\n4668,March2021.\\n[94] K.Rojas,E.Savary,B.Clément,M.Maus,F.Courbin,C.Lemon,J.H.H.Chan,G.Vernardos,\\nR.Joseph,R.Cañameras,andA.Galan. SearchofstronglenssystemsintheDarkEnergy\\nSurveyusingconvolutionalneuralnetworks. A&A,668:A73,December2022.\\n[95] KarinaRojas,ThomasE.Collett,DanielBallard,MarkR.Magee,SimonBirrer,Elizabeth\\nBuckley-Geer,JamesH.H.Chan,BenjaminClément,JoséM.Diego,FabrizioGentile,Jimena\\nGonzález,RémyJoseph,JorgeMastache,StefanSchuldt,CrescenzoTortora,TomásVerdugo,\\nAprajitaVerma,TansuDaylan,MartinMillon,NealJackson,SimonDye,AlejandraMelo,\\nGuillaume Mahler, Ricardo L. C. Ogando, Frédéric Courbin, Alexander Fritz, Aniruddh\\nHerle,JavierA.AcevedoBarroso,RaoulCañameras,ClaudeCornen,BirendraDhanasingham,\\nKarlGlazebrook,MichaelN.Martinez,DanRyczanowski,ElodieSavary,FilipeGóis-Silva,\\nL.ArturoUreña-López,MatthewP.Wiesner,JoshuaWilde,GabrielValimCalçada,Rémi\\nCabanac, Yue Pan, Isaac Sierra, Giulia Despali, Micaele V. Cavalcante-Gomes, Christine\\nMacmillan,JacobMaresca,AleksandraGrudskaia,JacksonH.O’Donnell,EricPaic,Anna\\nNiemiec, Lucia F. de la Bella, Jane Bromley, Devon M. Williams, Anupreeta More, and\\nBenjaminC.Levine. Theimpactofhumanexpertvisualinspectiononthediscoveryofstrong\\ngravitationallenses. MNRAS,523(3):4413–4430,August2023.\\n[96] AndreaRoncoli,AleksandraC´iprijanovic´,MaggieVoetberg,FranciscoVillaescusa-Navarro,\\nandBrianNord. DomainAdaptiveGraphNeuralNetworksforConstrainingCosmological\\nParametersAcrossMultipleDataSets,April2024. arXiv:2311.01588[astro-ph].\\n[97] AndreaJ.Ruff,RaphaëlGavazzi,PhilipJ.Marshall,TommasoTreu,MatthewW.Auger,and\\nFlorenceBrault. TheSL2SGalaxy-scaleLensSample.II.CosmicEvolutionofDarkand\\nLuminousMassinEarly-typeGalaxies. ApJ,727(2):96,February2011.\\n[98] D.Schaerer,R.Marques-Chaves,L.Barrufet,P.Oesch,Y.I.Izotov,R.Naidu,N.G.Guseva,\\nandG.Brammer. FirstlookwithJWSTspectroscopy: $z\\\\sim8$galaxiesresemblelocal\\nanalogues. Astronomy&Astrophysics,665:L4,September2022. arXiv:2207.10034[astro-ph].\\n[99] MaximilianSeitzer,ArashTavakoli,DimitrijeAntic,andGeorgMartius. Onthepitfallsof\\nheteroscedasticuncertaintyestimationwithprobabilisticneuralnetworks. InInternational\\nConferenceonLearningRepresentations,2022.\\n[100] S.Serjeant. SynergiesbetweenSALTandHerschel,EuclidandtheSKA:stronggravitational\\nlensingandgalaxyevolution. InDavidBuckleyandAnjaSchroeder,editors,SALTScience\\nConference2015(SSC2015),page16,June2015.\\n[101] I.Sevilla-Noarbe,K.Bechtol,M.CarrascoKind,A.CarneroRosell,M.R.Becker,A.Drlica-\\nWagner,R.A.Gruendl,E.S.Rykoff,E.Sheldon,B.Yanny,A.Alarcon,S.Allam,A.Amon,\\nA.Benoit-Lévy,G.M.Bernstein,E.Bertin,D.L.Burke,J.Carretero,A.Choi,H.T.Diehl,\\nS.Everett, B.Flaugher, E.Gaztanaga, J.Gschwend, I.Harrison, W. G.Hartley, B. Hoyle,\\nM.Jarvis,M.D.Johnson,R.Kessler,R.Kron,N.Kuropatkin,B.Leistedt,T.S.Li,F.Menan-\\nteau, E. Morganson, R. L. C. Ogando, A. Palmese, F. Paz-Chinchón, A. Pieres, C. Pond,\\n18M. Rodriguez-Monroy, J. Allyn Smith, K. M. Stringer, M. A. Troxel, D. L. Tucker, J. de\\nVicente,W.Wester,Y.Zhang,T.M.C.Abbott,M.Aguena,J.Annis,S.Avila,S.Bhargava,\\nS. L. Bridle, D. Brooks, D. Brout, F. J. Castander, R. Cawthon, C. Chang, C. Conselice,\\nM.Costanzi,M.Crocce,L.N.daCosta,M.E.S.Pereira,T.M.Davis,S.Desai,J.P.Dietrich,\\nP. Doel, K. Eckert, A. E. Evrard, I. Ferrero, P. Fosalba, J. García-Bellido, D. W. Gerdes,\\nT.Giannantonio,D.Gruen,G.Gutierrez,S.R.Hinton,D.L.Hollowood,K.Honscheid,E.M.\\nHuff,D.Huterer,D.J.James,T.Jeltema,K.Kuehn,O.Lahav,C.Lidman,M.Lima,H.Lin,\\nM. A. G. Maia, J. L. Marshall, P. Martini, P. Melchior, R. Miquel, J. J. Mohr, R. Morgan,\\nE.Neilsen,A.A.Plazas,A.K.Romer,A.Roodman,E.Sanchez,V.Scarpine,M.Schubnell,\\nS.Serrano,M.Smith,E.Suchyta,G.Tarle,D.Thomas,C.To,T.N.Varga,R.H.Wechsler,\\nJ. Weller, R. D. Wilkinson, and DES Collaboration. Dark Energy Survey Year 3 Results:\\nPhotometricDataSetforCosmology. ApJS,254(2):24,June2021.\\n[102] Anowar J. Shajib, Graham P. Smith, Simon Birrer, Aprajita Verma, Nikki Arendse, and\\nThomasE.Collett. StronggravitationallensesfromtheVeraC.RubinObservatory. arXiv\\ne-prints,pagearXiv:2406.08919,June2024.\\n[103] Laurens Sluijterman, Eric Cator, and Tom Heskes. Optimal Training of Mean Variance\\nEstimationNeuralNetworks. arXive-prints,pagearXiv:2302.08875,February2023.\\n[104] Alessandro Sonnenfeld, Raphaël Gavazzi, Sherry H. Suyu, Tommaso Treu, and Philip J.\\nMarshall. TheSL2SGalaxy-scaleLensSample.III.LensModels,SurfacePhotometry,and\\nStellarMassesfortheFinalSample. ApJ,777(2):97,November2013.\\n[105] GeorgeStein,JacquelineBlaum,PeterHarrington,TomislavMedan,andZarijaLukic´. Mining\\nforStrongGravitationalLenseswithSelf-supervisedLearning. ApJ,932(2):107,June2022.\\n[106] F.Stoppa,R.RuizdeAustri,P.Vreeswijk,S.Bhattacharyya,S.Caron,S.Bloemen,G.Za-\\nharijas, G. Principe, V. Vodeb, P. J. Groot, E. Cator, and G. Nelemans. AutoSourceID-\\nFeatureExtractor.Opticalimageanalysisusingatwo-stepmeanvarianceestimationnetwork\\nforfeatureestimationanduncertaintycharacterisation. Astronomy&Astrophysics,680:A108,\\nDecember2023. arXiv:2305.14495[astro-ph,physics:hep-ph].\\n[107] BaochenSun,JiashiFeng,andKateSaenko. Correlationalignmentforunsuperviseddomain\\nadaptation,2016.\\n[108] PaxsonSwierc,MeganZhao,AleksandraC´iprijanovic´,andBrianNord. DomainAdaptation\\nforMeasurementsofStrongGravitationalLenses,November2023. PublicationTitle: arXiv\\ne-printsADSBibcode: 2023arXiv231117238S.\\n[109] AikRuiTan,ShingoUrata,SamuelGoldman,JohannesC.B.Dietschreit,andRafaelGómez-\\nBombarelli. Single-modeluncertaintyquantificationinneuralnetworkpotentialsdoesnot\\nconsistentlyoutperformmodelensembles. npjComputationalMathematics,9:225,January\\n2023.\\n[110] YaroneM.Tokayer,IsaqueDutra,PriyamvadaNatarajan,GuillaumeMahler,MathildeJauzac,\\nandMassimoMeneghetti. TheGalaxy–GalaxyStrongLensingCrossSectionandtheInternal\\nDistributionofMatterinΛCDMSubstructure. ApJ,970(2):143,August2024.\\n[111] TommasoTreu. StrongLensingbyGalaxies. ARA&A,48:87–125,September2010.\\n[112] Tommaso Treu and Anowar J. Shajib. Strong Lensing and H . arXiv e-prints, page\\n0\\narXiv:2307.05714,July2023.\\n[113] LarissaT.Triess,MariellaDreissig,ChristophB.Rist,andJ.MariusZöllner. ASurveyon\\nDeepDomainAdaptationforLiDARPerception.In2021IEEEIntelligentVehiclesSymposium\\nWorkshops(IVWorkshops),pages350–357,July2021. arXiv:2106.02377[cs].\\n[114] LaurentValentinJospin,WrayBuntine,FaridBoussaid,HamidLaga,andMohammedBen-\\nnamoun. Hands-onBayesianNeuralNetworks–aTutorialforDeepLearningUsers. arXiv\\ne-prints,pagearXiv:2007.06823,July2020.\\n[115] GuidoVanRossum.ThePythonLibraryReference,release3.8.2.PythonSoftwareFoundation,\\n2020.\\n19[116] FrancescoVerdojaandVilleKyrki. NotesontheBehaviorofMCDropout. arXive-prints,\\npagearXiv:2008.02627,August2020.\\n[117] SebastianWagner-Carena,JelleAalbers,SimonBirrer,EthanO.Nadler,EliseDarragh-Ford,\\nPhilipJ.Marshall,andRisaH.Wechsler. FromImagestoDarkMatter: End-to-endInference\\nofSubstructurefromHundredsofStrongGravitationalLenses. ApJ,942(2):75,January2023.\\n[118] MikeWalmsley,MicahBowles,AnnaM.M.Scaife,JasonShingiraiMakechemu,AlexanderJ.\\nGordon,AnnetteM.N.Ferguson,RobertG.Mann,JamesPearson,JürgenJ.Popp,JoBovy,\\nJoshSpeagle,HughDickinson,LucyFortson,TobiasGéron,SandorKruk,ChrisJ.Lintott,\\nKameswaraMantha,DevinaMohan,DavidO’Ryan,andInigoV.Slijepevic. ScalingLawsfor\\nGalaxyImages. arXive-prints,pagearXiv:2404.02973,April2024.\\n[119] Yun Wang, Zhongxu Zhai, Anahita Alavi, Elena Massara, Alice Pisani, Andrew Benson,\\nChristopherM.Hirata,LadoSamushia,DavidH.Weinberg,JamesColbert,OlivierDoré,Tim\\nEifler,ChenHeinrich,ShirleyHo,ElisabethKrause,NikhilPadmanabhan,DavidSpergel,and\\nHarryI.Teplitz. TheHighLatitudeSpectroscopicSurveyontheNancyGraceRomanSpace\\nTelescope. TheAstrophysicalJournal,928:1,March2022. Publisher: IOPADSBibcode:\\n2022ApJ...928....1W.\\n[120] MichaelL.Waskom. seaborn: statisticaldatavisualization. JournalofOpenSourceSoftware,\\n6(60):3021,2021.\\n[121] WesMcKinney. DataStructuresforStatisticalComputinginPython. InStéfanvanderWalt\\nandJarrodMillman,editors,Proceedingsofthe9thPythoninScienceConference,pages56–\\n61,2010.\\n[122] Garrett Wilson and Diane J. Cook. A Survey of Unsupervised Deep Domain Adaptation,\\nFebruary2020. arXiv:1812.02849[cs,stat]version: 2.\\n[123] WenxiaoXiao,ZhengmingDing,andHongfuLiu. VisualizingTransferredKnowledge: AnIn-\\nterpretiveModelofUnsupervisedDomainAdaptation. arXive-prints,pagearXiv:2303.02302,\\nMarch2023.\\n[124] KaiYe,TiejinChen,HuaWei,andLiangZhan.UncertaintyRegularizedEvidentialRegression.\\narXive-prints,pagearXiv:2401.01484,January2024.\\n[125] E. A. Zaborowski, A. Drlica-Wagner, F. Ashmead, J. F. Wu, R. Morgan, C. R. Bom, A. J.\\nShajib,S.Birrer,W.Cerny,E.J.Buckley-Geer,B.Mutlu-Pakdil,P.S.Ferguson,K.Glazebrook,\\nS.J.GonzalezLozano,Y.Gordon,M.Martinez,V.Manwadkar,J.O’Donnell,J.Poh,A.Riley,\\nJ.D.Sakowska,L.Santana-Silva,B.X.Santiago,D.Sluse,C.Y.Tan,E.J.Tollerud,A.Verma,\\nJ. A. Carballo-Bello, Y. Choi, D. J. James, N. Kuropatkin, C. E. Martínez-Vázquez, D. L.\\nNidever,J.L.NiloCastellon,N.E.D.Noël,K.A.G.Olsen,A.B.Pace,S.Mau,B.Yanny,\\nA.Zenteno,T.M.C.Abbott,M.Aguena,O.Alves,F.Andrade-Oliveira,S.Bocquet,D.Brooks,\\nD.L.Burke,A.CarneroRosell,M.CarrascoKind,J.Carretero,F.J.Castander,C.J.Conselice,\\nM. Costanzi, M. E. S. Pereira, J. De Vicente, S. Desai, J. P. Dietrich, P. Doel, S. Everett,\\nI.Ferrero,B.Flaugher,D.Friedel,J.Frieman,J.García-Bellido,D.Gruen,R.A.Gruendl,\\nG.Gutierrez,S.R.Hinton,D.L.Hollowood,K.Honscheid,K.Kuehn,H.Lin,J.L.Marshall,\\nP. Melchior, J. Mena-Fernández, F. Menanteau, R. Miquel, A. Palmese, F. Paz-Chinchón,\\nA.Pieres,A.A.PlazasMalagón,J.Prat,M.Rodriguez-Monroy,A.K.Romer,E.Sanchez,\\nV.Scarpine,I.Sevilla-Noarbe,M.Smith,E.Suchyta,C.To,N.Weaverdyck,(DELVE,and\\nDESCollaborations). Identificationofgalaxy–galaxystronglenscandidatesinthedecamlocal\\nvolumeexplorationsurveyusingmachinelearning. TheAstrophysicalJournal,954(1):68,aug\\n2023.\\n[126] LeiZhangandXinboGao. TransferAdaptationLearning: ADecadeSurvey,November2020.\\narXiv:1903.04687[cs].\\n[127] KaiyangZhou,ZiweiLiu,YuQiao,TaoXiang,andChenChangeLoy.DomainGeneralization:\\nASurvey. arXive-prints,pagearXiv:2103.02503,March2021.\\n[128] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu,\\nHui Xiong, and Qing He. A Comprehensive Survey on Transfer Learning, June 2020.\\narXiv:1911.02685[cs,stat].\\n20[129] A.C´iprijanovic´,D.Kafkes,K.Downey,S.Jenkins,G.N.Perdue,S.Madireddy,T.Johnston,\\nG.F.Snyder,andB.Nord. DeepMerge-II.Buildingrobustdeeplearningalgorithmsformerg-\\ninggalaxyidentificationacrossdomains. MonthlyNoticesoftheRoyalAstronomicalSociety,\\n506:677–691,September2021. Publisher: OUPADSBibcode: 2021MNRAS.506..677C.\\n[130] A.C´iprijanovic´,D.Kafkes,S.Jenkins,K.Downey,G.N.Perdue,S.Madireddy,T.Johnston,\\nandB.Nord. Domainadaptationtechniquesforimprovedcross-domainstudyofgalaxymerg-\\ners,November2020. PublicationTitle: arXive-printsADSBibcode: 2020arXiv201103591C.\\n[131] A.C´iprijanovic´,D.Kafkes,G.N.Perdue,K.Pedro,G.Snyder,F.J.Sánchez,S.Madireddy,\\nS.M.Wild,andB.Nord. Robustnessofdeeplearningalgorithmsinastronomy–galaxymor-\\nphologystudies. arxiv,2021. Publisher: arXivtex.copyright: CreativeCommonsAttribution\\n4.0International.\\n[132] A C´iprijanovic´, A Lewis, K Pedro, S Madireddy, B Nord, G N Perdue, and S M Wild.\\nDeepAstroUDA:Semi-SupervisedUniversalDomainAdaptationforCross-SurveyGalaxy\\nMorphologyClassificationandAnomalyDetection. MachineLearning: ScienceandTechnol-\\nogy,4(2):025013,June2023.\\n[133] AleksandraC´iprijanovic´,DianaKafkes,GregorySnyder,FJavierSánchez,GabrielNathan\\nPerdue,KevinPedro,BrianNord,SandeepMadireddy,andStefanMWild. DeepAdversaries:\\nExaminingtheRobustnessofDeepLearningModelsforGalaxyMorphologyClassification.\\nMachineLearning: ScienceandTechnology,3(3):035007,September2022.\\n[134] Aleksandra C´iprijanovic´, Ashia Lewis, Kevin Pedro, Sandeep Madireddy, Brian Nord,\\nGabriel N. Perdue, and Stefan M. Wild. Semi-Supervised Domain Adaptation for\\nCross-SurveyGalaxyMorphologyClassificationandAnomalyDetection,November2022.\\narXiv:2211.00677[astro-ph].\\n21AcknowledgmentsandDisclosureofFunding\\nA Funding\\nWeacknowledgetheDeepSkiesLabasacommunityofmulti-domainexpertsandcollaborators\\nwho’ve facilitated an environment of open discussion, idea generation, and collaboration. This\\ncommunitywasimportantforthedevelopmentofthisproject.\\nWork supported by the Fermi National Accelerator Laboratory, managed and operated by\\nFermiResearchAlliance,LLCunderContractNo. DE-AC02-07CH11359withtheU.S.Department\\nofEnergy. TheU.S.Governmentretainsandthepublisher,byacceptingthearticleforpublication,\\nacknowledgesthattheU.S.Governmentretainsanon-exclusive,paid-up,irrevocable,world-wide\\nlicensetopublishorreproducethepublishedformofthismanuscript,orallowotherstodoso,for\\nU.S.Governmentpurposes.\\nThis material is based upon work supported by the Department of Energy under grant No.\\nFNAL21-25.\\nB AuthorContributions\\nAgarwal: Methodology,Formalanalysis,Software,Validation,DataCuration,Investigation,Writing\\n-OriginalDraft\\nC´iprijanovic´: Conceptualization, Methodology, Formal analysis, Writing - Review & Edit-\\ning,Supervision,Projectadministration\\nNord: Conceptualization, Methodology, Formal analysis, Resources, Writing - Original\\nDraft,Writing-Review&Editing,Supervision,Projectadministration,Fundingacquisition\\nWethankthefollowingcolleaguesfortheirinsightsanddiscussionsduringthedevelopmentofthis\\nwork: RebeccaNevin.\\nC SoftwareAttribution\\nWe used the following software packages: Astropy [11, 9, 10], deeplenstronomy [82],\\nlenstronomy[12,14],Matplotlib[54],Numpy[46],Pandas[88]Python[115],PyTorch[89],\\nScipy[56,121],Seaborn[120],Sklearn[16,90],Torch[22],Torchvision[76],\\nD MVENetworkArchitecture\\nSeeTable3forthedetailedMVEnetworkarchitecture. Thereare112,866trainableparameters. We\\nnotethattheactivationfunctionforthefinaldenselayersischosentobesigmoidratherthanReLU,\\nsinceReLUpredictsavalueofzeroforanynegativeinput,encouragingpredictionsofzeromeanor\\nvariance. Thisissuecanalsobesolvedbyalternativeapproaches,suchastheuseofLeakyReLUor\\notheractivationfunctionsthatdisincentivizeapredictionofzero.\\nE Modelinferencewithvariedweightinitializations\\nWeperformedexperimentsfivetimes, eachwithadifferentrandomseedforthenetworkweight\\ninitialization. All models received the same optimization procedure (§3). The performance of\\nMVE-only model on the target data sets is inconsistent across the seed choices. In contrast, the\\nMVE-UDAmodelperformsconsistentlyslightlyworsethantheMVE-onlymodelonthesourcedata\\n22Table3: ThearchitectureoftheMVEnetwork. Thefirstcolumnliststhelayertype,thesecondlists\\nthedimensionalityoftheoutputfromthatlayer,andthethirdcolumnliststheparametersofthat\\nlayer;kisthekernelsize,andsisthestride. Thefinallayeroutputsthemeanandvariance.\\nLayer Outputshape Parameters\\nConv2d [-1,8,40,40] k =3,s=1\\nBatchNorm2d [-1,8,40,40] k =3,s=1\\nMaxPool2d [-1,8,20,20] k =2,s=2\\nConv2d [-1,16,20,20] k =3,s=1\\nBatchNorm2d [-1,16,20,20] k =3,s=1\\nMaxPool2d [-1,16,20,20] k =2,s=2\\nConv2d [-1,32,10,10] k =3,s=1\\nBatchNorm2d [-1,32,10,10] k =3,s=1\\nMaxPool2d [-1,32,5,5] k =2,s=2\\nLinear [-1,128] -\\nLinear [-1,32] -\\nLinear [-1,2] -\\nacrossvariedweightinitialization. However,unliketheMVE-onlymodel,itconsistentlyperforms\\nequallywellonthetargetdataasonthesourcedata. ThisindicatesUDAaddsstabilityagainstthe\\ndomainshiftandisnecessaryfortheapplicationofMVEtodatasetswithadomainshift. Forsome\\ninitializations,theMVE-UDAmodeltrainingstartswithpredictionsofzeroforthemeanorvariance,\\nwhichiserroneous. Furthertrainingdoesnotimprovetheperformance. Investigatingthispatternin\\ndetailisoutsidethescopeofthiswork. Wechoseseedswherethispathologicalbehaviordoesnot\\noccurinthefirstepochoftraining.\\nF Computationalcostsforexperiments\\nAllcomputingwasexecutedonanNVIDIAA100GPUwith40GBmemory. Thesecomputations\\nwereperformedontheFermilabElasticAnalysisFacility[EAF;50]. TrainingwithandwithoutUDA\\nrequirethesameamountoftime,∼2.5hours.\\n23Table4: Meanresidual⟨δθ ⟩,meanaleatoricuncertainty⟨σ ⟩,meancorrelationcoefficient⟨R2⟩,\\nE al\\nandmeanNLLloss⟨L ⟩acrosseachdatasetforeachmodel,MVE-only,MVE-UDA.\\nβ−NLL\\nMVE-only MVE-UDA\\nMetric Seed Source Target Source Target\\nResidual: ⟨δθ ⟩ 56 0.0164 0.0693 0.0358 0.0436\\nE\\n11 0.0149 0.0287 0.0389 0.0425\\n31 0.0201 0.0585 0.0386 0.0461\\n6 0.0150 0.0818 0.0484 0.0510\\n63 0.0174 0.0240 0.0452 0.0551\\nUncertainty: ⟨σ ⟩ 56 0.0243 0.0253 0.0489 0.0503\\nal\\n11 0.0180 0.0179 0.0602 0.0599\\n31 0.0269 0.0239 0.0634 0.0634\\n6 0.0192 0.0199 0.0678 0.0678\\n63 0.0203 0.0205 0.0628 0.0628\\nCorrelation: ⟨R2⟩ 56 0.9986 0.9642 0.9924 0.9835\\n11 0.9988 0.9939 0.9917 0.9897\\n31 0.9979 0.9727 0.9922 0.9886\\n6 0.9988 0.9418 0.9880 0.9861\\n63 0.9984 0.9968 0.9889 0.9832\\nNLLLoss: ⟨L ⟩ 56 −3.3603 4.5586 −2.6600 −2.4204\\nβ−NLL\\n11 −3.4737 −1.0705 −2.5098 −2.4385\\n31 −3.1443 15503.4180 −2.4316 −2.2854\\n6 −3.4925 25.4278 −2.2687 −2.2070\\n63 −3.2745 −2.6643 −2.2982 −2.0623\\n24',\n",
       " 'Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders.pdf': 'Piano Transcription by Hierarchical Language Modeling with\\nPretrained Roll-based Encoders\\nDichucheng Li Yongyi Zang Qiuqiang Kong†\\nDSP Lab, Electrical Engineering Dept. Independent Researcher DSP Lab, Electrical Engineering Dept.\\nThe Chinese University of Hong Kong Seattle, WA, USA The Chinese University of Hong Kong\\nHong Kong SAR, China zyy0116@gmail.com Hong Kong SAR, China\\ndccli21@m.fudan.edu.cn qqkong@ee.cuhk.edu.hk\\nAbstract—Automatic Music Transcription (AMT), aiming to get mu- Frame-level and language model (LM)-based systems have tradi-\\nsical notes from raw audio, typically uses frame-level systems with tionally been viewed as distinct approaches in AMT. Frame-level\\npiano-rolloutputsorlanguagemodel(LM)-basedsystemswithnote-level\\nsystems utilize a compact piano-roll objective but require complex\\npredictions. However, frame-level systems require manual thresholding,\\npost-processing, while LM-based systems directly output note-level\\nwhiletheLM-basedsystemsstrugglewithlongsequences.Inthispaper,\\nweproposeahybridmethodcombiningpre-trainedroll-basedencoders predictions. However, LM-based systems face challenges due to the\\nwithanLMdecodertoleveragethestrengthsofbothmethods.Besides, lengthy sequences created by flattening note events that contain\\nourapproachemploysahierarchicalpredictionstrategy,firstpredicting tokens of onset, offset, pitch, and velocity, resulting in resource-\\nonset and pitch, then velocity, and finally offset. The hierarchical\\nintensive training and inference processes. Furthermore, audio en-\\nprediction strategy reduces computational costs by breaking down long\\nsequences into different hierarchies. Evaluated on two benchmark roll- coder selection has been explored in related domains such as audio\\nbased encoders, our method outperforms traditional piano-roll outputs captioning [15]–[19] and multimodal large language models [20]–\\n0.01and0.022inonset-offset-velocityF1score,demonstratingitspoten- [23],yetitsimpactonAMTremainsunexplored.Thisgapinresearch\\ntial as a performance-enhancing plug-in for arbitrary roll-based music\\npresentsanopportunitytobridgethedividebetweenframe-leveland\\ntranscriptionencoder.\\nIndex Terms—Automatic Music Transcription, Music Information LM-based approaches.\\nRetrieval In this paper, we introduce a novel approach that leverages the\\nI. INTRODUCTION strengthsofbothroll-basedsystemsandnote-basedlanguagemodels\\nfor music representation. Our proposed method employs pre-trained\\nAutomaticmusictranscription(AMT)isataskofconvertingaudio\\nroll-based systems as encoders and a language model as a decoder,\\nrecordingsintosymbolicrepresentations[1].Asakeytopicinmusic\\neffectively combining their respective advantages. To enhance pre-\\ninformationretrieval(MIR),AMTbridgesaudio-basedandsymbolic-\\ndiction efficiency, we implement a hierarchical prediction strategy:\\nbased music understanding. AMT systems enable applications such\\nfirst predicting onset and pitch, followed by velocity, and finally\\nas score following [2] and audio-score alignment [3].\\noffset. To achieve the hierarchical prediction strategy, we trained\\nPiano transcription, an instrument-specific subtask of AMT, is\\nthree models with the same model architecture to predict onset and\\na challenging task due to the high polyphony of piano music.\\npitch, velocity, and offset, respectively. This approach significantly\\nNumerous methods have been utilized for piano transcription in\\nreduces the prediction sequence length compared to a flattened note\\nrecent decades, including Factorization-based models [4], adaptive\\nevent sequence, resulting in improved performance. We empirically\\nestimation of harmonic spectra [5], and SVM-HMM structure [6].\\nevaluate the impact of different roll-based encoders and language\\nWith deep learning’s rise, models like CNN [7] and CRNN [8]\\nmodel decoder size. Our findings reveal that the choice of encoder\\nhave been effectively applied in AMT. Onsets & Frames system [9]\\nhas a much more substantial effect on overall performance than the\\nsignificantly improved note-level metrics by integrating onset and\\nsize of the language model. Notably, we observe that increasing the\\npitch detection. Kong et al. [10] further enhance the AMT system\\nlanguagemodelsizedoesnotreflectasimprovedmodelperformance,\\nby proposing a high-resolution AMT system trained by regressing\\ncorroborating observations reported in [14]. We further found that\\nprecise onset and offset times of piano notes. To minimize model\\nvelocity modeling is more prone to overfitting compared to onset-\\nsize, studies [11], [12] have used prior knowledge of harmonic\\npitch and offset. Our findings highlight the importance of encoder\\nstructures in audio representations to develop Dilated Convolutional\\nselectioninAMTtasks,callingforfurtherresearchinimprovingthe\\nnetworks. Transformer is a revolutionary model with a encoder-\\nscalability of language-model-based AMT systems.\\ndecoder architecture, the self-attention mechanism of which can\\nThis paper is structured as follows: Section II provides a detailed\\nextract global features and catch long-term relationships. Toyama et\\ndescription of both the piano roll-based and LM-based systems. In\\nal.[13]proposedatwo-levelhierarchicalfrequency-timeTransformer\\nSection III, we compare the traditional flattened token construction\\nto catch long-term spectral and temporal dependencies to determine\\nmethod with our proposed hierarchical approach. Our experimental\\nthe precise onset and offset for each note. The above methods use\\ndesign is outlined in Section IV, followed by Section V, which\\npianorollsasoutput,whichhasaframe-levelresolutionandrequires\\npresents our findings, including results, ablation studies, and related\\na threshold and a post-processing stage to decode it into a note\\ndiscussions. Finally, Section VI offers concluding remarks.\\nsequence. Hawthorne et al. [14] revolutionize the AMT framework\\nby treating it as a sequence-to-sequence task, where the the output II. ROLL-BASEDANDLM-BASEDAMTSYSTEMS\\nis directly a sequence of note-event tokens, eliminating the need for\\nA. Roll-based AMT Systems\\nextensive threshold-based post-processing\\nIn roll-based AMT, a waveform x is firstly transformed to an\\n†Correspondingauthor feature in time-frequency domain X ∈ RT×F, where T is time\\n5202\\nnaJ\\n7\\n]DS.sc[\\n2v83030.1052:viXraon-1 pn-1 vn-1 dn-1 on pn vn dn\\n(a) …\\non-1 pn-1 on pn\\nRoll-based Encoder (b1) …\\non-1 pn-1 vn-1 on pn vn\\n(b2) …\\nRoll-based Decoder LM-based Decoder on-1 pn-1 vn-1 dn-1 on pn vn dn\\n(b3) …\\n<time=36> <note=97> Fig.2:Flattenedandhierarchicaltokensequence.o n,p n,v n andd n\\n<velocity=32> represents a note event with onset time o , pitch p , velocity v ,\\nn n n\\n… andoffsetd .Flattenedapproach(a)formsonesequence,whilethe\\nn\\n(a) Pre-training Stage (b) LM-training Stage hierarchical approach (b 1, b 2 and b 3) forms three sequences. Two\\nlinesonoandptokensdenotethattheyarefixedfromb duringb\\n1 2\\nFig.1:Proposedsystemarchitecture.(a)Pre-trainingstagetrainsthe\\nand b . Best viewed in color. See Sec. III for details.\\n3\\nroll-basedencoderwithframe-levelobjectives.(b)LM-trainingstage\\nconnects it to a LM decoder, training with note-level objectives.\\nthe quality of the generated sequence. This approach allows for\\ndirect generation of note-level predictions without the need for\\nframes and F is frequency bins, using short-time Fourier transform\\npost-processing, potentially capturing long-term dependencies in the\\n(STFT). Then, the feature is transformed to predict a piano roll\\nmusic. While LM-based systems offer the advantage of direct note-\\nY ∈{0,1}T×K ,whereK is88possiblepitches,and0or1encodes\\nlevelprediction,theyareoftencomputationallyexpensiveduetothe\\nabsenceorpresenceofeachpitch.Theneuralnetworkmodelf (X)\\nθ need for flattening of note event sequence.\\npredicts Yˆ ∈ [0,1]T×K, representing predicted pitch probabilities.\\nTraining typically uses binary cross-entropy loss:\\nIII. FLATTENEDANDHIERARCHICALTOKENSTRUCTURE\\nT K\\nL BCE =− T1 K (cid:88)(cid:88) [Y t,klog(Yˆ t,k)+(1−Y t,k)log(1−Yˆ t,k)]. codO eu rr fsys ,t ae sm ili ls usc tro am tep do is ned Fio gf ura en 1e .n Tc ho ede er ncf oe dnc era sn fd a aL rM ep-b rea -s te rad ind ee d-\\nt=1k=1 dec enc\\n(1) on piano roll objectives, and transforms the input audio X ∈RT×F\\nAt inference time, the continuous predictions Yˆ t,k are typically into a sequence of hidden representations H = f enc(X) ∈ RT′×D,\\nthresholded to obtain binary predictions, which are then post- where the LM decoder f is designed to predict note-level output\\ndec\\nprocessed to extract note events with onset and offset times. While Y = (y ,...,y ) from the frame-level feature H extracted by the\\n1 N\\nroll-basedsystemshaveshowngoodperformance,theneedforpost- encoder.Weproposeahierarchicalpredictionstrategyfornoteevents,\\nprocessinglimitstheirusecases,andhavemotivatedthedevelopment where f predicts note pitch, velocity, and offset sequentially,\\ndec\\nof LM-based systems. controlled by task-specific query tokens q ∈ {q ,q ,q } with a\\np v f\\nvocabulary size of three. The probability of generating a note event\\nB. LM-based AMT Systems\\ny can be expressed as:\\ni\\nLanguageModel(LM)-basedAMTsystemstreatmusictranscrip-\\ntionasasequencegenerationtask.Inthesesystems,theinputaudio p (y |y ,X,q)=f (y ,H,q), (4)\\nθ i <i dec <i\\nX ∈ RT×F is typically first encoded into a sequence of hidden\\nrepresentations H ∈ RT′×D, where T′ is the number of encoded where θ represents the learnable parameters of both the encoder\\ntimestepsandD isthedimensionofthehiddenrepresentation.The and decoder. In this section, we detail how we construct the token\\nsystem then generates a sequence of note events Y = (y ,...,y ), sequence used to train our system.\\n1 N\\nwhere each y\\ni\\nrepresents a note event typically consisting of onset LetH =(x 1:T′)bethehiddenrepresentationsextractedfromthe\\ntime, pitch, duration, and velocity. The neural network model in an inputaudiosequence,andY =y 1:N bethesequenceofnoteevents,\\nLM-basedsystemcanberepresentedasaconditionallanguagemodel whereeachy n =(o n,p n,v n,d n)representsanoteeventwithonset\\np θ(Y|X),whereθarethelearnableparameters.Thismodelgenerates time o n, pitch p n, velocity v n, and offset f n. For p onset-pitch, p velocity,\\nthe probability distribution of the next note event given the previous and d offset, we add <sos> to the sequence and append task-specific\\nevents and the input audio: query tokens q p, q v, or q d. Notes are organized by onset time (first\\nto last), then pitch (low to high). We use <eos> to end sequences\\nN\\n(cid:89) and <pad> for batching. For flattened sequences, we follow [14],\\np (Y|X)= p (y |y ,X). (2)\\nθ θ i <i\\norganizing note onset, pitch, velocity, and offset similarly.\\ni=1\\nDifferentlythan[14],whichemploysanencoder-decoderlanguage\\nTherefore,thetrainingobjectiveforLM-basedsystemstypicallyuses\\nmodelT5[24],weuseLLaMA[25],adecoder-onlylanguagemodel\\nthe negative log-likelihood loss:\\narchitecture. The primary difference between these architectures lies\\n1 (cid:88)N in how they process the input sequence to generate the output\\nL NLL =− N logp θ(y i|y <i,X). (3) sequence.Theencoder-decoderarchitectureprocessesthepreviously\\ni=1 generatedtokensy usinganencoderintoasequenceofhidden\\n1:n−1\\nAt inference time, the model generates note events autoregressively, representations H , which is used to predict the next token y ,\\nenc n\\noften using beam search or other decoding strategies to improve i.e. p(y ) = p(y |H ). In contrast, a decoder-only architecture\\nn n encgenerates the output sequence by directly conditioning on the pre- for onset-pitch, velocity, and offset are made sequentially, with each\\nvious tokens without needing an explicit encoder step. The model prediction conditioned on the previous ones.\\nautoregressivelypredictsthenexttokenfromtheprecedingtokensin Theefficiencyofthishierarchicalapproachisreflectedinitstime\\nthe sequence, i.e. p(y n)=p(y n|x 1,y 1:n−1). complexity. For each language model, the time complexity remains\\nA critical aspect of the model is its ability to encode positional O((T +N)2D), where T is the length of the input sequence, N\\ninformation, as the Transformer architecture itself is agnostic to the is the length of the note sequence, and D is the hidden dimension.\\norder of tokens. To address this, we use two types of positional However, the overall complexity is reduced to O(3(T +N)2D) by\\nencodings: absolute positional encodings for audio embeddings and splitting the task across three separate models. This is a significant\\nrotary position embeddings (RoPE) [26] for note event tokens. improvementovertheO((T+3N)2D)complexitythatwouldresult\\nAbsolutepositionalencodingsintroduceexplicitpositioninforma- from using a single model for all tasks. Given that T ≪ N, this\\ntion to the input tokens by adding a fixed positional vector to each leads to an almost threefold reduction in time complexity, greatly\\ntoken embedding. The positional vector is calculated using sine and improving the model’s efficiency while maintaining high accuracy.\\ncosine functions of varying wavelengths, which ensure that each\\nposition in the sequence has a unique encoding. Formally, for a IV. EXPERIMENTDESIGN\\nposition pos and dimension i, the positional encoding is defined as: A. Encoders\\n(cid:18) (cid:19)\\npos For a comprehensive evaluation, we employ two benchmark roll-\\nPE(pos,2i)=sin ,\\n(cid:18)100002 di\\n(cid:19) (5)\\nbased systems, and adapt them as encoder. Specifically, we use\\npos CRNN [10] and HPPNet [11]. CRNN is comprised of convolutional\\nPE(pos,2i+1)=cos ,\\n100002 di layers, followed by bi-directional GRU layers and a linear readout\\nlayer. Two models of the same architecture are designed to perform\\nwhere d is the dimensionality of the embeddings. This encoding\\nnote and pedal predictions. We take the embedding before the final\\nis added directly to the token embeddings, allowing the model to\\nreadout layer, with 768 dimensions, and concatenate both to form a\\ndifferentiatebetweentokensbasedontheirpositionsinthesequence.\\n1536-dim embedding as the representation H into the LM decoder.\\nIncontrast,RotaryPositionEmbeddings(RoPE)[26]offeramore\\nHPPNetcombinesconvolutionalandrecurrentelements,introducing\\nflexible and efficient way of encoding positional information, espe-\\n”harmonicdilatedconvolution”(HD-Conv)layerstoexploitharmonic\\ncially for tasks involving long-range dependencies. RoPE modifies\\ncharacteristics of the input constant-Q transform.\\nthe query (Q) and key (K) vectors by applying a rotation in the\\nembedding space. This introduces a relative positioning between\\nB. Token Dictionary\\ntokens while preserving the inner-product structure of the attention\\nThe size of our token dictionary is 1265. Beyond task-specific\\nmechanism. The rotary transformation is applied as follows:\\nquerytokensandspecialtokens(<sos>forstartofsentence,<eos>\\nQ′ i =Q icos(θ)+Q i+1sin(θ), for end of sentence, <pad> for padding and <unk> for unknown),\\n(6)\\nK′ =K cos(θ)+K sin(θ), weencodetimeat10msresolution,yielding1001uniquetokensfor\\ni i i+1\\n10-secondsegments.Following[14],weuse128tokenseachforpitch\\nwhere θ is a position-dependent angle. Recall the probability of\\nand velocity. We also introduce a note-sustain” token, used when a\\ngenerating the entire sequence Y is given by:\\nnote extends beyond the boundary of a training segment, and either\\n(cid:89)N its beginning or ending falls outside the current training area.\\np(Y)= p(y |x ,y ). (7)\\nn 1 1:n−1\\nn=1 C. Dataset\\nIn our hierarchical model, we extend this with task-specific query\\nWe employ the Maestro dataset [27], which contains about 200\\ntokensq.Theprobabilityofgeneratingeachnotey isnowfactorized\\nn hours of paired piano recordings and MIDI score, sourced from\\ninto subcomponents, each handled by a separate language model:\\ntheInternationalPiano-e-Competition.Thescoreisdirectlycaptured\\np(y )=p(o ,p |x ,y ,q ) from the Yamaha Disklaviers piano, and have been aligned to have\\nn n n 1 1:n−1 p\\nan error margin of within 3 milliseconds against the recordings.\\n×p(v |x ,y ,o ,p ,q ) (8)\\nn 1 1:n−1 n n v\\nThe dataset is then segmented into individual musical pieces. We\\n×p(d |x ,y ,o ,p ,v ,q ).\\nn 1 1:n−1 n n n f utilize the official train/validation/test split provided by the Maestro\\nHere,p ,p ,andp representdistinctlanguagemodels dataset, where the number of recordings and total duration in hours\\nonset-pitch velocity offset\\nfor onset-pitch, velocity, and offset predictions, respectively. These are 962/137/177 songs and 159.2/19.4/20.0 hours, respectively.\\nmodels utilize the attention mechanism described earlier, where\\nthe query, key, and value matrices are computed from the input D. Training and Evaluation Setup\\nsequenceandpriorpredictions.Theuseofseparatelanguagemodels The original CRNN model is trained on 10-second long audio\\nfor each aspect of the musical event sequence reduces interference segments, while the HPPNet model is trained on 20-second long\\nbetween tasks and enables more focused learning. Each language ones. For a fair comparison, we retrain HPPNet on 10-second long\\nmodelfollowsthesameTransformer-basedstructure,whereW p isa segments and achieves comparable performance of reported in [11].\\nlearnable linear projection matrix: For the LM decoder, we use 6 transformer layers with 16 attention\\nheads, and an embedding dimension of 1024. After the models are\\np (·)=softmax(W ·FFN(MultiHead(Q,K,V))). (9)\\nmodel p re-trained, we connect their output to the LM decoder through a\\nHere, FFN represents Feed Forward Network. This formulation linear layer, then train end-to-end using the AdamW optimizer with\\nallowseachsubmodeltospecializeinaspecificattributeofthemusi- alearningrateof1e-5,abatchsizeof5,andamaximumstepcount\\ncal sequence while maintaining a consistent underlying architecture. of1million.AllexperimentsareconductedonNVIDIARTX4090s.\\nThe model benefits from this hierarchical structure, as predictions We train all settings until convergence is observed.TABLE I: Experimental results. Best performing setting for each TABLE III: Results for scaling experiments. Best results are shown\\nmetric is shown in bold. in bold.\\nModels Params OnF1 OnOffF1 OnOffVelF1 Models Params OnF1 OnOffF1 OnOffVelF1\\nHawthorneetal.[14] 54M 0.960 0.839 0.826 HPPNettiny 41M 0.938 0.807 0.745\\nHawthorneetal.[14] 213M 0.956 0.828 0.814 HPPNetsmall 105M 0.963 0.805 0.763\\nHPPNetbase 181M 0.971 0.852 0.832\\nCRNNRoll 200M 0.967 0.825 0.809\\nCRNNFlatten 200M 0.943 0.393 0.386 HPPNetlarge 335M 0.967 0.777 0.740\\nCRNNHierarchy 200M 0.962 0.845 0.819\\nHPPNetRoll 181M 0.971 0.822 0.810\\nHPPNetFlatten 181M 0.950 0.390 0.382\\nHPPNetHierarchy 181M 0.971 0.852 0.832 8\\nTABLE II: Different LM Decoder Settings. 6\\nSetting #Layer #Head #EmbedDim BatchSize\\n4\\nTiny 4 8 512 64\\nSmall 6 12 768 56\\n2\\nBase 6 16 1024 40\\nLarge 12 32 1024 24\\n0 50000 100000 150000 200000 250000 300000 350000 400000\\nSteps\\nE. Metrics\\nWe follow the default settings in mir_eval to determine if\\na predicted note is correct. Compared to a ground-truth note, a\\ncorrectly predicted note should have an onset within a window of\\n±50milliseconds,apitchwithinawindowof±50cents,avelocity\\nwithin a window of 0.1 after normalizing to the interval [0,1], and\\nan offset within ±50 milliseconds or 20% of the note’s duration,\\nwhicheverislarger.Followingpreviousliterature[10],[11],[14],we\\nprimarily use an F score that takes into account ‘pitches, onsets,\\n1\\noffsets, and velocities (On Off Vel F )’. We also include results for\\n1\\nF scores that consider ‘pitches and onsets (On F )’ or ‘pitches,\\n1 1\\nonsets and offsets (On Off F )’.\\n1\\nV. RESULTSANDDISCUSSIONS\\nResultsareshowninTab.I.Comparingbetweenthethreesettings,\\nwe can see that the flattened sequence is slightly worse at modeling\\nonsetbehavior,butdrasticallyworseatpredictingnoteoffset;whereas\\nthe hierarchical setting consistently reports comparable or better\\nperformance. It is worth noting that the “Roll” approach requires\\nsetting a threshold to gate notes as posterior information, whereas\\nthe “Hierarchy” approach do not. We have also achieved new state-\\nof-the-art result of the LM-based piano transcription model with the\\nHPPNet setting on all three F scores.\\n1\\nComparing between our results and results from [14], which also\\nappliesaflattenedsequenceduringtraining,weseethattheirresults\\naremuchclosertothe“Roll”approach.Webelievethisisprimarily\\nduetotheinfluenceofsequencelength.In[14],eachsegmentis4.088\\nseconds,whileinours,thesegmentlengthis10seconds.Thisresulted\\ninmorenotespersequence,andwiththeflattenedapproach,sequence\\nlength grows quickly with note events, which may have hindered\\nmodel performance. Also, [14] used an encoder-decoder language\\nmodelingarchitecture,whileweuseadecoder-onlylanguagemodel.\\nWe hypothesize that the non-autoregressive nature of the encoder-\\ndecoderarchitecturehelpeditbetterencodeinformationthatwouldbe\\nespeciallylostinthelong,flattenedsequence[28],thereforeincreased\\nits performance compared to our flattened setting.\\nLanguage models have been observed to show a “scaling law”\\nwhere large models with more parameters exhibit better perfor-\\nmance [29]. However, on the piano transcription task, [14] observed\\nthat larger model overfits rather than generalize better. To better\\nssoL\\nSolid: Training\\nOnset\\nDotted: Validation\\nOffset\\nVelocity\\nFig.3:Onset-pitch,velocityandoffsetlossonthetrainingset(solid\\nlines) and validation set (dotted lines). Best viewed in color.\\nexamine this phenomenon, we conduct three scaling experiments by\\ntraininghierarchicaltokensequencemodelsonthreesettings,dubbed\\nas“tiny”,“small”and“large”,asshowninTableII.Weconductthese\\nscaling experiments on 8 NVIDIA RTX 4090s.\\nResults for the scaling experiments are shown in Table III. We\\nobserve that compared to the original setting, no significant change\\nin any metric is observed, while all settings slightly under-perform\\nthe “base” setting. To examine the training process, we plot the\\ntraining and validations sets’ loss at different timesteps in Figure 3.\\nWeobservethatwhileonset-pitchandoffsetlanguagemodelsquickly\\nplateaus during training, the velocity training show over-fitting at\\nonlyabout100ksteps,similartothephenomenondescribedin[14].\\nThis suggests that the scaling behavior for different token types are\\ndifferent, and further merits our hierarchical approach.\\nVI. CONCLUSIONS\\nIn this paper, we propose a hybrid method that combines pre-\\ntrained roll-based encoders with an LM decoder. Besides, our ap-\\nproach employs a hierarchical prediction strategy, first predicting\\nonset and pitch, then velocity, and finally offset. The hierarchical\\nprediction strategy reduces computational costs by breaking down\\nlong sequences. Evaluated on two benchmark roll-based encoders,\\nourmethodoutperformstraditionalpiano-rolloutputs0.01and0.022\\nin onset-offset-velocity F1 score, demonstrating its potential as a\\nperformance-enhancing plug-in for any roll-based encoder. Results\\nshow that encoder choice significantly impacts performance more\\nthan LM size, highlighting the importance of encoder selection in\\nAMT. This study calls for further investigation into improving the\\nscalability of LM-based AMT systems.\\nVII. ACKNOWLEDGEMENT\\nThis research is supported by IdeaBooster funding from the Chi-\\nneseUniversityofHongKongwithprojectcodeofIDBF24ENG07.REFERENCES IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2024,pp.24185–24198.\\n[1] E. Benetos, S. Dixon, Z. Duan, and S. Ewert, “Automatic music [21] Y.Chu,J.Xu,X.Zhou,Q.Yang,S.Zhang,Z.Yan,C.Zhou,andJ.Zhou,\\ntranscription:Anoverview,”IEEESignalProcessingMagazine,vol.36, “Qwen-audio: Advancing universal audio understanding via unified\\nno.1,pp.20–30,2018. large-scale audio-language models,” arXiv preprint arXiv:2311.07919,\\n[2] B. Li and Z. Duan, “An approach to score following for piano perfor- 2023.\\nmances with the sustained effect,” IEEE/ACM Transactions on Audio, [22] S. Liu, A. S. Hussain, C. Sun, and Y. Shan, “Music understanding\\nSpeech,andLanguageProcessing,vol.24,no.12,pp.2425–2438,2016. llama:Advancingtext-to-musicgenerationwithquestionansweringand\\n[3] B. Niedermayer and G. Widmer, “A multi-pass algorithm for accurate captioning,”inIEEEInternationalConferenceonAcoustics,Speechand\\naudio-to-score alignment.” in Proceedings of the 11th International SignalProcessing,ICASSP. IEEE,2024,pp.286–290.\\nSociety for Music Information Retrieval Conference, ISMIR, 2010, pp. [23] Z. Deng, Y. Ma, Y. Liu, R. Guo, G. Zhang, W. Chen, W. Huang,\\n417–422. and E. Benetos, “Musilingo: Bridging music and text with pre-trained\\n[4] A. Khlif and V. Sethu, “An iterative multi range non-negative matrix language models for music captioning and query response,” arXiv\\nfactorizationalgorithmforpolyphonicmusictranscription.”inProceed- preprintarXiv:2309.08730,2023.\\nings of the 16th International Society for Music Information Retrieval [24] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\\nConference,ISMIR,2015,pp.330–335. Y.Zhou,W.Li,andP.J.Liu,“Exploringthelimitsoftransferlearning\\n[5] E. Vincent, N. Bertin, and R. Badeau, “Adaptive harmonic spectral with a unified text-to-text transformer,” Journal of machine learning\\ndecomposition for multiple pitch estimation,” IEEE Transactions on research,vol.21,no.140,pp.1–67,2020.\\nAudio,Speech,andLanguageProcessing,vol.18,no.3,pp.528–537, [25] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei,\\n2009. N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale et al., “Llama\\n[6] J. Nam, J. Ngiam, H. Lee, M. Slaney et al., “A classification-based 2: Open foundation and fine-tuned chat models,” arXiv preprint\\npolyphonic piano transcription approach using learned feature repre- arXiv:2307.09288,2023.\\nsentations.”inProceedingsofthe12thInternationalSocietyforMusic [26] J.Su,M.Ahmed,Y.Lu,S.Pan,W.Bo,andY.Liu,“Roformer:Enhanced\\nInformationRetrievalConference,ISMIR,2011,pp.175–180. transformerwithrotarypositionembedding,”Neurocomputing,vol.568,\\n[7] R. Kelz, M. Dorfer, F. Korzeniowski, S. Bo¨ck, A. Arzt, and G. Wid- p.127063,2024.\\nmer, “On the potential of simple framewise approaches to piano tran- [27] C. Hawthorne, A. Stasyuk, A. Roberts, I. Simon, C.-Z. A. Huang,\\nscription,” in Proceedings of the 17th International Society for Music S. Dieleman, E. Elsen, J. Engel, and D. Eck, “Enabling factorized\\nInformationRetrievalConference,ISMIR,2016. piano music modeling and generation with the maestro dataset,” in\\n[8] S. Sigtia, E. Benetos, and S. Dixon, “An end-to-end neural network InternationalConferenceonLearningRepresentations,ICLR.\\nfor polyphonic pianomusic transcription,” IEEE/ACM Transactions on [28] Z. Fu, W. Lam, Q. Yu, A. M.-C. So, S. Hu, Z. Liu, and N. Collier,\\nAudio,Speech,andLanguageProcessing,vol.24,no.5,pp.927–939, “Decoder-only or encoder-decoder? interpreting language model as a\\n2016. regularizedencoder-decoder,”arXivpreprintarXiv:2304.04052,2023.\\n[9] C. Hawthorne, E. Elsen, J. Song, A. Roberts, I. Simon, C. Raffel, [29] J.Kaplan,S.McCandlish,T.Henighan,T.B.Brown,B.Chess,R.Child,\\nJ.Engel,S.Oore,andD.Eck,“Onsetsandframes:Dual-objectivepiano S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws for neural\\ntranscription,”inProceedingsofthe19thInternationalSocietyforMusic languagemodels,”arXivpreprintarXiv:2001.08361,2020.\\nInformationRetrievalConference,ISMIR,2018,pp.50–57.\\n[10] Q. Kong, B. Li, X. Song, Y. Wan, and Y. Wang, “High-resolution\\npiano transcription with pedals by regressing onset and offset times,”\\nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\nvol.29,pp.3707–3717,2021.\\n[11] W.Wei,P.Li,Y.Yu,andW.Li,“Hppnet:Modelingtheharmonicstruc-\\ntureandpitch invariance inpianotranscription,”inProceedingsofthe\\n23thInternationalSocietyforMusicInformationRetrievalConference,\\nISMIR,2022.\\n[12] M. P. Fernandez, H. Kirchhoff, X. Serra et al., “Triad: Capturing har-\\nmonicswith3dconvolutions,”inProceedingsofthe24thInternational\\nSocietyforMusicInformationRetrievalConference,ISMIR,2023.\\n[13] K.Toyama,T.Akama,Y.Ikemiya,Y.Takida,W.-H.Liao,andY.Mit-\\nsufuji, “Automatic piano transcription with hierarchical frequency-time\\ntransformer,”inProceedingsofthe24thInternationalSocietyforMusic\\nInformationRetrievalConference,ISMIR,2023.\\n[14] C. Hawthorne, I. Simon, R. Swavely, E. Manilow, and J. Engel,\\n“Sequence-to-sequence piano transcription with transformers,” in Pro-\\nceedings of the 22nd International Society for Music Information Re-\\ntrievalConference,ISMIR,2021.\\n[15] X. Mei, X. Liu, Q. Huang, M. D. Plumbley, and W. Wang, “Audio\\ncaptioningtransformer,”arXivpreprintarXiv:2107.09817,2021.\\n[16] X. Mei, C. Meng, H. Liu, Q. Kong, T. Ko, C. Zhao, M. D. Plumbley,\\nY. Zou, and W. Wang, “Wavcaps: A chatgpt-assisted weakly-labelled\\naudio captioning dataset for audio-language multimodal research,”\\nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n2024.\\n[17] G.ZhuandZ.Duan,“Cacophony:Animprovedcontrastiveaudio-text\\nmodel,”arXivpreprintarXiv:2402.06986,2024.\\n[18] J.Kim,J.Jung,J.Lee,andS.H.Woo,“Enclap:Combiningneuralaudio\\ncodecandaudio-textjointembeddingforautomatedaudiocaptioning,”\\nin IEEE International Conference on Acoustics, Speech and Signal\\nProcessing,ICASSP. IEEE,2024,pp.6735–6739.\\n[19] X.Xu,H.Liu,M.Wu,W.Wang,andM.D.Plumbley,“Efficientaudio\\ncaptioning with encoder-level knowledge distillation,” arXiv preprint\\narXiv:2407.14329,2024.\\n[20] Z.Chen,J.Wu,W.Wang,W.Su,G.Chen,S.Xing,M.Zhong,Q.Zhang,\\nX. Zhu, L. Lu et al., “Internvl: Scaling up vision foundation models\\nand aligning for generic visual-linguistic tasks,” in Proceedings of the',\n",
       " 'PRMBench A Fine-grained and Challenging Benchmark for Process-Level Reward Models.pdf': 'PRMBENCH: A Fine-grained and Challenging Benchmark for\\nProcess-Level Reward Models\\nMingyangSong1,3,ZhaochenSu2,XiaoyeQu3,JiaweiZhou4†,YuCheng5†\\n1FudanUniversity,2SoochowUniversity,3ShanghaiAILaboratory\\n4StonyBrookUniversity,5TheChineseUniversityofHongKong\\nmysong23@m.fudan.edu.cn;suzhaochen0110@gmail.com;\\nquxiaoye@pjlab.org.cn;jzhou@ttic.edu;chengyu@cse.cuhk.edu.hk;\\nProjectPage: https://prmbench.github.io\\nAbstract Given that\\nis a three-dimensional vector, prove that: Can MVT be used in\\nsuch that 3-D situations?\\nProcess-level Reward Models (PRMs) are Question . This is a situation of\\ncrucial for complex reasoning and decision- falling for deception!\\nStep 1. Understand the Given Information ...\\nmaking tasks, where each intermediate step Step 2. Recall the classical Mean Value Theorem ...\\nStep 3. Apply the scalar MVT to each component ...\\nplays an important role in the reasoning pro-\\ncess. Sincelanguagemodelsarepronetovar-\\nioustypesoferrorsduringthereasoningpro-\\n0.28 0.84\\ncess, PRMs are required to possess nuanced Step 4. In the one-dimensional case, an elegant ...\\ncapabilitiesfordetectingvariousimpliciterror\\ntypesinreal-worldscenarios.However,current 0.67\\nbenchmarks primarily focus on step correct-\\n0.60 0.85\\nness, failing to evaluate PRMs’ performance Step 6. Conclusion\\nsystematically. Toaddressthisgap,weintro-\\nducePRMBENCH,aprocess-levelbenchmark\\nspecificallydesignedtoassessthefine-grained\\nerror detection capabilities of PRMs. PRM-\\nBENCH comprises 6,216 carefully designed\\nproblemsand83,456step-levellabels,evaluat-\\ningmodelsacrossmultipledimensions,includ-\\ning simplicity, soundness, and sensitivity. In\\nourexperimentson15models,spanningboth\\nopen-sourcePRMsandclosed-sourcelargelan-\\nguagemodelspromptedascriticmodels,weun-\\ncoversignificantweaknessesincurrentPRMs.\\nThesefindingsunderscorethechallengesinher-\\nent in process-level evaluation and highlight\\nkey directions for future research. We hope\\nPRMBENCHbearobustbenchforadvancing\\nresearchonPRMevaluationanddevelopment.\\n1 Introduction\\nRecent large language models (LLMs) (OpenAI,\\n2024a,b;Team, 2024a), trainedonlarge-scalere-\\ninforcement learning, has significantly improved\\ntheirperformanceincomplexreasoningtaskssuch\\nas mathematics and code generation (Su et al.,\\n2022;Yuetal.,2023;Guoetal.,2024;DeepMind,\\n2024;Luoetal.,2023;Luetal.,2024a,b). Akey\\nfactorbehindtheirsuccessesistheuseofprocess\\nrewardmodels(PRMs)(Wangetal.,2023;Light-\\nmanetal.,2023;Uesatoetal.,2022),whichevalu-\\natethecorrectnessandusefulnessofintermediate\\n†Equalseniorcontribution\\n... ...\\nHowever, these points might not coincide. We\\nwant a single that works for all components. Skywork-7B MathShepherd-7B\\nStep 5. By the Mean Value Theorem (in its integral form)\\nfor real functions, there is a single such that\\n0.89\\nFigure 1: Given a question Q, the o1 model fails to\\nresist the deception and generates a pseudo-proof for\\nthe question. When provided with the same question\\nand reasoning process, both Skywork-7B and Math-\\nShepherd-7Bareunabletoidentifytheerroneoussteps.\\nHere,r∗,r∗,andr∗representthreecandidatevaluesfor\\n1 2 3\\nr∗,andMVTreferstotheMeanValueTheorem.\\nreasoningstepstorefinethemodels’thinkingpro-\\ncess(Qinetal.,2024;Zhangetal.,2024b).\\nDespiterecentadvancements,PRMsremainfal-\\nlibleandpronetoinaccuracies(Zhengetal.,2024).\\nAsillustratedinFigure1,givenamisleadingques-\\ntionQ,theo1modelfailstorecognizethedecep-\\ntionandgeneratesapseudo-proofforthequestion.\\nThe red text highlights an erroneous reasoning\\nstep where the Mean Value Theorem (MVT) is\\nincorrectly applied in 3-D contexts. Notably, al-\\nthough the yellow text indicates that the model\\nrecognizes the inconsistency between 1-D MVT\\nand3-Dscenarios,itcontinuestomakeerrors. Un-\\nderthiscircumstance,bothSkywork-7B(o1Team,\\n2024)andMath-Shepherd-7B(Wangetal.,2023)\\nfail to identify the incorrect steps, indicating the\\nunreliabilityofcurrentPRMs. Unfortunately,cur-\\nrentPRMevaluationbenchmarkstypicallyrelyon\\nstep-levelreasoningdataannotatedwithbinaryla-\\nbels(e.g.,correct,orincorrect)(Zhengetal.,2024;\\n1\\n5202\\nnaJ\\n7\\n]LC.sc[\\n2v42130.1052:viXraPRM ErrorType Fine-grained Step TestCase Average\\nAnnotator\\nBenchmarks? Detection? classes† Evaluation Size Steps\\nMR-GSM8K(Zengetal.,2023) ✗ ✗ 1 ✓ Human 2,999 8.3\\nRMBench(Liuetal.,2024) ✗ ✗ 1 ✗ Synthetic+Human 1,327 -\\nCriticBench(Linetal.,2024) ✗ ✗ 1 ✗ - - -\\nMathCheck-GSM(Zhouetal.,2024) ✗ ✗ 1 ✓ Synthetic 516 -\\nMR-Ben(Zengetal.,2024b) ✗ ✗ 1 ✓ Human 5,975 9.5\\nProcessBench(Zhengetal.,2024) ✓ ✗ 1 ✓ Human 3,400 7.1\\nPRMBENCH ✓ ✓ 9 ✓ Synthetic+Human 6,216 13.4\\nTable1: ComparisonbetweenourproposedPRMBENCHandotherbenchmarksordatasetsrelatedtoreasoning\\nprocessassessment. †: Fine-grainedclassesmeanthenumberofevaluationsubjectsaccordingtofine-grainederror\\ntypesofmodelgeneration.\\nZeng et al., 2024b). However, the status of erro- uationsubjectsandninesub-categoriesincluding\\nneousreasoningstepsisbeyondsimplebinaryclas- simplicity,soundness,andsensitivity. Withthese\\nsificationsinthereal-worldscenario. Forinstance, fine-grainedevaluationsubjects,wecanconduct\\nasinglestepcanberedundant, conditionallycor- tailoredassessmentsofmodelsontheirspecified\\nrect,orentirelyincorrect,eachofwhichisformally capabilitiesandrevealtheirpotentialweaknesses\\ndistinct. Consequently, previous benchmarks are duringtherewardingprocedure.\\ninsufficient for evaluating the diverse error types\\n• BasedonourproposedPRMBENCH,weconduct\\nandscenarioswithinreasoningprocesses,andthey\\nin-depthpilotexperimentsonsixteenmodelsin-\\nlackcomprehensiveanalysesofthepotentialweak-\\ncluding PRMs along with SOTA LLMs. Our\\nnessesofPRMsinsuchevaluations.\\nfindingsuncovercriticalweaknessesandprovide\\nTo address this limitation, we present PRM-\\nvaluableinsightstoguidefutureresearchtoim-\\nBENCH,acomprehensiveandfine-grainedbench-\\nprovethecapabilitiesofPRMs.\\nmarkdesignedforevaluatingPRMs. Specifically,\\nPRMBENCH systematically assesses the perfor- • Tofacilitatefutureresearch,wereleasethePRM-\\nmanceofPRMsacrossdiverseerrorcategories,in- EVALtoolkit,featuringanautomatedevaluation\\ncludingsimplicity,soundness,andsensitivity. Our framework and a customizable data generation\\nbenchmark includes 6,216 fine-grained data in- and annotation system. We hope PRMBENCH\\nstances spreading across three major evaluation willadvanceresearchincomplexstep-levelrea-\\nsubjectsandninesub-categories,whosequalityis soningRLHFscenariosandcontributetothede-\\nensuredbyprofessionalannotators. Additionally, velopmentofmorereliableandrobustPRMs.\\nwe utilize style-controlled data curation methods\\n2 RelatedWork\\ntoensureevaluationsamplesunderconsistentdiffi-\\ncultylevels,mitigatingconfoundingvariables.\\n2.1 Process-levelRewardModels\\nInourstudy,weconductextensiveexperiments\\nusingPRMBENCHtoevaluate15models,includ- Process-level reward models (PRMs) have been\\ning dedicated PRMs and SOTA general-purpose shown to have advancement over traditional\\normathematicalLLMs,promptedascriticmodels. outcome-level reward models (ORMs) in train-\\nWeobservethatallPRMspartiallygraspmulti-step ingmodels’process-levelreasoningaccuracyand\\nprocessevaluation. Eventhebest-performingmod- improving their long-process reasoning abilities\\nels, such as Gemini-2-Thinking, achieve results (Lightmanetal.,2023;Uesatoetal.,2022). More\\nmarginally above random guessing, highlighting and more PRMs have been proposed for use in\\nsubstantialroomforimprovement. Tosumup,our process-levelRLHF(Wangetal.,2023;Xiaetal.,\\ncontributionsarethreefold: 2024;o1Team,2024). Lightmanetal.(2023)re-\\nleasedalargeamountoflabeleddataatthehuman-\\n• WepresentPRMBENCH,thefirstcomprehensive\\nannotated process level, providing great research\\nprocess-levelrewardmodelbenchmark,compris-\\nopportunitiesformulti-stepreasoning. Wangetal.\\ning6,216carefullycuratedsamplesand83,456\\n(2023)introducesaself-supervisedautomaticdata\\nstep-level labels for a series of evaluations on\\ngenerationandPRMtrainingpipelinethatcanauto-\\nprocess-levelrewardmodels.\\nmaticallygeneratetheprocess-levellabel. Xiaetal.\\n• PRMBENCH coversthreecarefully-craftedeval- (2024)utilizePRMasanautoevaluatortoassess\\n2Non-Redundancy\\nNon-Circular Logic A C B\\nA\\nMulti-Solution Consistency\\nStep Consistency B C\\nA B C A D\\nB\\' C\\'\\nDomain Consistency Deception Resistance\\nA A\\nB B\\'\\nConfidence Invariance Prerequisite Sensitivity\\nA B C A\\nB C\\nM ?\\nConfident\\ntcerroC yroehT Deception A A\\nB B\\nA niamoD Domain\\nB\\nSelect correct Empirical Soundness\\nPRM800K solution path A C B C B\\n(a). Original Data Instances G\\nQuestions Steps Answers\\n(b). Data Construction & Annotation\\nPerturbate on Original\\nSteps\\nLLMs\\nFilter Out Low-Quality\\nAnnotator Samples and check\\nmanually\\n(c). Evaluation Data Instances\\nErroneous Steps\\nCorrect Steps\\nData Construction PRMBench: A Comprehensive Evaluation of\\nProcedure PRMs\\nFigure2: AnoverviewofourPRMBENCH. Theleftpartillustratesourdatacurationprocedure. Intherightpartof\\nthefigure,weshowcasedemonstrationsofourevaluationsubjectsandtherelativeperformanceoftestedmodels,\\nwith green, yellow,and gray boxesindicatingsimplicity,soundness,andsensitivityrespectively,where red\\ncirclesrepresenterroneousstepsand green circlesindicatecorrectregularsteps.\\nthemultistepreasoningaccuracyofLMs. Dueto et al., 2024; Li et al., 2024a; Lin et al., 2024; Su\\ntheemergenceofmassiveworkonPRMtraining etal.,2024c). Althoughthoroughandcomprehen-\\nand data curating, many PRMs (o1 Team, 2024; sive, they are not designed for PRMs and cannot\\nXiongetal.,2024;Team,2024b;Gaoetal.,2024) evaluatethestep-levelrewardmodels. Somework\\nhavebeenproposed. Inaddition,someworksfocus (Zeng et al., 2023, 2024b; Yan et al., 2024) let\\nonusingnaturallanguagefeedbackfromLLMasa LLMs play a role as a teacher to judge whether\\nreward(McAleeseetal.,2024;Zhangetal.,2024a; eachstepiscorrectusingprocess-levellabeleddata\\nGao et al., 2024), which are called critic models. curatedbyhumanorauto-generated,whichalong\\nHowever, PRMs or critic models are fallible and with Zheng et al. (2024) can be used to evaluate\\nnot always correct, emphasizing the necessity of thereasoningcapabilitiesofPRMs. However,ex-\\ncomprehensivebenchmarks. Inthispaper,wepro- isting benchmarkscan onlyassess whether PRM\\npose PRMBENCH, a comprehensive benchmark candetectthevalidityofreasoningstepsbutover-\\nforevaluatingPRMsonfine-grainedsubjects,es- looktheimpliciterrortypeofreasoningprocedures.\\ntablishingastrongfoundationforPRMevaluation. Some work conducts the error type classification\\nbutisnotspecifiedforPRMsandlacksfine-grained\\n2.2 ReasoningBenchmarks step-levellabels(Lietal.,2024b). Hence,wepro-\\nposePRMBENCHasasolutiontothesechallenges,\\nEvaluating the reasoning capabilities of LLMs is\\nwhichhasfine-grainedevaluationsubjectsandcan\\ncrucial for understanding their potential and lim-\\ndetectdifferenterrortypes.\\nitations. ROSCOE (Golovneva et al., 2022) in-\\ntroducesasemanticcomparison-basedmulti-step 3 PRMBENCH\\nreasoning accuracy evaluation benchmark. How-\\never,somerecentresearchpointsoutitcannotbe 3.1 EvaluationSubjects\\nassumed that the labeled data can enumerate all\\nInthissection,weprovideadetailedintroduction\\nsolutionpathsexhaustively(Wangetal.,2023;Xia\\ntotheevaluationsubjectsofPRMBENCH,which\\net al., 2024). Therefore, Xia et al. (2024) utilize\\nisorganizedintothreemaindomains:\\nPRMsorCriticmodelsasevaluatorstoevaluatethe\\nstep-levelreasoningaccuracyofLLMs. Neverthe- • Simplicity primarily evaluates the redundancy\\nless,PRMscannotjudgetheprocess-leveldatavery detection capabilities of PRMs. It is important\\naccurately,soacomprehensiveevaluationbench- sincetheredundancywithinthereasoningsteps\\nmark for PRMs is important. There exists mas- would cause unnecessary computing costs and\\nsiveresearchonbenchmarkingrewardmodels(Liu reduceefficiency,althoughitdoesnotharmthe\\n3Overall NR. NCL. ES. SC. DC. CI. PS. DR. MS.\\nAvg.Steps 13.4 15.3 10.3 13.8 14.2 13.3 14.2 12.7 13.4 14.1\\nAvg.ErrorSteps 2.1 2.0 2.8 2.8 1.6 1.8 1.7 2.5 2.3 0.0\\nAvg.FirstErrorStep 7.8 7.8 4.9 8.0 9.1 6.8 11.4 6.2 8.3 N/A\\nAvg.QuestionLength 152.7 153.6 152.5 153.5 149.7 152.5 152.7 158.0 153.5 132.2\\n#ofInstances 6216 758 758 757 758 757 757 756 750 165\\nTable 2: Statistics of PRMBENCH. NR., NCL., ES., SC., DC., CI., PS., DR., and MS. represent for Non-\\nRedundancy, Non-Circular Logic, Empirical Soundness, Step Consistency, Domain Consistency, Confidence\\nInvariance,PrerequisiteSensitivity,DeceptionResistance,andMulti-SolutionConsistencyrespectively.\\ncorrectness (Qin et al., 2024; Xia et al., 2024). movedwithoutaffectingthecorrectnessoftheover-\\nFurthermore, a reasoning process can offer a allsolutionpath. Forexample,asshowninFigure\\nclearervisualizationofthecoreoftheproblem 2,ifA → B representsacorrectinferencechain,\\nandenhancetheoverallunderstandabilityofthe the redundant reasoning procedure can be dis-\\nreasoning(Suetal.,2024a). playedasA → C → B. whereC representsone\\normoreredundantstepsC = {c|cisredundant}.\\n• Soundness is one of the key capabilities of\\nPRMs,asitevaluatestheirrewardaccuracy. As\\nNon-CircularLogic Inthissub-category,PRMs\\ndiscussed in Section 1, the status of erroneous\\nare required to detect the implicit circular logic\\nstepsisfine-grained,varyinginbothcausesand\\nwithin the reasoning process. Circular logic is a\\nformsofexpression(Lietal.,2024b). Therefore,\\nspecificformofredundancy,distinctfromgeneral\\nwenotonlyassessthecorrectnessoftherewards\\nredundancy, in that it finally loops back to a pre-\\nbut also evaluate fine-grained performance, ac-\\nvious reasoning step. For example, as shown in\\ncountingforthevarioustypesoferrorsandtheir\\nFigure 2, if A → B represents a correct infer-\\nnuancesinthereasoningprocess.\\nence chain, circular logic can be formulated as\\n• Sensitivityassessesrobustnessorsensitivityto A → C → A → B,wherethereasoningstartsat\\ndetailswithinonequestionofPRMs,forinstance, stepA,progressesthroughasequenceofsteps,and\\nessentialconditionsorimplicitrequirements. We ultimatelyloopsbacktoA. WelistNon-Circular\\nemphasizetheimportanceofSensitivityasitre- Logicseparatelyduetoitscommonoccurrencein\\nlatestothecompletenessoflogicandresistance reasoningprocesses.\\ntomisleadinginformation,whichcontributesto\\n3.1.2 Soundness\\ntheoverallrobustnessofPRMs.\\nWe divide the Soundness category into four sub-\\nEachdomainisfurtherdividedintodetailedsub- categoriesduetoitscomplexity: EmpiricalSound-\\ncategoriesforamoregranularevaluation,whichis ness,StepConsistency,DomainConsistency,and\\ndiscussedindetailbelow. Theoverallstructureof ConfidenceInvariance. Thedefinitionofeachsub-\\nPRMBENCH alongwithrepresentativeexamples categoryisdiscussedbelow.\\nof each sub-category are illustrated in Figure 2,\\nand the detailed instances of every sub-category EmpiricalSoundness demandsPRMtodetect\\nareshowninAppendixC. theimplicitcounterfactualmistakeswithintherea-\\nsoning process. A counterfactual step refers to a\\n3.1.1 Simplicity statementwithinareasoningchainthatcontradicts\\nSpecifically, the Simplicity evaluation subject is established ground truth G. Such contradictions\\ndividedintotwosub-categories: Non-Redundancy canarisefromrelyingonoutdatedtheories,omit-\\nandNon-CircularLogic,withdetaileddescriptions tingcriticalconstraintsintheory,orincorporating\\nprovidedbelow: erroneousassumptions.\\nNon-Redundancy requires PRM to detect the Step Consistency expects PRM to detect the\\nimplicit redundancy within the reasoning proce- implicit step-wise contradiction, which means a\\ndure. Theredundancysituationreferstoaprocess conflict between a specific step and other steps\\nthat is not the most concise or efficient, as it in- within a reasoning path. Given a reasoning path\\ncludesoneormoreredundantstepsthatcanbere- P = {S ,S ,...,S },astepcontradictionexists\\n1 2 n\\n4ifS ⊥ S ,wherei,j ∈ [1,n]andi ̸= j. displayedinTable2,withthecurationprocedure\\ni j\\noutlinedbelow.\\nDomainConsistency Underthiscircumstance,\\nPRMsarerequiredtodetectimplicitdomainincon- Meta Data Extraction Our metadata instance\\nsistencymistakes,wheredomaininconsistencyis canberepresentedas(Q,A,S). Here,Qdenotes\\naspecialtypeofcounterfactual. Itreferstoastep aquestion,Arepresentsthegroundtruthanswerto\\nwithinthereasoningchainthatusesastatementor thequestion,S correspondstoacompletelycorrect\\ntheory valid in other domains or cases but is not step-levelsolutionprocess.\\nvalidwithinthecurrentreasoningchain. OurmetadataisbuiltuponPRM800K(Lightman\\net al., 2023), which provides the questions (Q),\\nConfidenceInvariance demandsthePRMtode-\\nground truth answers (A), and ground truth step-\\ntectover-confidenthallucinations,atypeofcounter-\\nlevelsolutionprocesses(S). Weselectcompletely\\nfactualwhereanincorrectstatementismadewith\\ncorrect solutions from both the training and test\\nunwarranted certainty, contradicting established\\nsets,filteringoutlow-qualityinstancestoestablish\\ngroundtruth.\\nourgroundtruthanswers.\\n3.1.3 Sensitivity\\nTest Case Construction We subsequently con-\\nThiscategoryincludesthreesub-categories: Prereq- structourtestcasesusingthepre-extractedmeta-\\nuisiteSensitivity,DeceptionResistance,andMulti- data. Each test case instance is represented as\\nSolution Consistency, with detailed descriptions (Q′,A,S′),whereQ′ denotesthetestquestionand\\nprovidedbelow. S′ representsthetestsolutionprocess,whichmay\\nincludeerrors. Duringthetestingphase,modelsare\\nPrerequisite Sensitivity requires the PRM to\\ntaskedwithevaluatingS′ andprovidingjudgments\\nmaintain sensitivity to missing conditions or pre-\\nforeachstepintheprocess.\\nrequisitemistakes,whichmeansaflawintherea-\\nWith the first eight class-specific prompts, as\\nsoningchainwherecriticalpremises,assumptions,\\ndemonstratedinAppendixD.1andoursupplemen-\\nornecessaryconditionsareabsent. Thisomission\\ntarymaterial,wequeryoneofthemostadvanced\\nresults in logical gaps, incomplete reasoning, or\\nLLMs, GPT-4o (OpenAI, 2024a), to modify the\\nbiasedconclusions. Forexample,whenamissing\\nground-truthreasoningprocessintoversionscon-\\ncondition occurs, the model is required to solve\\ntainingerroneoussteps. Subsequently,thesemod-\\ntheproblemthroughcaseanalysisorfurtherinves-\\nifications are manually reviewed to filter out un-\\ntigation. However,theanswerbecomesincorrect\\nreasonableorunqualifiedchanges. Thisprocedure\\nifthemodeloverlooksthemissingconditionand\\nallowsustoconstructalltestcases,exceptforthe\\nproceedswithstandardreasoningmethods.\\nmulti-solution cases. For the multi-solution sub-\\nDeceptionResistance demandsthePRMtode- ject, we leverage the newly proposed multi-step\\ntecttheimplicitdeceptionortrapwithinareason- reasoningmodelQwQ† (Team,2024a)togenerate\\ning process, that is, statements that appear to be candidateanswersforthegivenquestions. These\\ncorrect or align with ground truth but are subtly answersarethenfilteredtoexcludeunreasonable\\nalteredtointroduceinaccuracieswhilemaintaining or incorrect ones, resulting in multi-solution rea-\\ntheillusionofcorrectness. soningprocessesforasinglequestion.\\nMulti-Solution Consistency expects the PRM 3.3 QualityControl\\ntomaintainconsistencywhenfacedwithdifferent\\nTo ensure a high-quality dataset, we implement\\nsolution paths of the same problem. Concretely,\\na series of steps to filter out unqualified data and\\ntoevaluatethesensitivityandthegeneralizability\\nmaintaindataintegrity. Thespecificproceduresare\\nof PRMs, we utilize multiple correct reasoning\\noutlinedbelow:\\nprocessesofthesamequestiontotestwhetherthe\\nPRMcanperformcorrectly. Feature Filtering Even with detailed instruc-\\ntions,LLMscannotconsistentlygenerateoutputs\\n3.2 DataCuration that fully adhere to the required structure (Asai\\nWecuratethedatasetbyextractingmetadataand et al., 2024; Zeng et al., 2024a; Su et al., 2024b).\\nconstructing test cases according to our category\\n†Qwen/QwQ-32B-Preview:https://huggingface.co/\\ndefinitions. Detailedstatisticsof PRMBENCHare Qwen/QwQ-32B-Preview\\n5Simplicity Soundness Sensitivity\\nModelName Overall\\nNR. NCL. Avg. ES SC. DC. CI Avg. PS DR. MS. Avg.\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 31.7 31.4 35.8 33.6 32.4 25.7 26.0 30.2 28.6 33.1 32.3 81.1 48.8\\nSkywork-PRM-7B 36.2 35.7 41.2 38.4 36.7 29.1 30.6 34.4 32.7 36.8 37.4 88.8 54.3\\nLlemma-PRM800k-7B 52.0 49.3 53.4 51.4 56.4 47.1 46.7 53.3 50.9 51.0 53.5 93.6 66.0\\nLlemma-MetaMath-7B 50.5 50.2 50.5 50.3 51.9 47.6 44.4 52.1 49.0 50.5 51.3 96.0 66.0\\nLlemma-oprm-7B 50.3 48.7 49.3 49.0 54.2 46.8 44.5 53.5 49.8 49.2 51.3 91.8 64.1\\nMATHMinos-Mistral-7B 54.2 48.8 54.0 51.4 57.0 52.1 50.7 57.8 54.4 52.8 55.8 91.1 66.5\\nMathShepherd-Mistral-7B 47.0 44.0 50.3 47.1 49.4 44.5 41.3 47.7 45.7 47.2 48.6 86.1 60.7\\nReasonEval-7B 60.0 61.0 50.1 55.5 62.1 65.9 61.5 66.0 63.9 55.6 58.0 99.5 71.0\\nRLHFlow-PRM-Mistral-8B 54.4 46.1 47.3 46.7 56.6 55.1 54.4 63.8 57.5 51.5 56.2 97.9 68.5\\nRLHFlow-PRM-Deepseek-8B 54.2 46.4 48.9 47.6 55.7 55.0 53.2 66.2 57.5 49.0 55.4 99.8 68.1\\nReasonEval-34B 60.5 54.8 48.1 51.5 66.4 60.3 57.8 67.5 63.0 57.7 64.3 97.2 73.1\\nAvg. 50.1 46.9 48.1 47.5 52.6 48.1 46.5 53.9 50.3 48.6 51.3 93.0 64.3\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 66.8 57.0 62.4 59.7 72.0 69.7 70.7 71.1 70.9 62.5 65.7 99.2 75.8\\no1-mini 68.8 65.6 63.7 64.6 74.5 67.7 73.8 72.3 72.1 61.8 64.8 100.0 75.5\\nGemini-2.0-flash-exp 66.0 67.2 58.1 62.7 70.4 65.7 66.0 67.3 67.3 61.8 66.2 98.2 75.4\\nGemini-2.0-thinking-exp-1219 68.8 68.5 63.8 66.2 72.9 71.3 71.0 71.8 71.8 60.3 65.7 99.8 75.3\\nAvg. 67.6 64.6 62.0 63.3 72.4 68.6 70.4 70.7 70.5 61.6 65.6 99.3 75.5\\nTable3: PerformancescomparisonofpopularmodelsonPRMBENCH. Thebestperformanceforeachcategoryand\\ntaskisinbold,whilethesecond-bestperformanceisunderlined.\\nSinceourdatasetimposesstrictstructuralrequire- Accuracy PRM\\nModel Sim.\\nmentsonthegeneratedresponses,anyoutputsthat Pos. Neg. Score\\ndo not conform to these specifications cannot be ReasonEval-7B 95.5 21.2 60.0 91.6\\nconsideredvalidforaccuratelyassessingtheperfor- ReasonEval-34B 79.1 48.4 60.5 82.8\\nmanceoftherewardmodel. Thiswouldcompro- Skywork-7B 30.1 79.7 36.2 74.3\\nRLHFlow-DeepSeek-8B 95.0 13.0 54.2 95.0\\nmisetheoverallqualityofthedataset. Tomaintain\\nGPT-4o 82.9 58.2 66.8 76.6\\nhighdataquality,wedefinestringentfilteringrules\\nGemini-2-thinking 89.0 49.8 68.8 82.0\\ntoexcludeinstancesthatfailtomeetthenecessary Random 50.0 50.0 50.0 79.4\\nstructuralcriteria. Detailedstructuralrequirements\\nareprovidedinAppendixD.1,andthefulldescrip- Table4: Comparisonofmodelperformanceonpositive\\ntionofourdatagenerationprocesscanbefoundin andnegativetestcases,alongwiththeirsimilarities.\\nthesupplementarymaterials.\\nstudyingprocess-levellanguagerewardmodels.\\nHumanVerification Furthermore,tofurtheren-\\nsure the quality of the data, we manually evalu-\\n4 Experiments\\nate 10% of the total instances. We focus on two\\nkey qualities for each data instance: ❶ Correct-\\n4.1 Models\\nnessofmodification: Whetherthemodifications\\nmade to the data instance are correct and reason- To provide a comprehensive evaluation of vari-\\nable. ❷Differenceinthemodification: Whether ous models on PRMBENCH, we select a diverse\\nthemodifieddatainstancediffersfromtheoriginal. set of models, ranging from open-source PRMs\\nDetailedinstructionsforthemanualfilteringpro- to proprietary LLMs configured as critic mod-\\ncessareprovidedinAppendixE.Werecruitedfive els. Specifically, the open-source PRMs include\\nvolunteerstoevaluateourproposed PRMBENCH smallmodelslikeSkywork-PRM-1.5B(o1Team,\\nandobserveover92%qualificationrateonthecor- 2024), mid-sized models such as Llemma-PRM-\\nrectnessmetricandover98%qualificationrateon 7B(Team,2024b),MATHMinos-PRM(Gaoetal.,\\nthedifferencemetric. Thisvalidationensuresthe 2024), MathShepherd-PRM (Wang et al., 2023),\\noverallqualityofourdatasetanditssuitabilityfor andRLHFlowPRMs(Xiongetal.,2024),aswell\\n635\\n30\\n25\\n20\\n15\\n10\\n5\\n0\\n2 4 6 8 10 12 14 16\\nError Position\\n)%(\\nycneuqerF\\nSimplicity 70\\nSoundness\\n60\\nSensitivity\\nAll 50\\n40\\n30\\n20\\n10\\n0 2 3 4 5 6 7 8 9 10\\nStep\\nFigure3: Distributionoferrorpositions,truncatedto16\\nforbettervisualization,correspondingtothelabelfield\\nasshowninFigure2.\\naslargemodelslikeReasonEval-34B.Additionally,\\nweevaluatestate-of-the-artgeneral-purposeLLMs,\\nsuchasGPT-4o(OpenAI,2024a),andmulti-step\\nreasoning-enhancedLLMs,includingtheo1series\\nmodels(OpenAI,2024b)andGemini-2-Thinking\\n(DeepMind,2024).\\nAll open-source PRMs and proprietary LLMs\\nareevaluatedonthecompletePRMBENCHdataset,\\nexceptfortheo1-seriesmodels. Fortheo1-series\\nmodels, evaluations were conducted on a subset\\nof PRMBENCH comprising394samples,propor-\\ntionallyselectedtoreflecttheclassdistribution,in\\nordertoreduceevaluationcosts.\\nConsidering the complexity of the task, which\\ninvolves question comprehension, evaluation of\\nthe provided processes, and adherence to format\\nconstraints,few-shotdemonstrationsetupsareem-\\nployed to help the model adapt to the output\\nformatthroughIn-ContextLearning(ICL)exam-\\nples. Specifically,weusetwo-shotexampleswhen\\npromptinggeneral-purposeLLMs. Theimpactof\\nfew-shotsettingsisdiscussedinSection5.4\\n4.2 EvaluationMetrics\\nFor each annotated question-solution pair, the re-\\nward models are tasked with evaluating the cor-\\nrectness and redundancy of each step, assigning\\na step-level validity score and a step-level redun-\\ndancyscoretoeachstep. Wesubsequentlyutilize\\nthespecifiedthresholdofeachmodeltoobtainthe\\npredictionindicatingwhetherthestepiscorrector\\nredundant. This task is therefore framed as a bi-\\nnaryclassificationproblem. Givenouremphasison\\nevaluatingtheerrordetectioncapabilities,weuse\\nthenegativeF1scoreasametricforerrordetection\\nperformance. However,thismetricmaybeaffected\\n)%(ycaruccA\\nReasonEval-34B MathShepherd-7B GPT-4o Gemini-thinking\\nFigure4: Themodels’error-detectionaccuracyacross\\ndifferenterrorsteps,wherestep1andstepsbeyond11\\naretruncatedforimprovedvisualization.\\nbytheinherentbiasesofmodels. Tomitigatethis\\nandprovideaunified,normalizedscorethatreflects\\ntheoverallcompetencyoftheevaluatedmodel,fol-\\nlowingZhengetal.(2024),weintroduceametric\\ncalledPRMScore,definedformallyinEquation1.\\nPRM-Score = w ∗F1 +w ∗F1\\n1 neg 2\\n(1)\\nWhereF1andF1 refertoF1scoresandnega-\\nneg\\ntiveF1scoresrespectively. w andw areweights\\n1 2\\nthataredesignedtomaximizethedifferentiationbe-\\ntweendifferentmodels. Besides,wealsoprovide\\nresults of all evaluation subjects in fine-grained\\nmetricsinAppendixB.2.\\n4.3 MainResults\\nThemainresultsareshowninTable3. Someob-\\nservationscanbesummarizedasfollows:\\nThe PRMs partially grasp multi-step process\\nevaluation Ouranalysisindicatesthat,although\\nGemini-2-Thinking achieves the highest perfor-\\nmanceamongallevaluatedmodels,itsscoreisonly\\nmarginally better than random guessing (68.8 vs.\\n50.0),underscoringsignificantroomforimprove-\\nmentinmulti-stepprocessevaluation. Moreover,\\nthebest-performingopen-sourcePRMsachievean\\nevenlowerscoreof60.5,andtheaveragescorefor\\nallPRMsis50.1,whichindicatestheirsuboptimal\\nperformance. Some models even perform worse\\nthan random guessing, highlighting their limited\\nreliability and potential training biases. Notably,\\nthebestopen-sourcePRMsfailtomatchtheperfor-\\nmanceofgeneral-purposeproprietaryLLMs,with\\nscoresthatremainsignificantlylowerthanthoseof\\n7state-of-the-artmodels. Forinstance,ReasonEval- erage step accuracy within a solution. We then\\n34B achieves a score of 60.5, while the Gemini- computetheoverallaveragesimilarityacrossthe\\n2.0-Thinking model scores 68.8. This suggests whole dataset. The results, shown in Table 4, re-\\nthatevenspecificallytrainedPRMsstilllagbehind veal that certain models, such as ReasonEval-7B\\nleadinggeneral-purposemodels. andRLHFlow-DeepSeek-8B,exhibitsignificantly\\nhighersimilaritythanthenormalsimilarityscore\\nSimplicityismorechallengingforPRMs Our\\n(79.4),showcasingpotentiallimitationsindifferen-\\nanalysishighlightssignificantvariationsinmodel\\ntiatingpositiveandnegativesteps.\\nreasoning capabilities across evaluation cate-\\ngories. For instance, in the Sensitivity category, 5.2 Performanceacrossdifferentstep\\nReasonEval-34Bperformsrelativelywell,achiev- positions\\ning an average score of 73.1. Especially in the\\nTakeaway 2. PRMs show a gradual improve-\\nMulti-Solutionssub-category,itexcelswithaPRM-\\nment in performance as the step position in-\\nScoreof97.2,approachingnear-perfectclassifica-\\ncreases.\\ntion accuracy. This suggests models perform rel-\\nativelybetteroncorrectinstancejudgment. How-\\nTocomprehensivelyevaluatetheerror-detection\\never, its performance declines markedly in more\\nperformance of PRMs, PRMBENCH includes a\\ncomplex scenarios. In the Simplicity category,\\nwiderangeoferrorsteppositions. Thedistribution\\nReasonEval-34B’sPRMScoredropsto51.5,sug-\\noferrorpositionsisillustratedinFigure3. While\\ngestingpartiallyreliableperformance.\\ndifferencesexistacrosscategories,theoverallpat-\\nternremainsconsistent: allcategoriespeakinfre-\\n5 FurtherAnalysis\\nquencyatstep5andgraduallydecreasethereafter.\\n5.1 Similarityanalysis This raises an interesting question: Does the\\nvariationinsteppositionsaffectmodelperfor-\\nTakeaway 1. PRMs show a clear bias during mance? To investigate, we focus on error steps\\nevaluation,oftenfavoringpositiverewards. to assess how erroneous step positions influence\\nmodel accuracy. The evaluation results are illus-\\nAsshowninTable3, mostopen-sourcePRMs trated in Figure 4, featuring four representative\\nexhibitsignificantbiasinourtestcases,withsome models: two PRMs and two proprietary LLMs\\nmodels performing worse than random guessing. prompted as critic models. As depicted in Fig-\\nThissuggeststhepotentialpresenceofbiaswithin ure 4, proprietary LLMs maintain stable perfor-\\ntheinferenceprocedureforourtestcases. Tovali- mance across different error step positions. In\\ndatethisassumption,weselectedasubsetofmod- contrast,PRMs,includingMath-Shepherd-7Band\\nels and evaluated their accuracy on positive and ReasonEval-7B, show a gradual improvement in\\nnegativestepsseparately. Theresultsaredisplayed performanceaserrorsteppositionsincrease. No-\\nin Table 4. Surprisingly, some models display a tably,incertainerrorsteps,theopen-sourcePRMs\\nclearbiasduringevaluation,oftenfavoringposi- outperform proprietary LLMs, potentially due to\\ntiverewards. Additionally,certainmodels,suchas inferencebias,asdiscussedinSection5.1. Despite\\nSkywork-7B,exhibitatendencytoassignnegative this occasional advantage, the full accuracy and\\nlabels to steps. Although proprietary LLMs also PRMScoreofopen-sourcePRMsstilllagbehind\\nexhibitbias,theyoutperformopen-sourcePRMs, thoseofproprietaryLLMs.\\nwithacomparativelymilderrewardtendency.\\n5.3 ErrorAnalysis\\nAdditionally, to further investigate inference\\nbias, we evaluate the reward similarity between A representative test case and the corresponding\\ncompletely correct reasoning processes and our modelperformancesarepresentedinTable5. This\\ntestcases. Specifically,weselectcompletelycor- example involves a counterfactual reasoning pro-\\nrect reasoning procedures for each question in cess, where steps eight through thirteen contain\\nour test cases and evaluate the solution-level per- information that contradicts the correct computa-\\nformance similarity between these and the test tionalprinciplesandshouldbeclassifiedas“nega-\\ncases. The solution-level similarity is defined as tive”. However,mostmodelsfailtoidentifythese\\nS = 100 − |Acc − Acc |, where Acc de- erroneousreasoningstepsandassignrelativelypos-\\npos neg\\nnotessolution-levelaccuracy,calculatedastheav- itive rewards, except for GPT-4o. While GPT-4o\\n8StepDescriptions GT ReasonE MathS GPT-4o Gemini\\nQuestion\\nCompute(cid:0) 1+cosπ(cid:1)(cid:0) 1+cos3π(cid:1)(cid:0) 1+cos5π(cid:1)(cid:0) 1+cos7π(cid:1)\\n. - - - - -\\n8 8 8 8\\nStep1 Let’scalltheexpressionwe’retryingtocomputex. ✓ 89.1 87.5 100.0 100.0\\nStep2 Usethefactthatcos(π−a)=−cosa. ✓ 77.5 82.8 100.0 100.0\\nStep3 Thenwehavex=(cid:0) 1+cosπ(cid:1)(cid:0) 1+cos3π(cid:1)(cid:0) 1+cos5π(cid:1)(cid:0) 1+cos7π(cid:1) . ✓ 71.4 76.7 100.0 100.0\\nStep4 Thisequals(cid:0) 1+cosπ(cid:1)(cid:0)8 1+cos3π(cid:1)8(cid:0) 1−cosπ(cid:1)(cid:0)8 1−cos3π(cid:1) .8 ✓ 20.5 76.9 100.0 100.0\\nStep5 Bythedifferenceofsqu8 ares,thisequ8 als(cid:0) 1−cos28 π(cid:1)(cid:0) 1−cos28 3π(cid:1) . ✓ 56.0 83.7 100.0 100.0\\nStep6 AndbythePythagoreanidentity,thisequals(cid:0) sin8 2π(cid:1)(cid:0) sin23π(cid:1)8 . ✓ 63.5 80.4 100.0 100.0\\n8 8\\nStep7 Ok,nowwejustneedtocomputethesines. ✓ 84.1 79.1 50.0 50.0\\nStep8 Wecanusetheformulaforthesumofsines. ✗ 73.6 74.1 0.0 0.0\\nStep9 Thatformulaissin(a)+sin(b)=2sin(cid:0)a+b(cid:1) cos(cid:0)a−b(cid:1) . ✗ 79.1 78.5 0.0 100.0\\n(cid:16) 2(cid:17) (cid:16) 2 (cid:17)\\nStep10 Thatmeansthatsinπ+sin3π =2sin π/8+3π/8 cos π/8−3π/8 . ✗ 67.4 78.0 0.0 0.0\\n8 8 2 2\\nStep11 Thisequals2sinπ/2cos(−π/4). ✗ 68.1 72.1 0.0 100.0\\n2 √ 2\\nStep12 Thisequals2·1· 2. ✗ 49.2 73.8 0.0 100.0\\n√ 2\\nStep13 Thisequals 2. ✗ 35.1 73.8 0.0 100.0\\nStep14 Butthisstepdoesn’thelpuscomputetheoriginalproductofsines. ✗ 72.5 64.3 -50.0 100.0\\nStep15 So,(cid:0) sin2π(cid:1)(cid:0) sin23π(cid:1) remainsthesameandx= 1. ✗ 6.3 35.8 0.0 -100.0\\n8 8 8\\nStep16 Therefore,themistakedidn’tchangethevalueofx. ✓ 22.6 43.5 -100.0 -100.0\\nFinalAcc. - 100 56.2 50.0 93.8 62.5\\nAcounterfactualstepwasintroducedinsteps8through13bymistakenlyusingtheformula\\nReason forthesumofsinesinsteadoftheproductofsines.Thisleadstoincorrectintermediatecalculations.\\nHowever,duetofortunateerrors,theendresultironicallymatchesthecorrectanswerinstep15.\\nTable5: AnexampleofadatainstanceanderrorcasesfromPRMBENCH. Thenumbersreportedarestep-level\\nvalidity scores generated by models. Scores and labels in red indicate negative samples, while those in green\\nindicatepositivesamples. “GT”representsgroundtruth,while“ReasonE,”“MathS,”and“Gemini”correspondto\\nReasonEval-7B,Math-Shepherd-7B,andGemini-2.0-flash-thinking-exp,respectively.\\nprovidesarelativelyaccuratereward,itsjudgments Model 0-shot 1-shot 2-shot\\nforkeystepsareonlymarginallynegative,reflect-\\nGPT-4o 68.1 68.2 66.8\\ning low confidence. This highlights a significant\\nGemini-2-flash 65.3 64.9 66.0\\nroom for improvement in PRMs’ detailed error-\\nGemini-2-thinking 67.8 67.8 68.8\\ndetectioncapabilities.\\nTable6: TheimpactofICLfew-shotnumbersonmodel\\n5.4 ImpactsofICLsettings\\nperformance. ThenumberreportedhereisPRMScore.\\nTakeaway3. In-ContextLearninghassubtleim-\\npactonmodels’performanceon PRMBENCH\\n6 Conclusion\\nIn the main experiments of PRMBENCH, we In this paper, we investigate a crucial question:\\nutilize2-shotICLtoevaluatetheperformanceof CanexistingPRMsdetectvarioustypesoferro-\\nclose-sourcedmodels. Inthissection,weinvesti- neous reasoning steps and provide reasonable\\ngatetheimpactofICLfew-shotnumbersonmodel rewards? To address this, we introduce PRM-\\nperformanceonPRMBENCH. Wevarythenumber BENCH, a benchmark characterized by its fine-\\nofICLfew-shotsto0,1,and2toexaminewhether grainedevaluationsubjectsandchallengingrequire-\\nincreasingthefew-shotnumberenhancestheper- ments. We carefully curate 6,216 data samples\\nformanceofgenerativemodelspromptedascritic with 83,456 step-level labels through LLMs and\\nmodels. ThefinalPRMScoreofGPT-4o,Gemini-2- humanfiltering. PRMBENCHcanbeusedtoeval-\\nflash,andGemini-2-thinkingispresentedinTable uate different process-labeling models, ensuring\\n6. FortheGemini-seriesmodels,asubtleimprove- its general applicability. Through a comprehen-\\nmentinperformanceisobservedwithafew-shot sive evaluation of existing PRMs and generative\\nsetup. However, for GPT-4o, no significant im- LLMspromptedascriticmodels,wecanobserve\\nprovementisdetected,andinsomecases,alarger thatPRMsexhibitpartialcapabilityinmulti-step\\nfew-shot number even results in a decline in per- process evaluation, showcasing significant room\\nformance. Thesefindingssuggestthatafew-shot for improvement. Furthermore, we highlight the\\napproachexertsonlyasubtleimpactonmodelper- criticalneedfordetectingdetailederrortypesand\\nformanceon PRMBENCH. conducting comprehensive evaluations of PRMs.\\n9Despitetheseadvances,enhancingtherewardac- Zicheng Lin, Zhibin Gou, Tian Liang, Ruilin Luo,\\ncuracyofPRMsandimprovingmodels’reasoning Haowei Liu, and Yujiu Yang. 2024. Criticbench:\\nBenchmarking llms for critique-correct reasoning.\\nabilitiesremainopenresearchchallenges. Ween-\\narXivpreprintarXiv:2402.14809.\\ncouragefutureworktoleverageandexpandupon\\nPRMBENCHtoaddresstheseissues. YantaoLiu,ZijunYao,RuiMin,YixinCao,LeiHou,\\nandJuanziLi.2024. Rm-bench: Benchmarkingre-\\nwardmodelsoflanguagemodelswithsubtletyand\\nstyle. arXivpreprintarXiv:2410.16184.\\nReferences\\nZhenyiLu,ChenghaoFan,WeiWei,XiaoyeQu,Dan-\\nAkari Asai, Jacqueline He*, Rulin Shao*, Weijia\\ngyangChen,andYuCheng.2024a. Twin-merging:\\nShi, Amanpreet Singh, Joseph Chee Chang, Kyle\\nDynamicintegrationofmodularexpertiseinmodel\\nLo, Luca Soldaini, Sergey Feldman, Tian, D’arcy\\nmerging. arXivpreprintarXiv:2406.15479.\\nMike,DavidWadden,MattLatzke,Minyang,PanJi,\\nShengyanLiu,HaoTong,BohaoWu,YanyuXiong,\\nZhenyiLu,JieTian,WeiWei,XiaoyeQu,YuCheng,\\nLukeZettlemoyer,DanWeld,GrahamNeubig,Doug\\nDangyangChen,etal.2024b. Mitigatingboundary\\nDowney,Wen-tauYih,PangWeiKoh,andHannaneh\\nambiguity and inherent bias for text classification\\nHajishirzi. 2024. OpenScholar: Synthesizing sci-\\nintheeraoflargelanguagemodels. arXivpreprint\\nentificliteraturewithretrieval-augmentedlanguage\\nmodels. Arxiv.\\narXiv:2406.07001.\\nHaipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-\\nDeepMind. 2024. Gemini 2.0 flash experimen-\\ntal. https://deepmind.google/technologies/ guangLou,ChongyangTao,XiuboGeng,Qingwei\\ngemini/flash/. Accessed: 2024-12-25. Lin,ShifengChen,andDongmeiZhang.2023. Wiz-\\nardmath: Empoweringmathematicalreasoningfor\\nlarge language models via reinforced evol-instruct.\\nBofei Gao, Zefan Cai, Runxin Xu, Peiyi Wang,\\narXivpreprintarXiv:2308.09583.\\nCe Zheng, Runji Lin, Keming Lu, Junyang Lin,\\nChang Zhou, Wen Xiao, et al. 2024. Llm critics\\nNatMcAleese,RaiMichaelPokorny,JuanFelipeCeron\\nhelp catch bugs in mathematics: Towards a better\\nUribe,EvgeniaNitishinskaya,MajaTrebacz,andJan\\nmathematicalverifierwithnaturallanguagefeedback.\\nLeike.2024. Llmcriticshelpcatchllmbugs. arXiv\\nCoRR.\\npreprintarXiv:2407.00215.\\nOlga Golovneva, Moya Chen, Spencer Poff, Martin\\nSkywork o1 Team. 2024. Skywork-o1 open series.\\nCorredor,LukeZettlemoyer,MaryamFazel-Zarandi, https://huggingface.co/Skywork.\\nand Asli Celikyilmaz. 2022. Roscoe: A suite of\\nmetrics for scoring step-by-step reasoning. arXiv OpenAI. 2024a. Gpt-4o system card. https://\\npreprintarXiv:2212.07919. cdn.openai.com/gpt-4o-system-card.pdf. Ac-\\ncessed: 2024-09-26.\\nDaya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie,\\nKai Dong, Wentao Zhang, Guanting Chen, Xiao\\nOpenAI. 2024b. Learning to reason with\\nBi, Yu Wu, YK Li, et al. 2024. Deepseek-coder: llms. https://openai.com/index/\\nWhenthelargelanguagemodelmeetsprogramming– learning-to-reason-with-llms/.\\nthe rise of code intelligence. arXiv preprint\\narXiv:2401.14196.\\nYiweiQin,XuefengLi,HaoyangZou,YixiuLiu,Shijie\\nXia, Zhen Huang, Yixin Ye, Weizhe Yuan, Hector\\nLeiLi,YuanchengWei,ZhihuiXie,XuqingYang,Yi- Liu,YuanzhiLi,etal.2024. O1replicationjourney:\\nfan Song, Peiyi Wang, Chenxin An, Tianyu Liu, A strategic progress report–part 1. arXiv preprint\\nSujian Li, Bill Yuchen Lin, et al. 2024a. Vlre- arXiv:2410.18982.\\nwardbench: A challenging benchmark for vision-\\nlanguagegenerativerewardmodels. arXivpreprint Zhaochen Su, Juntao Li, Jun Zhang, Tong Zhu, Xi-\\narXiv:2411.17451. aoye Qu, Pan Zhou, Yan Bowen, Yu Cheng, et al.\\n2024a. Livinginthemoment: Canlargelanguage\\nXiaoyuan Li, Wenjie Wang, Moxin Li, Junrong Guo, modelsgraspco-temporalreasoning? arXivpreprint\\nYangZhang,andFuliFeng.2024b. Evaluatingmath- arXiv:2406.09072.\\nematicalreasoningoflargelanguagemodels:Afocus\\nonerroridentificationandcorrection. arXivpreprint ZhaochenSu,ZechengTang,XinyanGuan,LijunWu,\\narXiv:2406.00755. Min Zhang, and Juntao Li. 2022. Improving tem-\\nporal generalization of pre-trained language mod-\\nHunterLightman,VineetKosaraju,YuraBurda,Harri elswithlexicalsemanticchange. InProceedingsof\\nEdwards, Bowen Baker, Teddy Lee, Jan Leike, the2022ConferenceonEmpiricalMethodsinNat-\\nJohn Schulman, Ilya Sutskever, and Karl Cobbe. uralLanguageProcessing,pages6380–6393,Abu\\n2023. Let’s verify step by step. arXiv preprint Dhabi,UnitedArabEmirates.AssociationforCom-\\narXiv:2305.20050. putationalLinguistics.\\n10ZhaochenSu,JunZhang,XiaoyeQu,TongZhu,Yanshu ZhongshenZeng,YinhongLiu,YingjiaWan,JingyaoLi,\\nLi,JiashuoSun,JuntaoLi,MinZhang,andYuCheng. PengguangChen,JianboDai,YuxuanYao,Rongwu\\n2024b. Conflictbank: Abenchmarkforevaluating Xu,ZehanQi,WanruZhao,LinlingShen,Jianqiao\\nthe influence of knowledge conflicts in llm. arXiv Lu,HaochenTan,YukangChen,HaoZhang,Zhan\\npreprintarXiv:2408.12076. Shi,BailinWang,ZhijiangGuo,andJiayaJia.2024b.\\nMr-ben: Ameta-reasoningbenchmarkforevaluating\\nZhaochenSu,JunZhang,TongZhu,XiaoyeQu,Juntao system-2thinkinginllms. CoRR,abs/2406.13975.\\nLi, Min Zhang, and Yu Cheng. 2024c. Timo: To-\\nDiZhang,JingdiLei,JunxianLi,XunzhiWang,Yujie\\nwardsbettertemporalreasoningforlanguagemodels.\\narXivpreprintarXiv:2406.14192. Liu,ZonglinYang,JiatongLi,WeidaWang,Suorong\\nYang,JianboWu,etal.2024a. Critic-v: Vlmcritics\\nhelpcatchvlmerrorsinmultimodalreasoning. arXiv\\nQwenTeam.2024a. Qwq: Reflectdeeplyonthebound-\\npreprintarXiv:2411.18203.\\nariesoftheunknown.\\nDi Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong\\nScalableMath Team. 2024b. Easy-to-hard gen-\\nLi,TongXie,XiaoshuiHuang,ShufeiZhang,Marco\\neralization models. https://huggingface.co/\\nPavone,YuqiangLi,etal.2024b. Llama-berry: Pair-\\nScalableMath.\\nwiseoptimizationforo1-likeolympiad-levelmathe-\\nmaticalreasoning. arXivpreprintarXiv:2410.02884.\\nJonathanUesato,NateKushman,RamanaKumar,Fran-\\ncisSong,NoahSiegel,LisaWang,AntoniaCreswell, Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji\\nGeoffrey Irving, and Irina Higgins. 2022. Solv- Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jin-\\ningmathwordproblemswithprocess-andoutcome- gren Zhou, and Junyang Lin. 2024. Processbench:\\nbasedfeedback. arXivpreprintarXiv:2211.14275. Identifyingprocesserrorsinmathematicalreasoning.\\narXivpreprintarXiv:2412.06559.\\nPeiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai\\nDai, Yifei Li, Deli Chen, Y Wu, and Zhifang Sui. Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu,\\n2023. Math-shepherd: Verify and reinforce llms JindongWang,DerekFWong,XiaoweiHuang,Qi-\\nstep-by-step without human annotations. CoRR, ufeng Wang, and Kaizhu Huang. 2024. Is your\\nabs/2312.08935. modelreallyagoodmathreasoner? evaluatingmath-\\nematical reasoning with checklist. arXiv preprint\\narXiv:2407.08733.\\nShijie Xia, Xuefeng Li, Yixin Liu, Tongshuang Wu,\\nand Pengfei Liu. 2024. Evaluating mathemati-\\ncal reasoning beyond accuracy. arXiv preprint\\narXiv:2404.05692.\\nWeiXiong,HanningZhang,NanJiang,andTongZhang.\\n2024. Animplementationofgenerativeprm. https:\\n//github.com/RLHFlow/RLHF-Reward-Modeling.\\nYiboYan,ShenWang,JiahaoHuo,HangLi,BoyanLi,\\nJiaminSu,XiongGao,Yi-FanZhang,TianlongXu,\\nZhendongChu,etal.2024. Errorradar: Benchmark-\\ningcomplexmathematicalreasoningofmultimodal\\nlarge language models via error detection. arXiv\\npreprintarXiv:2410.04509.\\nLonghui Yu, Weisen Jiang, Han Shi, Jincheng Yu,\\nZhengying Liu, Yu Zhang, James T Kwok, Zhen-\\nguo Li, Adrian Weller, and Weiyang Liu. 2023.\\nMetamath: Bootstrapyourownmathematicalques-\\ntions for large language models. arXiv preprint\\narXiv:2309.12284.\\nZhiyuanZeng,JiatongYu,TianyuGao,YuMeng,Tanya\\nGoyal, and Danqi Chen. 2024a. Evaluating large\\nlanguagemodelsatevaluatinginstructionfollowing.\\nInTheTwelfthInternationalConferenceonLearning\\nRepresentations.\\nZhongshenZeng, PengguangChen, ShuLiu, Haiyun\\nJiang, and Jiaya Jia. 2023. Mr-gsm8k: A meta-\\nreasoningbenchmarkforlargelanguagemodeleval-\\nuation. arXivpreprintarXiv:2312.17080.\\n11A DetaildInformationfor PRMBENCH\\nA.1 EvaluationSubjects\\nIn this section, We provide detailed information\\non our evaluation subjects. The hierarchical cat-\\negories, corresponding descriptions, and illustra-\\ntions are shown in Figure 5. We have 6,216 data\\nsamplesand83,456step-levellabels. Thebench-\\nmarkspreadsacrossthreemainevaluationsubjects:\\nsimplicity,soundness,andsensitivity. Amongthem,\\nSimplicity comprises two sub-categories: Non-\\nredundantandNon-CircularLogic. Soundnessin-\\ncludesfourmainsub-categories: EmpiricalSound,\\nStepConsistency,DomainConsistency,andConfi-\\ndenceInvariant. Finally,Sensitivitymainlyevalu-\\natesmodelsinthreemainparts: PrerequisiteSen-\\nsitivity,DeceptionResistance,andMulti-solution\\nConsistency. Thedescriptionsofeachsub-category\\nareshowninFigure5.\\nB DetailedExperimentResults\\nB.1 AbbreviationOfSub-Categories\\nThefullnamesofabbreviationsusedinourtables\\nareshowninTable7.\\nAbbr. FullName EvaluationSubject\\nNR. Non-Redundancy Simplicity\\nNCL. Non-CircularLogic Simplicity\\nES. EmpiricalSoundness Soundness\\nSC. StepConsistency Soundness\\nDC. DomainConsistency Soundness\\nCI. ConfidenceInvariance Soundness\\nPS. PrerequisiteSensitivity Sensitivity\\nDR. DeceptionResistance Sensitivity\\nMS. Multi-SolutionConsistency Sensitivity\\nTable7: TheimpactofICLfew-shotnumbersonmod-\\nels’ final performance. The number reported here is\\nPRMScore.\\nB.2 DetailedResultsof PRMBENCH\\nInadditiontoPRMScoredisplayedinTable3,we\\nalsolistthefullresultswithdifferentmetricsacross\\ndifferentsub-categorieshere. Thedetailedevalua-\\ntionresultsareshowninTable8-16\\n1213\\nyticilpmiS\\nNon-Redundancy requires the PRM to detect redundant situatoins,\\nthat is, a process that includes one or more redundant steps that can\\nNon-Redundancy\\nbe removed without affecting the correctness of the overall\\nsolution.\\nNon-Circular Logic\\nEmpirical\\nSoundness\\nStep Consistency\\nDomain Consistency\\nConfidence Invariance\\nPrerequisite Sensitivity\\nDeception Resistance\\nMulti-Solution\\nConsistency\\nssendnuoS\\nytivitisneS\\nA C B\\nCircular logic is a specific form of redundancy, characterized by a\\nreasoning chain that starts at a step , progresses through a\\nsequence of steps, and ultimately loops back to .\\nEmpirical Soundness requires the prm to detect a counterfactual A A\\' B\\nstep, concretly, a statement within a reasoning chain that contradicts\\nestablished ground truth. G\\nStep Consistency requires the PRM to detect a conflict between a A B C\\nspecific step and other steps within a reasoning path.\\nDomain Consistency requires the PRM to maintain robust when\\nA A faced with a step that uses a statement or theory valid in other\\ndomains or cases but is not valid within the current reasoning\\nscene. B B\\nConfidence Invariance requires the PRM to maintain invariant\\nwhen faced with a statement within the reasoning chain that\\ncontradicts established ground truth and is presented with an overly\\nconfident tone.\\nPrerequisite Sensitivity requires the PRM to detect the flaw in the\\nreasoning chain where critical premises, assumptions, or necessary\\nconditions are absent and the absense would cause errors.\\nDeception Resistance requires the PRM to detect statements that\\nappear to be correct or align with ground truth but are subtly altered\\nto introduce inaccuracies while maintaining the illusion of\\ncorrectness.\\nMulti-Solution Consistency requires the PRM to maintain\\nconsistent when faced with different solution paths of the same\\nproblem.\\nA\\nniamoD\\nDomain\\nB\\nA B C\\nConfident\\nA\\nB C\\n?\\nM\\nA A\\nB B\\'\\ntcerroC yroehT\\nDeception\\nCategories Descriptions Illustration\\nC A B\\nB C\\nA D\\nB\\' C\\'\\nFigure5: Examplesofanin-depthevaluationofPRMBench.14\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 31.7 37.7 25.7 32.3 24.1 79.4 74.7 76.3\\nSkywork-PRM-7B 36.2 45.1 27.4 37.5 30.1 79.7 76.6 74.3\\nLlemma-PRM800k-7B 52.0 75.7 28.3 63.7 66.4 48.5 22.2 79.5\\nLlemma-MetaMath-7B 50.5 80.4 20.7 68.5 75.6 27.7 15.1 84.2\\nLlemma-oprm-7B 50.3 77.3 23.3 64.9 69.9 36.1 16.6 83.7\\nMATHMinos-Mistral-7B 54.2 79.2 29.1 67.9 72.8 41.7 38.0 84.6\\nMathShepherd-Mistral-7B 47.0 64.9 29.2 53.0 51.5 61.1 54.6 83.5\\nReasonEval-7B 60.0 90.8 29.2 83.8 95.5 21.2 30.3 91.6\\nRLHFlow-PRM-Mistral-8B 54.4 87.7 21.1 78.8 90.2 17.9 22.1 92.8\\nRLHFlow-PRM-Deepseek-8B 54.2 89.9 18.6 82.0 95.0 13.0 17.0 95.0\\nReasonEval-34B 60.5 83.8 37.2 74.2 79.1 48.4 50.8 82.8\\nAvg. 50.1 73.9 26.3 64.2 68.2 43.2 38.0 84.4\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 66.8 86.9 46.7 79.0 82.9 58.2 64.4 76.6\\no1-mini† 68.8 89.2 48.3 82.1 86.9 55.4 56.4 80.4\\nGemini-2.0-flash-exp 66.0 86.5 45.5 78.4 82.3 57.2 64.3 80.0\\nGemini-2.0-thinking-exp-1219 68.8 89.7 47.8 82.8 89.0 49.8 57.0 82.0\\nAvg. 67.6 88.1 47.1 80.6 85.3 55.2 60.5 79.7\\nTable8: AperformancecomparisonofpopularmodelsacrossdetailedmetricsinALLcategoriesofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 31.4 43.7 19.1 33.6 29.4 62.6 59.1 92.2\\nSkywork-PRM-7B 35.7 52.6 18.8 40.2 38.0 55.5 52.5 94.1\\nLlemma-PRM800k-7B 49.3 77.7 20.9 65.2 69.2 36.9 20.5 86.4\\nLlemma-MetaMath-7B 50.2 85.3 15.0 75.0 83.2 17.6 15.3 94.4\\nLlemma-oprm-7B 48.7 80.3 17.2 68.1 74.1 26.5 16.0 92.0\\nMATHMinos-Mistral-7B 48.8 82.7 14.9 71.2 79.2 19.0 20.8 95.7\\nMathShepherd-Mistral-7B 44.0 67.7 20.2 54.0 55.6 43.7 39.7 93.8\\nReasonEval-7B 61.0 91.5 30.5 84.8 94.0 25.0 32.8 89.8\\nRLHFlow-PRM-Mistral-8B 46.1 89.1 3.2 80.3 92.3 2.4 3.4 98.5\\nRLHFlow-PRM-Deepseek-8B 46.4 91.0 1.9 83.5 96.1 1.2 1.5 99.0\\nReasonEval-34B 54.8 86.7 22.9 77.4 85.3 25.3 31.6 83.8\\nAvg. 46.9 77.1 16.8 66.7 72.4 28.7 26.7 92.7\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 57.0 77.8 36.3 67.0 66.5 70.4 77.1 68.9\\no1-mini† 65.6 90.8 40.4 84.1 90.4 41.5 45.8 84.1\\nGemini-2.0-flash-exp 67.2 91.5 42.9 85.1 91.8 41.7 49.7 82.4\\nGemini-2.0-thinking-exp-1219 68.5 91.4 45.6 85.1 90.9 47.1 56.5 84.7\\nAvg. 64.6 87.9 41.3 80.4 84.9 50.2 57.3 80.0\\nTable9: AperformancecomparisonofpopularmodelsacrossdetailedmetricsinNR.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.15\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 35.8 34.7 36.9 35.8 22.7 75.2 71.4 72.9\\nSkywork-PRM-7B 41.2 44.2 38.1 41.3 30.9 72.6 71.6 73.5\\nLlemma-PRM800k-7B 53.4 65.5 41.3 56.6 54.9 61.4 15.7 65.6\\nLlemma-MetaMath-7B 50.5 70.8 30.3 58.8 66.4 36.0 15.7 74.8\\nLlemma-oprm-7B 49.3 66.3 32.2 55.0 59.0 42.9 10.2 73.3\\nMATHMinos-Mistral-7B 54.0 70.8 37.2 60.2 66.6 43.2 40.6 79.1\\nMathShepherd-Mistral-7B 50.3 60.4 40.2 52.3 49.9 58.6 50.3 79.0\\nReasonEval-7B 50.1 80.8 19.4 69.0 89.8 13.6 19.0 88.1\\nRLHFlow-PRM-Mistral-8B 47.3 79.8 14.9 67.3 88.7 10.5 18.9 93.7\\nRLHFlow-PRM-Deepseek-8B 48.9 82.3 15.4 70.7 93.6 9.8 15.6 94.6\\nReasonEval-34B 48.1 76.7 19.5 63.9 81.9 16.0 19.9 83.4\\nAvg. 48.1 66.6 29.6 57.4 64.0 40.0 31.7 79.8\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 62.4 73.5 51.3 65.6 65.4 66.2 80.6 59.9\\no1-mini† 63.7 80.4 47.0 71.4 80.6 46.6 47.9 -\\nGemini-2.0-flash-exp 58.1 81.8 34.5 71.5 88.1 27.4 34.7 79.4\\nGemini-2.0-thinking-exp-1219 63.8 81.2 46.4 72.2 82.8 44.0 54.8 74.6\\nAvg. 62.0 79.2 44.8 70.2 79.2 46.1 54.5 71.3\\nTable10: AperformancecomparisonofpopularmodelsacrossdetailedmetricsinNCL.sub-categoryofPRM-\\nBENCH. The best performance for each metric is highlighted in bold, while the second-best performance is\\nunderlined. †: Toreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 32.4 32.9 32.0 32.4 20.3 85.4 76.4 72.2\\nSkywork-PRM-7B 36.7 39.1 34.4 36.8 24.9 88.9 82.5 67.6\\nLlemma-PRM800k-7B 56.4 76.8 36.1 65.9 69.2 51.7 20.0 81.2\\nLlemma-MetaMath-7B 51.9 78.0 25.8 66.0 73.9 31.7 15.4 83.3\\nLlemma-oprm-7B 54.2 77.3 31.1 65.9 71.4 41.6 15.6 83.5\\nMATHMinos-Mistral-7B 57.0 77.3 36.7 66.6 71.1 48.6 39.7 82.0\\nMathShepherd-Mistral-7B 49.4 62.4 36.4 52.7 48.9 68.0 58.0 81.6\\nReasonEval-7B 62.1 89.7 34.6 82.2 96.6 23.7 37.4 91.2\\nRLHFlow-PRM-Mistral-8B 56.6 85.8 27.4 76.2 89.6 22.5 24.5 90.5\\nRLHFlow-PRM-Deepseek-8B 55.7 87.8 23.5 79.0 94.6 16.2 21.4 93.5\\nReasonEval-34B 66.4 83.3 49.4 74.9 78.1 61.9 61.1 81.5\\nAvg. 52.6 71.8 33.4 63.5 67.1 49.1 41.1 82.6\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 72.0 88.9 55.2 82.2 88.8 55.4 63.2 78.7\\no1-mini† 74.5 88.9 60.0 82.7 85.6 69.8 75.0 -\\nGemini-2.0-flash-exp 70.4 85.3 55.4 77.9 80.0 69.4 76.3 77.1\\nGemini-2.0-thinking-exp-1219 72.9 89.4 56.4 83.0 89.8 55.5 64.8 79.5\\nAvg. 72.4 88.1 56.7 81.4 86.0 62.5 69.8 78.4\\nTable11:AperformancecomparisonofpopularmodelsacrossdetailedmetricsinES.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.16\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 25.7 32.0 19.3 26.2 19.4 84.8 80.4 73.6\\nSkywork-PRM-7B 29.1 37.0 21.2 30.0 23.0 90.3 87.3 68.8\\nLlemma-PRM800k-7B 47.1 75.2 18.9 62.1 64.3 42.5 24.1 80.5\\nLlemma-MetaMath-7B 47.6 81.3 13.9 69.2 74.5 23.9 15.5 85.0\\nLlemma-oprm-7B 46.8 77.6 16.1 64.6 68.3 32.6 16.8 83.4\\nMATHMinos-Mistral-7B 52.1 80.7 23.5 69.2 72.6 42.4 39.4 85.5\\nMathShepherd-Mistral-7B 44.5 64.9 24.2 52.0 49.9 68.6 63.0 81.9\\nReasonEval-7B 65.9 94.1 37.7 89.2 96.7 29.4 40.1 92.3\\nRLHFlow-PRM-Mistral-8B 55.1 90.0 20.2 82.2 90.0 20.1 22.9 92.3\\nRLHFlow-PRM-Deepseek-8B 55.0 92.4 17.7 86.1 95.2 13.4 16.6 95.1\\nReasonEval-34B 60.3 83.7 36.9 74.1 74.8 68.2 70.6 81.5\\nAvg. 48.1 73.5 22.7 64.1 66.3 46.9 43.3 83.6\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 69.7 89.9 49.6 83.1 84.3 74.3 76.9 76.3\\no1-mini† 67.7 89.7 45.7 82.7 84.4 68.6 70.8 74.2\\nGemini-2.0-flash-exp 65.7 86.0 45.4 77.7 77.0 83.1 85.6 77.3\\nGemini-2.0-thinking-exp-1219 71.3 91.4 51.2 85.4 87.6 68.5 72.8 81.0\\nAvg. 68.6 89.3 48.0 82.3 83.3 73.6 76.5 77.2\\nTable12:AperformancecomparisonofpopularmodelsacrossdetailedmetricsinSC.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 26.0 31.1 20.8 26.3 19.0 78.0 72.1 73.1\\nSkywork-PRM-7B 30.6 37.6 23.7 31.3 23.6 85.5 80.6 68.2\\nLlemma-PRM800k-7B 46.7 71.6 21.9 58.3 59.9 47.1 20.5 74.3\\nLlemma-MetaMath-7B 44.4 76.0 12.9 62.3 68.0 22.5 12.9 79.1\\nLlemma-oprm-7B 44.5 73.4 15.6 59.6 63.8 30.2 13.6 79.4\\nMATHMinos-Mistral-7B 50.7 76.1 25.3 63.8 66.6 45.8 39.0 80.6\\nMathShepherd-Mistral-7B 41.3 59.2 23.3 46.7 44.6 60.5 52.2 79.8\\nReasonEval-7B 61.5 92.1 30.9 85.8 95.3 23.8 30.5 91.2\\nRLHFlow-PRM-Mistral-8B 54.4 87.8 21.0 78.9 87.8 20.9 18.8 90.4\\nRLHFlow-PRM-Deepseek-8B 53.2 90.4 15.9 82.8 93.7 12.2 11.6 94.2\\nReasonEval-34B 57.8 80.3 35.3 69.7 71.0 61.9 57.9 77.5\\nAvg. 46.5 70.5 22.4 60.5 63.0 44.4 37.2 80.7\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 70.7 88.2 53.3 81.2 81.3 80.4 81.4 71.4\\no1-mini† 73.8 92.2 55.5 86.7 87.7 77.8 74.5 80.0\\nGemini-2.0-flash-exp 66.0 83.6 48.4 75.1 73.2 87.5 87.3 70.8\\nGemini-2.0-thinking-exp-1219 71.0 88.8 53.2 81.9 82.6 77.2 79.2 73.7\\nAvg. 70.4 88.2 52.6 81.2 81.2 80.7 80.6 74.0\\nTable13:AperformancecomparisonofpopularmodelsacrossdetailedmetricsinDC.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.17\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 30.2 37.7 22.7 31.0 23.5 88.2 85.5 81.1\\nSkywork-PRM-7B 34.4 44.4 24.4 35.9 28.9 90.4 87.7 77.4\\nLlemma-PRM800k-7B 53.3 79.9 26.6 68.5 70.9 50.0 29.4 86.2\\nLlemma-MetaMath-7B 52.1 83.7 20.4 73.0 78.5 30.3 15.6 88.9\\nLlemma-oprm-7B 53.5 81.7 25.4 70.6 74.0 43.8 27.2 89.0\\nMATHMinos-Mistral-7B 57.8 82.5 33.1 72.3 74.5 56.3 53.8 87.3\\nMathShepherd-Mistral-7B 47.7 66.6 28.7 54.5 51.7 75.1 72.2 87.3\\nReasonEval-7B 66.0 93.7 38.2 88.6 96.9 28.9 40.3 93.0\\nRLHFlow-PRM-Mistral-8B 63.8 91.0 36.7 84.2 90.7 37.5 45.0 90.9\\nRLHFlow-PRM-Deepseek-8B 66.2 93.0 39.5 87.5 94.9 33.5 43.3 92.1\\nReasonEval-34B 67.5 87.7 47.2 80.1 81.0 73.3 73.3 86.9\\nAvg. 53.9 76.5 31.2 67.8 69.6 55.2 52.1 87.3\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 71.1 92.1 50.2 86.3 90.4 56.5 60.4 85.2\\no1-mini† 72.3 91.6 53.1 85.7 87.3 72.7 75.0 80.1\\nGemini-2.0-flash-exp 67.3 88.3 46.4 80.8 82.4 68.8 76.0 84.9\\nGemini-2.0-thinking-exp-1219 71.8 92.6 51.1 87.1 91.4 55.8 60.5 86.1\\nAvg. 70.7 91.1 50.2 85.0 87.9 63.5 68.0 84.1\\nTable14: AperformancecomparisonofpopularmodelsacrossdetailedmetricsinCI.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 33.1 36.2 30.1 33.3 23.2 78.4 73.9 70.2\\nSkywork-PRM-7B 36.8 42.9 30.8 37.4 28.8 76.0 72.8 70.2\\nLlemma-PRM800k-7B 51.0 71.7 30.3 59.7 62.3 47.9 24.4 75.0\\nLlemma-MetaMath-7B 50.5 78.7 22.4 66.5 75.5 26.5 15.6 82.8\\nLlemma-oprm-7B 49.2 74.4 24.1 61.7 68.0 33.4 16.1 81.2\\nMATHMinos-Mistral-7B 52.8 77.5 28.0 65.7 73.3 34.2 29.5 83.1\\nMathShepherd-Mistral-7B 47.2 63.6 30.9 52.3 51.8 54.5 45.0 81.4\\nReasonEval-7B 55.6 88.4 22.9 79.8 95.4 15.4 17.3 92.8\\nRLHFlow-PRM-Mistral-8B 51.5 85.3 17.6 75.0 89.9 13.7 16.2 93.1\\nRLHFlow-PRM-Deepseek-8B 49.0 87.0 10.9 77.4 94.4 7.1 6.7 95.9\\nReasonEval-34B 57.7 80.5 35.0 70.0 76.8 41.6 35.2 82.6\\nAvg. 48.6 71.5 25.7 61.7 67.2 39.0 32.1 82.6\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 62.5 86.8 38.3 78.2 88.8 34.7 33.3 83.8\\no1-mini† 61.8 84.9 38.7 75.7 88.6 33.1 18.8 -\\nGemini-2.0-flash-exp 61.8 83.2 40.4 73.8 80.5 45.7 44.2 81.4\\nGemini-2.0-thinking-exp-1219 60.3 87.1 33.5 78.4 90.5 28.0 27.0 87.0\\nAvg. 61.6 85.5 37.7 76.5 87.1 35.4 30.8 84.1\\nTable15:AperformancecomparisonofpopularmodelsacrossdetailedmetricsinPS.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.18\\nModelName PRMScore F1 NegativeF1 Acc PositiveAcc NegativeAcc First similarity\\nOpen-sourceProcessLevelRewardModels\\nSkywork-PRM-1.5B 32.3 36.3 28.2 32.5 22.8 84.0 79.1 74.5\\nSkywork-PRM-7B 37.4 44.9 29.9 38.3 29.8 83.3 77.8 73.3\\nLlemma-PRM800k-7B 53.5 77.8 29.1 66.2 70.4 43.8 23.1 85.1\\nLlemma-MetaMath-7B 51.3 80.6 22.1 68.9 76.6 27.9 15.1 85.6\\nLlemma-oprm-7B 51.3 78.4 24.1 66.4 72.5 33.8 17.2 86.6\\nMATHMinos-Mistral-7B 55.8 79.1 32.4 68.1 72.8 45.2 41.4 83.7\\nMathShepherd-Mistral-7B 48.6 65.6 31.7 54.2 52.5 62.8 57.1 84.0\\nReasonEval-7B 58.0 90.6 25.4 83.2 96.7 16.9 24.6 93.8\\nRLHFlow-PRM-Mistral-8B 56.2 87.5 24.9 78.6 90.3 21.0 27.1 92.2\\nRLHFlow-PRM-Deepseek-8B 55.4 89.5 21.4 81.5 95.1 14.9 19.4 95.0\\nReasonEval-34B 64.3 84.4 44.3 75.6 79.4 57.3 56.8 83.6\\nAvg. 51.3 74.1 28.5 64.9 69.0 44.6 39.9 85.2\\nProprietaryLLMs,PromptedasCriticModels\\nGPT-4o 65.7 89.2 42.2 81.8 90.5 39.3 41.3 84.8\\no1-mini† 64.8 86.7 42.9 78.4 84.5 48.2 43.8 -\\nGemini-2.0-flash-exp 66.2 86.3 46.1 78.1 82.7 55.5 60.2 83.4\\nGemini-2.0-thinking-exp-1219 65.7 89.7 41.8 82.5 91.8 37.0 40.2 86.4\\nAvg. 65.6 88.0 43.2 80.2 87.4 45.0 46.4 84.9\\nTable16:AperformancecomparisonofpopularmodelsacrossdetailedmetricsinDR.sub-categoryofPRMBENCH.\\nThebestperformanceforeachmetricishighlightedinbold,whilethesecond-bestperformanceisunderlined. †: To\\nreducecosts,weevaluatedonlyasubsetof394samplesfortheo1seriesmodels.C ExamplesForDifferentEvaluationSubjects\\nInthissection,weprovidedetailedexamplesofthevariousevaluationsubjectsandtheircorresponding\\nsub-categories. TheabbreviationsusedarelistedinTable7.\\nC.1 Example for NR. category\\n1. OriginalProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\nStep 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Nowwejusthavetosolvetheequationx=1000000*0.00125.\\nStep5: Sox=1250.\\nStep6: That’sthefinalanswer.\\nStep7: Right. So1,000,000lireisequivalentto$1250.\\n2. ModifiedProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\nStep 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Butlet’sconfirmthecomputationagain: 1.50 = 0.00125.\\n1200\\nStep5: Nowwejusthavetosolvetheequationx=1000000*0.00125.\\nStep6: Sox=1250.\\nStep7: Let’sdouble-checkbyperformingthemultiplicationagain: 1000000*0.00125=1250.\\nStep8: That’sthefinalanswer.\\nStep9: Right. So1,000,000lireisequivalentto$1250.\\n3. Reason\\nStep 4 unnecessarily repeats the computation of 1.50, which was already completed in Step 7\\n1200\\nredundantlyre-checksthemultiplication,addingnonewinformation. Theseredundantstepsmake\\nthereasoningprocesslessconcisewithoutaffectingcorrectness.\\nC.2 Example for NCL. category\\n1. OriginalProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nStep1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Ok. Wecanusethequadraticformulatofindx.\\n19√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a\\nStep4: Yes,that’scorrect. Inthiscasea,b,andcare1,-1,and-1,respectively.\\n√\\nStep5: Soifweplugthosevaluesin,wegetx = 1± 12−4∗1∗−1.\\n√ 2∗1√ √\\nStep6: Thatsimplifiestox = 1± 5. Soxcanbeeither 1+ 5 or 1− 5.\\n2 2 2\\nStep7: Nowlet’smovetothesecondequation.\\nStep8: Yes,weneedtofindx3−2x+1.\\nStep 9: Right. Well since we now know that x2 −x−1 = 0, we can replace x2 in the second\\nequationwithx+1.\\nStep10: Thatmeansthatx3−2x+1 = x(x+1)−2x+1.\\nStep 11: And if we substitute in the possible values of x that we found earlier, we get either\\n√ √ √ √ √ √\\n1+ 5(1+ 5 +1)−21+ 5 +1or 1− 5(1− 5 +1)−21− 5 +1.\\n2 2 2 2 √2 √ 2 √\\nStep12: Let’sstartwiththefirstcase: 1+ 5(1+ 5 +1)−21+ 5 +1.\\n2 2 2\\nStep13: There’sashorterway. Wehavex3−2x+1 = x(x+1)−2x+1.\\nStep14: x3−2x+1 = (x2+x)−2x+1.\\nStep15: Andweknowthatx2−x−1 = 0,sox2 = x+1.\\nStep16: Sowecanjustsubstitutex+1forx2.\\nStep17: Sox3−2x+1 = (x2+x)−2x+1becomesx3−2x+1 = (x+1+x)−2x+1.\\nStep18: Andthatsimplifiestox3−2x+1 = (2x+1)−2x+1.\\nStep19: Sox3−2x+1 = 2.\\nStep20: So,wedon’tneedtodothesecondcasebecausewealreadyhavetheanswer.\\nStep21: Right. Soifx2−x−1 = 0thenx3−2x+1 = 2.\\n2. ModifiedProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nStep1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Ok. Wecanusethequadraticformulatofindx.\\n√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a\\nStep4: Yes,that’scorrect. Inthiscasea,b,andcare1,-1,and-1,respectively.\\n√\\nStep5: Soifweplugthosevaluesin,wegetx = 1± 12−4∗1∗−1.\\n√ 2∗1√ √\\nStep6: Thatsimplifiestox = 1± 5. Soxcanbeeither 1+ 5 or 1− 5.\\n2 2 2\\nStep7: Nowlet’smovetothesecondequation.\\nStep8: Assumex3−2x+1 = 2forverification.\\nStep9: Substitutingx3−2x+1 = 2intotheequation,itimpliesx(x2)−2x+1 = 2.\\nStep10: Sincex2 = x+1,x(x+1)−2x+1 = 2.\\nStep11: Simplifyingconfirmsx3−2x+1 = 2,verifyingtheassumption.\\nStep12: Therefore,x3−2x+1 = 2iscorrect.\\n3. Reason\\nSteps 8 and 9 assume the result (x3 −2x+1 = 2) before deriving it, and step 11 uses circular\\nlogic to verify the assumption by substituting it back into the equation. This process does not\\nindependentlysolvetheproblemandcreatesaflawedreasoningchain.\\nC.3 Example for ES. category\\n1. OriginalProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\n20Step 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Nowwejusthavetosolvetheequationx = 1000000∗0.00125.\\nStep5: Sox=1250.\\nStep6: That’sthefinalanswer.\\nStep7: Right. So1,000,000lireisequivalentto$1250.\\n2. ModifiedProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\nStep 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx = 1000000∗ 1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Nowwejusthavetosolvetheequationx = 1000000∗0.00125.\\nStep5: Sox=1250.\\nStep6: Butwait,weneedtoaccountfortransactionfeesthataddanadditional10%.\\nStep7: Sox = 1250+0.10∗1250.\\nStep8: Thatgivesx=1375.\\nStep9: Right. So1,000,000lireisequivalentto$1375.\\n3. Reason\\nAcounterfactualstepwasintroducedinstep6byclaimingtheneedtoaccountforanadditional\\n10%transactionfee,whichisnotmentionedintheproblem. Thiserroneousassumptionleadsto\\ntheincorrectresultof$1375insteadof$1250.\\nC.4 Example for SC. category\\n1. OriginalProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nStep1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Wecanusethequadraticformulatofindx.\\n√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a √\\nStep4: Substitutinga = 1,b = −1,andc = −1,wegetx = 1± 5.\\n2\\nStep5: Sincex2−x−1 = 0,wereplacex2 withx+1inx3−2x+1.\\nStep6: Substituting,x3−2x+1 = x(x+1)−2x+1.\\nStep7: Simplify: x3−2x+1 = (x2+x)−2x+1.\\nStep8: Substitutex2 = x+1 : x3−2x+1 = (x+1+x)−2x+1.\\nStep9: Simplify: x3−2x+1 = 2.\\n2. ModifiedProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\n21Step1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Wecanusethequadraticformulatofindx.\\n√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a √\\nStep4: Substitutinga = 1,b = −1,andc = −1,wegetx = 1± 5.\\n2\\nStep5: Sincex2−x−1 = 0,wereplacex2 withx+1inx3−2x+1.\\nStep6: Substituting,x3−2x+1 = x(x+1)−2x+1.\\nStep7: Simplify: x3−2x+1 = (x2+x)−2x+1.\\nStep8: Incorrectlysubstitutex2 = x−1insteadofx+1: x3−2x+1 = (x−1+x)−2x+1.\\nStep9: Simplify: x3−2x+1 = 0.\\n3. Reason\\nStep8introducesastepcontradictionbyincorrectlysubstitutingx2 = x−1insteadofthecorrect\\nx2 = x+1. Thisconflictswiththeearlierderivationfromx2−x−1 = 0,wherex2 = x+1. As\\naresult,thefinalanswerbecomes0insteadofthecorrectvalue,2.\\nC.5 Example for DC. category\\n1. OriginalProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nStep1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Wecanusethequadraticformulatofindx.\\n√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a √\\nStep4: Substitutinga = 1,b = −1,andc = −1,wegetx = 1± 5.\\n2\\nStep5: Sincex2−x−1 = 0,wereplacex2 withx+1inx3−2x+1.\\nStep6: Substituting,x3−2x+1 = x(x+1)−2x+1.\\nStep7: Simplify: x3−2x+1 = (x2+x)−2x+1.\\nStep8: Substitutex2 = x+1: x3−2x+1 = (x+1+x)−2x+1.\\nStep9: Simplify: x3−2x+1 = 2.\\n2. ModifiedProcess\\nQuestion: Ifx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nStep1: Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2: Wecanusethequadraticformulatofindx.\\n√\\nStep3: Thequadraticformulaisx = −b± b2−4ac.\\n2a √\\nStep4: Substitutinga = 1,b = −1,andc = −1,wegetx = 1± 5.\\n2\\nStep5: Sincex2−x−1 = 0,wereplacex2 withx+1inx3−2x+1.\\nStep6: Substituting,x3−2x+1 = x(x+1)−2x+1.\\n√\\nStep7: Tosimplifyx3,usethepropertyofcubicroots: x3 = 3 x.\\n√ √\\nStep8: Substitutex3 = 3 xandx2 = x+1intox3−2x+1: x3−2x+1 = 3 x−2x+1.\\n√\\nStep9: Simplifyfurther: x3−2x+1 = 3 x−x+1.\\n3. Reason\\n√\\nA domain inconsistency was introduced in Step 7 by incorrectly assuming that x3 = 3 x. This\\nassumptionisvalidforroot-basedequationsbutnotinthecontextofsolvingapolynomialequation.\\nThiserrorpropagatesthroughtherestofthereasoning,leadingtoaflawedsolution.\\nC.6 Example for CI. category\\n221. OriginalProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\nStep 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Nowwejusthavetosolvetheequationx = 1000000∗0.00125.\\nStep5: Sox=1250.\\nStep6: That’sthefinalanswer.\\nStep7: Right. So1,000,000lireisequivalentto$1250.\\n2. ModifiedProcess\\nQuestion: In1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelato\\nwouldhavecost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,\\nhowmanydollarswouldbeequivalentto1,000,000lire?\\nStep 1: Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2: Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3: Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4: That’strue. Nowwejusthavetosolvetheequationx=1000000*0.00125.\\nStep5: Sox=1250.\\nStep6: That’sthefinalanswer.\\nStep 7: Actually, after a closer look, x = 0.00125 × 1000000 should be 12500. I must have\\nmiscalculatedearlier.\\nStep8: So1,000,000lireisequivalentto$12500.\\n3. Reason\\nStep7introducesaconfidenthallucination. Itcontradictsthecorrectvalueof1250byrecalculating\\nand asserting that the result is 12500, which is false. This error is presented with unwarranted\\ncertaintytosimulateconfidentmisjudgment.\\nC.7 Example for PS. category\\n1. OriginalProcess\\nQuestion: Findallvaluesofxsuchthat|x−3| = 5.\\nStep1: Startwiththeequation|x−3| = 5.\\nStep2: Recognizethattheabsolutevalueequation|a| = bimpliestwocases: a = bora = −b.\\nStep3: Applythisruleto|x−3| = 5,resultingintwoequations: x−3 = 5orx−3 = −5.\\nStep4: Solveeachequation: x = 8fromx−3 = 5andx = −2fromx−3 = −5.\\nStep5: Thesolutionsarex = 8andx = −2.\\n232. ModifiedProcess\\n√\\nQuestion: Findallvaluesofxsuchthat( x−3)2 = 5.\\n√\\nStep1: ( x−3)2 = 5canberepresentedasaspecialformof|x−3| = 5.\\nStep2: Startwiththeequation|x−3| = 5.\\nStep3: Recognizethattheabsolutevalueequation|a| = bimpliestwocases: a = bora = −b.\\nStep4: Applythisruleto|x−3| = 5,resultingintwoequations: x−3 = 5orx−3 = −5.\\nStep5: Solveeachequation: x = 8fromx−3 = 5andx = −2fromx−3 = −5.\\nStep6: Thesolutionsarex = 8andx = −2.\\n3. Reason\\nThefirststepintroducesamissingconditionbychangingtheequationto|x−3| = 5,whichignores\\ntheimplicitrequirementthatx−3mustbenon-negative. Thefinalstepincorrectlyassertsthatthe\\nsolutionsarex = 8andx = −2withoutconsideringthedomainrestriction.\\nC.7 Example for PS. category\\n1. OriginalProcess\\nQuestion: Given that F(r) = (f(r),g(r),h(r)) is a three-dimensional vector, prove that:\\n∀r ,r ,∃r < r∗ < r suchthatF(r )−F(r ) = (r −r )∇F(r∗).\\n1 2 1 2 1 2 1 2\\nStep 1: Understanding the Given Information and Problem We have a vector function F(r) =\\n(f(r),g(r),h(r)),wheref,g,andharereal-valuedfunctionsoftherealvariabler. Weneedto\\nprovethatforanyr ,r ,thereexistsanr∗ suchthatr < r∗ < r and\\n1 2 1 2\\nF(r )−F(r ) = (r −r )∇F(r∗),\\n1 2 1 2\\nwhere∇F(r∗)denotesthegradientofFatr∗ (i.e.,avectorcomposedofthederivativesofeach\\ncomponentwithrespecttor).\\nStep2: BreakingDowntheProblemintoComponentsExpressthevectorequationintermsofits\\ncomponents:\\n(f(r )−f(r ),g(r )−g(r ),h(r )−h(r )) = (r −r )(f′(r∗),g′(r∗),h′(r∗)).\\n1 2 1 2 1 2 1 2\\nThus,weneedtofindanr∗ ∈ (r ,r )suchthatforeachcomponent:\\n1 2\\nf(r )−f(r ) g(r )−g(r ) h(r )−h(r )\\n1 2 = f′(r∗), 1 2 = g′(r∗), 1 2 = h′(r∗).\\nr −r r −r r −r\\n1 2 1 2 1 2\\nStep 3: Considering the Application of the One-Dimensional Mean Value Theorem In one di-\\nmension, the Mean Value Theorem (MVT) states that for a function f continuous on [a,b] and\\ndifferentiableon(a,b),thereexistsc ∈ (a,b)suchthat:\\nf(b)−f(a) = f′(c)(b−a).\\nApplyingtheMVTtoeachcomponentfunctionf,g,andh,weobtaincorrespondingpointsc ,\\nf\\nc , and c . However, these points generally differ (c ̸= c ̸= c ), so we cannot guarantee the\\ng h f g h\\nexistenceofacommonr∗ whereallcomponentequationsholdsimultaneously.\\nStep 4: Considering a Counterexample Since we cannot guarantee a common r∗ satisfying all\\ncomponents, let’s attempt to find a specific counterexample to demonstrate that the original\\npropositionmaynothold.\\nStep 5: Trying the Function F(r) = (sinr,cosr,r) Let F(r) = (sinr,cosr,r). Choose two\\ndistinctrealnumbers,forexample,r = 0andr = π.\\n1 2\\n24Step6: ComputeF(r )−F(r ):\\n1 2\\nF(0)−F(π) = (sin0−sinπ, cos0−cosπ,0−π) = (0−0,1−(−1), −π) = (0,2, −π).\\nStep7: Compute(r −r )∇F(r∗):\\n1 2\\n(r −r )(cosr∗, −sinr∗,1) = (0−π)(cosr∗, −sinr∗,1) = (−π)(cosr∗, −sinr∗,1).\\n1 2\\nStep8: Weneedtofindr∗ ∈ (0,π)suchthat:\\n(0,2, −π) = (−πcosr∗,πsinr∗, −π).\\nStep9: Thisleadstotheequations:\\n−πcosr∗ = 0, πsinr∗ = 2, −π = −π.\\nStep10: Thethirdequationisalwaystrue. Simplifyingthefirsttwoequations: From−πcosr∗ = 0:\\ncosr∗ = 0.\\nStep11: Fromπsinr∗ = 2:\\n2\\nsinr∗ = .\\nπ\\nStep12: However,cosr∗ = 0impliesr∗ = π. Substitutingr∗ = π intothesecondequation:\\n2 2\\n(cid:16)π(cid:17) 2\\nsin = 1 ̸= .\\n2 π\\nStep 13: Since 2 ≈ 0.6366, the equality does not hold. Therefore, there is no r∗ in (0,π) that\\nπ\\nsatisfiesbothequationssimultaneously.\\nStep14: TheabovecalculationsshowthatforthefunctionF(r) = (sinr,cosr,r),theredoesnot\\nexistanr∗ ∈ (r ,r )suchthat:\\n1 2\\nF(r )−F(r ) = (r −r )∇F(r∗).\\n1 2 1 2\\n2. ModifiedProcess\\nQuestion: Given that F(r) = (f(r),g(r),h(r)) is a three-dimensional vector, prove that:\\n∀r ,r ,∃r < r∗ < r suchthatF(r )−F(r ) = (r −r )∇F(r∗).\\n1 2 1 2 1 2 1 2\\nStep 1: Understanding the Given Information and Problem We have a vector function F(r) =\\n(f(r),g(r),h(r)),wheref,g,andharereal-valuedfunctionsoftherealvariabler. Weneedto\\nprovethatforanyr ,r ,thereexistsanr∗ suchthatr < r∗ < r and\\n1 2 1 2\\nF(r )−F(r ) = (r −r )∇F(r∗),\\n1 2 1 2\\nwhere∇F(r∗)denotesthegradientofFatr∗ (i.e.,avectorcomposedofthederivativesofeach\\ncomponentwithrespecttor).\\nStep2: BreakingDowntheProblemintoComponentsExpressthevectorequationintermsofits\\ncomponents:\\n(f(r )−f(r ),g(r )−g(r ),h(r )−h(r )) = (r −r )(f′(r∗),g′(r∗),h′(r∗)).\\n1 2 1 2 1 2 1 2\\nThus,weneedtofindanr∗ ∈ (r ,r )suchthatforeachcomponent:\\n1 2\\nf(r )−f(r ) g(r )−g(r ) h(r )−h(r )\\n1 2 = f′(r∗), 1 2 = g′(r∗), 1 2 = h′(r∗).\\nr −r r −r r −r\\n1 2 1 2 1 2\\n25Step3: ApplyingtheMeanValueTheoremforVector-ValuedFunctionsTheMeanValueTheorem\\n(MVT)canbeextendedtovector-valuedfunctions. Specifically,ifF(r)iscontinuouson[r ,r ]\\n1 2\\nanddifferentiableon(r ,r ),thenthereexistssomer∗ ∈ (r ,r )suchthat:\\n1 2 1 2\\nF(r )−F(r ) = F′(r∗)(r −r ).\\n2 1 2 1\\nStep4: ExpressingtheDerivativeandRearrangingtheEquationRecallthatthederivativeF′(r)is\\ngivenby:\\nF′(r) = (cid:0) f′(r),g′(r),h′(r)(cid:1) = ∇F(r).\\nRewritingtheequationfromStep3:\\nF(r )−F(r ) = (r −r )F′(r∗).\\n1 2 1 2\\nStep5: ConfirmingtheEqualityHoldsComponent-WiseThisequationholdsforeachcomponent:\\nf(r )−f(r ) = (r −r )f′(r∗),\\n1 2 1 2\\ng(r )−g(r ) = (r −r )g′(r∗),\\n1 2 1 2\\nh(r )−h(r ) = (r −r )h′(r∗).\\n1 2 1 2\\nStep6: ConcludingtheProofSinceallcomponentssatisfytheMeanValueTheorematthesame\\npointr∗,wehave:\\nF(r )−F(r ) = (r −r )∇F(r∗),\\n1 2 1 2\\nwherer∗ ∈ (r ,r ).\\n1 2\\nStep7: FinalStatementTherefore,foranyr andr ,thereexistsanr∗ betweenthemsuchthatthe\\n1 2\\noriginalequationholds,whichcompletestheproof.\\n3. Reason\\nMVTcannotbeusedin3Dspace,whichisadeceptionortrap,andthecounterexampleisagood\\nwaytoshowthatthepropositionmaynothold. Butwechangedittoacorrectproofbyextending\\nMVTtovector-valuedfunctionsandignoringtherestrictionsofMVT\\nC.9 Example for MS. category\\n1. Process1\\nQuestion: Threepencilsandajumboerasercost$1.24. Fivepencilsandajumboerasercost$1.82.\\nNopricesincludetax. Incents,whatisthecostofapencil?\\nStep1: Let’scallthepriceofapencilpandthepriceofajumboerasere. Thenwecanwritetwo\\nequations.\\nStep2: Wehave3p+e = 1.24and5p+e = 1.82.\\nStep3: Tosolvethissystem,let’ssubtractthefirstequationfromthesecondequation. Thiswill\\neliminatee.\\nStep4: 5p+e−3p−e = 1.82−1.24.\\nStep5: Thissimplifiesto2p = 0.58. Sop = 0.29.\\nStep6: Thatmeansapencilcosts29cents.\\nAnswer\\n29\\n262. Process2\\nQuestion: Threepencilsandajumboerasercost$1.24. Fivepencilsandajumboerasercost$1.82.\\nNopricesincludetax. Incents,whatisthecostofapencil?\\nStep1: Ineedtosolvethisproblemtofindthecostofapencilincents. Theproblemgivesmetwo\\nscenariosinvolvingpencilsandjumboerasers,alongwiththeirtotalcosts. Let’sfirstunderstand\\nwhat’sbeingasked.\\nStep2: Theproblemstates:\\n-Threepencilsandonejumboerasercost$1.24.\\n-Fivepencilsandonejumboerasercost$1.82.\\nAnditasksforthecostofapencilincents.\\nStep3: Sincethepricesaregivenindollars,Ishouldconvertthemtocentstomakecalculations\\neasierbecausetheanswerisrequiredincents.\\n-$1.24isequalto124cents.\\n-$1.82isequalto182cents.\\nSo,Icanrephrasetheproblemas:\\n-3pencils+1jumboeraser=124cents\\n-5pencils+1jumboeraser=182cents\\nStep4: Now,Ineedtofindthecostofonepencil. Let’sdenote:\\n-Letpbethecostofonepencilincents.\\n-Letebethecostofonejumboeraserincents.\\nSo,Icanwritetheequationsbasedonthegiveninformation:\\nEquation1: 3p+e=124\\nEquation2: 5p+e=182\\nStep5: Ihaveasystemoftwoequationswithtwovariables(pande). Tofindthevalueofp,Ican\\nusethemethodofeliminationorsubstitution. Ithinkeliminationmightbestraightforwardhere.\\nStep6: IfIsubtractEquation1fromEquation2,thee(erasercost)willcancelout,andIcansolve\\nforp.\\nSo,Equation2-Equation1:\\n(5p+e)-(3p+e)=182-124\\nSimplifying:\\n5p+e-3p-e=58\\nWhichreducesto:\\n2p=58\\nStep7: Now,solvingforp:\\np=58/2\\np=29cents\\nStep8: So,thecostofonepencilis29cents. Buttomakesure,Ishouldcheckifthismakessense\\nwithbothoriginalequations.\\nStep9: Pluggingp=29intoEquation1:\\n3(29)+e=124\\n87+e=124\\ne=124-87\\ne=37cents\\nStep10: Now,pluggingp=29ande=37intoEquation2toverify:\\n5(29)+37=145+37=182cents,whichmatchesthesecondequation.\\nStep11: Everythingchecksout,sothecostofapencilisindeed29cents.\\nFinalAnswer\\n29\\n27D Prompts\\nD.1 PromptsForGeneratingData\\nAsintroducedinSection3.2,wequeryGPT-4o(OpenAI,2024a)tosynthesizethemetadataatthevery\\nfirststepofourdatacurationprocedure. TobetterpromptLLMstogeneratehigh-qualitydatainstances,\\nwecarefullydesignedourprompts,whicharedisplayedbelow. Wedisplayonlyoneexampleheredueto\\nlimitationsinspace. Andthefullpromptscanbefoundinoursupplementarymaterials.\\nD.1.1 Prompts for NR. category\\n1. SystemPrompt\\nTaskDescriptionYouareahelpfulAIassistantwhoisverygoodatreasoninganddataconstruction.\\nNowIwanttotesttheabilityofprocess-levelrewardmodelstojudgewhetherastepwithinthe\\nreasoningprocessiscorrect. Todothis,pleasehelpmebuildflawedcasesbyintroducingspecific\\ntypesoferrorsintoagivenreasoningprocess.\\nYouwillbeprovidedwith:\\n1. Amathematicalproblem.\\n2. Itsstandardcorrectanswer.\\n3. Acorrectstep-by-stepreasoningprocessusedtosolveit.\\nYourtaskistomodifythequestion,adjustoneormoresteps,orintroduceadditionalstepsintothe\\noriginal process chain to create a reasoning process that appears plausible but is incorrect. The\\nobjectiveistosimulateflawedsolutionsbyincorporatingthespecifiederrordetailedafter\"Error\\nTypetoIntroduce\".\\nErrorTypetoIntroduce\\nRedundancyreferstoaprocessthatisnotthemostconciseorefficient,asitincludesoneormore\\nredundantstepsthatcanberemovedwithoutaffectingthecorrectnessoftheoverallsolutionpath.\\nForexample,ifA → B representsacorrectinferencechain,yourtaskistointroduceoneormore\\nredundantstepsC = {c|cisredundent}andreformulatethesolutionchainasA → C → B.\\nFormattingInstructions\\nAftermakingthemodifications,providethefollowingstructuredoutput:\\n{\\n\"original_question\": \"The original mathematical problem.\",\\n\"modified_question\": \"The modified problem or original problem\\n\"original_process\": [\"original_step 1\", \"original_step 2\", ...],\\n\"modified_process\": [\"modified_step 1\", \"modified_step 2\", ...],\\n\"modified_steps\": [1, 5, 7, ...],\\n\"error_steps\": [5, 6, ...],\\n\"reason\": \"Explanation for the changes.\"\\n}\\nDetailedRequirements:\\n1. original_question: Astringrepresentingtheoriginalmathematicalproblemasprovided.\\n2. modified_question: A string representing the modified problem after your changes. If the\\nproblemremainsthesame,youcancopytheoriginalquestion.\\n3. original_process: Anon-emptylistofstringsrepresentingtheoriginalreasoningstepsprovided\\nasinput.\\n4. modified_process: A non-empty list of strings representing the reasoning process after your\\nmodifications.\\n5. modified_steps: A non-empty list of integers indicating the indexes of all modified steps.\\nIndexingstartsat1.\\n6. error_steps: Anon-emptylistofintegersrepresentingthestepsthatcontainhallucinationsor\\nerrors. Theseshouldalsobepartofmodified_steps.\\n7. reason: Aclearexplanationofthemodificationsmade,whytheywereintroduced,andhowthey\\n28alignwiththespecifiederrortypes.\\nNotes:\\n1. Ensurealllistsarenon-empty. 2. UsetheLaTeXformatforallmathematicalsymbols(e.g.,x2\\nforxsquared). DonotuseUnicodesymbolssuchas\\\\u2248or\\\\u00f7. 3. EnsuretheJSONobject\\niswell-formed,withproperescapingforspecialcharacterslikebackslashn(e.g.,usebackslash\\nbackslashnfornewlines). 4. Allindexesstartfrom1,thatis,thefirststep’sindexis1,not0. 5.\\nYoucanchoosetomodifythequestionornot,ifthequestionremainsthesame,youcancopythe\\noriginal question. But if the question is modified, ensure that the steps are judged based on the\\nmodifiedquestion. 6. Pleasegivetheoriginalprocessasprovidedbytheprompt,donotmodifyit.\\n2. FewShots\\nUser1\\nQuestion:\\nIfx2−x−1 = 0,whatisthevalueofx3−2x+1?\\nSteps:\\nStep1. Let’sstartwiththefirstequationandseeifwecansolveforx.\\nStep2. Wecanusethequadraticformulatofindx.\\n√\\nStep3. Thequadraticformulaisx = −b± b2−4ac.\\n2a √\\nStep4. Substitutinga = 1,b = −1,andc = −1,wegetx = 1± 5.\\n2\\nStep5. Sincex2−x−1 = 0,wereplacex2 withx+1inx3−2x+1.\\nStep6. Substituting,x3−2x+1 = x(x+1)−2x+1.\\nStep7. Simplify: x3−2x+1 = (x2+x)−2x+1.\\nStep8. Substitutex2 = x+1: x3−2x+1 = (x+1+x)−2x+1.\\nStep9. Simplify: x3−2x+1 = 2.\"\\nAnswer\\n2\\nAssistant1\\n{\\n\"original_question\": \"If $x^2 - x - 1 = 0$, what is the value of $x^3 - 2x\\n+ 1$?\",\\n\"modified_question\": \"If $x^2 - x - 1 = 0$, what is the value of $x^3 - 2x\\n+ 1$?\",\\n\"original_process\": [\\n\"Let\\'s start with the first equation and see if we can solve for x.\",\\n\"We can use the quadratic formula to find x.\",\\n\"The quadratic formula is $x = \\\\\\\\frac{-b \\\\\\\\pm \\\\\\\\sqrt{b^2 - 4ac}}{2a}$\\n.\",\\n\"Substituting $a = 1$, $b = -1$, and $c = -1$, we get $x = \\\\\\\\frac{1 \\\\\\\\\\npm \\\\\\\\sqrt{5}}{2}$.\",\\n\"Since $x^2 - x - 1 = 0$, we replace $x^2$ with $x + 1$ in $x^3 - 2x +\\n1$.\",\\n\"Substituting, $x^3 - 2x + 1 = x(x + 1) - 2x + 1$.\",\\n\"Simplify: $x^3 - 2x + 1 = (x^2 + x) - 2x + 1$.\",\\n\"Substitute $x^2 = x + 1$: $x^3 - 2x + 1 = (x + 1 + x) - 2x + 1$.\",\\n\"Simplify: $x^3 - 2x + 1 = 2$.\"\\n],\\n\"modified_process\": [\\n\"Let\\'s start with the first equation and see if we can solve for x.\",\\n\"We can use the quadratic formula to find x.\",\\n\"The quadratic formula is $x = \\\\\\\\frac{-b \\\\\\\\pm \\\\\\\\sqrt{b^2 - 4ac}}{2a}$\\n.\",\\n\"Substituting $a = 1$, $b = -1$, and $c = -1$, we get $x = \\\\\\\\frac{1 \\\\\\\\\\npm \\\\\\\\sqrt{5}}{2}$.\",\\n\"Since $x^2 - x - 1 = 0$, we replace $x^2$ with $x + 1$ in $x^3 - 2x +\\n1$.\",\\n\"Substituting, $x^3 - 2x + 1 = x(x + 1) - 2x + 1$.\",\\n\"Simplify: $x^3 - 2x + 1 = (x^2 + x) - 2x + 1$.\",\\n29\"Now let\\'s verify that $x^2 = x + 1$ by re-solving $x^2 - x - 1 = 0$\\nagain.\",\\n\"Substitute $x^2 = x + 1$: $x^3 - 2x + 1 = (x + 1 + x) - 2x + 1$.\",\\n\"Simplify: $x^3 - 2x + 1 = 2$.\"\\n],\\n\"modified_steps\": [8],\\n\"error_steps\": [8],\\n\"reason\": \"Step 8 re-solves $x^2 - x - 1 = 0$ unnecessarily, introducing\\nredundancy. This step does not provide new information, as $x^2 = x + 1\\n$ was already established in The reasoning is still correct but less\\nefficient.\"\\n}\\nUser2\\nQuestion:\\nIn1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelatowouldhave\\ncost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,howmany\\ndollarswouldbeequivalentto1,000,000lire?\\nSteps:\\nStep 1. Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*\\nfrac1.501200.\\nStep2. Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3. Ithinkthesecondwaywillbeeasier.\\nfrac1.501200 = 0.00125.\\nStep4. That’strue. Nowwejusthavetosolvetheequationx=1000000*0.00125.\\nStep5. Sox=1250.\\nStep6. That’sthefinalanswer.\\nStep7. Right. So1,000,000lireisequivalentto$1250.\\nAnswer\\n1250\\nAssistant2\\n{\\n\"original_question\": \"In 1992, a scoop of gelato could be purchased in\\nItaly for 1200 lire. The same gelato would have cost $\\\\\\\\$1.50$ in the U\\n.S. At the equivalent exchange rate between the lire and the dollar,\\nhow many dollars would be equivalent to 1,000,000 lire?\",\\n\"modified_question\": \"In 1992, a scoop of gelato could be purchased in\\nItaly for 1200 lire. The same gelato would have cost $\\\\\\\\$1.50$ in the U\\n.S. At the equivalent exchange rate between the lire and the dollar,\\nhow many dollars would be equivalent to 1,000,000 lire?\",\\n\"original_process\": [\\n\"Let\\'s call the number of dollars x. So, the problem is asking us to\\nsolve the equation x=1000000*$\\\\\\\\frac{1.50}{1200}$.\",\\n\"There are two ways to solve this equation. We could either divide 100\\n0000 by 1200 and then multiply the result by 1.50 or we could\\ndivide 1.50 by 1200 and then multiply the result by 1000000.\",\\n\"I think the second way will be easier. $\\\\\\\\frac{1.50}{1200}=0.00125$.\"\\n,\\n\"That\\'s true. Now we just have to solve the equation x=1000000*0.00125\\n.\",\\n\"So x=$1250$.\",\\n\"That\\'s the final answer.\",\\n\"Right. So 1,000,000 lire is equivalent to $\\\\\\\\$1250$.\"\\n],\\n\"modified_process\": [\\n\"Let\\'s call the number of dollars x. So, the problem is asking us to\\nsolve the equation x=1000000*$\\\\\\\\frac{1.50}{1200}$.\",\\n30\"There are two ways to solve this equation. We could either divide 100\\n0000 by 1200 and then multiply the result by 1.50 or we could\\ndivide 1.50 by 1200 and then multiply the result by 1000000.\",\\n\"I think the second way will be easier. $\\\\\\\\frac{1.50}{1200}=0.00125$.\"\\n,\\n\"That\\'s true. But let\\'s confirm the computation again: $\\\\\\\\frac{1.50}{1\\n200}=0.00125$.\",\\n\"Now we just have to solve the equation x=1000000*0.00125.\",\\n\"So x=$1250$.\",\\n\"Let\\'s double-check by performing the multiplication again: 1000000*0.\\n00125=$1250$.\",\\n\"That\\'s the final answer.\",\\n\"Right. So 1,000,000 lire is equivalent to $\\\\\\\\$1250$.\"\\n],\\n\"modified_steps\": [4, 7, 8],\\n\"error_steps\": [4, 7, 8],\\n\"reason\": \"Step 4 unnecessarily repeats the computation of $\\\\\\\\frac{1.50}{1\\n200}$, which was already completed in Step 7 redundantly re-checks the\\nmultiplication, adding no new information. These redundant steps make\\nthe reasoning process less concise without affecting correctness.\"\\n}\\nD.2 PromptsForEvaluatingGenerativeLLMs\\nAsintroducedinSection4.1,wepromptsomestate-of-the-artgenerativeLLMsascriticmodelsto\\nevaluatetheirrewardingcapabilitieson PRMBENCH. Tomakeafaircomparisonbetweendifferent\\nmodels,wecarefullydesignthepromptsandutilizeaunifiedprompttoquerythem. Thepromptusedis\\ndisplayedbelow.\\nD.2.1 Prompts for Evaluating Generative LLMs\\n1. SystemPrompt\\nYouareamathematicalreasoningevaluator. Yourtaskistoanalyzemathematicalproblem-solving\\nstepsandprovidestructuredassessmentsinJSONformat.\\nForeachsolutionstep,youneedtoevaluatetwoaspects:\\n1. ValidityScore(-1to+1):\\n*+1: Completelycorrectmathematicalreasoning\\n*0: Partiallycorrectwithsomemistakes\\n*-1: Completelyincorrect\\n*Useanyvalueinbetweentoindicatevaryingdegreesofcorrectness\\n2. RedundancyScore(-1to+1):\\n*-1: Criticalstep,absolutelynecessaryforthesolution\\n*0: Moderatelyimportantstep\\n*+1: Completelyredundant,canbeomitted\\n*Useanyvalueinbetweentoindicatevaryingdegreesofredundancy\\nRequirements:\\n-Evaluateeachstepindependently\\n-Providescoresasfloating-pointnumbers\\n-ReturnresultsinstrictJSONformat: \"validity\": [scores],\"redundancy\": [scores]\\n-Ensurebotharrayshavethesamelengthasthenumberofsteps\\n-Maintainmathematicalrigorinyourevaluation\\n-Considermathematicalaccuracy,logicalcoherence,andsolutionefficiency\\nExampleoutputformat:\\n{\"validity\": [0.8, -0.5, 1.0], \"redundancy\": [-1.0, 0.3, 0.7]}\\n312. FewShots\\nUser1\\nQuestion:\\nIn1992,ascoopofgelatocouldbepurchasedinItalyfor1200lire. Thesamegelatowouldhave\\ncost$1.50intheU.S.Attheequivalentexchangeratebetweenthelireandthedollar,howmany\\ndollarswouldbeequivalentto1,000,000lire?\\nSolution:\\nStep 1. Let’s call the number of dollars x. So, the problem is asking us to solve the equation\\nx=1000000*1.50.\\n1200\\nStep2. Therearetwowaystosolvethisequation. Wecouldeitherdivide1000000by1200and\\nthenmultiplytheresultby1.50orwecoulddivide1.50by1200andthenmultiplytheresultby\\n1000000.\\nStep3. Ithinkthesecondwaywillbeeasier. 1.50 = 0.00125.\\n1200\\nStep4. That’strue. Nowwejusthavetosolvetheequationx=1000000*0.00125.\\nStep5. Sox=1250.\\nStep6. Sox=1250.\\nStep7. That’sthefinalanswer.\\nStep8. Right. So1,000,000lireisequivalentto$1250.\\nAnswer\\n1250\\nAssistant1\\n{\\\\\"validity\\\\\": [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\\\\\"redundancy\\\\\": [-1.0,\\n0.5, -0.5, -0.5, -1.0, 1.0, 0.5, 1.0]}\\nUser2\\nQuestion:\\nFourpoints,A,B,C,andD,arechosenrandomlyandindependentlyonthecircumferenceofa\\ncircle. WhatistheprobabilitythatsegmentsAB andCD intersect?\\nSolution:\\nStep1. Let’sthinkaboutwhatitmeansforthesegmentstointersect.\\nStep2. WhethertheyintersectisentirelyafunctionoftheorderofB,C,D onthecircle,whenwe\\nlookatitcounterclockwiseandconsiderAtocomefirst.\\nStep3. Exactly. Solet’sconsiderthedifferentpossibleordersofB,C,D.\\nStep4. Thenumberofpossibleordersis3! = 6.\\nStep 5. Yes, that’s right. Now, we need to figure out how many of these result in the segments\\nintersecting.\\nStep6. IfC isinbetweenB andD,thenthesegmentswillintersect.\\nStep7. IfB isinbetweenC andD,thenthesegmentswillintersect.\\nStep8. Right. That’stwoofthepossibleorders.\\n2 1\\nStep9. So,theprobabilitythatthesegmentsintersectis = .\\n6 3\\nStep10. Andthat’souranswer.\\nAnswer\\n1/3\\nAssistant2\\n{\\\\\"validity\\\\\": [1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.8, 1.0, 1.0, 1.0],\\\\\"\\nredundancy\\\\\": [-1.0, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -1.0, 1.0]}\\n32E InstructionsForAnnotators\\nAsdescribedinSection3.3,werecruitedfivevolunteerstoevaluateourproposed PRMBENCH. The\\ninstructionsareshownbelow.\\nE.1 Instruction for Annotators\\n1. Backgrounds\\nWiththeemergenceofmulti-stepreasoningenhancedlanguagemodelssuchasOpenAIo1,and\\nDeepmindGemini-thinking,thesemodelsdemonstratetheabilitytodecomposecomplexproblems\\nandsolvethemstepbystep. However,whiletheirsolutionsoftenappearcorrect,theymaycontain\\nerrors in understanding, calculation, or reasoning logic. A popular way to evaluate the results\\ngenerated by these models is by utilizing process-level reward models (PRMs). Nevertheless,\\nPRMsarefallibleandnotalwayscorrect. ExistingbenchmarksarenotadequatetoevaluatePRMs\\non different error types. Under this circumstance, we are building a comprehensive evaluation\\nbenchmarkforPRMsthatcanhaveafine-graineddetectionofPRMs.\\n2. TaskDefinition\\nWe begin by collecting completely correct multi-solution data and leveraging state-of-the-art\\n(SOTA)LLMstointroducevarioustypesoferrorsintothesecorrectsolutions,therebygenerating\\nourtestcases. ThedetailederrortypesaredescribedinSection3. Allsynthesizeddatainstances\\nundergoaninitialfilteringprocessbasedonspecificfeatures.\\nYourtaskistoidentifywhetherthemodificationtakenisreasonableandwhetherthemodifieddata\\ninstanceisdifferentfromtheoriginaldatainstance.\\n2.1Sub-task1\\nThefirstsub-taskisabinaryclassificationtaskwhoseoptionsincludeyesandno. Yourtaskisto\\ndecidewhetherthemodifiedstep-by-stepsolutiongeneratedbyLLMsisreasonable. Theword\\n“reasonable”hastwoaspectsforevaluation.\\n• The modified process generated by LLMs seems like a possible solution path that could\\nhappen.\\n• ThemodifiedprocessgeneratedbyLLMsisexactlywrongandthetypeoferrorissuitablefor\\nthecurrent“classification”.\\nPleaseassigna“yes”forthissub-taskifbothoftheanswerstotheabovetwoquestionsare“yes”.\\nOtherwise,assigna“no”forthissub-task.\\n2.2Sub-task2\\nThesecondsub-taskisabinaryclassificationtaskwhoseoptionsincludeyesandno. Yourtask\\nistodecidewhetherthemodifiedstep-by-stepsolutiongeneratedbyLLMsisdifferentfromthe\\noriginalsolutionprocess. Theword“different”meansthemodifiedsolutionprocessislogically\\ndifferentfromtheoriginalone,orthereexistdifferentstatementscomparedtotheoriginalprocess.\\nPlease assign a “yes” to this sub-task if your answer to the above question is “yes”. Otherwise,\\nassigna“no”forthissub-task.\\n3. ErrorTypes\\nRedundancy refersto aprocessthatis notthemost conciseorefficient, as itincludesone or\\nmoreredundantstepsthatcanberemovedwithoutaffectingthecorrectnessoftheoverallsolution\\npath. Forexample,ifA → B representsacorrectinferencechain,yourtaskistointroduceoneor\\nmoreredundantstepsC = {c|cisredundent}andreformulatethesolutionchainasA → C → B.\\n33Circularlogic isaspecificformofredundancy,characterizedbyareasoningchainthatstartsat\\nastepS,progressesthroughasequenceofsteps,andultimatelyloopsbacktoS. Symbolically,\\nthiscanbeexpressedasS → A → B → S, whereS, A, andB representindividualreasoning\\nsteps. Yourtaskistomodifythereasoningprocesstointroducesuchcircularlogic.\\nCounterfactual Acounterfactualstepreferstoastatementwithinareasoningchainthatcontra-\\ndicts established ground truth. Such contradictions can arise from relying on outdated theories,\\nomittingcriticalconstraintsinatheory,orincorporatingerroneousassumptions. Yourtaskisto\\nmodifythereasoningprocesstointroducesuchcounterfactualsteps.\\nStepcontradiction referstoaconflictbetweenaspecificstepandotherstepswithinareasoning\\npath. GivenareasoningpathP = S ,S ,...,S , astepcontradictionexistsifS ⊥ S , where\\n1 2 n i j\\ni,j ∈ [1,n] and i ̸= j. Your task is to modify the reasoning process to introduce such step\\ncontradictionsteps.\\nDomaininconsistency isaspecialtypeofcounterfactual. Itreferstoastepwithinthereasoning\\nchain that uses a statement or theory valid in other domains or cases but is not valid within the\\ncurrentreasoningchain. Yourtaskistomodifythereasoningprocesstointroducesuchdomain\\ninconsistencysteps.\\nConfidenthallucination isaspecialtypeofcounterfactual. Itreferstoastatementwithinthe\\nreasoningchainthatcontradictsestablishedgroundtruthandispresentedwithanoverlyconfident\\ntone. Inotherwords,itinvolvesstatinganincorrectstatementwithunwarrantedcertainty. Your\\ntaskistomodifythereasoningprocesstointroducesuchconfidenthallucinationsteps.\\nMissingconditionorprerequisite referstoaflawinthereasoningchainwherecriticalpremises,\\nassumptions,ornecessaryconditionsareabsent. Thisomissionresultsinlogicalgaps,incomplete\\nreasoning, or biased conclusions. For example, when a missing condition occurs, the model\\nis required to solve the problem through case analysis or further investigation. However, the\\nanswerbecomesincorrectifthemodeloverlooksthemissingconditionandproceedswithstandard\\nreasoning methods. Your task is to modify the reasoning process to introduce such missing\\nconditionerrorsteps.\\nDeceptionortraps refertostatementsthatappeartobecorrectoralignwithgroundtruthbut\\naresubtlyalteredtointroduceinaccuracieswhilemaintainingtheillusionofcorrectness. Yourtask\\nistomodifythereasoningprocesstointroducesuchdeceptionortraperrorsteps.\\n34',\n",
       " 'Rethinking Adversarial Attacks in Reinforcement Learning from Policy Distribution Perspective.pdf': 'Rethinking Adversarial Attacks in Reinforcement\\nLearning from Policy Distribution Perspective\\nTianyang Duan1, Zongyuan Zhang1, Zheng Lin2, Yue Gao3, Ling Xiong4,\\nYong Cui5, Hongbin Liang6, Xianhao Chen2, Heming Cui1, Dong Huang1\\n1 Department of Computer Science, The University of Hong Kong, Hong Kong, China.\\n2 Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, China.\\n3 School of Computer Science, Fudan University, Shanghai, China.\\n4 School of Computer and Software Engineering, Xihua University, Chengdu, China.\\n5 Department of Computer Science and Technology, Tsinghua University, Beijing, China.\\n6 School of Transportation and Logistics, Southwest Jiaotong University, Chengdu, China.\\nAbstract—Deep Reinforcement Learning (DRL) suffers from\\nuncertainties and inaccuracies in the observation signal in real-\\nworld applications. Adversarial attack is an effective method\\nfor evaluating the robustness of DRL agents. However, existing\\nattackmethodstargetingindividualsampledactionshavelimited\\nimpactsontheoverallpolicydistribution,particularlyincontin-\\nuous action spaces. To address these limitations, we propose the\\nDistribution-AwareProjectedGradientDescentattack(DAPGD).\\nDAPGDusesdistributionsimilarityasthegradientperturbation\\ninput to attack the policy network, which leverages the entire\\npolicydistributionratherthanrelyingonindividualsamples.We\\nutilize the Bhattacharyya distance in DAPGD to measure policy\\nsimilarity,enablingsensitivedetectionofsubtlebutcriticaldiffer-\\nences between probability distributions. Our experiment results\\ndemonstratethatDAPGDachievesSOTAresultscomparedtothe\\nFig.1. TwomethodsforgeneratingadversarialexamplesintheGoaltask.In\\nbaselines in three robot navigation tasks, achieving an average thistask,theagentneedstonavigatearoundHazardsandreachtheGoal.Top:\\n22.03% higher reward drop compared to the best baseline. Existingmethods(e.g.,PGD)samplefromthepolicyandcalculatethesign\\nIndex Terms—Reinforcement learning, Deep neural network, gradientofmeansquareerrorlosstoattack.Bottom:Ourmethod(DAPGD)\\nStochastic policy, Adversarial attack. directly utilizes the policy distribution similarity, which calculates the sign\\ngradientoftheBhattacharyyadistancebetweenpoliciestoattack.\\nI. INTRODUCTION\\nintroducing carefully designed perturbations to input data,\\nDeep Reinforcement Learning (DRL) has exhibited excep-\\nthese attacks effectively reveal the vulnerabilities of DRL\\ntional performance across a spectrum of complex robotic\\nmodels under uncertainties and environmental changes [16].\\ncontrol tasks [1]–[3], successfully solving challenges such\\nTraining DRL agents in the presence of such adversarial\\nas robot navigation [4]–[6], obstacle avoidance [7], [8], and\\nscenarios has been shown to improve their robustness [17].\\nrobotic manipulation [9], [10]. However, in real-world appli-\\nWhilecurrentresearchonadversarialattacksprimarilyfocuses\\ncations,observationsignalsareoftensubjecttonoise,latency,\\nonsupervisedlearningtasks,suchasimageclassification[18]–\\nand inaccuracies [11], [12]. Moreover, subtle variations in\\n[20], the application in the domain of DRL remains relatively\\nenvironmental dynamics, such as changes in surface friction\\nunexplored. Existing efforts have concentrated on developing\\nor lighting conditions, can substantially degrade DRL perfor-\\ndefense mechanisms compatible with DRL frameworks [21]–\\nmance [13].\\n[23], while little attention is paid to devising attack methods\\nAdversarial attacks have emerged as an effective method\\nagainstDRL,particularlyinhigh-dimensionalcontinuousstate\\nfor evaluating the robustness of DRL models [14], [15]. By\\nand action spaces.\\nUnlike supervised learning [24]–[27], which involves de-\\nCopyright 2025 IEEE. Published in ICASSP 2025 – 2025 IEEE Interna-\\ntional Conference on Acoustics, Speech and Signal Processing (ICASSP), terministic input-output mappings [28]–[30], DRL learns a\\nscheduled for 6-11 April 2025 in Hyderabad, India. Personal use of this policyfunctionthatmapsstatespacetoactionspace,typically\\nmaterial is permitted. However, permission to reprint/republish this material\\nmodeledasaconditionalprobabilitydistributionoverpossible\\nforadvertisingorpromotionalpurposesorforcreatingnewcollectiveworks\\nfor resale or redistribution to servers or lists, or to reuse any copyrighted actions [31]. As illustrated in the top of Figure 1, existing ad-\\ncomponent of this work in other works, must be obtained from the IEEE. versarial attack methods primarily target the output, which in\\nContact:Manager,CopyrightsandPermissions/IEEEServiceCenter/445\\nDRL manifests as calculating adversarial perturbations based\\nHoesLane/P.O.Box1331/Piscataway,NJ08855-1331,USA.Telephone:\\n+Intl.908-562-3966. on sampled actions from the policy (or the action with the\\n5202\\nnaJ\\n8\\n]GL.sc[\\n2v26530.1052:viXrahighest probability) [32], [33]. However, perturbation attacks through strategic attacks on agents over a sequence of time\\ntargeting individual actions may have a limited impact on steps. Weng et al. [43] present a model-based DRL attack\\ntheoverallpolicydistribution,particularlyinhigh-dimensional framework designed to enhance the efficacy of adversarial\\ncontinuous state and action spaces. This is because adjacent attacks in DRL. Other works focus on adversarial defense,\\nactions within the action space can be selected to counteract primarilyusingadversarialexamplestotrainagentstoimprove\\nthe effects of attacks targeting specific actions. The inherent policy robustness. Fischer et al. [44] devise Robust Student-\\nflexibility of continuous action spaces enables more robust DQN (RS-DQN), a method that enables simultaneous robust\\nadjustments in response to local perturbations. Moreover, online training of Q-networks and policy networks. Zhang et\\nexisting methods often overlook the inherent randomness in al. [45] proposed SA-MDP to theoretically unify the adver-\\naction selection. Consequently, gradients of the loss function sarial defense process in DRL. Oikarinen et al. [23] develop\\ncalculated from a single sampled action fail to capture the RADIAL-RLframeworktoenhancetheeffectivenessofadver-\\nbroader vulnerability of the entire policy distribution, thereby sarialdefense.However,thesemethodscomputeperturbations\\ndiminishing the effectiveness of the attacks. forattackordefensebasedonactionssampledfromthepolicy\\nTo address these issues, we propose the Distribution-Aware (or actions with the highest weights), thus failing to capture\\nProjectedGradientDescent(DAPGD)attack.Asshowninthe broader vulnerability across the policy distribution.\\nbottomofFigure1,ourmethodutilizesdistributionsimilarity,\\nIII. METHODOLOGY\\ninstead of sampled outcomes, as the input for gradient pertur-\\nA. Problem Formalization\\nbation to attack the policy network. This approach capitalizes\\non the full information of the policy distribution rather than DRL is formulated as a Markov decision process [46],\\nrelying solely on the local characteristics of individual sam- whichisformalizedasatuple⟨S,A,P,R,γ⟩,whereS andA\\nples. Furthermore, this gradient can generate more consistent denotetheactionandstatespaces.Policyπ :S →P(A)rep-\\nperturbation effects across the observation space, resulting resentsaprobabilitydistributionmappingfromthestatespace\\nin adversarial samples that more closely resemble real-world to the action space. At each time step t, the agent chooses an\\ndisturbances. This is particularly crucial for assessing DRL actiona ∼π(·|s )basedonthecurrentstates andinteracts\\nt t t\\nrobustness in practical application scenarios. In our DAPGD with the environment. The environment transitions to a new\\nattack method, we employ the Bhattacharyya distance as a state s following the state-transition probability function\\nt+1\\nmeasure of policy similarity. The Bhattacharyya distance [34] P (s |s ,a ) and provides a reward R(s ,a ) to the\\nt t+1 t+1 t t\\nquantifies the overlap between two probability distributions agent. The agent’s goal is to learn a policy π to maximize the\\nand is sensitive to marginal changes, facilitating the detec- expected discounted return E(cid:2)(cid:80)∞ γiR(s ,a )(cid:3) , where\\ni=0 t+i t+i\\ntion of subtle but potentially critical differences in policies. γ denotesthediscountfactor.Inanadversarialattacktopolicy,\\nExperimental results show that DAPGD outperforms seven assuming π (·|s) represents a parameterized policy that has\\nθ\\nstate-of-the-art baselines across three robotic navigation tasks. converged in the environment, where θ denotes the network\\nDAPGD achieves an average reward reduction 18.67% and parameters of the policy. For notational simplicity, we use\\n25.38% higher than the best baseline when attacking benign π(·|s) as π[s]. Given a state-action pair (s,a), the goal\\nand robust models, respectively. of the adversarial attack is to find an adversarial example s∗\\nthat maximizes the loss function while satisfying a paradigm\\nII. RELATEDWORK\\nconstraint [14]:\\nAdversarialattacksarepredominantlyappliedtosupervised\\nargmax J(s∗,a), s.t. ∥s∗−s∥ ≤ϵ, (1)\\nlearning tasks such as image recognition [35]–[37]. FGSM s∗ p\\n[35]isabasicattackmethodthatgeneratesadversarialsamples where s∗ = s+η and η denote the adversarial perturbation,\\nby perturbing inputs based on the sign of gradients in a J(s∗,a)representsthelossfunction,and∥·∥ istheL norm.\\np p\\nsingle step, evaluating the robustness of deep neural networks\\nIncaseswherethestateandactionspacearediscrete,theloss\\n(DNNs) [38], [39]. PGD [36] extends FGSM with an iterative\\nfunction is the cross-entropy loss, while for continuous cases,\\nprocess and projection step, generating stronger adversarial\\nit is the mean square error loss. L norm is usually the L\\np 1\\nsamplesthroughmultipleupdateswithinconstrainedperturba-\\nnorm, L norm or L norm.\\n2 ∞\\ntions.MostcurrentattackmethodsarebuiltonPGD[40]–[42].\\nB. Distribution Similarity Projected Gradient Descent\\nMomentum Iterative MI-FGSM [40] incorporates momentum\\nandgradientiterationtechniquestostabilizeupdatedirections. The core idea of gradient-based attack methods is to calcu-\\nDI2-FGSM[41]appliesrandomtransformations(e.g.,scaling, latethegradientoftheinputdataandthenapplysmallpertur-\\ntranslation, and rotation) to the input image each iteration bationstotheinputdataalongthegradientdirectiontoinduce\\nbefore calculating gradients. NI-FGSM [42] introduces the incorrect output from the model [35], [36]. Numerous studies\\nNesterov gradient acceleration technique to generate more have demonstrated that this method can also significantly\\neffectiveadversarialsamplesandimprovetheirtransferability. degradetheperformanceofDRL.Forapplyinggradient-based\\nIn DRL, Huang et al. [32] first use FGSM to study its attack methods to DRL, existing approaches typically rely on\\nability to interfere with agent policies. Lin et al. [33] propose policysamplingtogenerateadversarialexamples.Tomotivate\\nan enchanting attack to maliciously manipulate DRL agents this, we use the PGD [36] as an example to illustrate thisAlgorithm 1 DAPGD with L ∞ norm constraint policy distribution, and the Bhattacharyya distance effectively\\nInput: State s, stochastic policy π θ[s], iteration step α, the number quantifies the degree of overlap between two distributions. By\\nof iterations N, scaling factor ε, constraint threshold ϵ. maximizing the distance, we can induce an overall bias in the\\nOutput:Adversarialexamples∗.\\npolicy distribution. This approach is particularly effective in\\n1: s∗ ←s+ε·N(0,I)\\ncontinuous action spaces, as it simultaneously impacts high-\\n2: for k=0 to N −1 do\\nprobability actions and their adjacent alternatives, thereby\\n3: Calculate the distribution similarity loss:\\nexposing potential vulnerabilities in the policy. Specifically,\\n(cid:90)\\nJ(π [s∗],π [s])=−ln (cid:112) π (a|s∗)π (a|s)da we define the distribution similarity loss, built on the Bhat-\\nθ θ θ θ\\nA tacharyya distance between policy distributions, as follows:\\n4: Calculate the gradient: (cid:90)\\n(cid:112)\\nJ(π [s∗],π [s])=−ln π (a|s∗)π (a|s)da (4)\\ngrad[s∗]=▽ s∗J(π θ[s∗],π θ[s]) θ θ\\nA\\nθ θ\\nBased on Eq. 4, the process of generating adversarial\\n5: s∗ ←s∗+α·sgn(grad[s∗]) samples by DAPGD can be expressed as follows:\\n6: s∗ ←s∗+clip(s∗−s,−ϵ,ϵ)\\n7: end for\\n8: return s∗ s∗ =s∗ +α·sgn(▽ J(π [s∗],π [s]))\\nk+1 k s∗ θ θ (5)\\nwhere s∗ =s+ε·N (0,I),k =0,1,...,N −1.\\n0\\nprocess. Specifically, given a state-action pair (s,a), PGD-\\nThe pseudocode for DAPGD is presented in Algorithm 1.\\nbased adversarial examples in DRL can be formulated as:\\nAs there are no constraints on gradient computations or itera-\\ns∗ =s∗ +α·sgn(▽ J(a∗,a)) tionmethods,thedistributionsimilaritylossishighlyversatile\\nk+1 k s∗ k\\nwhere s∗ =s+ε·N (0,I), and can be integrated with most existing adversarial attack\\n0 (2) methods. Moreover, it is applicable to DRL algorithms that\\na∗ ∼π [s∗],a∼π [s],\\nk θ k θ utilize stochastic policies, whether in discrete or continuous\\nk =0,1,...,N −1, action spaces.\\nwhere α denotes the iteration step size, N is the number of IV. EVALUATION\\niterations, sgn(·) represents the sign function, ε is the scaling\\nA. Experimental Setup\\nfactor, and N (0,I) denotes the multivariate standard normal\\ndistribution.Althoughsamplingactionstoattackpoliciesonly Environments We conduct extensive experiments on three\\ncalculate the sign gradient for one action in each iteration to continuous control navigation tasks from the Safety Gym-\\ngenerate adversarial examples. However, in continuous action nasium framework [47]: SafetyRacecarButton1-v0 (Button),\\nspaces, agents can select other adjacent actions to counteract SafetyRacecarCircle1-v0(Circle),andSafetyRacecarGoal1-v0\\ntheimpactofattackstargetingspecificactions.Thiscontinuity (Goal).Thesetaskssimulatescenariosrelevanttoautonomous\\nprovides a degree of fault tolerance and flexibility, allowing vehicle navigation, such as activating buttons, maintaining\\nthe policy to remain relatively stable under small perturba- circular trajectories, and reaching targets, while adhering to\\ntions.Moreover,inmanypracticalapplications,multiplenear- safety constraints like avoiding hazards and boundaries. The\\noptimalpoliciesarecommon.Forexample,innavigationtasks, agent operates with realistic car dynamics in a 2-dimensional\\nthere are often several paths leading to the goal. This means actionspace(velocityandsteeringangle),andtheobservation\\nthatinthesamestate,indicatingthatmultiplehigh-probability space includes multiple sensor data from lidar, accelerometer,\\nactions may exist for the same state. The sign gradient based speedometer, gyroscope, and magnetometer.\\nonasinglesampledactionreflectsonlythelocalvulnerability Agent and Training Configuration We evaluate the ef-\\nof the policy, thereby limiting the effectiveness of the attack. fectiveness of various adversarial attack methods on DRL\\nToovercometheselimitations,weconstructanoptimization agents trained for continuous control navigation tasks. In\\nobjectivebasedonthesimilarityofpolicydistributionstogen- each environment, agents are trained using the Trust Region\\nerate adversarial examples. This design reduces the impact of Policy Optimization (TRPO) algorithm [48]. The agents are\\nrandomness introduced by action sampling and leverages the configured with 20 conjugate gradient iterations, 15 search\\ncomplete probability information of the agent’s action choice steps, 10 learning iterations, a discount factor γ of 0.99, a\\nin a given state instead of individual action. Specifically, our batchsizeof128,andamaximumgradientnormof50,trained\\nobjective is to maximize the following loss function under L p for 1×107 steps. All networks consist of two hidden layers\\nnorm constraint: with 64 nodes.\\nAttack Methods We implement and evaluate a range of\\nargmax J(π [s∗],π [s]), s.t. ∥s∗−s∥ ≤ϵ. (3)\\ns∗ θ θ p attack methods, including FGSM [35], DI2-FGSM [41], MI-\\nWe utilize the Bhattacharyya distance [34] as a metric FGSM[40],NI-FGSM[42],PGD[36],TPGD[49],EOTPGD\\nfor measuring the similarity between policy distributions. [50], and our proposed DAPGD method. For iterative meth-\\nAdversarial attacks fundamentally act as perturbations to the ods, we conduct experiments with the number of iterationTABLEI\\nAVERAGEREWARDINDIRECTATTACKSETTING\\nTask\\nMethod Iters Goal Circle Button\\nNoattack - 26.043±0.223 42.144±0.023 9.148±0.343\\nFGSM - 23.059±0.252 40.889±0.013 7.478±0.804\\nDI2-FGSM 50 21.360±0.338 39.850±0.028 7.900±0.711\\nDI2-FGSM 100 20.807±0.603 39.931±0.038 7.414±1.047\\nMI-FGSM 50 21.689±0.328 40.115±0.049 7.160±0.797\\nMI-FGSM 100 20.929±0.788 40.075±0.008 7.339±0.448\\nNI-FGSM 50 23.630±0.694 38.769±0.048 7.143±0.497\\nFig.2. Averagerewardobtainedbytheagentundereachattackconfiguration NI-FGSM 100 24.626±0.185 37.187±0.121 7.274±0.716\\ninButton.Lowerrewardsindicatemoreeffectiveattacks. PGD 50 24.642±0.361 41.391±0.055 8.445±0.433\\nPGD 100 22.958±0.602 40.890±0.055 6.973±0.450\\nTPGD 50 20.336±1.314 33.870±0.079 6.546±0.815\\nN =50 or 100. We set the iteration step α=2/255, scaling TPGD 100 20.651±0.512 33.752±0.099 6.952±0.581\\nfactor ε=0.001, and constraint threshold ϵ=0.1. EOTPGD 50 21.031±0.996 40.272±0.007 7.097±0.642\\nEvaluationSchemesTwoschemesareusedforperformance EOTPGD 100 20.982±1.236 40.243±0.012 6.775±0.105\\nevaluation:a)Directattacks:Attackthemodelstrainedwithout DAPGD(ours) 50 20.074±0.446 33.351±0.043 5.934±0.764\\nnoise.b)Post-defenseattacks:Attackmodelsthathaveunder- DAPGD(ours) 100 19.965±0.813 33.467±0.082 5.382±0.310\\ngone additional defensive training with PGD (the number of\\niteration N = 50) for 5×106 training steps, keeping other\\nTABLEII\\nparameters unchanged. This setup demonstrates DAPGD’s AVERAGEREWARDINPOST-DEFENSEATTACKSSETTING(DEFENDEDBY\\neffectivenessonbothbenignDNNs(withoutadversarialtrain- PGD,THENUMBEROFITERATIONN =50)\\ning) and robust DNNs (with adversarial training). The agents’\\nTask\\nperformance under various attack methods is measured by the\\nMethod Iters Goal Circle Button\\naverage episode reward obtained over 1000 episodes in three\\nPGD(defended) 50 24.746±0.574 39.855±0.098 9.291±1.079\\nindependent experiments. Attacks are applied to the agents’\\nPGD 100 22.354±0.221 39.461±0.019 8.995±0.658\\nobservation, perturbing the input before it is processed by FGSM - 23.852±0.320 38.461±0.055 9.098±0.402\\nthe policy network. We record the mean reward obtained by DI2-FGSM 50 23.408±0.465 40.402±0.022 8.656±0.975\\nthe agents under each attack scenario, with lower rewards DI2-FGSM 100 22.471±0.278 40.400±0.050 7.873±0.168\\nindicating more successful attacks. MI-FGSM 50 23.336±0.435 39.119±0.066 8.326±0.146\\nMI-FGSM 100 22.741±0.456 39.207±0.018 9.109±0.513\\nB. Overall performance of DAPGD NI-FGSM 50 24.380±0.472 39.988±0.064 8.444±0.485\\nNI-FGSM 100 24.883±0.453 40.369±0.046 8.890±0.845\\nIn Table I, all attack methods reduce the agent’s average\\nTPGD 50 22.456±0.855 38.114±0.038 8.422±0.195\\nreward across the three tasks (Goal, Circle, Button) compared\\nTPGD 100 22.739±0.378 38.038±0.025 8.001±0.388\\nto the non-attacked case. The DAPGD method demonstrates\\nEOTPGD 50 22.990±0.273 39.326±0.046 7.825±0.325\\nthebestattackperformanceacrossalltasks.DAPGDachieves\\nEOTPGD 100 22.948±0.245 39.417±0.069 8.337±0.778\\nan average reward reduction 18.67% higher than the best DAPGD(ours) 50 22.701±0.438 38.028±0.057 7.511±0.347\\nbaseline. DAPGD(ours) 100 21.179±0.151 37.936±0.085 8.033±0.693\\nTableIIpresentstheattackperformanceunderthedefensed\\nmodel (after adversarial training with PGD). While the agent\\nexhibits a certain degree of robustness following defense the attack. Figure 2 illustrates the performance of different\\ntraining, DAPGD still causes a significant performance drop. divergence metrics across different numbers of iterations of\\nDAPGDoutperformallothermethodsacrossalltasks,causing attack. BD achieves the lowest reward values across all\\nthe most significant reduction in rewards, average 25.38% iteration counts, indicating its ability to craft more potent\\nhigher than the best baseline. In the presence of defense attacks. The superior performance of BD can be attributed\\nmechanisms, DAPGD’s advantage over baselines becomes to its comprehensive capture of distribution disparities. By\\neven more pronounced. This is attributed to DAPGD more maximizing the BD, a broader shift in the policy distribution\\neffectively attacking the policy distribution rather than relying is induced, impacting both high-probability actions and their\\nsolely on sampling individual actions, thus revealing vulnera- neighbors.\\nbilities that PGD struggle to defend against.\\nV. CONCLUSION\\nTo further investigate the effectiveness of the use of Bhat-\\ntacharyya distance (BD) in DAPGD, we conducted an abla- We propose DAPGD, a novel adversarial attack method\\ntion study comparing the following three alternative metrics for DRL agents. DAPGD utilizes distribution similarity and\\nKullback-Leibler Divergence (KL), Jensen-Shannon Diver- targets the entire policy distribution addressing limitations\\ngence (JS), and 2-Wasserstein Distance (WD) [51] used in of existing attacks, especially in continuous action spaces.It use Bhattacharyya distance to measure policy similarity, [18] J.Su,D.V.Vargas,andK.Sakurai,“Onepixelattackforfoolingdeep\\nenabling sensitive detection of subtle but critical differences neural networks,” IEEE Transactions on Evolutionary Computation,\\nvol.23,no.5,pp.828–841,2019.\\nbetween probability distributions. Experimental results show\\n[19] A. Modas, S.-M. Moosavi-Dezfooli, and P. Frossard, “Sparsefool: a\\nthat DAPGD outperforms the all baselines in three navigation few pixels make a big difference,” in Proceedings of the IEEE/CVF\\ntasks,achievingaverage22.03%higherrewarddropcompared conferenceoncomputervisionandpatternrecognition,2019,pp.9087–\\n9096.\\nto the best baseline. As a potential future direction, we are\\n[20] J.Pomponi,S.Scardapane,andA.Uncini,“Pixle:afastandeffective\\nlooking forward to extending our DAPGD to improve the black-box attack based on rearranging pixels,” in 2022 International\\nperformance of various applications such as large language JointConferenceonNeuralNetworks(IJCNN). IEEE,2022,pp.1–7.\\n[21] J. Sun, T. Zhang, X. Xie, L. Ma, Y. Zheng, K. Chen, and Y. Liu,\\nmodels [52]–[54], multi-modal training [55]–[58], distributed\\n“Stealthy and efficient adversarial attacks against deep reinforcement\\nmachine learning [59], [60] and autonomous driving [55], learning,” in Proceedings of the AAAI Conference on Artificial Intelli-\\n[61]–[64]. gence,vol.34,no.04,2020,pp.5883–5891.\\n[22] H.Zhang,H.Chen,D.Boning,andC.-J.Hsieh,“Robustreinforcement\\nlearning on state observations with learned optimal adversary,” arXiv\\nREFERENCES\\npreprintarXiv:2101.08452,2021.\\n[23] T. Oikarinen, W. Zhang, A. Megretski, L. Daniel, and T.-W. Weng,\\n[1] T.Xu,Y.Liang,andG.Lan,“Crpo:Anewapproachforsafereinforce-\\n“Robustdeepreinforcementlearningthroughadversarialloss,”Advances\\nmentlearningwithconvergenceguarantee,”inInternationalConference\\ninNeuralInformationProcessingSystems,vol.34,pp.26156–26167,\\nonMachineLearning. PMLR,2021,pp.11480–11491.\\n2021.\\n[2] J. Achiam, D. Held, A. Tamar, and P. Abbeel, “Constrained policy [24] Z.Lin,G.Qu,W.Wei,X.Chen,andK.K.Leung,“AdaptSFL:Adaptive\\noptimization,”inInternationalconferenceonmachinelearning. PMLR, Split Federated Learning in Resource-constrained Edge Networks,”\\n2017,pp.22–31. arXivpreprintarXiv:2403.13101,Mar.2024.\\n[3] L.Yang,J.Ji,J.Dai,Y.Zhang,P.Li,andG.Pan,“Cup:Aconservative [25] M.Hu,J.Zhang,X.Wang,S.Liu,andZ.Lin,“AcceleratingFederated\\nupdatepolicyalgorithmforsafereinforcementlearning,”arXivpreprint Learning With Model Segmentation for Edge Networks,” IEEE Trans.\\narXiv:2202.07565,2022. GreenCommun.Netw.,Jul.2024.\\n[4] H.Surmann,C.Jestel,R.Marchel,F.Musberg,H.Elhadj,andM.Ar- [26] Y. Zhang, Z. Lin, Z. Chen, Z. Fang, W. Zhu, X. Chen,\\ndani, “Deep reinforcement learning for real autonomous mobile robot J. Zhao, and Y. Gao, “SatFed: A Resource-Efficient LEO Satellite-\\nnavigation in indoor environments,” arXiv preprint arXiv:2005.13857, AssistedHeterogeneousFederatedLearningFramework,”arXivpreprint\\n2020. arXiv:2409.13503,Sep.2024.\\n[5] K.ZhuandT.Zhang,“Deepreinforcementlearningbasedmobilerobot [27] Z. Lin, G. Zhu, Y. Deng, X. Chen, Y. Gao, K. Huang, and Y. Fang,\\nnavigation:Areview,”TsinghuaScienceandTechnology,vol.26,no.5, “Efficient Parallel Split Learning Over Resource-Constrained Wireless\\npp.674–691,2021. EdgeNetworks,”IEEETrans.MobileComput.,Jan.2024.\\n[6] Z. Lin, G. Qu, Q. Chen, X. Chen, Z. Chen, and K. Huang, “Pushing [28] Z. Lin, Z. Chen, Z. Fang, X. Chen, X. Wang, and Y. Gao, “FedSN:\\nLarge Language Models to the 6G Edge: Vision, Challenges, and A Federated Learning Framework over Heterogeneous LEO Satellite\\nOpportunities,”arXivpreprintarXiv:2309.16739,Sep.2023. Networks,”IEEETrans.MobileComput.,Oct.2024.\\n[7] K. Wang, C. Mu, Z. Ni, and D. Liu, “Safe reinforcement learning [29] Y.Zhang,H.Chen,Z.Lin,Z.Chen,andJ.Zhao,“FedAC:AAdaptive\\nand adaptive optimal control with applications to obstacle avoidance Clustered Federated Learning Framework for Heterogeneous Data,”\\nproblem,”IEEETransactionsonAutomationScienceandEngineering, arXivpreprintarXiv:2403.16460,Mar.2024.\\n2023. [30] Z.Lin,W.Wei,Z.Chen,C.-T.Lam,X.Chen,Y.Gao,andJ.Luo,“Hi-\\n[8] P.Wang,R.Liu,X.Tian,X.Zhang,L.Qiao,andY.Wang,“Obstacle erarchicalSplitFederatedLearning:ConvergenceAnalysisandSystem\\navoidanceforenvironmentally-drivenusvsbasedondeepreinforcement Optimization,”arXivpreprintarXiv:2412.07197,Dec.2024.\\nlearninginlarge-scaleuncertainenvironments,”OceanEngineering,vol. [31] X. Wang, S. Wang, X. Liang, D. Zhao, J. Huang, X. Xu, B. Dai, and\\n270,p.113670,2023. Q.Miao,“Deepreinforcementlearning:Asurvey,”IEEETransactions\\n[9] O.KilincandG.Montana,“Reinforcementlearningforroboticmanip- on Neural Networks and Learning Systems, vol. 35, no. 4, pp. 5064–\\nulationusingsimulatedlocomotiondemonstrations,”MachineLearning, 5078,2022.\\npp.1–22,2022. [32] S. Huang, N. Papernot, I. Goodfellow, Y. Duan, and P. Abbeel,\\n“Adversarial attacks on neural network policies,” arXiv preprint\\n[10] A. Franceschetti, E. Tosello, N. Castaman, and S. Ghidoni, “Robotic\\narXiv:1702.02284,2017.\\narmcontrolandtasktrainingthroughdeepreinforcementlearning,”in\\n[33] Y.-C.Lin,Z.-W.Hong,Y.-H.Liao,M.-L.Shih,M.-Y.Liu,andM.Sun,\\nInternationalConferenceonIntelligentAutonomousSystems. Springer,\\n“Tactics of adversarial attack on deep reinforcement learning agents,”\\n2021,pp.532–550.\\narXivpreprintarXiv:1703.06748,2017.\\n[11] G. Ditzler, M. Roveri, C. Alippi, and R. Polikar, “Learning in non-\\n[34] T. Kailath, “The divergence and bhattacharyya distance measures in\\nstationary environments: A survey,” IEEE Computational Intelligence\\nsignal selection,” IEEE transactions on communication technology,\\nMagazine,vol.10,no.4,pp.12–25,2015.\\nvol.15,no.1,pp.52–60,1967.\\n[12] Z. Lin, G. Qu, X. Chen, and K. Huang, “Split Learning in 6G Edge\\n[35] I.J.Goodfellow,J.Shlens,andC.Szegedy,“Explainingandharnessing\\nNetworks,”IEEEWirelessCommun.,May.2024.\\nadversarialexamples,”arXivpreprintarXiv:1412.6572,2014.\\n[13] S. Padakandla, “A survey of reinforcement learning algorithms for [36] A. Madry, “Towards deep learning models resistant to adversarial\\ndynamicallyvaryingenvironments,”ACMComputingSurveys(CSUR), attacks,”arXivpreprintarXiv:1706.06083,2017.\\nvol.54,no.6,pp.1–25,2021.\\n[37] Q. Bu, D. Huang, and H. Cui, “Towards building more robust models\\n[14] H. Xu, Y. Ma, H.-C. Liu, D. Deb, H. Liu, J.-L. Tang, and A. K. Jain, with frequency bias,” in Proceedings of the IEEE/CVF International\\n“Adversarialattacksanddefensesinimages,graphsandtext:Areview,” ConferenceonComputerVision,2023,pp.4402–4411.\\nInternational journal of automation and computing, vol. 17, pp. 151– [38] J. Peng, Z. Chen, Z. Lin, H. Yuan, Z. Fang, L. Bao, Z. Song, Y. Li,\\n178,2020. J.Ren,andY.Gao,“Sums:SniffingUnknownMultibandSignalsunder\\n[15] A.Chakraborty,M.Alam,V.Dey,A.Chattopadhyay,andD.Mukhopad- LowSamplingRates,”IEEETrans.MobileComput.,Nov.2024.\\nhyay,“Asurveyonadversarialattacksanddefences,”CAAITransactions [39] H. Yuan, Z. Chen, Z. Lin, J. Peng, Z. Fang, Y. Zhong, Z. Song,\\nonIntelligenceTechnology,vol.6,no.1,pp.25–45,2021. and Y. Gao, “SATSense: Multi-Satellite Collaborative Framework for\\n[16] A. Pattanaik, Z. Tang, S. Liu, G. Bommannan, and G. Chowdhary, SpectrumSensing,”arXivpreprintarXiv:2405.15542,May.2024.\\n“Robust deep reinforcement learning with adversarial attacks,” arXiv [40] Y.Dong,F.Liao,T.Pang,H.Su,J.Zhu,X.Hu,andJ.Li,“Boosting\\npreprintarXiv:1712.03632,2017. adversarialattackswithmomentum,”inProceedingsoftheIEEEconfer-\\n[17] E. Korkmaz, “Adversarial robust deep reinforcement learning requires enceoncomputervisionandpatternrecognition,2018,pp.9185–9193.\\nredefining robustness,” in Proceedings of the AAAI Conference on [41] C.Xie,Z.Zhang,Y.Zhou,S.Bai,J.Wang,Z.Ren,andA.L.Yuille,\\nArtificialIntelligence,vol.37,no.7,2023,pp.8369–8377. “Improvingtransferabilityofadversarialexampleswithinputdiversity,”in Proceedings of the IEEE/CVF conference on computer vision and [63] S. Hu, Z. Fang, Z. Fang, Y. Deng, X. Chen, and Y. Fang, “AgentsCo-\\npatternrecognition,2019,pp.2730–2739. Driver:LargeLanguageModelEmpoweredCollaborativeDrivingwith\\n[42] J. Lin, C. Song, K. He, L. Wang, and J. E. Hopcroft, “Nesterov LifelongLearning,”arXivpreprintarXiv:2404.06345,Apr.2024.\\nacceleratedgradientandscaleinvarianceforadversarialattacks,”arXiv [64] Z. Lin, L. Wang, J. Ding, B. Tan, and S. Jin, “Channel power gain\\npreprintarXiv:1908.06281,2019. estimationforterahertzvehicle-to-infrastructurenetworks,”IEEECom-\\n[43] T.-W.Weng,K.D.Dvijotham,J.Uesato,K.Xiao,S.Gowal,R.Stan- municationsLetters,vol.27,no.1,pp.155–159,2022.\\nforth, and P. Kohli, “Toward evaluating robustness of deep reinforce-\\nmentlearningwithcontinuouscontrol,”inInternationalConferenceon\\nLearningRepresentations,2019.\\n[44] M. Fischer, M. Mirman, S. Stalder, and M. Vechev, “Online ro-\\nbustness training for deep reinforcement learning,” arXiv preprint\\narXiv:1911.00887,2019.\\n[45] H.Zhang,H.Chen,C.Xiao,B.Li,M.Liu,D.Boning,andC.-J.Hsieh,\\n“Robustdeepreinforcementlearningagainstadversarialperturbationson\\nstateobservations,”AdvancesinNeuralInformationProcessingSystems,\\nvol.33,pp.21024–21037,2020.\\n[46] R.S.SuttonandA.G.Barto,Reinforcementlearning:Anintroduction.\\nMITpress,2018.\\n[47] J. Ji, B. Zhang, J. Zhou, X. Pan, W. Huang, R. Sun, Y. Geng,\\nY. Zhong, J. Dai, and Y. Yang, “Safety gymnasium: A unified safe\\nreinforcement learning benchmark,” in Thirty-seventh Conference on\\nNeural Information Processing Systems Datasets and Benchmarks\\nTrack, 2023. [Online]. Available: https://openreview.net/forum?id=\\nWZmlxIuIGR\\n[48] J. Schulman, “Trust region policy optimization,” arXiv preprint\\narXiv:1502.05477,2015.\\n[49] H. Zhang, Y. Yu, J. Jiao, E. Xing, L. El Ghaoui, and M. Jordan,\\n“Theoretically principled trade-off between robustness and accuracy,”\\nin International conference on machine learning. PMLR, 2019, pp.\\n7472–7482.\\n[50] X. Liu, Y. Li, C. Wu, and C.-J. Hsieh, “Adv-bnn: Improved adver-\\nsarial defense through robust bayesian neural network,” arXiv preprint\\narXiv:1810.01279,2018.\\n[51] L. Ru¨schendorf, “The wasserstein distance and approximation theo-\\nrems,”ProbabilityTheoryandRelatedFields,vol.70,no.1,pp.117–\\n129,1985.\\n[52] Z. Lin, X. Hu, Y. Zhang, Z. Chen, Z. Fang, X. Chen, A. Li,\\nP. Vepakomma, and Y. Gao, “SplitLoRA: A Split Parameter-Efficient\\nFine-Tuning Framework for Large Language Models,” arXiv preprint\\narXiv:2407.00952,Jul.2024.\\n[53] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,\\nandW.Chen,“Lora:Low-rankAdaptationofLargeLanguageModels,”\\narXivpreprintarXiv:2106.09685,Jun.2021.\\n[54] Z. Fang, Z. Lin, Z. Chen, X. Chen, Y. Gao, and Y. Fang, “Automated\\nFederated Pipeline for Parameter-Efficient Fine-Tuning of Large Lan-\\nguageModels,”arXivpreprintarXiv:2404.06448,Apr.2024.\\n[55] T. Zheng, A. Li, Z. Chen, H. Wang, and J. Luo, “AutoFed:\\nHeterogeneity-Aware Federated Multimodal Learning for Robust Au-\\ntonomousDriving,”inProc.ofthe29thACMMobiCom,Jul.2023,pp.\\n1–15.\\n[56] P.Hu,Y.Qian,T.Zheng,A.Li,Z.Chen,Y.Gao,X.Cheng,andJ.Luo,\\n“t-READi: Transformer-Powered Robust and Efficient Multimodal In-\\nference for Autonomous Driving,” IEEE Trans. Mobile Comput., Sep.\\n2024.\\n[57] Z.Fang,Z.Lin,S.Hu,H.Cao,Y.Deng,X.Chen,andY.Fang,“IC3M:\\nIn-CarMultimodalMulti-objectMonitoringforAbnormalStatusofBoth\\nDriverandPassengers,”arXivpreprintarXiv:2410.02592,Oct.2024.\\n[58] Y. Tang, Z. Chen, A. Li, T. Zheng, Z. Lin, J. Xu, P. Lv, Z. Sun, and\\nY.Gao,“Merit:MultimodalWearableVitalSignWaveformMonitoring,”\\narXivpreprintarXiv:2410.00392,2024.\\n[59] Z.Wang,K.Huang,andY.C.Eldar,“SpectrumBreathing:Protecting\\nOver-the-Air Federated Learning Against Interference,” IEEE Trans.\\nWirelessCommun.,vol.23,no.8,pp.10058–10071,2024.\\n[60] Z. Lin, Y. Zhang, Z. Chen, Z. Fang, C. Wu, X. Chen, Y. Gao, and\\nJ.Luo,“LEO-Split:ASemi-SupervisedSplitLearningFrameworkover\\nLEOSatelliteNetworks,”arXivpreprintarXiv:2501.01293,Jan.2025.\\n[61] S. Hu, Z. Fang, Z. Fang, Y. Deng, X. Chen, Y. Fang, and S. Kwong,\\n“AgentsCoMerge: Large Language Model Empowered Collaborative\\nDecisionMakingforRampMerging,”arXivpreprintarXiv:2408.03624,\\nAug.2024.\\n[62] Z.Lin,L.Wang,J.Ding,Y.Xu,andB.Tan,“Trackingandtransmission\\ndesign in terahertz v2i networks,” IEEE Transactions on Wireless\\nCommunications,vol.22,no.6,pp.3586–3598,2022.',\n",
       " 'Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective.pdf': 'Rethinking Byzantine Robustness in Federated Recommendation from Sparse\\nAggregation Perspective\\nZhongjianZhang1*,MengmeiZhang2*,XiaoWang3,LingjuanLyu4\\nBoYan1,JunpingDu1,ChuanShi1†\\n1BeijingUniversityofPostsandTelecommunications,2ChinaTelecomBestpay,3BeihangUniversity,4SonyAI\\nzhangzj@bupt.edu.cn,zhangmengmei@bestpay.com.cn,xiao wang@buaa.edu.cn,lingjuan.lv@sony.com\\n{boyan,junpingdu,shichuan}@bupt.edu.cn\\nAbstract\\nTo preserve user privacy in recommender systems, feder-\\natedrecommendation(FR)basedonfederatedlearning(FL)\\nemerges,keepingthepersonaldataonthelocalclientandup- datingamodelcollaboratively.UnlikeFL,FRhasaunique sparseaggregationmechanism,wheretheembeddingofeach\\nitemisupdatedbyonlypartialclients,insteadoffullclients\\ninadenseaggregationofgeneralFL.Recently,asanessen-\\ntial principle of FL, model security has received increasing\\nattention, especially for Byzantine attacks, where malicious\\n(a)DenseaggregationingeneralFL. (b)SparseaggregationinFR.\\nclientscansendarbitraryupdates.Theproblemofexploring\\ntheByzantinerobustnessofFRisparticularlycriticalsincein\\nthedomainsapplyingFR,e.g.,e-commerce,maliciousclients\\ncanbeinjectedeasilybyregisteringnewaccounts.However,\\nexistingByzantineworksneglecttheuniquesparseaggrega-\\ntion of FR, making them unsuitable for our problem. Thus,\\nwe make the first effort to investigate Byzantine attacks on\\nFRfromtheperspectiveofsparseaggregation,whichisnon-\\ntrivial:itisnotclearhowtodefineByzantinerobustnessun-\\nder sparse aggregations and design Byzantine attacks under\\nlimited knowledge/capability. In this paper, we reformulate\\ntheByzantinerobustnessundersparseaggregationbydefin-\\ningtheaggregationforasingleitemasthesmallestexecution\\nunit.Thenweproposeafamilyofeffectiveattackstrategies,\\nnamedSpattack,whichexploitthevulnerabilityinsparseag-\\ngregation and are categorized along the adversary’s knowl-\\nedge and capability. Extensive experimental results demon-\\nstratethatSpattackcaneffectivelypreventconvergenceand\\nevenbreakdowndefensesunderafewmaliciousclients,rais-\\ningalarmsforsecuringFRsystems.\\nIntroduction\\nAs an essential way to alleviate information overload, rec-\\nommender systems are widely used in e-commerce (Ying\\netal.2018),media(Wangetal.2018;Wuetal.2019a),and\\nsocial network (Fan et al. 2019), recommending items that\\nusersmaybeinterestedin.Despitetheremarkablesuccess,\\nconventionalrecommendersystemsrequirecentrallystoring\\nusers’personaldatafortraining,increasingprivacyrisks.\\nRecently,federatedlearning(FL)(McMahanetal.2016)\\nhasemergedasaprivacy-preservingparadigmandsuccess-\\n*Theseauthorscontributedequally.\\n†Correspondingauthor.\\nCopyright©2025,AssociationfortheAdvancementofArtificial\\nIntelligence(www.aaai.org).Allrightsreserved.\\n…\\nServer Server\\n𝚯 𝐯! 𝐕\\n𝐯\"\\n∇𝚯! ∇𝚯$ ∇𝚯% ∇∇ 𝐯𝐯! #!! ∇ ∇ ∇𝐯 𝐯 𝐯! $ \"$ $ $ …∇ ∇𝐯 𝐯! #% %\\n… 𝐮! 𝐮$ …𝐮%\\n: : :\\nClient1Client2 Clientn Client1 Client2 Clientn\\nFigure 1: Comparisons between dense aggregation of gen-\\neralFLandtheuniquesparseaggregationofFR.\\nfullyappliedtotherecommendationarea.Infederatedrec-\\nommendation (FR) (Sun et al. 2024; Luo, Xiao, and Song\\n2022),theglobalitemembeddingsareuploadedtoacentral\\nserver for aggregation. Meanwhile, each user’s interaction\\ndataandprivacyfeaturesarekeptonthelocalclient.Inthis\\nway,theprivacyoflocaldataiswellprotected.\\nUnlike general FL systems, FR has a unique sparse ag-\\ngregation mechanism. As shown in Fig. 1, for general FL,\\neach element (circle) of model parameters can be updated\\nby all n clients, named dense aggregation. While for FR,\\nthe interactions of users and items are usually sparse (Ma\\netal.2008),resultingineachitem’sembeddingcanonlybe\\nupdated by partial clients. For example, client n can only\\nproduceandsendsubstantivegradients{∇vn,∇vn}forits\\n1 3\\ninteracted items {v ,v }. For the remaining items, the up-\\n1 3\\ndatesarezerovectorsorempty,namedsparseaggregation.\\nBy far, FR has provided satisfactory performance with-\\nout collecting users’ private data, extending recommenda-\\ntionapplicationstoprivacy-sensitivescenarios.Despitesuc-\\ncess, the model security, as an essential principle, has re-\\nceivedincreasingattention.Hereweconsidertheworst-case\\nattack,i.e.,Byzantineattack(Fangetal.2024,2019;Blan-\\nchardetal.2017a),whereattackersareomniscientandcol-\\nlusive, and can control several clients to upload arbitrary\\nmalicious gradients. Note that Byzantine robustness is es-\\npecially critical for FR, since in the domains applying FR,\\ne.g.,e-commerce,maliciousclientscanbeinjectedeasilyby\\nregisteringnewaccounts.Thisraisesonequestionnaturally:\\nWiththeuniquesparseaggregations,howrobustthefeder-\\natedrecommendationmodelisagainstByzantineattacks?\\nForthisquestion,existingByzantineworkscannotbedi-\\n5202\\nnaJ\\n8\\n]RC.sc[\\n2v10330.1052:viXrarectly employed, since they mainly focus on dense aggre- alongattacker’sknowledgeandcapability.\\ngation in general FL (Rodr’iguez-Barroso et al. 2022; Xu (3)Weperformexperimentsonmultiplebenchmarkdatasets\\netal.2021;Blanchardetal.2017b).Despiteafewpriorat- for different FR systems. The results show that our Spat-\\ntacksagainstFRemerges(Yuanetal.2023;Yuetal.2023; tackcanpreventtheconvergenceofvanillaevendefenseFR\\nRongetal.2022;Wuetal.2022),theyalsoneglecttoana- modelsbyonlycontrollingafewmaliciousclients.\\nlyzehowthesparseaggregationaffectstherobustnessofFR.\\nWeanswerthisproblembysolvingtwochallenges:(1)How BackgroundandPreliminary\\nto define Byzantine robustness under sparse aggregations?\\nExistingByzantineattacksanddefensesaremainlydefined CentralizedRecommendation\\nbased on the dense aggregation mechanism in the general\\nHere, a recommender system contains a set of users U =\\nFL.InFR,duetosparseuser-iteminteraction,foranitem,its\\n{u ,··· ,u }andasetofitemsV = {v ,··· ,v },where\\nembeddingisupdatedonlybyitsinteractedusers,andthere- 1 n 1 m\\nn and m are the numbers of users and items, respectively.\\nmainingusersuploadzero-valuedoremptyupdates.Sothe\\nEachuseru ∈U hasalocaltrainingdatasetD ,consisting\\naggregated item embedding may be skewed towards zero- i i\\nofimplicitfeedbacktuples(u ,v ,r ).Thesetuplesrepre-\\nvalued when directly applying existing dense aggregators, i j ij\\nsentuser-iteminteractions(e.g.,purchased,clicked),where\\nsincethezero-valueupdateismajority.Hence,itisvitalto\\nr =1andr =0indicatepositiveandnegativeinstances,\\ntransferthemintoFRandre-examinetheirtheoreticalguar- ij ij\\nrespectively, i.e., whether u interacted with v . For each\\nantee and effectiveness. (2) How to design general Byzan- i j\\nuseru ,wedefineV ={v ∈V|(u ,v ,r )∈D }asthe\\ntineattacksagainstFRforattackerswithdifferentlevelsof i ui j i j ij i\\nsetoftheitemsthatinteractwithu .LetU =[u ,··· ,u ]\\nknowledgeandcapabilityinreality.Specifically,itishardto i 1 n\\nandV =[v ,··· ,v ]denotetheembeddingsofusersand\\nhavefullknowledgeofallusers,duetothelargenumberof 1 m\\nitems, respectively. The recommender system is trained to\\nparticipating users in FR. Besides, since user-item interac-\\npredict the rating score rˆ = f (u ,v ) between u and\\ntionsareusuallysparse,Byzantineclientsshouldnotupdate ij Θ i j i\\nv , where rˆ represents how much u likes v , f is the\\ntoomanyitems.Otherwise,amonitorbasedonthenumber j ij i j Θ\\nscorefunction,{U,V,Θ}arelearnableparameters.Then,\\nof user interactions can be triggered easily under such ag-\\nthesystem recommendsanitem listforeach userthat they\\ngressivemodifications(Wuetal.2022).\\nmightbeinterestedinbysortingtheratingscores.Intradi-\\nIn this paper, we make the first effort to investigate the\\ntional centralized training, the personal dataset D of each\\ni\\nByzantinerobustnessoffederatedrecommendationfromthe\\nuseru isstoredonacentralserver,yieldingatotaldataset\\ni\\nperspective of sparse aggregations. For the first challenge,\\nDformodeltraining,whichwillincreasetheprivacyrisks.\\nwe transfer the existing aggregators to FR by treating the\\naggregationforasingleitemasthesmallestexecutionunit.\\nFederatedRecommendation\\nNamely, for each item embedding, the gradients are col-\\nlected and aggregated separately and concurrently. Based Considering privacy issues, in FR, the privacy data D of\\ni\\non this, we further point out that such a sparse aggregation user u is kept on the local device. The shared model pa-\\ni\\nmechanism of FR will lead to a unique Byzantine vulnera- rameters V and Θ are aggregated over clients by sending\\nbility:itemswithdifferentdegreesreceivedifferentamounts thelocalgradientstoacentralserver.Accordingtothebase\\nofupdates,leadingtoindividualrobustness.Thedegreesof recommender,theparametersΘaredifferent:inMatrixFac-\\nall items usually meet long tail distribution in reality (Ab- torization(MF)recommendermodels,theinteractionfunc-\\ndollahpouri,Burke,andMobasher2019),wheremostitems tionisfixedand Θ isanemptyset. Indeeplearning-based\\n(namedtaileditems)areonlyinteractedwithbyafewusers, recommendermodels,Θisthesetofweightsofneuralnet-\\nmaking them extremely fragile. For the second challenge, works. Following (Rong et al. 2022), we adopt the classic\\nwe design a series of attack strategies, named Spattack, and widely used MF as the base recommender for simplic-\\nbased on the vulnerability from sparse aggregation in FR. ity,wheref isfixedtobedotproduct,i.e.,rˆ = u ⊙v .\\nij i j\\nThenwecategorizethemalongtheattacker’sknowledgeand Following (Rong et al. 2022), we take Bayesian Personal-\\ncapability into four classes. To be specific, following (Xie, izedRanking(BPR)(Rendleetal.2009),apairwiseperson-\\nKoyejo,andGupta2020;Fangetal.2019;Baruch,Baruch, alizedrankingloss,asthelocallossofeachclient:\\nand Goldberg 2019), we consider both omniscient attacker\\n(cid:88)\\n(Spattack-O)andlimitednon-omniscientattacker(Spattack- L (u ,V)=− lnσ(rˆ −rˆ ), (1)\\ni i ij ik\\nL).Thenwefurtherdividethemdependingonwhetherlim-\\niting the maximum number of each client’s poisoned items riv jj =, 1vk ∧∈ rV iku =i 0\\nornot.Insummary,ourcontributionsarethreefolds:\\n(1) We first systematically study the Byzantine robustness where σ is the logistic sigmoid function. It assumes that\\nofFRfromtheperspectiveofuniquesparseaggregation,by the user prefers the positive items over all negative items.\\ntreatingtheaggregationforasingleitemasthesmallestex- In each training iteration, the central server sends the cur-\\necutionunit.Wetheoreticallyanalyzeitsconvergenceguar- rent item embeddings Vt to all clients. For each user u i,\\nanteeandpointoutaspecialvulnerabilityofFR. theclientcomputeslossL i(ut i,Vt)thenlocallyupdatesits\\n(2)Weproposeafamilyofeffectiveattackstrategies,named privateuserembeddingatepochtasfollows:\\nSpattack,utilizingthevulnerabilityfromsparseaggregation.\\nut+1 ←ut−η·∇ut, (2)\\nThen Spattack can be categorized into four different types i i iHeadItems TailedItems\\n(b)Our Byzantine attack against FR.\\n…\\n…\\nServer\\nServer\\n𝐯 ! 𝐕 𝐯\\n𝚯 %\\n𝐯\\n\"\\nRobustAGR RobustAGRfor𝐯 ! RobustAGRfor𝐯 %\\n97%Items\\n∇𝚯! ∇𝚯$ ∇𝚯*! ∇𝚯*$( ∇𝐯 !! ∇𝐯 !$ ∇𝐯% !! ∇𝐯% #&’\\n∇𝐯 #! ∇𝐯 %$ ∇ 𝐯% %! ∇𝐯% \"&’\\n… … 𝐮 ! … 𝐮 $ 𝐮& ! …𝒖& &’\\n: :\\nHeadItems TailedItems\\nBenignClients FewMaliciousClients BenignClients FewMaliciousClients\\n(a)Existing Byzantine attack againstgeneral FL. (c)Itempopularity of Steamdataset.\\nFigure 2: Analysis of Byzantine robustness in general FL and FR. Under Byzantine attacks, a robust aggregator can filter\\noutliersingeneralFL,butfailstodefendfortaileditems’embedding.\\nwhereη isthelearningrate.Thenu uploadsitslocalitem than 0.5, the Median aggregator can guarantee the model\\ni\\nembedding gradients ∇Vi,t to a central server. After col- convergence under Byzantine attacks, yielding the correct\\nlectinggradientsfromallclients,theserverupdatesVtby: gradient(greenstar)inFig.2(a).\\n(cid:88)\\nVt+1 ←Vt−η· ∇Vi,t. (3) Methodology\\ni∈[n] In this section, we re-define the Byzantine robustness un-\\nAsshowninFig.1(b),foreachuseru ,theprivateinterac- dersparseaggregationofFR,andtheoreticallypointoutthe\\ni\\ntionhistory(itemlist)anduserembedding(greenu vector) inherentvulnerability.Basedonsuchvulnerabilityandcon-\\ni\\nis preserved on the local client device, and only the gradi- sidering attackers’ knowledge and capability, we design a\\nentsofitemembeddingsV aresent.Throughoutthetraining familyofattackstrategies,namedSpattack.\\nstage,allusers’privacyiswellprotected.\\nProblemDefinition\\nByzantineAttackandDefense For Byzantine attacks, attackers can inject some Byzan-\\nByzantineAttack.InByzantineattacks,theattackeraimsto tine users U˜ = {u˜ ,··· ,u˜ }, limiting the proportion\\n1 n˜\\ndegrade model performance and even prevent convergence of malicious ones less than ρ, i.e., n˜/(n + n˜) < ρ. A\\nbycontrollingafewmaliciousclients.AsshowninFig.2(a), malicious client u˜ can upload arbitrary gradient values\\ni\\nmalicious client u˜\\ni\\nis allowed to send arbitrary (red) gradi- ∇V˜i,t\\nat any epoch t, to directly perturb the item em-\\nent\\n∇Θ˜i\\n. Following existing Byzantine attack studies (Xu bedding. The server will collect and aggregate all gradi-\\netal.2021;Fangetal.2019;Baruch,Baruch,andGoldberg entsincludingbenign{∇V1,t,··· ,∇Vn,t}andmalicious\\n2019),consideringtheworstcase,weassumeattackershave {∇V˜1,t\\n,···\\n,∇V˜n˜,t\\n}. Let AGR(·) be the aggregation op-\\nfull knowledge of all benign gradients {∇Θ1,··· ,∇Θn}\\neratoroffederatedlearning,whichcanbethemostcommon\\nandallthemaliciousclientsarecollusivebydefault,which\\nMEAN(·)orstatisticallyrobustMEDIAN(·).OurByzantine\\nhelptounderstandtheseverityofmodelpoisoningthreats.\\nattackeraimstopreventmodelconvergence,namely,keep-\\nByzantine Defense. Since servers have no access to the\\ningtherecommendationlossL fromdecreasing.Formally,\\ni\\nraw training data of clients, the defense is generally im-\\ninFR,theobjectiveoftheByzantineattackisdefinedasthe\\nplemented on the server side as a robust aggregator, which\\nfollowingoptimizationproblem:\\ncan filter Byzantine updates and guarantee model con-\\nvergence. As shown in Fig. 2(a), let {∇Θ1,··· ,∇Θn} max (cid:88)n (cid:0) L (ut+1,Vt+1)−L (ut,Vt)(cid:1) ,\\nbe the gradient vectors of n benign clients in FL. The i i i i\\n{∇V˜t:i∈n˜}\\nserver collects and aggregates the training gradient of i i=1\\neach client model using a federated aggregator. In non- s.t.Vt+1 =Vt−η·AGR({∇Vi,t :i∈[n]}\\nr Mob Eu Ast N(F ∇L Θs 1e ,t ·ti ·n ·g ,s ∇, Θco no )rd =ina 1te (cid:80)-w nise ∇M Θea in isi an\\nn\\nf eo ffr em ctivo ef ∪{∇V˜i,t\\n:i∈[n˜]}),\\naggregation rule. However, MEn ANi= ca1 n be manipulated by ut+1 =ut−η∇ut, fori∈[n],\\ni i i\\nseveral malicious clients (Blanchard et al. 2017b). There- n˜\\nfore,multiplerobustaggregators(Yinetal.2018;Blanchard ≤ρ, (4)\\nn+n˜\\netal.2017b;Xuetal.2021)areproposedtofiltertheByzan-\\nwhereattackersaimtofindtheoptimalsetofmaliciousgra-\\ntineupdates.Forexample,coordinate-wiseMedianaggrega-\\ntor computes the median for each element Θ in parameter\\ndients{∇V˜t\\n:i∈[n˜]},toraisethelossafterupdating.Be-\\ni i\\nΘacrossallclients,yielding0.5breakdownpoint(Yinetal. foresolvingthisoptimizationproblem,wefindthatFRhas\\n2018).Namely,whenthefractionofmaliciousclientsisless auniquesparseaggregationmechanismdefinedasfollows:Definition1. (Dense/SparseAggregation).Letθ ∈ Rd be modelshaveaconsistentlyhighbreakdownpoint,e.g.,when\\nthesharedmodelparametervector.Ifthereexistsanelement ρ < 50%, Median can theoretically guarantee the conver-\\nθ (i ∈ [d]) for which only a subset of clients can produce gence of FL as proved in (Yin et al. 2018). However, we\\ni\\nvaluableupdates,theparameterθissparselyaggregated.If findthatFRmodelshavevariedbreakdownpointsfordiffer-\\nallclientscansupportit,itisadenseaggregation. entitems,whichdependsontheitem’sdegree.Specifically,\\neachitemembeddingcanonlybeupdatedbyspecificclients\\nAsshowninFig.2(a),ingeneralFL,eachelement(green\\nwith whom the item interacts. Obviously, the popular item\\ncircle)ofmodelparametersΘisassumedtobeinvolvedin\\nwith massive updates is more robust. Unfortunately, in FR,\\nall clients’ loss functions, i.e., dense aggregation. Different\\nonlyafewitemsinteractfrequently(headitems),whilethe\\nfromFL,foraclientu inFR,notallitemembeddingsV =\\ni\\nremaining items interact less frequently (tailed items). We\\n{v ,··· ,v } are employed in local loss L in Eq. 1, i.e.,\\n1 m i\\nplotthepopularity(itemdegree)oftheSteamrecommenda-\\nsparseaggregation.Forexample,clientu inFig.2(b)only\\n1\\ncomputes valuable gradients {∇v1,∇v1} for items v and tiondataset(Cheuque,Guzma´n,andParra2019)inFig.2(c).\\n1 3 1 Wefindthat97%taileditems(redlongtailarea)haveinter-\\nv , while the gradients for the remaining items are either\\n3\\nactionslessthan200times,andonly3%headitems(green\\nzerooranemptyset.Whendirectlyapplyingtheaggregators\\narea)interactfrequentlyover200times.Therefore,existing\\nonallV ,theembeddingwillbeskewedtowardszerovalue.\\ni\\nstatistically-basedFLdefenseswillfailtoguaranteethecon-\\nTherefore,weneedtoadaptthemtoFR.\\nvergenceofmostitems.Formally,letxbethedegreeofan\\nAdaptingDenseAggregatortoSparse.Weadaptexist-\\nitemandp(x)beitsprobability.Weassumethattheproba-\\ningaggregatorsfromdensetosparseaggregationbytreating\\nbilitydistributioncanbedefinedasatypicalpower-lawdis-\\nthe aggregation for a single item as the smallest execution\\ntribution p(x) = Cx−β, where C is a normalization con-\\nunit.AsshowninFig.2(b),theaggregatorisconductedsep-\\nstantandβ isthescalingparameter.Thefailureofdefenses\\naratelyforeachitem.Takingtheembeddingofj-thitemas\\ncanbeformallycharacterizedasfollows:\\nanexample,theembeddingisupdatedby:\\nvt+1 =vt −η·AGR({∇vi,t|useri∈U }), (5) Proposition 2. Let α be the breakdown point of robust\\nj j j vj federated aggregator, the amount of benign and malicious\\nwhereU isthesetofusersthattheitemv interactswith, clients are n and n˜ respectively, and β is the scaling pa-\\nvj j\\n∇vi,t isthegradientofitemv sentfromclientu atepoch rameterofthepower-lawdistributionofitems’degreewith\\nj j i constant C. Then at least 1− C (1−αn˜)(1−β) percent of\\nt.Onlyiftheuseru ihasinteractionwithitemv j,thegradi- β−1 α\\nents∇vi,tcanbeaggregatedtovt+1separatelyandconcur- items’embeddingscanbebrokendown.\\nj j\\nrently.Intuitively,thenumbersofreceivedgradientsarevar- TheproofofProposition2referstotheAppendix.Taking\\niedfordifferentitems,leadingtoeachitemhavingpersonal the Steam dataset as an example, the degree distribution of\\nrobustness. Therefore, we need to theoretically re-examine itemscanbemodeledasatypicalformofpower-lawdistri-\\nthe convergence guarantee of existing aggregators against butionasshowninFig.2(c).Forexample,ifanattackercan\\nByzantineattacksunderthesparseaggregation. controlρ=5%clients,eachitemcanreceive197malicious\\ngradientsatmost.Clearly,for97%taileditemsthatinteract\\nByzantineRobustnessAnalysis\\nlessthan200times,fewmalicious(red)updatescanbecome\\nRobustness of FR without Defense. Like general FL, FR themajorityanddominatetheaggregation.Inthiscase,the\\nwithoutdefenseoftenusestheMeanaggregatortocompute statistically robust Median aggregator will pick the major-\\nthe average of input gradients, which is highly susceptible ity(redcircles),yieldingthemaliciousoutput(redstar).In\\ntoByzantineattacks.Evenonemaliciousclientcanalsode- conclusion, due to the sparse aggregation vulnerability of\\nstroytheMeanaggregatorasstatedinProposition1. FR,statisticallyrobustaggregatorsinFLcanalsobeeasily\\nProposition1. Foreachitemv ,let{∇vi,t|useri ∈ U } brokendownbyByzantineattacker.\\nj j vj\\nbethesetofbenigngradientvectorsatepocht.Considera\\nMean aggregator averaging updates for each element. Let Spattack:ByzantineAttackStrategies\\n∇v˜ be a malicious update with arbitrary values in Rd.\\nj Intuition.InEq.4,theattackeraimstokeeptherecommen-\\nThe output of MEAN({∇vi j,t|useri ∈ U vj} ∪ ∇v˜ j) = dation loss from decreasing to prevent recommender con-\\n1 ((cid:80) ∇vi,t + ∇v˜ ) can be controlled as zero vergence.Consideringtheuniquevulnerabilityfromsparse\\n|Uvj|+1 i∈Uvj j j\\naggregation, i.e., the majority of tailed items have a lower\\nvectorbyonlysinglemalicious∇v˜ .Whenalltheitemsare\\nj breakdown point, we can conclude that: (1) The gradients\\nattacked,onemaliciousclientcanpreventconvergence.\\narefartherawayfromtruegradients,themoreconsiderable\\nProof. If the attacker registers one malicious client, where corruption is. (2) More items are disrupted in the training\\nthe embedding gradient of each item v is ∇v˜ = process,leadingtomorepowerfulattacks.Therefore,theat-\\nj j\\n−(cid:80) ∇vi,t, the output of aggregator is zero vector, tackobjectiveoftheproposedSpattackcanbesimplifiedto\\ni∈Uj j maximally uploading gradients farther away from true gra-\\nwhichcanpreventconvergence.\\ndientsandgreedilydisruptingtheembeddingsofitems.\\nRobustnessofFRwithDefense.Themostcommonde- Attack Taxonomy. In real scenarios, depending on the\\nfensemethodistouseaggregatorsthatarestatisticallymore attacker’s knowledge about benign gradients and the maxi-\\nrobust against outliers than Mean. In these defenses, FL mumnumberofpoisoneditemsineachmaliciousclient,weTable 1: Attack Taxonomy. For each malicious client in Table2:Statisticsofdatasets.\\nSpattack,knowledgemeansknowingbenigngradients,and\\nDataset #Users #Items #Edges Sparsity\\ncapabilityreferstopoisoningallitems.\\nML100K 943 1,682 100,000 93.70%\\nSpattack O-D O-S L-D L-S ML1M 6,040 3,706 1,000,209 95.53%\\nKnowledge Steam 3,753 5,134 114,713 99.40%\\nCapability\\nExperiment\\noutlinedifferentscenariosofSpattackthatcanbelaunched.\\nWe conduct extensive experiments to answer the follow-\\nAsshowninTab.1,wehavefourpossiblescenarios:\\ning research questions. RQ1: How does Spattack perform\\nSpattack-O-D is considered a worst case, where the at- comparedwithexistingByzantineattacks?RQ2:CanSpat-\\ntackerisbothomniscientandomnipotent,i.e.,attackerscan tack break the defenses deployed on FR? RQ3: Can Spat-\\nobtain benign gradients at each epoch and the maximum tacktransfertodifferentFRsystems?RQ4:Howdohyper-\\nnumberofpoisoneditemsisnotlimited.Followingthefirst parameters impact on Spattack? Given the limited space,\\nintuitionthatthemaliciousgradientsfartherawayfromtrue pleaserefertotheAppendixformoredetailedexperiments.\\ngradients can cause larger corruption, attackers upload the\\ngradients in the opposite direction of the benign ones. For- ExperimentalSetup\\nmally,foraitemv ,wecollectbenigngradient∇vi,t from\\nj j DatasetsandFederatedRecommenderSystems.Follow-\\nu , where u interacts with v , i.e., u ∈ U . Then we\\ni i j i vj ing(Rongetal.2022),Spattackisevaluatedonthreewidely\\ncompute the sum of the collected benign gradients to ob-\\nused datasets, including movie recommendation datasets\\ntain the expected gradient ∇v¯t = (cid:80) ∇vi,t. Lastly, ML1MandML100K(HarperandKonstan2016),andgame\\nj ui∈Uvj j\\neach malicious client u˜ ∈ U˜ will upload malicious gradi- recommendation dataset Steam (Cheuque, Guzma´n, and\\ni\\nParra 2019). The dataset statistics refer to Tab. 2. The test\\nents∇v˜i,t =− 1 ∇v¯t.Followingthesecondintuitionthat\\nj |U˜| j setisdividedwiththeleave-one-outmethod,wherethelat-\\ngreedilydisruptsitems,theattackeffectivenesswillbemax- estinteractionofauserisleftasthetestsetandtheremain-\\nimizedbyuploadingpoisoninggradientsforallitems.Inthis inginteractionsasthetrainingset.FedMF(Rongetal.2022)\\nattack,thenon-robustMeanaggregatorwilloutputzerogra- andtheSOTAFedGNN(Wuetal.2021)areselectedaseval-\\ndients,whilestatisticallyrobustaggregatorswillselectma- uation models. More dataset and reproducibility details are\\nliciousgradientsforthemajorityoftaileditems,preventing intheAppendix.\\ntheconvergenceofitemembeddings.AccordingtoProposi- Evaluation Protocols. We utilize two common evalua-\\ntion 1 and Proposition 2, even only having a small portion tionprotocols,includinghitratio(HR)andnormalizeddis-\\nofmaliciousclients,Spattack-O-Dcanstillguaranteetodis- countedcumulativegain(nDCG)atranks5and10.Foreach\\nruptthemajorityofitemembeddings. user, since ranking the test item among all items is time-\\nSpattack-L-Duploadsrandomnoiseasmaliciousgradi- consuming, following the widely-used strategy (He et al.\\nents for all items, where attackers are non-omniscient but 2017), we randomly sample 100 items that do not interact\\nomnipotent,i.e.,attackersdonothaveanyknowledgeabout withthe user,thenrank thetestitem amongthe100 items.\\nthe benign gradients but can attack all items. Specifically, Notably,allmetricsareonlycalculatedonbenignclients.\\nattackersconstructthemaliciousgradientbyrandomlysam- Baselines. We compare Spattack with two categories of\\nplingfromtheGaussiannoiseandkeepingthesamenoisein methods. First is the data poisoning attack, where attack-\\nallmaliciousclients.UndertheMeanaggregator,theaggre- ersgeneratemaliciousgradientsbymodifyingtrainingdata.\\ngated gradients can be skewed by such noise. Even worse, LabelFlip(Tolpeginetal.2020)flipstraininglabelsforpoi-\\nthe statistically robust aggregators, e.g., Median, can pick soning, while FedAttack (Wu et al. 2022) uses misaligned\\ntheuploadedrandomnoiseasoutputfortaileditems.Sothis samples. Second is model poisoning attacks, where attack-\\nattackcanstillpreventmodelconvergence. ersdirectlymodifytheuploadedgradients.Gaussian(Fang\\nSpattack-O-S and Spattack-L-S only upload mali- et al. 2019) estimates the Gaussian distribution of benign\\ncious gradients for partial items, where attackers are non- gradients and then samples from it. LIE (Baruch, Baruch,\\nomnipotent. Let m˜ be the maximum number of poi- and Goldberg 2019) adds small amounts of noise towards\\nmax\\nsoneditemsineachmaliciousclient.Thelargerm˜ ,the theaverageofbenigngradients.Cluster(Yuetal.2023)up-\\nmax\\nstrongertheattack,buttheexcessivem˜ mayleadtothe loadsmaliciousgradientsthataimtomakeitemembeddings\\nmax\\nattack being detected. To limit malicious users to behaving collapseintoseveraldenseclusters.Fang(Fangetal.2019)\\nlike benign users, we restrict m˜ as the maximum num- addsnoisetooppositedirectionsoftheaveragenormalgra-\\nmax\\nber of interactions in benign clients. Specifically, to make dient.MoredetailscanbefoundintheAppendix.\\nthe injections of malicious clients as imperceptible and ef- ByzantineDefenseStrategies.WeevaluateSpattackper-\\nfectiveaspossible,basedonthedistributionofitempopular- formanceunderthefollowingdefensestrategies:Meanisthe\\nity,weuseasamplingoperationtodeterminethepoisoned vanillanon-robustaggregatorthatcomputesthemeanvalue\\nitems for each malicious client. Therefore, the attacker can ofgradientsforeachdimension.Median (Yinetal.2018)is\\nautomatically assign more malicious gradients to the items astatisticallyrobustaggregatorwitha0.5breakdownpoint,\\nhavingmoreinteractions.Thenwegeneratemaliciousgradi- computing the element-wise median value. Trimmed-mean\\nentsbasedontheoppositebenigngradients(Spattack-O-S) (Yin et al. 2018) trims several extreme values for each di-\\norrandomnoise(Spattack-L-S),respectively. mensionandthenaveragestherest.Krum (Blanchardetal.Table3:ComparisonofSpattackwithbaselinesundera3%maliciousrate.Lowerscoresrepresentbetterattackeffectiveness.\\nWeadditionallyreporttheperformancedrop(%)comparedwiththeperformanceonthecleanmodel.\\nDataset Metric Clean LabelFlip FedAttack Gaussian LIE Cluster Fang TypeL-S TypeL-D TypeO-S TypeO-D\\n0.2517 0.2550 0.2550 0.2539 0.2461 0.1957 0.1018 0.0721 0.0594 0.0530\\nHR@5 0.2513\\n(-3%) (-2%) (-2%) (-2%) (-5%) (-25%) (-59%) (-71%) (-76%) (-79%)\\n0.1706 0.1721 0.1729 0.1724 0.1678 0.1229 0.0620 0.0380 0.0362 0.0339\\nnDCG@5 0.1643\\n(-3%) (-2%) (-1%) (-2%) (-4%) (-30%) (-62%) (-77%) (-78%) (-79%)\\nML100K\\n0.4083 0.4094 0.4116 0.4116 0.3982 0.2919 0.2163 0.1601 0.0997 0.0944\\nHR@10 0.4051\\n(-2%) (-2%) (-2%) (-2%) (-5%) (-30%) (-47%) (-60%) (-75%) (-77%)\\n0.2206 0.2213 0.2230 0.2229 0.2166 0.1541 0.0980 0.0658 0.0492 0.0470\\nnDCG@10 0.2131\\n(-2%) (-2%) (-1%) (-1%) (-4%) (-32%) (-54%) (-69%) (-77%) (-78%)\\n0.3051 0.3056 0.3053 0.3054 0.3033 0.2827 0.1007 0.0921 0.0925 0.0907\\nHR@5 0.3121\\n(-1%) (-1%) (-1%) (-1%) (-2%) (-9%) (-68%) (-71%) (-70%) (-71%)\\n0.2013 0.2021 0.2017 0.2018 0.2004 0.1858 0.0581 0.0521 0.0553 0.0549\\nnDCG@5 0.2054\\n(-2%) (-1%) (-1%) (-1%) (-2%) (-9%) (-72%) (-75%) (-73%) (-73%)\\nML1M\\n0.4632 0.4634 0.4634 0.4634 0.4592 0.3977 0.2141 0.1935 0.1753 0.1679\\nHR@10 0.4626\\n(-1%) (-1%) (-1%) (-1%) (-2%) (-15%) (-54%) (-58%) (-62%) (-64%)\\n0.2522 0.2528 0.2526 0.2526 0.2506 0.2231 0.0939 0.0846 0.0817 0.0793\\nnDCG@10 0.2539\\n(-1%) (-1%) (-1%) (-1%) (-2%) (-12%) (-63%) (-67%) (-68%) (-69%)\\n0.4792 0.4798 0.4879 0.4862 0.4263 0.0278 0.0426 0.0139 0.0671 0.0685\\nHR@5 0.5729\\n(-15%) (-15%) (-14%) (-14%) (-25%) (-95%) (-93%) (-98%) (-88%) (-88%)\\n0.3157 0.3172 0.3216 0.3209 0.2750 0.0160 0.0261 0.0080 0.0390 0.0408\\nnDCG@5 0.3815\\n(-17%) (-16%) (-15%) (-15%) (-27%) (-96%) (-93%) (-98%) (-90%) (-89%)\\nSteam\\n0.6429 0.6431 0.6474 0.6471 0.6220 0.0619 0.0834 0.0322 0.1308 0.1287\\nHR@10 0.6933\\n(-7%) (-7%) (-6%) (-6%) (-10%) (-91%) (-88%) (-95%) (-81%) (-81%)\\n0.3685 0.3700 0.3732 0.3730 0.3386 0.0269 0.0391 0.0138 0.0593 0.0601\\nnDCG@10 0.4207\\n(-12%) (-12%) (-11%) (-11%) (-19%) (-94%) (-91%) (-97%) (-86%) (-86%)\\n2017b)picksthegradientthatisthemostsimilartootherup- Mean, Median and Norm aggregators for all attacks. Since\\nloaded gradients. Norm (Suresh et al. 2019) clips the norm TrimMandKrumassumethenumberofmaliciousupdates\\nofgradientswithagiventhreshold. isfixedforeachitem,butSpattack-O/L-Suploadsdifferent\\nnumbers of updates for each item, making them cannot be\\nAttackPerformanceEvaluation(RQ1) applied.AsshowninFig.3,moreresultsandanalysisarein\\nWe compare the proposed Spattack against existing SOTA theAppendix.Wehaveobservationsasfollows:\\nattackbaselinesunder3%maliciousratio.Theexperimental • With only 5% malicious clients, Spattack can dramati-\\nresultsarereportedinTab.3,wefind: cally degrade recommendation performance and even pre-\\n•SpattackcanpreventFRconvergencebycontrollingafew vent convergence. The explanation is that different items\\nmaliciousclients.Forexample,Spattackcanachievea47%- have varied amounts of updates, and the defense of tailed\\n98%performancedropunder3%maliciousclients,demon- itemscanbemoreeasilybrokenthanheaditems.\\nstratingthatFRisextremelyvulnerabletoSpattack. •Whentheattacker’sknowledgeandcapabilityarelimited,\\n•Spattacksignificantlyoutperformsotherbaselines.Theex- withtheincreasingmaliciousratioρ,theperformanceofde-\\nplanation is that Spattack fully utilizes the sparse aggrega- fenseFRconsistentlydecreasesevenreachinganuntrained\\ntion vulnerability by greedily breaking more items. Specif- model.Theresultsalsodemonstratethathidingthegradients\\nically, LabelFlip and FedAttack only indirectly manipulate ofbenignclientscannotprotectFR,becausetheattackercan\\nthe gradient by modifying data, while LIE, Cluster and breakthedefenseusingonlyrandomnoise.\\nFangdirectlymanipulatethegradientsandthuscanachieve\\nhigherattackimpacts.AlthoughFangalsoperturbsinoppo- TransferabilityofAttack(RQ3)\\nsite directions of benign gradients, the malicious gradients TodemonstratethegeneralizabilityofSpattacktootherfed-\\nareskewedtozerovectorwithoutconsideringthesparseag- erated recommender systems, we perform Spattack on the\\ngregationofFR,leadingtolesseffectiveattacks. SOTAFedGNN(Wuetal.2021)byextrauploadingthema-\\n•TheresultsonSteamoveralldropmorethanML100Kand licious gradients of the GNN model. No Defense and De-\\nML1M. A possible reason is that Steam involves fewer in- fense correspond to mean and median aggregators, respec-\\nteractions on average (referring to the sparsity in Tab. 2), tively.Themaliciousratioρissetto10%.Pleaserefertothe\\nmeaningtherearemoretaileditems,whichmakesthemodel Appendixformoreresultsandanalysis.AsshowninFig.4,\\nmoresusceptibletoattacks. wehavethefollowingobservations:\\n• The performance of FedGNN dramatically drops un-\\nAttackEffectivenessunderDefense(RQ2)\\nder Spattack, demonstrating the common vulnerability of\\nWealsoevaluatetheeffectivenessofSpattackunderdiffer- FedMFandFedGNN.EventhoughtheparametersofGNN\\nentdefenses.Wesetmaliciousratioρas1%,3%and5%for aredenselyaggregated,theattackercanstillpreventconver-\\nomniscientSpattack-O,andsetthehigher5%,10%and15% genceofmodeltrainingbypoisoningitemembeddings.\\nforthehardernon-omniscientSpattack-L.WeequipFRwith •Spattackcanachievemoreeffectiveattacksunderdefense.\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x000\\x00H\\x00D\\x00Q\\n\\x000\\x00H\\x00G\\x00L\\x00D\\x00Q \\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x001\\x00R\\x00U\\x00P \\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x007\\x00U\\x00L\\x00P\\x000 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00.\\x00U\\x00X\\x00P \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(a) Steam(Spattack-O-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(b) Steam(Spattack-O-S)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(c) Steam(Spattack-L-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(d) Steam(Spattack-L-S)\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(e) ML100K(Spattack-O-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(f) ML100K(Spattack-O-S)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(g) ML100K(Spattack-L-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(h) ML100K(Spattack-L-S)\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x08 \\x00\\x16\\x00\\x08 \\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(i) ML1M(Spattack-O-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(j) ML1M(Spattack-O-S)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(k) ML1M(Spattack-L-D)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(l) ML1M(Spattack-L-S)\\nFigure3:PerformanceofSpattackagainstmultipledefensestrategiesunderdifferentratiosofByzantineclients.\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00$\\x00W\\x00N\\n\\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x006 \\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x00\\' \\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13 \\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x006 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13 \\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x00\\' \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(a)ML100K\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(b)Steam\\nFigure4:AttackperformanceonFedGNNmodel.\\nApossiblereasonisthatformostitems,i.e.,taileditem,the\\nmalicious gradients can easily be the majority in its aggre-\\ngation,sotheMedianAGRtendstopickthemaliciousgra-\\ndientasoutput,whilethepoisoninginMeanAGRwillbein\\nremissionbyaveragingmaliciousandbenigngradients.\\nHyperparameterAnalysis(RQ4)\\nLastly,weinvestigatetheimpactofthehyper-parameteron\\nSpattack. In Fig. 5, we show the convergence of FR under\\nmeanaggregatorsonSteam,wherethemaliciousratioisset\\nto 10%, and the results correspond to starting attacks at 0,\\n20,40and60.PleaserefertotheAppendixformoreresults\\nandanalysis.Wehavethefollowingobservations:\\n• Spattack with a small starting epoch tends to have better\\nattackperformancebecausethemodelhasconvergedunder\\nalargestartingepoch.\\n• When Spattack is launched, Spattack-O prevents the\\nmodelfromcontinuingtoconverge,whileSpattack-Lcauses\\nthe performance dramatically drops. The reason is that\\nSpattack-O uploads malicious gradients with an average\\nequal to the negative of the benign gradients’ average, re-\\nsultinginzerogradientsafteraggregation.\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x15\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x17\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13 \\x00\\x19\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(a)Spattack-O-D\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(b)Spattack-O-S\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(c)Spattack-L-D\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(d)Spattack-L-S\\nFigure5:Attackperformanceondifferentstartepochs.\\nConclusion\\nInthispaper,wefirstsystematicallystudytheByzantinero-\\nbustnessoffederatedrecommenderfromtheperspectiveof\\nsparse aggregation, where the item embedding in FR can\\nonly be updated by partial clients, instead of full clients\\n(denseaggregationingeneralFL).Thenwedesignaseries\\nof attack strategies, called Spattack, based on the vulnera-\\nbility from sparse aggregation in FR. Our Spattack can be\\nemployed by attackers with different levels of knowledge\\nandcapability.Extensiveexperimentalresultsdemonstrated\\nthat FR is extremely fragile to Spattack. In the future, we\\naimtodesignamorerobustaggregatorinFRfromtheper-\\nspectiveofsparseaggregation,whichfocusesontherobust\\naggregationfortaileditems.Acknowledgments He,X.;Liao,L.;Zhang,H.;etal.2017. NeuralCollabora-\\ntiveFiltering. Proceedingsofthe26thInternationalConfer-\\nThis work is supported by the National Key Research and\\nenceonWorldWideWeb.\\nDevelopment Program of China (2023YFF0725103), the\\nNationalNaturalScienceFoundationofChina(U22B2038, Liu,Z.;Yang,L.;Fan,Z.;etal.2021. FederatedSocialRec-\\n62322203, 62172052, 62192784), and the Young Elite ommendation with Graph Neural Network. ACM Transac-\\nScientists Sponsorship Program (No.2023QNRC001) by tionsonIntelligentSystemsandTechnology(TIST).\\nCAST. Luo, S.; Xiao, Y.; and Song, L. 2022. Personalized Fed-\\neratedRecommendationviaJointRepresentationLearning,\\nReferences User Clustering, and Model Adaptation. Proceedings of\\nthe 31st ACM International Conference on Information &\\nAbdollahpouri,H.;Burke,R.;andMobasher,B.2019.Man-\\nKnowledgeManagement.\\naging Popularity Bias in Recommender Systems with Per-\\nLyu,L.;Yu,H.;Ma,X.;etal.2022. Privacyandrobustness\\nsonalizedRe-ranking. InTheFloridaAIResearchSociety.\\ninfederatedlearning:Attacksanddefenses. IEEEtransac-\\nAmmaduddin,M.;Ivannikova,E.;Khan,S.A.;etal.2019.\\ntionsonneuralnetworksandlearningsystems.\\nFederated Collaborative Filtering for Privacy-Preserving\\nLyu, L.; Yu, H.; Zhao, J.; et al. 2020. Threats to federated\\nPersonalizedRecommendationSystem. arXiv:Information\\nlearning. FederatedLearning:PrivacyandIncentive.\\nRetrieval.\\nMa, H.; Yang, H.; Lyu, M. R.; et al. 2008. SoRec: social\\nBaruch,G.;Baruch,M.;andGoldberg,Y.2019. ALittleIs\\nrecommendationusingprobabilisticmatrixfactorization. In\\nEnough:CircumventingDefensesForDistributedLearning.\\nInternational Conference on Information and Knowledge\\nInNeuralInformationProcessingSystems.\\nManagement.\\nBlanchard, P.; Mhamdi, E. M. E.; Guerraoui, R.; et al. McMahan, H. B.; Moore, E.; Ramage, D.; et al. 2016.\\n2017a. MachineLearningwithAdversaries:ByzantineTol- Communication-EfficientLearningofDeepNetworksfrom\\nerantGradientDescent. InNIPS. Decentralized Data. In International Conference on Artifi-\\nBlanchard, P.; Mhamdi, E. M. E.; Guerraoui, R.; et al. cialIntelligenceandStatistics.\\n2017b. Machine learning with adversaries: byzantine tol- Mhamdi,E.M.E.;Guerraoui,R.;andRouault,S.2018.The\\nerantgradientdescent. NeuralInformationProcessingSys- HiddenVulnerabilityofDistributedLearninginByzantium.\\ntems. InInternationalConferenceonMachineLearning.\\nChai,D.;Wang,L.;Chen,K.;etal.2019. SecureFederated Pillutla,K.;Kakade,S.M.;andHarchaoui,Z.2019. Robust\\nMatrixFactorization. IEEEIntelligentSystems. AggregationforFederatedLearning. IEEETransactionson\\nChen, C.; Zhang, J.; Tung, A. K.; Kankanhalli, M.; and\\nSignalProcessing.\\nChen, G. 2020. Robust federated recommendation system. Rendle,S.;Freudenthaler,C.;Gantner,Z.;etal.2009. BPR:\\narXivpreprintarXiv:2006.08259. Bayesian Personalized Ranking from Implicit Feedback.\\nArXiv.\\nCheuque, G.; Guzma´n, J.; and Parra, D. 2019. Recom-\\nmenderSystemsforOnlineVideoGamePlatforms:theCase Rodr’iguez-Barroso,N.;L’opez,D.J.;Luz’on,M.V.;etal.\\nof STEAM. Companion Proceedings of The 2019 World 2022. Survey on Federated Learning Threats: concepts,\\nWideWebConference. taxonomy on attacks and defences, experimental study and\\nchallenges. ArXiv.\\nElkahky,A.M.;Song,Y.;andHe,X.2015. AMulti-View\\nRong, D.; Ye, S.; Zhao, R.; et al. 2022. FedRecAttack:\\nDeepLearningApproachforCrossDomainUserModeling\\nModel Poisoning Attack to Federated Recommendation.\\nin Recommendation Systems. Proceedings of the 24th In-\\n2022 IEEE 38th International Conference on Data Engi-\\nternationalConferenceonWorldWideWeb.\\nneering(ICDE).\\nFan,W.;Ma,Y.;Yin,D.;etal.2019. Deepsocialcollabora-\\nSun, Z.; Xu, Y.; Liu, Y.; He, W.; Kong, L.; Wu, F.; Jiang,\\ntive filtering. Proceedings of the 13th ACM Conference on\\nY.; and Cui, L. 2024. A survey on federated recommenda-\\nRecommenderSystems.\\ntion systems. IEEE Transactions on Neural Networks and\\nFang, M.; Cao, X.; Jia, J.; et al. 2019. Local Model Poi- LearningSystems.\\nsoningAttackstoByzantine-RobustFederatedLearning. In\\nSuresh, A. T.; McMahan, B.; Kairouz, P.; et al. 2019. Can\\nUSENIXSecuritySymposium.\\nYouReallyBackdoorFederatedLearning. arXiv:Learning.\\nFang, M.; Zhang, Z.; Hairi; Khanduri, P.; Liu, J.; Lu, S.; Tolpegin,V.;Truex,S.;Gursoy,M.E.;etal.2020.DataPoi-\\nLiu, Y.; and Gong, N. 2024. Byzantine-robust decentral- soning Attacks Against Federated Learning Systems. Cor-\\nizedfederatedlearning. InProceedingsofthe2024onACM nellUniversity-arXiv.\\nSIGSACConferenceonComputerandCommunicationsSe-\\nWang, H.; Zhang, F.; Xie, X.; et al. 2018. DKN: Deep\\ncurity,2874–2888.\\nKnowledge-Aware Network for News Recommendation.\\nFu,S.;Xie,C.;Li,B.;etal.2019. Attack-ResistantFeder- Proceedingsofthe2018WorldWideWebConference.\\natedLearningwithResidual-basedReweighting. ArXiv. Wu, C.; Wu, F.; An, M.; et al. 2019a. NPA: Neural News\\nHarper, F. M.; and Konstan, J. A. 2016. The MovieLens Recommendation with Personalized Attention. Proceed-\\nDatasets:HistoryandContext. ACMTrans.Interact.Intell. ingsofthe25thACMSIGKDDInternationalConferenceon\\nSyst. KnowledgeDiscovery&DataMining.Wu,C.;Wu,F.;Lyu,L.;etal.2021.Afederatedgraphneural Zhang, M.; Wang, X.; Shi, C.; Lyu, L.; Yang, T.; and Du,\\nnetwork framework for privacy-preserving personalization. J. 2023b. Minimum topology attacks for graph neural net-\\nNatureCommunications. works. In Proceedings of the ACM Web Conference 2023,\\n630–640.\\nWu,C.;Wu,F.;Qi,T.;etal.2022. FedAttack:Effectiveand\\nCovertPoisoningAttackonFederatedRecommendationvia Zhang, M.; Wang, X.; Zhu, M.; Shi, C.; Zhang, Z.; and\\nHard Sampling. Proceedings of the 28th ACM SIGKDD Zhou,J.2022. Robustheterogeneousgraphneuralnetworks\\nConferenceonKnowledgeDiscoveryandDataMining. againstadversarialattacks.InProceedingsoftheAAAICon-\\nferenceonArtificialIntelligence,4,4363–4370.\\nWu, Y.; Hu, X.; Sun, Y.; Zhou, Y.; Zhu, W.; Rao, F.;\\nZhang,S.;Yin,H.;Chen,T.;etal.2021. PipAttack:Poison-\\nSchiele, B.; and Yang, X. 2024a. Number it: Temporal\\nGrounding Videos like Flipping Manga. arXiv preprint ingFederatedRecommenderSystemsforManipulatingItem\\narXiv:2411.10332. Promotion. ProceedingsoftheFifteenthACMInternational\\nConferenceonWebSearchandDataMining.\\nWu,Y.;Zhou,S.;Yang,M.;Wang,L.;Zhu,W.;Chang,H.;\\nZhang,Z.;Wang,X.;Zhou,H.;Yu,Y.;Zhang,M.;Yang,C.;\\nZhou,X.;andYang,X.2024b. UnlearningConceptsinDif-\\nandShi,C.2024a.CanLargeLanguageModelsImprovethe\\nfusionModelviaConceptDomainCorrectionandConcept\\nAdversarial Robustness of Graph Neural Networks? arXiv\\nPreservingGradient. arXivpreprintarXiv:2405.15304.\\npreprintarXiv:2408.08685.\\nWu,Z.;Ling,Q.;Chen,T.;etal.2019b.FederatedVariance-\\nZhang,Z.;Zhang,M.;Yu,Y.;Yang,C.;Liu,J.;andShi,C.\\nReduced Stochastic Gradient Descent With Robustness to\\n2024b. EndowingPre-trainedGraphModelswithProvable\\nByzantine Attacks. IEEE Transactions on Signal Process-\\nFairness. In Proceedings of the ACM on Web Conference\\ning.\\n2024,1045–1056.\\nXie, C.; Koyejo, O.; and Gupta, I. 2020. Fall of empires:\\nBreaking byzantine-tolerant sgd by inner product manipu-\\nlation. In Uncertainty in Artificial Intelligence, 261–270.\\nPMLR.\\nXu,J.;Huang,S.-L.;Song,L.;etal.2021. Byzantine-robust\\nFederatedLearningthroughCollaborativeMaliciousGradi-\\nentFiltering. 2022IEEE42ndInternationalConferenceon\\nDistributedComputingSystems(ICDCS).\\nYan, B. 2024. Federated Graph Condensation with\\nInformation Bottleneck Principles. arXiv preprint\\narXiv:2405.03911.\\nYan, B.; Cao, Y.; Wang, H.; Yang, W.; Du, J.; and Shi, C.\\n2024. Federated heterogeneous graph neural network for\\nprivacy-preservingrecommendation. InProceedingsofthe\\nACMonWebConference2024,3919–3929.\\nYin,D.;Chen,Y.;Ramchandran,K.;etal.2018. Byzantine-\\nRobust Distributed Learning: Towards Optimal Statistical\\nRates. arXiv:Learning.\\nYing, R.; He, R.; Chen, K.; et al. 2018. Graph Convolu-\\ntional Neural Networks for Web-Scale Recommender Sys-\\ntems. Proceedingsofthe24thACMSIGKDDInternational\\nConferenceonKnowledgeDiscovery&DataMining.\\nYing,S.2020.SharedMF:Aprivacy-preservingrecommen-\\ndationsystem. ArXiv.\\nYu,Y.;Liu,Q.;Wu,L.;etal.2023.Untargetedattackagainst\\nfederatedrecommendationsystemsviapoisonousitemem-\\nbeddingsandthedefense. InProceedingsoftheAAAICon-\\nferenceonArtificialIntelligence.\\nYuan, W.; Nguyen, Q. V. H.; He, T.; et al. 2023. Manip-\\nulating Federated Recommender Systems: Poisoning with\\nSyntheticUsersandItsCountermeasures. InSIGIR.\\nZhang, H.; Luo, F.; Wu, J.; He, X.; and Li, Y. 2023a.\\nLightFR: Lightweight federated recommendation with\\nprivacy-preservingmatrixfactorization. ACMTransactions\\nonInformationSystems.RelatedWork Notations\\nWepresentallnotationsrelevanttoourpaperinTab.4.\\nTable4:Notations\\nFederated Recommender. Federated learning aims to col-\\nlaboratively train a shared model based on the distributed D allinteractions\\ndata in a privacy-preserving manner (Yan et al. 2024; D i localinteractionofuseru i\\nMcMahan et al. 2016; Zhang et al. 2023a). Accordingly, U setofnbenignusers\\na federated recommender ensures individual users’ histor- U˜ setofn˜malicioususers\\nical data is locally stored and only uploads intermediate V setofmitems\\ndatatotheserverforcollaborativetraining.Inthisprocess, V ui setofitemsinteractingwithu i\\nthe user’s rating behaviors (the set of interacted items or\\nU\\nvj\\nsetofusersinteractingwithv\\nj\\nrating scores) are private information. Ammaduddin et al. U theuserembeddingswhereU ={u 1,...,u n}\\n(2019) first proposed a federated collaborative filter frame- V theitemembeddingswhereV ={v 1,...,v m}\\nwork for the privacy-preserving recommendation. The user ∇Vi,t the embedding gradient of V from benign user u i at\\nepocht\\nembeddingsarestoredandupdatedlocallywhilethegradi-\\nents of item embeddings are uploaded to the server for ag-\\n∇V˜i,t\\ntheembeddinggradientofVfrommalicioususeru˜ iat\\ngregation. Moreover, for better privacy, (Chai et al. 2019) epocht\\napplied homomorphic encryption; (Ying 2020) further im- ∇vi j,t theembeddinggradientofv j frombenignuseru i at\\nepocht\\nproved the efficiency by utilizing secret sharing instead of\\nhomomorphicencryption.Recently,federatedrecommenda- ∇v˜i j,t theembeddinggradientofv j frommalicioususeru˜ i\\natepocht\\ntions based on graph neural networks have emerged (Wu\\nΘ theparametersofneuralnetworkmodel\\net al. 2021; Liu et al. 2021; Luo, Xiao, and Song 2022;\\n[n] Setofintegers{1,···,n}\\nYan 2024; Zhang et al. 2023b), further incorporating high-\\nη learningrate\\norder user-item interactions into local training data. Over-\\nρ theproportionofmalicioususers\\nall,mostexistingfederatedrecommendersystemsfollowthe\\nα thebreakingpointofstatisticallyrobustaggregator\\nparadigm where the gradients of item embeddings are up-\\nloaded to the server for aggregation. So they are all sparse\\naggregations where each item embedding can only be up- DetailedProofforProposition2\\ndatedbypartialclients,leadingtovariedrobustnessofeach Proof. Consider the robust aggregator with breaking point\\nitem.Thispapershedsthefirstlightonthisuniquevulnera- α,themodelconvergencecanbeguaranteedwhenthenum-\\nbilityintheviewofsparseaggregation. ber of malicious clients meets n˜ < α in FL. While in\\nn+n˜\\nRobustnessofFederatedLearning.Thesecurityoffed- FR,givenanitemvwithdegreed v,theaggregatoronlycol-\\nerated learning has drawn increasing attention in recent lects d v benign gradients in sparse aggregation. In Byzan-\\nyears (Lyu et al. 2022, 2020; Zhang et al. 2024a, 2022, tine attacks, all the malicious clients can easily collude to\\n2024b; Wu et al. 2024b,a), and a large number of attacks sendconsistentmaliciousgradientstocertainitemv.Once\\nagainst FL have been proposed. Among the attack strate- n˜/(d v+n˜)>α,namelyv’sdegreemeetsd v <(n˜−αn˜)/α,\\ngies, the Byzantine attack is one of the most popular at- the malicious updates will ultimately dominate and hence\\ntacks (Rodr’iguez-Barroso et al. 2022). The classic mean the statically robust aggregator will be tricked to pick the\\naggregator can be easily skewed by arbitrary updates from maliciousupdates.Letp(x)=Cx−β bethepower-lawdis-\\nByzantine clients. Therefore, a lot of Byzantine defense tributionofitems’degrees.Itscumulativedistributionfunc-\\nbased on statistics has been proposed in recent year (Yin tion P(x) is defined as the probability that the quantity of\\net al. 2018; Blanchard et al. 2017b; Mhamdi, Guerraoui, theitem’sdegreeislargerthanx:\\nandRouault2018;Xuetal.2021;Rodr’iguez-Barrosoetal. (cid:90) +∞\\nP(x)=Pr(X >x)=C p(X)dX\\n2022; Pillutla, Kakade, and Harchaoui 2019; Wu et al.\\nx\\n2019b;Fuetal.2019;Chenetal.2020),whichaimedtofil-\\n(cid:90) +∞ Cx(1−β)\\ntertheByzantineupdatesandguaranteetheconvergenceof =C X−βdX = . (6)\\nfederatedlearning.AlthoughtheByzantinerobustnessprob- β−1\\nx\\nlem is well-studied in FL, existing Byzantine attacks and So the probability that item’s degree is smaller than (n˜ −\\ndefenses of FL are defined based on the dense aggregation αn˜)/αcanbecalculatedasfollowing:\\nandcannotapplytooursparseaggregationinFR.Morere- 1−α C 1−α\\ncently, a few attacks have been proposed against federated 1−P(X > n˜)=1− ( n˜)(1−β). (7)\\nα β−1 α\\nrecommender,amongwhich,(Rongetal.2022;Zhangetal.\\n2021) focus on targeted attacks aiming to promote target\\nitems by increasing their exposure chances, and (Wu et al.\\nReproducibilitySupplement\\n2022) employs improper positive/negative samples to ma-\\nnipulate model parameters indirectly. (Yu et al. 2023) up- DatasetandEvaluationMetric\\nloadspoisonousgradientsthatcollapseallitemembeddings Following (Rong et al. 2022), Spattack is evaluated\\ntoseveralclusterstoconfusedifferentitems.However,they on three widely used datasets, including a movie rec-\\nallneglecttheuniquesparsityinfederatedrecommender. ommendation dataset MovieLens-1M (ML1M) (Harperand Konstan 2016), the small version MovieLens-100K Table5:Thenumberofmaliciousclientsunderdifferentat-\\n(ML100K),andgamerecommendationdatasetSteam-200K tackratiosρ.\\n(Steam) (Cheuque, Guzma´n, and Parra 2019). For all Dataset 1% 3% 5% 10% 15%\\ndatasets,wecloselyfollowthedatasetconfigurationsinpre- ML100K 9 29 49 105 166\\nviousworks(Heetal.2017;Rongetal.2022)byunifying ML1M 61 186 317 671 1066\\ninteractionsasimplicitfeedbackandremovingduplicatein- Steam 37 116 197 417 662\\nteractions. To evaluate the ranking quality of the test item\\n• Cluster (Yu et al. 2023) uploads malicious gradients that\\nrecommendation, we adopt two common evaluation proto-\\naim to make item embeddings collapse into several dense\\ncols,i.e.,hitratio(HR)andnormalizeddiscountedcumula-\\nclusters.Wesettheinitialnumberofclustersas1.Therange\\ntivegainatrankK (nDCG@K).\\nofthenumberofclustersandthethresholdissetto[1,10].\\nHere,weuseK as5and10.Foreachuser,sinceranking\\nthetestitemamongallitemsistime-consuming,following\\nAdditionalImplementationDetails\\nthe widely-used strategy (Elkahky, Song, and He 2015; He\\netal.2017),werandomlysample100itemsfromtheitems • General settings. The default optimization algorithm is\\nthathavenotinteractedwiththeuser,thenrankthetestitem stochasticgradientdescent,andthelearningrateis0.01.We\\namong the 100 items. The HR@K indicates whether the settheepochnumberto200andthemaliciousclientscon-\\ntestitemisrankedinthetop-K,andthenNDCG@K takes duct attacks from the first epoch. The number of malicious\\nposition significance into account. The higher HR@K and clientsunderdifferentattackratiosρareshowninTab.5.\\nnNDCG@K indicate better recommendation performance. • FR models. For the input user and item embedding, the\\nNotethatthesemetricsareonlycalculatedonbenignclients. dimension is set to 32. The hidden layer unit size is 64 in\\nFedGNN. In FedMF, following (Rong et al. 2022), we ini-\\nFederatedRecommenderSystems tialize the representations of users and items with normal\\nWeuseFedMF(Rongetal.2022)asourtargetmodel’sar- distributionwithameanvalueof0andastandarddeviation\\nchitecture in evaluation. We outline the details for repro- of0.01.InFedGNN,weinitializetheGNNweightmatrices\\nducibility below. Following (Rong et al. 2022), with BPR withXavierGlorot’sinitializationwithagainvalueof1.\\nloss,theFedMFupdatesuserembeddingslocallyandopti- • Spattack-O-S/D. For omniscient attackers, we generate\\nmizes item embeddings on the server. We set the unit size malicious gradients in the opposite direction of the benign\\nof embeddings to 32. To evaluate the generalization ability ones.Suchthatthemeanaggregatorwilloutputzerogradi-\\nof Spattack, we also conduct attacks on the state-of-the-art ents,preventingtheconvergenceofitemembeddings.\\nFedGNN (Wu et al. 2021), which can collaboratively train • Spattack-L-S/D. For non-omniscient attackers, we sam-\\nGNNmodelsmeanwhileexploitinghigh-orderuser-itemin- ple the Gaussian noise with a mean value of 0 and a stan-\\nteraction information with privacy well protected. We use darddeviationof1asthecurrentgradient.Andallmalicious\\nBPRlosstotraina2-layerFedGNNmodel,wherebothitem clientswilluploadthesamemaliciousgradient.\\nembeddings and GNN parameters are globally optimized. • Spattack-O/L-S. When the maximum number of poi-\\nFortheinputuseranditemembedding,thedimensionisset soneditemsm˜ max islimited,wesamplethepoisoneditem\\nto 32. For the hidden layer, we set the hidden unit size to listforeachmaliciousclientfromthedistributionofitemde-\\n64.Stochasticgradientdescentisselectedasthedefaultop- gree.Theitemswithmorebenignupdateswillreceivemore\\ntimizationalgorithm,anditslearningrateis0.01. maliciousupdates.Andthesamplingoperationofthemali-\\nciousclientsisnon-repeatable.\\nBaselines\\nExperimentEnvironmentandSourceCode\\n• LabelFlip (Tolpegin et al. 2020) poisons data by flipping\\nthetraininglabelsofmaliciousclientsanddoesnotrequire All experiments are conducted on a Linux server with one\\nknowledgeofthetrainingdatadistribution.Eachmalicious GPU (NVIDIA GeForce RTX 3090 GPU) and CPU (In-\\nclient uses positive samples as negative samples and uses tel Xeon Gold 6348), and its operating system is Ubuntu\\nnegativesamplesaspositivesamples. 18.04.5. We implement Spattack with the deep learning li-\\n• FedAttack (Wu et al. 2022) conducts data poisoning by brary PyTorch. The main source code of Spattack can be\\nemploying improper positive/negative samples. Each mali- foundathttps://github.com/zhongjian-zhang/Spattack.\\ncious client selects the items that are most similar to the\\nuser’sinterestasnegativesampleswhileregardingitemsthat SupplementalExperimentalResults\\naremostdissimilartotheuser’sinterestaspositivesamples.\\nPerformanceEvaluationofSpattack-O-D\\n•Gaussian(Fangetal.2019)estimatesaGaussiandistribu-\\ntionofbenigngradientsandthenuploadssamplesfromit. We report the detailed results of Spattack-O-D in Tab. 6,\\n• LIE (Baruch, Baruch, and Goldberg 2019) adds small where attackers know total benign gradients and with no\\namounts of noise towards the average of benign gradients. limitation of maximum number of updating items. We first\\nWeassign0.1asthescalingfactorthataffectsthestandard find that with the increasing malicious ratio ρ, the defense\\ndeviationofmodelparameters. performanceunderSpattack-O-Dconsistentlydecreasesand\\n• Fang (Fang et al. 2019) adds noise to opposite directions evenreachesanuntrainedstate,indicatingexistingdefenses\\noftheaveragenormalgradient.Weselecttheattackscaling aremorefragileinFRthanexpected.Whenρ=3%,theav-\\nfactorfromrandomlyuniformsamplesfrom[3,4]. eragedperformancedroprateofdefensesisabout71%,andTable6:RecommendationperformanceunderSpattack-O-D.Wealsoreporttheperformancedropratew.r.t.cleanmodel.\\n1% 3% 5%\\nDataset Defense\\nHR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10\\n0.0551 0.0354 0.0986 0.0491 0.0530 0.0339 0.0944 0.0470 0.0573 0.0352 0.0944 0.0470\\nMean\\n(-78%) (-78%) (-76%) (-77%) (-79%) (-79%) (-77%) (-78%) (-77%) (-79%) (-77%) (-78%)\\n0.2312 0.1545 0.3510 0.1924 0.1485 0.0943 0.2725 0.1339 0.0371 0.0233 0.0732 0.0346\\nMedian\\n(-9%) (-10%) (-9%) (-10%) (-42%) (-45%) (-29%) (-37%) (-85%) (-87%) (-81%) (-84%)\\n0.1972 0.1305 0.3181 0.1691 0.1410 0.0981 0.2153 0.1216 0.0530 0.0340 0.1018 0.0496\\nNorm\\nML100K (-17%) (-18%) (-18%) (-18%) (-41%) (-38%) (-45%) (-41%) (-78%) (-79%) (-74%) (-76%)\\n0.2269 0.1488 0.3489 0.1876 0.0647 0.0407 0.1198 0.0582 0.0361 0.0213 0.0721 0.0328\\nTrimM\\n(-10%) (-9%) (-14%) (-12%) (-74%) (-75%) (-70%) (-73%) (-86%) (-87%) (-82%) (-85%)\\n0.1941 0.1235 0.3065 0.1596 0.0255 0.0134 0.0456 0.0199 0.0509 0.0295 0.0891 0.0418\\nKrum\\n(+1%) (+3%) (0%) (+1%) (-87%) (-89%) (-85%) (-87%) (-73%) (-75%) (-71%) (-73%)\\n0.1151 0.0702 0.2149 0.1022 0.0907 0.0549 0.1679 0.0793 0.0730 0.0437 0.1366 0.0640\\nMean\\n(-63%) (-66%) (-54%) (-60%) (-71%) (-73%) (-64%) (-69%) (-77%) (-79%) (-70%) (-75%)\\n0.2955 0.1975 0.4422 0.2446 0.0394 0.0228 0.0839 0.0370 0.0457 0.0270 0.0919 0.0418\\nMedian\\n(-5%) (-4%) (-5%) (-4%) (-87%) (-89%) (-82%) (-85%) (-85%) (-87%) (-80%) (-84%)\\n0.3000 0.1981 0.4465 0.2453 0.2901 0.1893 0.4306 0.2347 0.1442 0.0989 0.2104 0.1202\\nNorm\\nML1M (-2%) (-2%) (-2%) (-2%) (-5%) (-7%) (-5%) (-6%) (-53%) (-51%) (-54%) (-52%)\\n0.2593 0.1765 0.4151 0.2262 0.0391 0.0222 0.0838 0.0364 0.0445 0.0255 0.0863 0.0390\\nTrimM\\n(-17%) (-14%) (-10%) (-11%) (-87%) (-89%) (-82%) (-86%) (-86%) (-88%) (-81%) (-85%)\\n0.2361 0.1504 0.3586 0.1899 0.0368 0.0216 0.0776 0.0346 0.0462 0.0268 0.0929 0.0418\\nKrum\\n(0%) (0%) (-4%) (-3%) (-84%) (-86%) (-79%) (-82%) (-80%) (-82%) (-75%) (-79%)\\n0.0677 0.0403 0.1276 0.0596 0.0685 0.0408 0.1287 0.0601 0.069 0.0411 0.129 0.0603\\nMean\\n(-88%) (-89%) (-82%) (-86%) (-88%) (-89%) (-81%) (-86%) (-88%) (-89%) (-81%) (-86%)\\n0.1719 0.1205 0.2323 0.1400 0.0442 0.0265 0.0791 0.0376 0.0290 0.0175 0.0568 0.0262\\nMedian\\n(-38%) (-38%) (-54%) (-47%) (-84%) (-86%) (-84%) (-86%) (-90%) (-91%) (-89%) (-90%)\\n0.0717 0.0428 0.1322 0.0622 0.0690 0.0409 0.1292 0.0602 0.0682 0.0408 0.1300 0.0605\\nNorm\\nSteam (-87%) (-88%) (-81%) (-84%) (-87%) (-88%) (-81%) (-85%) (-87%) (-88%) (-81%) (-85%)\\n0.2001 0.1622 0.2502 0.1783 0.0378 0.0228 0.0714 0.0335 0.0288 0.0175 0.0584 0.0269\\nTrimM\\n(-65%) (-57%) (-64%) (-58%) (-93%) (-94%) (-90%) (-92%) (-95%) (-95%) (-92%) (-94%)\\n0.1607 0.1253 0.2118 0.1416 0.0381 0.0237 0.0709 0.0341 0.0290 0.0175 0.0570 0.0264\\nKrum\\n(-37%) (-29%) (-55%) (-42%) (-85%) (-87%) (-85%) (-86%) (-89%) (-90%) (-88%) (-89%)\\nTable7:RecommendationperformanceunderSpattack-O-S.Wealsoreporttheperformancedropratew.r.t.cleanmodel.\\n1% 3% 5%\\nDataset Defense\\nHR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10\\n0.0647 0.0373 0.1421 0.0618 0.0594 0.0362 0.0997 0.0492 0.0541 0.0318 0.1039 0.0479\\nMean\\n(-74%) (-77%) (-65%) (-71%) (-76%) (-78%) (-75%) (-77%) (-78%) (-81%) (-74%) (-78%)\\n0.2365 0.1591 0.3606 0.1989 0.1994 0.1312 0.3075 0.1660 0.1198 0.0720 0.2068 0.0996\\nML100K Median\\n(-7%) (-8%) (-6%) (-7%) (-22%) (-24%) (-20%) (-22%) (-53%) (-58%) (-46%) (-54%)\\n0.2216 0.1417 0.3446 0.1811 0.1994 0.1249 0.3404 0.1698 0.1538 0.1032 0.2418 0.1314\\nNorm\\n(-7%) (-11%) (-11%) (-13%) (-16%) (-22%) (-12%) (-18%) (-35%) (-35%) (-38%) (-37%)\\n0.1204 0.0738 0.2230 0.1065 0.0925 0.0553 0.1753 0.0817 0.0805 0.0493 0.1568 0.0736\\nMean\\n(-61%) (-64%) (-52%) (-58%) (-70%) (-73%) (-62%) (-68%) (-74%) (-76%) (-66%) (-71%)\\n0.2995 0.2001 0.4452 0.2468 0.2439 0.1570 0.3641 0.1957 0.0447 0.0264 0.0897 0.0407\\nML1M Median\\n(-4%) (-2%) (-4%) (-3%) (-22%) (-23%) (-21%) (-23%) (-86%) (-87%) (-81%) (-84%)\\n0.3028 0.1986 0.4520 0.2468 0.2902 0.1898 0.4382 0.2375 0.2023 0.1402 0.2793 0.1648\\nNorm\\n(-1%) (-2%) (-1%) (-2%) (-5%) (-6%) (-4%) (-5%) (-34%) (-31%) (-39%) (-34%)\\n0.0701 0.0410 0.1404 0.0635 0.0671 0.0390 0.1308 0.0593 0.0695 0.0410 0.1348 0.0617\\nMean\\n(-88%) (-89%) (-80%) (-85%) (-88%) (-90%) (-81%) (-86%) (-88%) (-89%) (-81%) (-85%)\\n0.3333 0.2448 0.4602 0.2855 0.0266 0.0152 0.0600 0.0258 0.0218 0.0115 0.0498 0.0204\\nSteam Median\\n(+20%) (+27%) (-9%) (+8%) (-90%) (-92%) (-88%) (-90%) (-92%) (-94%) (-90%) (-92%)\\n0.1761 0.1226 0.2673 0.1520 0.0685 0.0398 0.1324 0.0602 0.0703 0.0414 0.1359 0.0623\\nNorm\\n(-67%) (-64%) (-61%) (-61%) (-87%) (-88%) (-81%) (-85%) (-87%) (-88%) (-80%) (-84%)\\nthedegradationwillfurtherincreaseto82%whenρ = 5%. detection based on the user’s degree and still achieve suc-\\nThe reason is that these tailed items in FR have lower de- cessfulattackswithfewmaliciousclients.\\nfensebreakingpointsandcanbeeasilybroken.\\nPerformanceEvaluationofSpattack-L-D\\nPerformanceEvaluationofSpattack-O-S\\nConsidering non-omniscient attackers, where the benign\\nThedetailedresultsofSpattack-O-SarereportedinTab.7, gradients are unavailable, we launch the Spattack-L-D by\\nwhere each malicious client only uploads malicious gradi- randomlygeneratingGaussiannoiseasmaliciousgradients.\\nentsforpartialitemstoavoidtriggeringtheanomalydetec- Togetcomparableresults,theratiosofmaliciousclientsin\\ntion based on the user’s degree. We restrict the m˜ as Spattack-L-D are set to higher values of {5%,10%,15%}.\\nmax\\nthemaximumnumberofuploadingitemsinbenignclients. As seen in Tab. 8, though equipped with statically robust\\nAsseen,Spattack-O-Scanstillsignificantlydegraderecom- aggregators,Spattack-L-Dcanstillpreventtheconvergence\\nmendationperformanceunder1%maliciousclientsandpre- with degradation of 81% to 97% under a 10% ratio. The\\nvent the model convergence for a 5% ratio. For example, results also provide a valuable implication that hiding the\\nSpattack-O-Sachieves35%(ML100K),31%(ML1M),and gradientsofbenignclientscannotprotectthefederatedrec-\\n80% (Steam) drop rate at least when the malicious client ommender well, because the attackers can break down the\\nratio ρ is 5%. Overall, Spattack-O-S can bypass anomaly modelbyusingrandomnoiseasasubstitution.Besides,oneTable8:RecommendationperformanceunderSpattack-L-D.Wealsoreporttheperformancedropratiow.r.t.cleanmodel.\\n5% 10% 15%\\nDataset Defense\\nHR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10\\n0.0318 0.0160 0.0785 0.0309 0.0233 0.0121 0.0562 0.0225 0.0265 0.0139 0.0562 0.0231\\nMean\\n(-87%) (-90%) (-81%) (-85%) (-91%) (-93%) (-86%) (-89%) (-89%) (-92%) (-86%) (-89%)\\n0.2163 0.1324 0.3637 0.1797 0.0095 0.0056 0.0233 0.0099 0.0233 0.0139 0.0530 0.0234\\nMedian\\n(-15%) (-23%) (-6%) (-16%) (-96%) (-97%) (-94%) (-95%) (-91%) (-92%) (-86%) (-89%)\\n0.2418 0.1480 0.3659 0.1876 0.1516 0.0910 0.2969 0.138 0.106 0.0601 0.1877 0.086\\nNorm\\nML100K (+2%) (-7%) (-6%) (-10%) (-36%) (-43%) (-23%) (-33%) (-55%) (-62%) (-52%) (-59%)\\n0.2269 0.1511 0.3690 0.1968 0.0074 0.0041 0.0286 0.0110 0.0276 0.0162 0.0551 0.0249\\nTrimM\\n(-10%) (-8%) (-9%) (-8%) (-97%) (-97%) (-93%) (-95%) (-89%) (-90%) (-86%) (-88%)\\n0.1474 0.0879 0.2259 0.1132 0.0159 0.0101 0.0318 0.0152 0.0286 0.0159 0.0615 0.0264\\nKrum\\n(-23%) (-27%) (-27%) (-28%) (-92%) (-92%) (-90%) (-90%) (-85%) (-87%) (-80%) (-83%)\\n0.0272 0.0153 0.0720 0.0295 0.0237 0.0128 0.0523 0.0219 0.0260 0.0146 0.0603 0.0254\\nMean\\n(-91%) (-93%) (-84%) (-88%) (-92%) (-94%) (-89%) (-91%) (-92%) (-93%) (-87%) (-90%)\\n0.0121 0.0055 0.0894 0.0296 0.024 0.0144 0.046 0.0215 0.0387 0.0220 0.0732 0.0330\\nMedian\\n(-96%) (-97%) (-81%) (-88%) (-92%) (-93%) (-90%) (-92%) (-88%) (-89%) (-84%) (-87%)\\nML1M\\n0.2805 0.1822 0.4333 0.2313 0.1962 0.1185 0.3343 0.1628 0.1119 0.0664 0.2240 0.1023\\nNorm\\n(-8%) (-10%) (-5%) (-8%) (-36%) (-42%) (-27%) (-35%) (-63%) (-67%) (-51%) (-59%)\\n0.0232 0.0103 0.1611 0.0537 0.0359 0.0207 0.0717 0.0321 0.0255 0.0152 0.0503 0.0231\\nTrimM\\n(-93%) (-95%) (-65%) (-79%) (-88%) (-90%) (-85%) (-87%) (-92%) (-93%) (-89%) (-91%)\\n0.0205 0.0114 0.0384 0.0170 0.0226 0.0129 0.0520 0.0221 0.0274 0.0155 0.0592 0.0256\\nMean\\n(-96%) (-97%) (-94%) (-96%) (-96%) (-97%) (-93%) (-95%) (-95%) (-96%) (-91%) (-94%)\\n0.0285 0.0160 0.0549 0.0245 0.0434 0.0261 0.0874 0.0400 0.0493 0.0293 0.0906 0.0426\\nMedian\\n(-90%) (-92%) (-89%) (-91%) (-84%) (-87%) (-83%) (-85%) (-82%) (-85%) (-82%) (-84%)\\n0.0171 0.0098 0.0442 0.0184 0.0226 0.0121 0.0560 0.0227 0.0250 0.0134 0.0634 0.0256\\nNorm\\nSteam (-97%) (-97%) (-94%) (-95%) (-96%) (-96%) (-92%) (-94%) (-95%) (-96%) (-91%) (-94%)\\n0.0296 0.0166 0.0552 0.0248 0.0440 0.0263 0.0879 0.0402 0.0480 0.0285 0.0903 0.0421\\nTrimM\\n(-95%) (-96%) (-92%) (-94%) (-92%) (-93%) (-87%) (-90%) (-92%) (-93%) (-87%) (-90%)\\n0.0288 0.0168 0.0554 0.0253 0.0434 0.0265 0.0866 0.0402 0.0472 0.0281 0.0895 0.0416\\nKrum\\n(-89%) (-90%) (-88%) (-90%) (-83%) (-85%) (-81%) (-84%) (-81%) (-84%) (-81%) (-83%)\\nTable9:RecommendationperformanceunderSpattack-L-S.Wealsoreporttheperformancedropratew.r.t.cleanmodel.\\n5% 10% 15%\\nDataset Defense\\nHR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10 HR@5 nDCG@5 HR@10 nDCG@10\\n0.0742 0.0425 0.1559 0.0683 0.0456 0.0249 0.1124 0.0462 0.0477 0.0264 0.0997 0.0428\\nMean\\n(-70%) (-74%) (-62%) (-68%) (-82%) (-85%) (-72%) (-78%) (-81%) (-84%) (-75%) (-80%)\\n0.2238 0.1433 0.3733 0.1913 0.0308 0.0179 0.0764 0.0321 0.0339 0.0206 0.0742 0.0336\\nML100K Median\\n(-12%) (-17%) (-3%) (-11%) (-88%) (-90%) (-80%) (-85%) (-87%) (-88%) (-81%) (-84%)\\n0.2397 0.1525 0.3690 0.1935 0.2068 0.1243 0.3118 0.1579 0.1315 0.0804 0.2503 0.1187\\nNorm\\n(+1%) (-4%) (-5%) (-7%) (-13%) (-22%) (-20%) (-24%) (-45%) (-50%) (-36%) (-43%)\\n0.0359 0.0207 0.0917 0.0385 0.0268 0.0156 0.0641 0.0274 0.0288 0.0166 0.0679 0.0290\\nMean\\n(-88%) (-90%) (-80%) (-85%) (-91%) (-92%) (-86%) (-89%) (-91%) (-92%) (-85%) (-89%)\\n0.0825 0.039 0.2237 0.0840 0.0285 0.0169 0.0536 0.0250 0.0387 0.0229 0.0728 0.0338\\nML1M Median\\n(-74%) (-81%) (-52%) (-67%) (-91%) (-92%) (-88%) (-90%) (-88%) (-89%) (-84%) (-87%)\\n0.2815 0.1822 0.4368 0.2321 0.2063 0.1246 0.3464 0.1696 0.1281 0.0746 0.2445 0.1118\\nNorm\\n(-8%) (-10%) (-4%) (-7%) (-33%) (-38%) (-24%) (-32%) (-58%) (-63%) (-46%) (-55%)\\n0.0453 0.0259 0.0901 0.0401 0.0440 0.0258 0.0914 0.0408 0.0410 0.0239 0.0890 0.0393\\nMean\\n(-92%) (-93%) (-87%) (-90%) (-92%) (-93%) (-87%) (-90%) (-93%) (-94%) (-87%) (-91%)\\n0.0378 0.0221 0.0791 0.0351 0.0488 0.0285 0.0927 0.0426 0.0450 0.0264 0.0938 0.0420\\nSteam Median\\n(-86%) (-89%) (-84%) (-87%) (-82%) (-85%) (-82%) (-84%) (-84%) (-86%) (-81%) (-84%)\\n0.0679 0.0389 0.1628 0.0692 0.0554 0.0322 0.1138 0.0508 0.0469 0.0265 0.1031 0.0444\\nNorm\\n(-87%) (-89%) (-76%) (-82%) (-90%) (-91%) (-84%) (-87%) (-91%) (-92%) (-85%) (-89%)\\ncan observe that Norm aggregators can provide better de- tio of 10% to the SOTA FedGNN (Wu et al. 2021), where\\nfensethanothers.Thereasonisthatthemaliciousgradients the Byzantine clients can only upload malicious gradients\\nof Spattack-L-D are from a Gaussian noise with the same of item embeddings. No Defense and Defense correspond\\nvariance: a large variance will benefit skewing data under tomeanandmedianaggregators,respectively.Asshownin\\nstaticallyrobustaggregatorsbutcanbeeasilyclippedbythe Fig. 6, we find that FedGNN’s performance dramatically\\nnorm-baseddefense. drops under Spattack, demonstrating the common vulnera-\\nbilityofFedMFandFedGNN.EventhoughGNN’sparame-\\nPerformanceEvaluationofSpattack-L-S tersaredenselyaggregated,attackerscanstillpreventmodel\\nWhenbothknowledgeandcapabilityarelimited,Spattack- convergencebyonlypoisoningitemembeddings.Moreover,\\nL-S still significantly degrades the FR model as shown in wealsoshowtheeffectivenessofSpattackundertheAdam\\nTab.9.Theperformancedropsbyabout56%,73%and78% optimizerinFig.9.Lastly,weevaluateSpattack’seffective-\\nunder5%,10%,15%maliciousratioonaverage,indicating ness when differential privacy is applied to the local gradi-\\nthattheFRsystemisvulnerabletoourattacks,whichcould entsin (Wuetal.2021).AsshowninFig.8,Spattackstill\\nhinderitsapplicabilityinvariousdomains. achievessuccessfulattacks.\\nMoreResultsontheTransferabilityofAttacks MoreresultsontheHyperparameterAnalysis\\nHere,weevaluatetheeffectivenessofSpattackonmoreFR In Fig. 7, we present the convergence of FR under defense\\nscenarios. First, we perform Spattack with a malicious ra- (i.e., Median AGR) against Spattack with a malicious ratio\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x001\\x00R\\x00\\x03\\x00$\\x00W\\x00N \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x1b \\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x006 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x00\\' \\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x006 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x15\\n\\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x00\\' \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x1b\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x16\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(a)ML100KHR@5\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(b)ML100KnDCG@5\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(c)ML100KHR@10\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(d)ML100KnDCG@10\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(e)SteamHR@5\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(f)SteamnDCG@5\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(g)SteamHR@10\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(h)SteamnDCG@10\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x1b\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x15\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x1b\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x16\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(i)ML1MHR@5\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(j)ML1MnDCG@5\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(k)ML1MHR@10\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(l)ML1MnDCG@10\\nFigure6:ExperimentalResultsonFedGNNModel.\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(a) Spattack-O-D(Defense)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(b) Spattack-O-S(Defense)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13 \\x00\\x17\\x00\\x13 \\x00\\x1b\\x00\\x13 \\x00\\x14\\x00\\x15\\x00\\x13 \\x00\\x14\\x00\\x19\\x00\\x13 \\x00\\x15\\x00\\x13\\x00\\x13\\n\\x00(\\x00S\\x00R\\x00F\\x00K\\n(c) Spattack-L-D(Defense)\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n(d) Spattack-L-S(Defense)\\nFigure7:PerformanceofSpattackstartingwithdifferentepochsonSteamdataset.\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00:\\x00\\x12\\x00R\\x00\\x03\\x00\\x03\\x00S\\x00U\\x00L\\x00Y\\x00D\\x00F\\x00\\\\ \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00:\\x00\\x12\\x00\\x03\\x00S\\x00U\\x00L\\x00Y\\x00D\\x00F\\x00\\\\ \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x00\\x13\\x00\\x08 \\x00\\x18\\x00\\x08 \\x00\\x14\\x00\\x13\\x00\\x08 \\x00\\x14\\x00\\x18\\x00\\x08\\n\\x003\\x00H\\x00U\\x00F\\x00H\\x00Q\\x00W\\x00\\x03\\x00R\\x00I\\x00\\x03\\x00%\\x00\\\\\\x00]\\x00D\\x00Q\\x00W\\x00L\\x00Q\\x00H\\x00\\x03\\x00&\\x00O\\x00L\\x00H\\x00Q\\x00W\\x00V\\n(a) FedMF.\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\nTable10:Theperformanceunderlowermaliciousratios.\\nAGR(·) Spattack Clean 1(0.1%) 5(0.5%) 9(1%) 29(3%) 49(5%)\\n0.0997 0.1029 0.0986 0.0944 0.0944\\nO-D 0.4051 Mean (-75.4%) (-74.6%) (-75.7%) (-76.7%) (-76.7%)\\n0.2471 0.175 0.1421 0.0997 0.1039 O-S 0.4051\\n(-39.0%) (-56.8%) (-64.9%) (-75.4%) (-74.4%)\\n0.3818 0.3743 0.3510 0.2725 0.0732\\nO-D 0.3849 Median (-0.8%) (-2.8%) (-8.8%) (-29.2%) (-81.0%)\\n0.3826 0.3765 0.3606 0.3075 0.2068\\n(b) FedGNN. O-S 0.3849\\n(-0.6%) (-2.2%) (-6.3%) (-20.1%) (-46.3%)\\nFigure8:Attackperformanceunderdifferentialprivacy.\\nWe report HR@10 on the ML-100K dataset under varying\\nmaliciousratios:0.1%,0.5%,1%,3%,and5%,correspond-\\nof 10%. The results correspond to starting attacks at 0, 20, ingto1,5,9,29,and49maliciousclients,respectively.The\\n40,and60,withavisualizationofHR@10in200epochson experimentalresultsarereportedinTab.10.Wehavethefol-\\nSteam.WeobservethattheMedianAGRdirectlypicksthe lowingobservations:\\nmaliciousgradientasoutputandrapidlydecreasesthemodel •Withoutdefense(i.e.,Mean),withonly0.1%maliciousra-\\nperformance along the opposite direction of the true gradi- tio(1maliciousclient),Spattack-O-Ddramaticallydegrades\\nent, which once again validates the vulnerability of sparse the performance by over 75% and prevents model conver-\\naggregationonFR. gence, which is consistent with Proposition 1. Even if the\\ncapabilityislimited,Spattack-O-Sstilleffectivelydegrades\\nTheeffectivenessunderlowermaliciousratio theperformanceby39%withonly1maliciousclient.\\nTo explore the lowest malicious ratio for the effectiveness •Forthedefenseaggregator(i.e.,Median),a3%malicious\\nofSpattack,weconsidertheworst-casescenario,Spattack- ratio(29maliciousclients)cansignificantlydegrademodel\\nO,wheretheattackerhavetheknowledgeoftotalgradients. performancebyover20%.\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x001\\x00R\\x00\\x03\\x00$\\x00W\\x00N \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x006\\n\\x00$\\x00W\\x00N\\x00\\x03\\x00/\\x00\\x10\\x00\\' \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13 \\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x006\\n\\x00$\\x00W\\x00N\\x00\\x03\\x002\\x00\\x10\\x00\\' \\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(a) ML100K\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(b) ML100K\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18 \\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(c) ML100K\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(d) ML100K\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(e) Steam\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x1a\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x19\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(f) Steam\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13 \\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(g) Steam\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(h) Steam\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n\\x00\\x18\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(i) ML1M\\n\\x00\\x18\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n\\x00\\x13\\x00\\x11\\x00\\x18\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x17\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(j) ML1M\\n\\x00\\x13\\x00\\x14\\x00#\\x005\\x00+\\n\\x00\\x13\\x00\\x11\\x00\\x16\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x15\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x14\\x00\\x13\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x18\\n\\x00\\x13\\x00\\x11\\x00\\x13\\x00\\x13 \\x001\\x00R\\x00\\x03\\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H \\x00\\'\\x00H\\x00I\\x00H\\x00Q\\x00V\\x00H\\n(k) ML1M\\n\\x00\\x13\\x00\\x14\\x00#\\x00*\\x00&\\x00\\'\\x00Q\\n(l) ML1M\\nFigure9:ResultsonFRModelwithAdamOptimizer.',\n",
       " 'Samba-ASR State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models.pdf': 'Samba-ASR: State-Of-The-Art Speech Recognition Leveraging\\nStructured State-Space Models\\nSyedAbdulGaffarShakhadri KruthikaKR KartikBasavarajAngadi\\nLeadAIDeveloper AIResearcher AIDeveloper\\nSandLogicTechnologiesPvtLtd. SandLogicTechnologiesPvtLtd SandLogicTechnologiesPvtLtd\\nsyed.abdul@sandlogic.com kruthika.kr@sandlogic.com kartik.angadi@sandlogic.com\\nABSTRACT\\nWe propose Samba ASR, the first state-of-the-art Automatic Speech Recognition (ASR) model\\nleveragingthenovelMambaarchitectureasbothencoderanddecoder,builtonthefoundationof\\nstate-spacemodels(SSMs). Unliketransformer-basedASRmodels, whichrelyonself-attention\\nmechanismstocapturedependencies,SambaASReffectivelymodelsbothlocalandglobaltemporal\\ndependenciesusingefficientstate-spacedynamics, achievingremarkableperformancegains. By\\naddressingthelimitationsoftransformers,suchasquadraticscalingwithinputlengthanddifficulty\\ninhandlinglong-rangedependencies,SambaASRachievessuperioraccuracyandefficiency.\\nExperimentalresultsdemonstratethatSambaASRsurpassesexistingopen-sourcetransformer-based\\nASRmodelsacrossvariousstandardbenchmarks,establishingitasthenewstate-of-the-artinASR.\\nExtensiveevaluationsonthebenchmarkdatasetshowsignificantimprovementsinWordErrorRate\\n(WER),withcompetitiveperformanceeveninlow-resourcescenarios. Furthermore,theinherent\\ncomputationalefficiencyandparameteroptimizationoftheMambaarchitecturemakeSambaASRa\\nscalableandrobustsolutionfordiverseASRtasks.\\nOurcontributionsincludethedevelopmentofanewSambaASRarchitectureforautomaticspeech\\nrecognition (ASR), demonstrating the superiority of structured state-space models (SSMs) over\\ntransformer-basedmodelsforspeechsequenceprocessing.Weprovideacomprehensiveevaluationon\\npublicbenchmarks,showcasingstate-of-the-art(SOTA)performance,andpresentanin-depthanalysis\\nofcomputationalefficiency,robustnesstonoise,andsequencegeneralization. Thisworkhighlights\\ntheviabilityofMambaSSMsasatransformer-freealternativeforefficientandaccurateASR.By\\nleveraging the advancements of state-space modeling, Samba ASR redefines ASR performance\\nstandardsandsetsanewbenchmarkforfutureresearchinthisfield.\\nKeywords Mamba · Structured State Space · Automatic Speech Recognition (ASR) · Mamba Blocks · Speech\\nProcessing\\n1 Introduction\\nTherapidevolutionofdeeplearninghassignificantlytransformedAutomaticSpeechRecognition(ASR),shifting\\nfromtraditionalsystemssuchasHiddenMarkovModels(HMMs)andGaussianMixtureModels(GMMs)toadvanced\\nend-to-endneuralarchitectures. WhileinnovationssuchasConnectionistTemporalClassification(CTC)andattention-\\nbasedencoder-decodermodelshaveestablishednewbaselines[1],transformer-basedmodelslikeOpenAI’sWhisper\\nhavefurtherpushedtheboundaries,settingstate-of-the-artbenchmarksformultilingual,multitaskASRsystems[2].\\nDespitetheirsuccesses,transformerarchitecturesfaceinherentchallengesinscalingtolongsequences,particularly\\nthoseencounteredinextendedaudiorecordings. Transformersexhibitquadraticcomplexitywithrespecttosequence\\nlength, leading to high computational costs and memory usage for tasks requiring long-context modeling [3],[4].\\nTheselimitationspresentasignificantobstacletoachievingscalableandefficientASRsystems,especiallyinresource-\\nconstrainedenvironmentsorforreal-timeapplications.\\n5202\\nnaJ\\n8\\n]LC.sc[\\n3v23820.1052:viXraStructured State-Space Models (SSMs) [5] have emerged as a compelling alternative, offering efficient sequence\\nmodeling with linear complexity. The Mamba architecture [6], an innovation within this domain, extends SSM\\ncapabilitiesbyintroducingselectiverecurrenceandhardware-awareoptimizations. Theseadvancementsaddressthe\\nlimitationsoftraditionallineartime-invariant(LTI)dynamics,enablingMambatodeliverexceptionalefficiencyand\\nscalability. Byleveragingselectivestate-spacedynamics,Mambaachievesefficientlong-rangedependencymodeling,\\nmakingitparticularlywell-suitedforASRtasks.\\nMamba’sarchitectureintroducesinput-dependentparametersintothestate-spaceequations, allowingfordynamic\\nadaptationtosequencecontent. Thiscapabilitycompressescontextintoasmallerstaterepresentationwhileeffectively\\ncapturingbothlocalandglobaldependencies[6]. Furthermore,Mambaemployshardware-awaretechniquessuchas\\nkernelfusionandparallelscan,optimizingcomputationalefficiencyandminimizingmemoryoverheadduringboth\\ntrainingandinference. ThesefeaturesestablishMambaasarobustsolutionforsequencemodelingacrossdiverse\\nmodalities.\\nWhile Mamba has demonstrated success in a range of applications, including language and vision tasks, its direct\\napplication to speech-to-text systems remained unexplored prior to this work. The development of Samba-ASR\\nrepresentsasignificantbreakthrough,showcasingthepotentialofMamba-basedarchitecturesinASR.Byreplacing\\ntraditionaltransformerencoderswithMamba’sefficientstate-spacemodeling,Samba-ASRachievesstate-of-the-art\\nperformance across major ASR benchmarks, including Gigaspeech [7] and SPGISpeech [8]. The model reduces\\ninferencelatencyandtrainingtimewhilemaintaininghighaccuracy,evenunderchallengingconditionssuchasnoisy\\norspontaneousspeech.\\nThe following sections delve into the technical details of State Space Models, the Mamba architecture, and its\\nadvancementsinbothlanguageandvisiontasks,settingthestageforourmotivationandcontributionstoefficientASR\\nsystemusingMamba.\\n1.1 Background\\n1.1.1 StateSpaceModels(SSMs)\\nStateSpaceModels(SSMs)[5]providearobustframeworkforsequencemodelingbyrepresentingdynamicalsystems\\nthroughalatentstatethatevolvesovertime. Thesemodelsdescribehowinputsaffectsystemstatesandhowstates\\ngenerateoutput,usingthefollowingequations:\\nh =A(h )+B(x ),y =C(h )\\nt+1 t t t t\\nwhere h is the latent state at time t, x is the input, y is the output, and A, B, C are parameter matrices. This\\nt t t\\nformulationallowsSSMstoefficientlymodelsequentialdatabytransitioningbetweenlatentstatesandproducing\\noutputsinfluencedbybothcurrentandhistoricalinputs.\\nTraditionally,SSMsarelineartimeinvariant(LTI),whereA,B,C remainconstantovertime. AlthoughLTIdynamics\\nprovidescomputationalefficiencyandstability,theylimitthemodel’sabilitytoadapttoinput-dependentvariations.\\nConsequently,classicalSSMsoftenstrugglewithcomplex,context-sensitivetasks,especiallyindiscreteandcontent-\\nrichmodalitiessuchaslanguage.\\nThematricesA,B,andC arelearnedparameterswiththefollowinginterpretations.\\n• A: Determineshowmuchtheprevioushiddenstateh shouldbeconsideredtocalculatethenewhiddenstate\\nt\\nh .\\nt+1\\n• B: Determineshowmuchtheinputx shouldbeconsideredtocalculatethenewhiddenstateh .\\nt t+1\\n• C: Determineshowmuchthehiddenstateh shouldbeconsideredincalculatingtheoutputy .\\nt t\\n1.1.2 Mamba: Linear-TimeSequenceModelingwithSelectiveStateSpaces\\nMamba[6]extendstraditionalSSMswithaselectivitymechanism,addressingthelimitationsofLTIdynamicswhile\\npreservingcomputationalefficiency. Mamba’sformulationintroducesinput-dependentparametersintothestate-space\\nequations:\\nh =A(h )+B(x ),y =C(x )h\\nt+1 t t t t t\\nwhereB(x )andC(x )arelearnedfunctionsoftheinputx ,allowingselectivepropagationofrelevantinformation\\nt t t\\nandenablesdynamicadaptationtosequencecontent,whileAremainsastructuredstatetransitionmatrix. Thisselective\\n2mechanismallowsMambatoefficientlycompresscontextintoasmallerstatewhilemaintainingtheabilitytocapture\\nlong-rangedependencies.\\nToefficientlyhandletheintroducedtime-varyingparameters,Mambaemploysahardware-awareimplementationusing\\ntechniqueslikekernelfusion,parallelscan,andrecomputation. ThisminimizesmemoryoverheadbyleveragingGPU\\nmemoryhierarchies,wherestateupdatesarecomputedinfast,low-levelmemory(e.g.,SRAM)andfinaloutputsare\\nwrittentohigh-bandwidthmemory(HBM).Byavoidingthematerializationoflargelatentstatesduringtraining,Mamba\\nachieveslinearcomputationalcomplexitywhileensuringflexibilityfordiversetasks. Furthermore,arecomputation\\nstrategyreducesmemoryrequirementsduringbackpropagationbyrecalculatingintermediatestatesonlywhenneeded.\\nTheMambaarchitecturesimplifiestraditionalSSMdesignsbycombiningsequencetransformationandgatingmecha-\\nnismsintoasinglehomogenousblock. Thisblockreplacesmulti-headattention(MHA)andMLPcomponentswitha\\nstreamlinedstructureinspiredbygatedmechanismsinRNNs,suchas:\\ng =σ(Linear(x )), h =(1−g )h +g x\\nt t t t t−1 t t\\nwhereg representstheselectiongate. Byiterativelystackingtheseblockswithnormalization(e.g.,LayerNorm)and\\nt\\nactivationfunctions(e.g.,SiLU),Mambaachieveshighexpressivenesswhilemaintainingsimplicity. Itsdesignbalances\\nperformanceandefficiency,makingitparticularlyeffectivefortaskssuchasAutomaticSpeechRecognition(ASR),\\nlanguagemodeling,andreinforcementlearning,wherelong-contextdependenciesandlowlatencyareessential.\\n1.1.3 AdvancementsinLargeLanguageandVisionModelsUtilizingMamba\\nThe Mamba architecture has inspired significant advancements in both language and vision modeling through its\\ninnovativestate-spacemechanism,leadingtohybridandpureMamba-basedmodels.\\nJamba[9]introducesanovelhybridarchitecturecombiningTransformerandMambalayers,interleavedwithmixture-of-\\nexperts(MoE)modules. ThishybriddesignaddresseslimitationsofpureTransformermodelsinhandlinglongcontexts\\nandcomputationalefficiency. Theresultingmodel,Jamba,achievesperformancecomparabletoMixtral-8x7Bwhile\\nsupportinganunprecedentedcontextlengthof256,000tokens—thelongestamongproduction-grademodels. Jamba’s\\nefficiencyisremarkable,deliveringthreetimesthethroughputofMixtral-8x7Bforlongcontextsandoperatingwithina\\nsingle80GBGPU.ThisdemonstratesthepotentialofintegratingTransformer’sattentionmechanismswithMamba’s\\nefficientstate-spacedynamicsforenhancedperformanceandresourceutilization.\\nFalconMamba[3]ontheotherhand,showcasesthecapabilitiesofapureMamba-basedlanguagemodel. This7B\\nparameter model trained on 5.8 trillion tokens challenges the notion that attention mechanisms are necessary for\\ncompetitiveperformance. Surpassingopen-weightTransformer-basedmodelslikeMistral7BandFalcon211B,Falcon\\nMambademonstratesthatefficientinferenceandconstantmemorycostsareachievableacrosscontextlengths. By\\naddressingtrainingstabilityissueswithstrategicinitializationsandRMSNormplacements,FalconMambaestablishes\\nitselfasacompetitiveandefficientalternativetohybridarchitectures.\\nZamba[4]representsanotherleapinMamba-basedinnovationbycombiningaMambabackbonewithauniqueshared\\nattentionmodule.This7Bparametermodelachievescompetitiveperformanceagainstleadingtransformer-basedmodels\\nwhilemaintainingSSMefficiency. Withfasterinferencespeedsandreducedmemoryrequirements,Zambastandsout\\nasaresource-efficientmodel,particularlyforgeneratinglongsequences. Althoughslightlybehindinreasoningand\\nin-contextlearningtasksduetolimitedtrainingdata,ZambademonstratestheviabilityofhybridSSM-attentiondesigns\\nforlarge-scalemodeling.\\nInvisiontasks,VisionMamba(Vim)[10]adaptsMambaforvisualrepresentationlearning,demonstratingthatself-\\nattentionmechanismsarenotessentialforeffectivevisionmodeling. VimintroducesbidirectionalMambablocksto\\naddresspositionalawarenessandglobalcontextchallengesinvisiontasks. Themodeldeliverssuperiorperformanceon\\nbenchmarkslikeImageNetandCOCO,achieving2.8×fasterinferencespeedsonhigh-resolutionimagescompared\\ntotransformer-basedmodelssuchasDeiT[11],whilereducingGPUmemoryusageby86.8%. Vim’ssubquadratic\\ncomputationandlinearmemorycomplexitymakeitahighlyefficientsolutionforhigh-resolutionvisualtasks.\\nTheseadvancementsillustratetheadaptabilityandefficacyofMamba-basedarchitecturesinovercomingchallenges\\nacrossmodalities,settinganewstandardforresource-efficientandhigh-performingmodelsinlanguageandvision\\ntasks.\\n1.2 Motivation\\nTransformer-basedASRmodels,whilesuccessful,sufferfromquadraticscaling,leadingtohighcomputationalcosts\\nandmemoryusagewhenprocessinglongaudiosequences. Thislimitationbecomesespeciallychallengingwithlarge\\n3datasetslikeGigaspeech[7]orSPGISpeech[8]. Toaddresstheseissues,weintroduceSamba-ASR,whichreplacesthe\\ntransformerencoderwiththeefficientMambaSSM.TheMambaarchitectureofferslinearcomplexity,allowingitto\\nmodellong-rangedependencieswithouttheheavycomputationalburden.\\nByleveragingMamba’sselectivestate-spacedynamics,Samba-ASRachievesstate-of-the-artperformanceacrossmajor\\nASRbenchmarks,surpassingtransformer-basedsystemsinbothaccuracyandefficiency. Ourmodelreducesinference\\nlatencyandtrainingtime,whilemaintainingrobustperformanceevenwithnoisyorspontaneousspeech. Samba-ASR\\npresentsascalable,efficient,andaccuratesolutionformodernASRtasks,settinganewstandardinthefield.\\n1.3 Contributions\\nThispapermakesthefollowingkeycontributions:\\n• EfficientASRArchitecture: WedesignSamba-ASR,integratingMambaSSMsasencodersanddecoder,\\nachievingbothaccuracyandefficiency.\\n• SOTA Performance: Samba-ASR achieves new benchmarks across Gigaspeech[7], LibriSpeech\\nClean/Other[12],andSPGISpeech[8],outperformingexistingtransformer-basedASRsystems.\\n• EfficiencyAnalysis: Samba-ASRreducesbothtrainingtimeandinferencelatency,withlinearscalingin\\nsequencelength\\n• Robustness: Samba-ASRshowsresiliencetonoisyandspontaneousspeech,generalizingwellacrossvaried\\ndatasets.\\nSamba-ASRsetsanewstandardforefficiencyandscalabilityinASRsystems,addressingcriticalchallengesinmodern\\nspeechrecognitionandpavingthewayforfutureinnovationsinthefield.\\n2 RelatedWork\\nInrecentyears, AutomaticSpeechRecognition(ASR)systemshavemadesignificantstridesinbothaccuracyand\\ncomputational efficiency. Traditional models relied on recurrent and convolutional neural networks, but modern\\narchitectures,particularlythoseleveragingTransformer-basedmodels,havesetnewbenchmarksinperformance. These\\nTransformermodels,suchasWave2Vec2.0[13],Conformer[14],Whisper[2],andNvidiaCanary[15],havegreatly\\nadvancedASRcapabilitiesbycapturingbothlocalandglobaldependenciesinspeechdata. However,despitetheir\\nsuccesses,thesemodelsoftenfacechallengesintermsofcomputationalresources,scalability,andperformanceon\\nlong-formspeechdata.RecentinnovationsinStateSpaceModels(SSMs),includingtheMamba-basedapproaches,have\\nemergedaspromisingalternatives,aimingtoovercometheselimitations. Thissectionreviewsthekeydevelopmentsin\\nASRtechnologies,discussingtheirstrengths,limitations,andthecontributionsoftheMamba-basedsystems.\\n2.1 PresentASRSystems\\n2.1.1 Wave2Vec2.0\\nThe Wav2Vec2[13] model is a widely adopted architecture for speech-to-text tasks, offering a robust method for\\nprocessingrawaudiointomeaningfultext. Itsarchitecturecomprisesthreemaincomponents: thefeatureencoder,\\nquantizationmodule,andTransformerencoder. Thefeatureencoderprocessesrawaudiowaveformsusingaseries\\nofconvolutionallayersthatextractlatentspeechrepresentationsbydownsamplingtheinputwhileretainingcritical\\ntemporalfeatures. Thequantizationmodulediscretizestheselatentrepresentationsintoafinitesetoflearnedspeech\\nunitsusingproductquantization,whichiscrucialforself-supervisedlearningobjectives. TheTransformerencoder,\\nacorepartofthearchitecture,captureslong-rangedependenciesintheaudiodatabycontextualizingtheextracted\\nfeaturesthroughmulti-layerattentionmechanisms. Duringpretraining,acontrastivelossisemployedbymasking\\na portion of the feature encoder’s output and predicting the corresponding quantized representations, allowing the\\nmodeltolearncontextualspeechrepresentationseffectively. Indownstreamtasks,suchasspeech-to-textgeneration,\\nWav2Vec2isfine-tunedwithlabeledaudio-textdata,leveragingtheConnectionistTemporalClassification(CTC)loss\\ntomapaudiofeaturesdirectlytotextsequences. Thisapproachhasdemonstratedexceptionalperformanceinautomatic\\nspeechrecognition(ASR),makingWav2Vec2afoundationalmodelinrelatedworksonASRandaudio-basedsequence\\ngenerationtasks.\\n42.1.2 Conformer\\nTheConformer[14]architecturehasemergedasasignificantadvancementinspeechprocessingmodels,particularlyfor\\nAutomaticSpeechRecognition(ASR).Itisdesignedtoimprovetheextractionofbothlocalandglobalfeaturesfrom\\naudiosignalsbycombiningthestrengthsofconvolutionalnetworksandtransformer-basedattentionmechanisms. This\\nhybridapproachenablesConformertoachievestate-of-the-artperformanceintasksrequiringtheunderstandingof\\nsequentialaudiodata,suchasspeechrecognition. ThecorestrengthoftheConformerliesinitsabilitytoeffectively\\nmodelbothshort-termandlong-termdependencies,achallengetypicallyfacedbytraditionalmodelsrelyingoneither\\nconvolutionsorattentionmechanismsalone.\\nThepreprocessingstageoftheConformermodelbeginswithaconvolutionalsubsamplinglayer.Thisinitialstepreduces\\ntheinputsequencelengthbydownsamplingthefeaturemaps,whichnotonlyreducescomputationalcomplexitybut\\nalsoretainsessentialinformationwhilediscardingirrelevantdetails. Theconvolutionallayercaptureslocalpatternsin\\ntheaudiosignal,whichiscrucialforpreservingfine-grainedtemporalinformation. Theoutputofthisstageisthen\\npassedontothemainencoder,wherethecorefeatureextractiontakesplace.\\nIntheencoder, theaudiodataisprocessedbyasequenceofConformerblocks, eachofwhichcomprisesfourkey\\nmodules: afeed-forwardmodule(FFN),amulti-headedself-attention(MHSA)module,aconvolutionmodule,anda\\nsecondFFNmodule. TheMHSAmoduleisresponsibleforcapturingglobalcontextualrelationshipswithintheinput\\nsequence,leveragingrelativepositionalencodingtomanagevaryingsequencelengths. Thishelpsthemodelgeneralize\\nbetteracrossdifferentinputsizes. Theuseofpre-normresidualconnectionsintheMHSAmoduleallowsforstableand\\nefficienttraining,aslayernormalizationisappliedbeforetheattentionmechanism,followedbyaresidualconnection\\nthataidsingradientflowduringtraining.\\nTheConformerarchitecturecombinesconvolutionalandattentionmechanismstoenhancespeechrecognition. By\\nintegratingthesecomponents,themodelisabletohandlevaryinginputlengthswhilepreservingbothlocalandglobal\\nfeaturesintheaudiosignal. Thedesign,whichusesasandwichstructureofdifferentmodules,helpsbalancefeature\\nextractionandcomputationalefficiency. ThismakesConformeravaluableapproachforspeechrecognitiontasksand\\notherspeechprocessingapplications.\\n2.1.3 Whisper\\nTheWhispermodel[2]isbuiltonasequence-to-sequenceTransformerarchitecture,whichisdesignedtohandlevarious\\nspeechprocessingtaskssuchastranscription,translation,voiceactivitydetection,andlanguageidentification. The\\ninputtothemodelisan80-channellog-magnitudeMelspectrogramderivedfromrawaudio,re-sampledat16kHz.\\nThespectrogramiscomputedusing25-millisecondwindowswitha10-millisecondstride,whichcapturestheessential\\nfeaturesoftheaudiosignal. Themodelprocessesthesefeaturesthroughaconvolutionalstemfollowedbyastackof\\nTransformerblockstolearnmeaningfulrepresentationsofthespeechsignal.\\nTheencoderprocessestheMelspectrogramsthroughtwoinitialconvolutionallayersfollowedbyTransformerblocks.\\nTheconvolutionlayerswithGELUactivationreducethedimensionalityofthespectrogramandcapturelocalpatterns,\\nwhiletheTransformerlayersareresponsibleforextractingglobaltemporaldependenciesintheaudio. Theencoder\\nalsoincludessinusoidalpositionembeddings,whichhelpthemodellearnthetemporalstructureoftheaudioinput.\\nTheencoder’soutputisasequenceofcontextualizedrepresentationsthatcapturetherelevantacousticandlinguistic\\ninformationfromtheaudio.\\nThedecodertakestheencoder’soutputandgeneratestextsequences,suchastranscriptionsortranslations,depending\\nonthetask. Ituseslearnedpositionembeddingsandasetofspecialtokenstospecifythetask(e.g., transcription,\\ntranslation). The decoder is trained to predict the next token in the sequence, conditioned on both the previously\\npredictedtokensandtheinputaudiofeatures. Themodelistrainedinamultitasksetup,enablingittoperformmultiple\\ntaskslikemultilingualtranscriptionandtranslationwithasingleunifiedarchitecture. Thedecoderendswithaspecial\\nendoftranscriptiontoken,markingtheendoftheoutputsequence.\\nThus,byusingaTransformer-basedarchitecturetohandlevariousspeechrecognitiontasksWhispermodelprocesses\\nMelspectrogramsthroughanencodertocaptureaudiofeaturesandthenusesadecodertogeneratetext. Thisapproach\\nprovidesaunifiedsolutionfortasksliketranscriptionandtranslation.\\n2.1.4 NvidiaCanary1B\\nTheCanarymodel[15]isanefficientencoder-decodermodeldesignedforautomaticspeechrecognition(ASR)and\\nautomaticspeechtranslation(AST).ItusesaFastConformer-basedarchitecture,aspeech-specificmodificationofthe\\nConformermodel,whichbalanceshighperformancewithreducedcomputationalresourcesandtrainingdata. The\\n5modelprocessesaudioasMelspectrograms,withafocusonminimizingtheneedforlargedatasetsandachievesa2.8x\\nspeedupovertraditionalmodelsbyincreasingthedownsamplingfactorto8.\\nThe model employs a unified multi-task training strategy, where special prompt tokens direct it to perform either\\ntranscriptionortranslationtasks. Canaryistrainedonsyntheticdatageneratedthroughmachinetranslation,using\\nadvancedtechniquessuchasdynamicdatablending,databalancing,dynamicbucketing,andnoise-robustfine-tuning.\\nThesemethodsoptimizetrainingefficiency,ensureconsistentlanguagerepresentation,andminimizehallucinations\\nwhennospeechispresent.\\nDespitebeingtrainedonjust86Khoursofspeech,muchlessthanmodelslikeWhisper,whichuseupto5Mhours,\\nCanarydeliverscompetitiveorsuperiorperformance. Itscompactarchitectureandinnovativetrainingstrategiesmakeit\\nhighlyeffectiveforASRandASTtasks,offeringimpressiveresultsacrossmultiplelanguageswithsignificantlyless\\ntrainingdata.\\n2.2 ExistingMambaBasedApproach\\nRecentadvancementsinspeechprocessinghavebeenlargelydrivenbyTransformer-based[16]modelsasdiscussedin\\nthesection2.1,whichexcelatcapturingglobaldependenciesbutfacecomputationalchallengesforlong-formsequences.\\nStateSpaceModels(SSMs),likeMamba,haveemergedasefficientalternativesduetotheirlinearcomputationalscaling\\nandabilitytohandlelong-rangedependencies. However,priorresearch,suchastheBiMamba[17]study,primarily\\nfocusedonexploringbidirectionalMambafortaskslikespeechenhancementandrecognitionwithoutproducinga\\nstandaloneASRsystemcompetitivewithTransformer-basedarchitectures. Similarly,”ExploringtheCapabilityof\\nMambainASR”[18]evaluatedMamba’spotentialacrossvariousspeechtasks,includingASR,text-to-speech,and\\nsummarization,showcasingcomparableorsuperiorperformancetoTransformermodelslikeConformer. However,this\\nworkremaineddomain-focusedanddidnotresultinafullyrealizedASRmodel.\\nThe”SpeechSlytherin”[19]studyextendedMamba’sapplicationtospeechseparationandsynthesis,introducinghybrid\\nmodelslikeMamba-TasNetandConMamba,whichachievedcompetitiveresultsbutfacedlimitationsinefficiencyfor\\nshorterinputsandjointtext-speechmodeling. WhilethesestudiesdemonstratedMamba’spromiseinspeechprocessing,\\nnoneproducedarobustASRsystemcapableofoutperformingleadingTransformer-basedmodels. Incontrast,ourwork\\nintroducesSamba-ASR,thefirstfullydevelopedMamba-basedASRsystemthatsurpassesTransformerarchitectures\\nacrossmajorbenchmarks,includingGigaspeech,LSClean,LSOther,andSPGISpeech. ThisestablishesSamba-ASR\\nasastate-of-the-artsolution,advancingtheboundariesofspeechrecognitionintermsofperformanceandcomputational\\nefficiency.\\n3 Dataprocessing\\nThe audio files are first loaded using the standard library torchaudio for efficient I/O operations. The audio file is\\ndecoded,down-mixedifnecessary,andresampledtoafixedsamplerateof16kHz,ensuringallaudioinputsarein\\nthesameformat,whichisessentialforuniformprocessing. Errorhandlingisimplementedtodealwithanyissues\\narisingduringtheloadingprocess,suchasfileformatincompatibilityorunsupportedcodecs. Theloadedaudioisthen\\nnormalizedtoarangeof[-1,1]tofacilitatemodeltraining. Toensurethattheaudioinputsmatchtheexpectedsizefor\\nprocessing,theyareeitherpaddedortrimmedtoaspecificlengthN ,definedbythemodel’srequirements. This\\nsamples\\nstepiscriticaltomaintainconsistencyinthelengthofaudiosegmentsprocessedbytheencoder[20]. Thechoiceof\\npaddingortrimminghelpsmaintainthesequencelengthacrossallinputsamples,enablingefficientbatchprocessing\\nduringtraining. Oncetheaudiodataisstandardized,itisconvertedintoalog-Melspectrogram[21],whichcaptures\\nfrequencycontentandtimedynamics. ThisisdonebyapplyingShort-TimeFourierTransform(STFT)[22]tothe\\naudiowaveformandprojectingitontotheMelfilterbanks. Theresultingmagnitudespectrogramisthenconvertedtoa\\nlogarithmicscaletobettermatchhumanauditoryperception. Thistransformationenhancesthediscriminativepowerof\\nthefeatures,makingthemmoresuitableforspeechrecognitiontasks. Thespectrogramsarefurtherscaledtoarange\\nthatensuresnumericalstabilityandarenormalizedbeforebeingfedintotheASRmodel,facilitatingaccuratetraining\\nandinference.\\n3.1 Tokenizer\\nThetokenizerisdesignedfortheMambaASR(AutomaticSpeechRecognition)model,whichconvertstextualinput\\nintoasequenceoftokenIDssuitableforprocessingbythemodel. Itincludesasetofspecialtokensthatmarkthe\\nbeginningandendofatranscription,indicatethetaskoftranscribingthetext,andpotentiallydenoteinformationfor\\naudiotranscriptions. Thesetokensarecrucialforguidingthemodel’sunderstandingoftheinputdata. Thetokenizer\\ncreatesabasicvocabularyforEnglishtextthatincludescommonASCIIcharacters,numbers,andpunctuationmarks. It\\n6usesatokenizerofBytelevelBPE(BytePairEncoding)[23]tosegmentthetextintoindividualtokens. Thismethod\\nensuresthateachelementoftheinputtextisrepresenteduniformly,facilitatingconsistentpreprocessingandaccurate\\ntranscriptionwhenusedwiththeMambaASRmodel.\\n4 Samba-ASR:Architecture\\n4.1 Overview\\nMambaASRintroducesanovelapproachtoAutomaticSpeechRecognition(ASR)byutilizingtheMambaarchitecture\\nasshowninthefigure1,astate-of-the-artsequencemodelingtechniqueknownforitscomputationalefficiencyand\\nabilitytocapturelong-rangedependencies. TraditionalTransformer-basedmodels(e.g.,Wav2Vec2andConformer)\\nwhichpredominantlyuseself-attentionmechanismsforbothaudiofeatureextractionandtextgeneration,MambaASR\\noffersanalternativethatusesstatespacemodels,allowingforbetterscalabilityandefficiencyinprocessinglonger\\nsequencesofdata. ThiskeydistinctioniscentraltoMambaASR’sabilitytohandleboththeaudioandtextcomponents\\nofASRtasksmoreeffectively.\\nAttheheartofMambaASRaretwoprimarycomponents: anaudioencoderandatextdecoder,bothbuiltwithMamba\\nblocks. Theseblocksaredesignedtohandlelong-rangedependenciesinbothspeechandtextsequences,offeringa\\nmoreefficientalternativetothememory-intensiveapproachesofTransformerandConformermodels. Incontrastto\\nthesemodels,whichuseself-attentionforglobalcontextcapture(withvaryingcomputationalefficiency),Mamba’s\\nstatespaceapproachenablesmoreefficientprocessingwithoutsacrificingperformanceontasksliketranscription.\\nFigure1: Architecturediagram(original)oftheSamba-ASRmodel,illustratingthekeycomponentsincludingthe\\nMambaencoder,whichprocessesrawaudiofeaturesusingMambablocks,andtheMambadecoderalongwiththe\\nMamba-Cross-Connectionbridge,whichgeneratestranscriptionsbyintegratingaudiocontextwithtextrepresentations.\\nThemodel’sdesignfocusesonefficientlong-rangedependencycaptureforaccurateautomaticspeechrecognition.\\n4.2 Encoder\\nTheMambaASR’saudioencoderprocessesrawaudioinput,representedasMelspectrograms,togeneratehigh-level\\nfeaturerepresentationsthatcaptureessentialspeechcharacteristics. Itbeginsbypassingtheaudioinputthroughseveral\\nconvolutionallayers[14], atechniqueborrowedfromimageprocessingmodels. Theselayershelptocapturelocal\\n7temporalpatternsintheaudiosignal,topreservefine-graineddetailsinaudiofeatures.Theoutputoftheseconvolutional\\nlayersisthenpassedthroughaseriesofMambablocks,whichformthecoreoftheencoder.\\nUnlike Transformer-based models such as Wav2Vec2 and Conformer, which rely on self-attention mechanisms to\\ncaptureglobalcontext,theMambaencoderusesastatespacemodelthatscaleslinearlywithsequencelength,makingit\\nmorecomputationallyefficientforlongaudiosequences. Thisresultsinamoreefficientmodelforhandlinglonger\\nspeechsequenceswithoutthequadraticcomplexitythatTransformer-basedmodelsface.\\nThe output from the Mamba blocks is a sequence of contextualized audio embeddings, with Layer Normalization\\nappliedtostabilizethefeaturesbeforetheyarepassedtothedecoder.Thisefficienthandlingoflong-rangedependencies\\ninaudiosequencesiscriticalforASRtasks,wherethemodelneedstocaptureandunderstandcontextacrosstheentire\\nutterance.\\n4.3 Decoder\\nThetextdecoderinMambaASRgeneratesthetranscriptionfromtheencodedaudiofeatures. Itbeginsbyembedding\\ntheinputtokens(representingthepartiallytranscribedtext)andaddingpositionalembeddingstoensuretheorderofthe\\nsequenceispreserved. TheseembeddingsarethenprocessedthroughaseriesofMambablocks,similartotheencoder.\\nHowever,here,thedecoderisconditionedontheencodedaudiofeaturesviaaMamba-cross-connectionmechanism.\\nThisallowsthedecodertofocusontherelevantportionsoftheaudiosequencewhilepredictingeachtoken,whichis\\nessentialforaccuratetranscription.\\nInTransformer-basedmodelslikeWav2Vec2andWhisper,theencoderdirectlyfeedsthedecoder,andtheself-attention\\nmechanismcapturestherelationshipbetweentheaudiofeaturesandthegeneratedtext. Incontrast,MambaASR’s\\nMamba-cross-connectionmechanismenablesmoretargetedalignmentbetweentheaudioandtextfeatures,improving\\nthemodel’sabilitytofocusonspecificaudiosegmentsthataremostrelevanttothecurrenttokenbeingpredicted.\\nThistargetedcross-connectionmechanismhelpsthedecoderrefinethetextrepresentations,integratingboththeaudio\\ncontextandpreviouslypredictedtokens.\\nAfterpassingthroughtheMambablocks,afinalLayerNormalizationisapplied,andtheoutputisprojectedontothe\\nvocabularyspaceviaalinearlayerfollowedbyasoftmaxfunction[24]. Thisproducesaprobabilitydistributionover\\ntheentirevocabulary,fromwhichthemodelselectsthemostlikelynexttoken. Tomaintaintheautoregressivenatureof\\ntextgeneration,acausalmaskensuresthatpredictionsarebasedonlyonpasttokens.\\nTheuniqueuseofMambablocksinthedecoderenablesMambaASRtomodeltheintricaterelationshipbetweenaudio\\nfeaturesandtexttokenseffectively,addressingthecomplexalignmentprobleminASRwhilealsobeingcomputationally\\nefficient.\\n5 Dataset\\nTotrainSamba-ASR,weutilizedadiversesetofhigh-qualityspeechdatasets. TheLibriSpeechcleansplit,containing\\n460hoursoftranscribed16kHzEnglishspeech,providedhigh-qualityaudiowithminimalnoise. Weleveragedboththe\\nTrain.100(100hours)andTrain.360(360hours)subsetsalongwithcorrespondingvalidationandtestsets.Thesesubsets\\nincluderecordingswithclearpronunciationsandlowWordErrorRates(WER),makingthemanidealfoundationfor\\nASRtraining.\\nAdditionally,weincorporatedtheGigaSpeechdataset,whichadded10,000hoursoftranscribedaudiofromvarious\\nsourcessuchasaudiobooks,podcasts,andYouTube. Thisdatasetcoversbothreadandspontaneousspeakingstyles\\nacrossdiversetopicsincludingscienceandarts, enhancingthemodel’sabilitytohandlemulti-domainspeechand\\nspontaneousvariationsinaudio.\\nWefurtherenrichedthetrainingdatawithSPGISpeech,adomain-specificdatasetconsistingof5,000hoursoftranscribed\\nfinancialaudio. Itfeaturesdiverseaccents(L1andL2Englishspeakers),varyingaudioquality,andprofessionally\\nformattedtranscripts. ThisdatasetplayedacrucialroleintrainingSamba-ASRtoexcelinrecognizingspecialized\\nfinancialterminologiesandhandlingchallengingaudioconditions.\\n6 TrainingDetails\\nAsdetailedinTable1,theSamba-ASRmodelwastrainedwithAdamW[25]andgradientnormclippingalongwith\\nalinearlearningratedecay. Abatchsizeof256wasused,andthemodelsweretrainedfor80epochswithaninitial\\nlearningrateof1e-4,aweightdecayof0.01,andanAdamepsilonsetto1e-8. Theseparameterswereselectedto\\n8TrainingParameters\\nLearningRate 1e-4\\nOptimizer AdamW\\nWeightDecay 0.01\\nAdameps 1e-8\\nBatchSize 256\\nTable1: DetailsofTrainingParametersusedforthetrainingofSamba-ASR\\nensurestableconvergenceandeffectivelymitigateoverfitting. Throughoutthetrainingprocess,wetrackedtrainingloss,\\nvalidationloss,andWordErrorRate(WER)tomonitormodelperformanceandgeneralization.\\nAsseenintheEpochvsLossgraphasshowninthefigure2,bothtrainingandvalidationlossconsistentlydecreased,\\nstartingfromaninitialvalueofapproximately7andconvergingcloseto0.5byepoch80. Similarly,theEpochvsWER\\ngraphasshowninthefigure3demonstratesasteadydeclineinWER,reducingfromover4.0toapproximately0.2\\nbyepoch80. TheseresultshighlighttheSamba-ASRmodel’sabilitytoachievestableconvergenceandsignificantly\\nimproverecognitionaccuracy,outperformingtransformer-basedASRmodels.\\nFigure2: Thisgraphshowsthecorrelationoftrainingandvalidationlossacrossepochs, withbothlossessteadily\\ndecreasingandconvergingaroundthe72ndepoch.\\n7 EvaluationandResults\\nWeevaluateSamba-ASR(SandLogic)onfourbenchmarkdatasets—GigaSpeech,LibriSpeech(LS)Clean,LSOther,\\nandSPGISpeech—andcompareitsperformancewithleadingASRmodelslistedontheOpenASRLeaderboardhosted\\nbyHuggingFace. Allresultsarecomputedusingthesameevaluationframeworktoensureconsistencyandfairness.\\nTheprimaryevaluationmetricistheWordErrorRate(WER).\\nAsshowninTable2,themodelachievesaremarkableaverageWERof3.65%,outperformingtop-performingsystems.\\nOnLSClean,itsetsanewstandardwithaWERof1.17%,whilemaintainingacompetitiveedgeonthemorechallenging\\nLSOthersubsetwithaWERof2.48%. ExceptionalresultsarealsoobservedonGigaSpeechandSPGISpeech,with\\nWERsof9.12%and1.84%,respectively. Theseoutcomeshighlightthemodel’sstate-of-the-artperformanceandits\\nabilitytogeneralizeeffectivelyacrossdiverseASRbenchmarks.\\n9Figure3: ThisgraphdemonstratesasignificantreductioninWordErrorRate(WER)throughoutthetrainingprocess,\\nindicatingimprovedmodelperformanceandaccuracy.\\nModel AverageWER Gigaspeech LSClean LSOther SPGISpeech\\nSamba-ASR(SandLogic) 3.65 9.12 1.17 2.48 1.84\\nnvidia/canary-1b 4.15 10.12 1.48 2.93 2.06\\nnyrahealth/CrisperWhisper 4.69 10.24 1.82 4.00 2.7\\nnvidia/parakeet-tdt-1.1b 7.01 9.52 1.40 2.60 3.16\\nopenai/whisper-large-v3 7.44 10.02 2.01 3.91 2.94\\nTable2: ModelPerformanceComparisonAcrossVariousDatasets\\n8 Conclusion\\nSamba-ASRrepresentsasignificantbreakthroughinautomaticspeechrecognitiontechnology,demonstratingsuperior\\nperformanceacrossmultiplebenchmarkdatasetsincludingGigaSpeech,LibriSpeechClean/Other,andSPGISpeech.\\nThemodelachievesremarkableresultswithanaverageWordErrorRate(WER)of3.65%,settinganewstate-of-the-art\\nbenchmarkwithparticularlyimpressiveperformanceonLibriSpeechClean(WER:1.17%)andSPGISpeech(WER:\\n1.84%).\\nThearchitecture’ssuccesscanbeattributedtoitsinnovativeuseofstate-spacemodels(SSMs)inbothencoderand\\ndecodercomponents,replacingtraditionaltransformer-basedattentionmechanisms. Thisdesignchoiceresultsinlinear\\ncomputationalcomplexity,enablingefficientprocessingoflongaudiosequenceswhilemaintaininghighaccuracy. The\\nmodel’srobustperformanceacrossdiversespeakingstyles,audioqualities,anddomainsdemonstratesitspractical\\nviabilityforreal-worldapplications.\\nSamba-ASR’sachievementsextendbeyondjustperformancemetrics. Themodel’sefficientarchitecturereducesboth\\ntrainingtimeandinferencelatency,whilemaintaininglinearscalingwithsequencelength.Thiscombinationofimproved\\naccuracyandcomputationalefficiencyestablishesSamba-ASRasacompellingalternativetotransformer-basedmodels,\\nsettinganewdirectionforfutureresearchinspeechrecognitiontechnology.\\n109 FutureScope\\nFutureworkonSamba-ASRwillexploremultiplekeydirectionstoenhanceitscapabilities,scalability,andbroader\\napplicability. AprimaryfocusisextendingsupportformultilingualASR[26]andtranslation,enablingthesystemto\\nprocessandtranscribespeechindiverselanguages,includingthosewithlimitedresources. ThiswillmakeSamba-ASR\\narobusttoolforglobalapplications,cateringtocross-lingualcommunicationandbreakinglanguagebarrierseffectively\\n[27].\\nToaddressdiversecomputationalrequirements,futureiterationswillexplorethedevelopmentofmodelvariantswith\\ndifferent sizes, from lightweight versions optimized for edge devices[28] to larger, high-performance models for\\nenterprise-level use. This scalability will ensure the system’s adaptability to various deployment scenarios, from\\nreal-timetranscriptiononmobiledevicestolarge-scaleprocessingincloudenvironments.\\nEnhancingtheencoderpre-trainingprocessisanothercriticalavenueofresearch. Byincorporatinglargerandmore\\ndiversedatasets,weaimtofurtherimprovegeneralizationacrossaccents,dialects,andspontaneousspeechvariations.\\nAdditionally, integrating domain-adaptive fine-tuning will allow the model to excel in specific industries, such as\\nhealthcareorlegaltranscription. Finally,effortstointegratereal-timeprocessingcapabilitiesandon-the-flylanguage\\ndetection will make Samba-ASR even more versatile for dynamic and interactive use cases. These advancements\\nwillsolidifySamba-ASRasaleading-edgesolutionintheASRlandscape,ensuringitscontinuedevolutiontomeet\\nemergingchallengesinspeechrecognition.\\nReferences\\n[1] Alex Graves, Santiago Ferna´ndez, Faustino Gomez, and Ju¨rgen Schmidhuber. Connectionist temporal clas-\\nsification: Labellingunsegmentedsequencedatawithrecurrentneuralnetworks. InProceedingsofthe23rd\\nInternationalConferenceonMachineLearning,pages369–376.ACM,2006.\\n[2] AlecRadford,JongWookKim,TaoXu,GregBrockman,ChristineMcLeavey,andIlyaSutskever. Robustspeech\\nrecognitionvialarge-scaleweaksupervision,2022.\\n[3] JingweiZuo,MaksimVelikanov,DhiaEddineRhaiem,IlyasChahed,YounesBelkada,GuillaumeKunsch,and\\nHakimHacid. Falconmamba: Thefirstcompetitiveattention-free7blanguagemodel,2024.\\n[4] PaoloGlorioso,QuentinAnthony,YuryTokpanov,JamesWhittington,JonathanPilault,AdamIbrahim,andBeren\\nMillidge. Zamba: Acompact7bssmhybridmodel,2024.\\n[5] AlbertGu,KaranGoel,andChristopherRe´. Efficientlymodelinglongsequenceswithstructuredstatespaces,\\n2022.\\n[6] AlbertGuandTriDao. Mamba: Linear-timesequencemodelingwithselectivestatespaces,2024.\\n[7] GuoguoChen,ShuzhouChai,GuanboWang,JiayuDu,Wei-QiangZhang,ChaoWeng,DanSu,DanielPovey,Jan\\nTrmal,JunboZhang,MingjieJin,SanjeevKhudanpur,ShinjiWatanabe,ShuaijiangZhao,WeiZou,XiangangLi,\\nXuchenYao,YongqingWang,YujunWang,ZhaoYou,andZhiyongYan. Gigaspeech: Anevolving,multi-domain\\nasrcorpuswith10,000hoursoftranscribedaudio,2021.\\n[8] PatrickK.O’Neill,VitalyLavrukhin,SomshubraMajumdar,VahidNoroozi,YuekaiZhang,OleksiiKuchaiev,\\nJagadeeshBalam,YuliyaDovzhenko,KeenanFreyberg,MichaelD.Shulman,BorisGinsburg,ShinjiWatanabe,\\nandGeorgKucsko. Spgispeech: 5,000hoursoftranscribedfinancialaudioforfullyformattedend-to-endspeech\\nrecognition,2021.\\n[9] OpherLieber,BarakLenz,HofitBata,GalCohen,JhonathanOsin,ItayDalmedigos,ErezSafahi,ShakedMeirom,\\nYonatanBelinkov,ShaiShalev-Shwartz,OmriAbend,RazAlon,TomerAsida,AmirBergman,RomanGlozman,\\nMichael Gokhman, Avashalom Manevich, Nir Ratner, Noam Rozen, Erez Shwartz, Mor Zusman, and Yoav\\nShoham. Jamba: Ahybridtransformer-mambalanguagemodel,2024.\\n[10] LianghuiZhu,BenchengLiao,QianZhang,XinlongWang,WenyuLiu,andXinggangWang. Visionmamba:\\nEfficientvisualrepresentationlearningwithbidirectionalstatespacemodel,2024.\\n[11] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve´ Je´gou.\\nTrainingdata-efficientimagetransformers&distillationthroughattention,2021.\\n[12] VassilPanayotov,GuoguoChen,DanielPovey,andSanjeevKhudanpur. Librispeech: Anasrcorpusbasedon\\npublicdomainaudiobooks. In2015IEEEInternationalConferenceonAcoustics,SpeechandSignalProcessing\\n(ICASSP),pages5206–5210,2015.\\n[13] Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A framework for\\nself-supervisedlearningofspeechrepresentations,2020.\\n11[14] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang,\\nZhengdongZhang,YonghuiWu,andRuomingPang. Conformer: Convolution-augmentedtransformerforspeech\\nrecognition,2020.\\n[15] KrishnaC.Puvvada,PiotrZ˙elasko,HeHuang,OleksiiHrinchuk,NithinRaoKoluguri,KunalDhawan,Somshubra\\nMajumdar,ElenaRastorgueva,ZhehuaiChen,VitalyLavrukhin,JagadeeshBalam,andBorisGinsburg. Lessis\\nmore: Accuratespeechrecognition&translationwithoutweb-scaledata,2024.\\n[16] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN.Gomez,LukaszKaiser,and\\nIlliaPolosukhin. Attentionisallyouneed,2023.\\n[17] XiangyuZhang,QiquanZhang,HexinLiu,TianyiXiao,XinyuanQian,BeenaAhmed,EliathambyAmbikairajah,\\nHaizhouLi,andJulienEpps. Mambainspeech: Towardsanalternativetoself-attention,2024.\\n[18] Koichi Miyazaki, Yoshiki Masuyama, and Masato Murata. Exploring the capability of mamba in speech\\napplications,2024.\\n[19] Xilin Jiang, Yinghao Aaron Li, Adrian Nicolas Florea, Cong Han, and Nima Mesgarani. Speech slytherin:\\nExaminingtheperformanceandefficiencyofmambaforspeechseparation,recognition,andsynthesis,2024.\\n[20] RongxiangWang,ZhimingXu,andFelixXiaozhuLin. Efficientwhisperonstreamingspeech,2024.\\n[21] Yuma Koizumi, Kenta Niwa, Yusuke Hioka, Kazunori Kobayashi, and Yoichi Haneda. Dnn-based source\\nenhancementtoincreaseobjectivesoundqualityassessmentscore. IEEE/ACMTransactionsonAudio,Speech,\\nandLanguageProcessing,26(10):1780–1792,October2018.\\n[22] Takuhiro Kaneko, Kou Tanaka, Hirokazu Kameoka, and Shogo Seki. istftnet: Fast and lightweight mel-\\nspectrogramvocoderincorporatinginverseshort-timefouriertransform,2022.\\n[23] RicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewordswithsubwordunits,\\n2016.\\n[24] Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. Fastspeech 2: Fast and\\nhigh-qualityend-to-endtexttospeech,2022.\\n[25] IlyaLoshchilovandFrankHutter. Decoupledweightdecayregularization,2019.\\n[26] VineelPratap,AnuroopSriram,PadenTomasello,AwniHannun,VitaliyLiptchinsky,GabrielSynnaeve,and\\nRonanCollobert. Massivelymultilingualasr: 50languages,1model,1billionparameters,2020.\\n[27] AlexGraves, AbdelrahmanMohamed, andGeoffreyHinton. Speechrecognitionwithdeeprecurrentneural\\nnetworks,2013.\\n[28] ZepingMin,QianGe,ZhongLi,andWeinanE. Mac: Aunifiedframeworkboostinglowresourceautomatic\\nspeechrecognition,2023.\\n12',\n",
       " 'SenseRAG Constructing Environmental Knowledge Bases with Proactive Querying for LLM-Based Autonomous Driving.pdf': 'SenseRAG: Constructing Environmental Knowledge Bases with Proactive\\nQuerying for LLM-Based Autonomous Driving\\nXuewenLuo1,FanDing1,†,FengzeYang2,†,YangZhou3,JunnyongLoo1,HwaHuiTew1,ChenxiLiu2,∗\\n1SchoolofInformationTechnology,MonashUniversity,BandarSunway,Selangor,Malaysia\\n2UniversityofUtah,SaltLakeCity,UT,USA\\n3TexasA&MUniversity,CollegeStation,TX,USA\\nAbstract LLMs possess a significant advantage in their ability\\ntorecognizeenvironmentalinformation,whichenablesthe\\nThisstudyaddressesthecriticalneedforenhancedsitu- systemtohandlethecomplexenvironment[6].Unlikeother\\nationalawarenessinautonomousdriving(AD)byleverag- perception technologies, LLMs can truly ”understand” the\\ningthecontextualreasoningcapabilitiesoflargelanguage context[7],whilemodelslikecomputervision(CV)relyon\\nmodels(LLMs). Unliketraditionalperceptionsystemsthat rigid,predefinedlabelslearnedduringtraining. CVmodels\\nrely on rigid, label-based annotations, it integrates real- are constrained by fixed annotations and lack flexibility in\\ntime,multimodalsensordataintoaunified,LLMs-readable newscenarios[8]. Incontrast,LLMscandynamicallypro-\\nknowledgebase,enablingLLMstodynamicallyunderstand cess diverse contexts and relationships within data. How-\\nand respond to complex driving environments. To over- ever,theirmainlimitationisthattheyaredesignedtohan-\\ncometheinherentlatencyandmodalitylimitationsofLLMs, dlelanguage-basedinformationandcannotdirectlyprocess\\na proactive Retrieval-Augmented Generation (RAG) is de- themultimodalsensordatafromVehicletoAnything(V2X)\\nsigned for AD, combined with a chain-of-thought prompt- andADsystems,suchasradar,cameras,orLidar[9][10].\\ning mechanism, ensuring rapid and context-rich under- Additionally,LLMstypicallyrequireconsiderableprocess-\\nstanding. Experimentalresultsusingreal-worldVehicle-to- ing time when handling very large datasets [11], which\\neverything(V2X)datasetsdemonstratesignificantimprove- wouldcompromisethereal-timeresponsivenessrequiredin\\nmentsinperceptionandpredictionperformance,highlight- ADscenarios.\\ningthepotentialofthisframeworktoenhancesafety,adapt- To address these challenges, a proactive RAG frame-\\nability, and decision-making in next-generation AD sys- work is proposed for LLM-based AD systems, which in-\\ntems. tegratestwokeycomponents. Oneissyntheticpriorknowl-\\nedgedatabasethatconsolidatesreal-timedatafromdiverse\\nsources, including meteorological sensors, traffic signals,\\n1.Introduction roadcamerasandLidars,intoastandardizedlanguagefor-\\nmat. This knowledge database serves as a foundation for\\nSituationawarenessplaysapivotalroleinAutonomous\\nenabling situation-awareness understanding and reasoning\\nDriving(AD)systemasitenablesthevehicletohandlethe\\nfor AVs. Another key component is the chain-of-thought\\ncomplex environment in transportation system [1]. Re-\\nprompting mechanism designed that empowers LLMs to\\ncently,variousArtificialIntelligence(AI)technologieshave\\nactively retrieve relevant information from the knowledge\\nbeen developed to enhance environmental understanding,\\ndatabaseaccordingtoneedsofAVs. Byleveragingthisap-\\nsuch as through deep learning models for object detection\\nproach,thesystemanalyzesenvironmentalconditions,pro-\\n[2], semantic segmentation [3], and computer vision tech-\\nvidingcontextperceptionandreasoning,toenhancesafety\\nniques[4]forspatialawareness. Notably,theadvancement\\nandintelligenceincomplexscenarios.\\noflargelanguagemodels(LLMs)hasopenednewopportu-\\nOur contributions in this study are highlighted as fol-\\nnitiesforAD[5]. ByharnessingthecapabilitiesofLLMs,\\nlows.\\nresearchers have achieved significant improvements in the\\nabilityofADsystemstounderstandsensordata,pavingthe\\n• This paper introduces a proactive SenseRAG frame-\\nwayforenhancedperceptionincomplexdrivingscenarios.\\nwork tailored for LLM-based AD systems and vali-\\n1.∗Correspondingauthor. dates its efficacy using real-world trajectory datasets.\\n2.†Theseauthorscontributedequallyassecondauthors. Empirical results show a substantial improvement in\\n1\\n5202\\nnaJ\\n8\\n]IA.sc[\\n2v53530.1052:viXraADperformance,reducingpredictiondisplacementer- robusttransportationnetworks[18][19].\\nrorsbyapproximately70%. Current cooperative perception systems primarily rely\\non vehicles passively receiving environmental information\\n• A novel knowledge database is constructed that con-\\nthrough V2X technologies [20]. This approach enables\\nsolidatesphysicaldatabyemployingmultimodalpre-\\nvehicles to obtain real-time data from surrounding vehi-\\nprocessing techniques to convert diverse sensor in-\\ncles, infrastructure, and other traffic participants. How-\\nputsintoastandardized,human-readableformat. This\\never,thispassivemethodoftenresultsininformationredun-\\ndatabase enables seamless integration, efficient stor-\\ndancyordelays,potentiallylimitingthereal-timedecision-\\nage, and accurate retrieval of environmental informa-\\nmaking capabilities of autonomous driving systems [21].\\ntion,therebyenhancingtheutilityofphysicaldatafor\\nTostrengthencooperativeperception,thestudyCodeFilling\\ndownstreamapplications.\\nadopts two key strategies: optimizing collaborative mes-\\nsages through improved representation and selection [22].\\n• Achain-of-thoughtpromptingmechanismisdesigned,\\nConsequently, optimizing V2X communication to actively\\nenablingproactivequeryinginknowledgedatabaseto\\nfilter and prioritize useful information for cooperative per-\\nenhanceitsreasoningcapabilities. Thisapproachim-\\nceptionremainsacriticalareaofresearch.\\nproves situation-awareness outputs, thereby optimiz-\\ningdecision-makingforADindynamicenvironments\\n2.2.LLMsEmpoweredAutonomousDriving\\nwithLLMs.\\nTherapidadvancementofLLMsisredefiningtheland-\\n2.RelatedWork scapeofAD,movingbeyondtraditional,narrowlyfocused\\nperception systems toward a more holistic form of envi-\\n2.1.Situation-awaredAutonomousDriving\\nronmental understanding. By unifying visual, textual, and\\nSituationawarenessplaysanincreasinglycriticalrolein sensor data, LLMs are emerging as pivotal components of\\nAD,enhancingbothsafetyandresilienceastransportation AD architectures, enabling vehicles to interpret complex\\nscenariosgrowmorecomplexanddiverse[12]. Recentad- traffic conditions and integrate information from multiple\\nvancementsinintelligenttransportationsystemshaveintro- streamstogaindeeperinsightsintotheirsurroundings[23].\\nduced cutting-edge sensing and communication technolo- Thismultifacetedapproachnotonlyenrichesperceptionbut\\ngies aimed at improving the robustness and safety of au- alsolaysthegroundworkformorenuancedpredictionand\\ntonomous driving in varied and complex traffic environ- decision-making processes, ultimately paving the way for\\nments[13]. Existingresearchinthisdomaincanbebroadly saferandmoreefficienton-roadperformance[24][25].\\ncategorized into two approaches: independent perception Building upon this foundation, recent research has be-\\n(decision-making based solely on in-vehicle sensors) and gun demonstrating how LLMs can streamline the entire\\ncooperative perception (decision-making enhanced by ex- AD pipeline, from initial data intake to final actuation [5].\\nternalinformation)[13]. Forinstance,bycombiningdiversedatasets—rangingfrom\\nIndependent perception relies heavily on advanced sen- camera feeds and radar signals to traffic reports—LLMs\\nsors and intra-vehicle sensor fusion to develop a com- candiscernintricatepatterns,identifysubtlecues,andcon-\\nprehensive understanding of the surrounding environment. tinually refine their understanding of the driving environ-\\nHowever, its effectiveness is often limited by its inherent ment [25,26]. As these models mature, they hold the po-\\n”short-sightedness” and inflexibility, particularly in highly tential to significantly enhance contextual reasoning, mak-\\ncomplex and diverse traffic scenarios, raising concerns ingitpossibleforautonomousvehiclestobetteranticipate\\naboutitsreliabilityinachievinghigh-levelautomation[14]. dynamicchangesandnavigatechallengingroadconditions\\nTo overcome these challenges, cooperative perception has withalevelofsophisticationnotpreviouslyattainable.\\nemerged as a promising solution. By integrating external Despite their potential, LLMs face significant limita-\\ndata sources and enabling communication among various tions in autonomous driving due to their dependence on\\ntransportation agents, cooperative perception facilitates a static pre-trained knowledge, which constrain their ability\\nbroader and more holistic understanding of traffic scenar- toadapttoreal-timedynamicsandintegratediverseexternal\\nios[13,15,16]. inputs [27]. The Retrieval Augmented Generation (RAG)\\nIn particular, cooperative sensing proves invaluable in paradigm offers a promising solution by enabling active\\nspecific situations, such as occlusions in high-density or queryingofexternaldatabases[28]. StudiessuchasRAG-\\ncrowded environments, where it can significantly improve Driver[29]andRAG-Guided[30]demonstratethevalueof\\nsituational awareness and potentially save lives [17]. The proactive querying in generating more accurate responses.\\nsharing of information within the network enhances the ByintegratingRAG,LLMscaneffectivelybridgethegaps\\nsafety, efficiency, and reliability of connected and au- inbothindividualandexternalknowledge, extendingtheir\\ntonomous systems, paving the way for more resilient and knowledge pool and paving the way for more robust and\\n2ing strategy to dynamically retrieve relevant information.\\nThis component enables AD systems to adaptively access\\ndata which are required from the database, optimizing the\\nprocessofaccessinginformation.\\n3.2.MultimodalSensorDataIntegration\\nFigure1.FrameworkofMethodology\\nreliableADsystems.\\n3.Methodology\\n3.1.FrameworkOverview\\nToenhancetheperceptionandsituationawarenesscapa-\\nbilitiesofLLM-basedADsystems,weproposeaproactive\\nSenseRAGframework,centeredaroundasyntheticknowl-\\nedge database. It empowers AVs to interpret and adapt to\\ndynamicscenariosbyleveraginganaccumulatedrepository\\nofmultimodalenvironmentaldata.Functioningasaclosed-\\nloop system, it facilitates continuous interaction between\\nvehicles and real-time environmental inputs, thereby ex-\\ntendingsituationalawarenessandenablingintelligentdriv-\\nFigure2.Overviewofthedataintegrationpipeline\\ning decisions. By integrating multimodal sensor data with\\nanactivequery-generationmechanism,thesystemdynami-\\nThis paper integrates unstructured inputs—360° cam-\\ncallyretrievesandprocessesrelevantinformationtoaddress\\nera imagery and LiDAR point clouds—capturing vehicles,\\ncomplextrafficconditions. Thisapproachsignificantlyim-\\npedestrians, and traffic signs, with structured data, includ-\\nprovesboththesafetyandoperationalefficiencyofAVsin\\ningsignaltimingplansandweatherrecords.Together,these\\nchallengingdrivingenvironments.\\nmultimodal sources provide a comprehensive environmen-\\nThe proposed structure 1 is composed of two key com-\\ntalsnapshot,showninFigure2,enablingtheLLMtoreason\\nponents:\\nabouttrafficconditionsandenhancedecision-making.\\nKnowledge database serves as the foundational compo-\\nnent of the framework, consolidating diverse sensor data,\\n3.2.1 UnstructuredMediaPreprocessing\\nincluding inputs from cameras, Lidars, and other environ-\\nmental sensors, into a standardized, language-compatible Given camera images I(t) and LiDAR point clouds L(t)\\nformat. This standardized repository enables seamless in- at time t, we construct a fused, normalized representation\\ntegrationofmultimodaldata,ensuringthattheautonomous F(t)forthevision-languagemodelasEq. 1.\\nvehicle can access and process comprehensive situational (cid:0) (cid:0) (cid:1)(cid:1)\\nF(t)=R C S (D (I(t))),S (D (L(t))) (1)\\ninformationefficiently. I I L L\\nBuiltupontheknowledgedatabase,theproactivequery- Where D (·) and D (·) denote denoising for images and\\nI L\\ngenerationmechanismemploysachain-of-thoughtprompt- LiDAR, respectively. S (·) and S (·) standardize images\\nI L\\n3and normalize LiDAR data. C(·,·) aligns the modalities This ensures the LLM learns to fuse textual and vi-\\nintoasharedframe,andR(·)appliesfinalresizingandfor- sual cues, producing accurate, context-rich outputs for au-\\nmattingtomeetmodelrequirements. tonomousdrivingscenarios.\\n3.2.2 StructuredDataPreprocessing\\n3.2.4 DataHarmonizationandInjection\\nForsignaltimingS(t,p)andweatherdataW(t,p)attime\\nt and position p, parse relevant fields and handle missing The harmonization step aligns VLM textual descriptors\\nvaluesviainterpolationordefaults. Removeduplicatesand with the structured data defined in the database schema.\\ncorrect anomalies. Convert all units to a standard system Givenrawvision-derivedtextdescriptionsattimeτ andlo-\\nandscalevaluesinEq. 2. cation(ℓ x,ℓ y),thispaperassociatesthemwithentriesinta-\\nbles such as vehicles, weather, pedestrians, intersections,\\nS′(t,p)=N(S(t,p)), W′(t,p)=N(W(t,p)) (2) traffic signs, traffic signals, and phases. Each integrated\\nrecordcanbeexpressedas\\nThen align S′(t,p) and W′(t,p) with sensor data times-\\ntampsandlocationstoensureconsistentspatiotemporalref- Record(τ,ℓ ,ℓ ,v ,s )\\nx y text structured\\nerencesfordownstreamreasoning.\\nwhere v denotes VLM-derived textual descriptors, and\\ntext\\n3.2.3 Vision-LanguageModel(VLM)Integration s corresponds to associated rows from the database\\nstructured\\ntables.\\nVisualFeatureExtractionandAlignment\\nData injection involves inserting these harmonized\\nAsuitableVLM,LLaVA[31],isemployedtobridgevi-\\nrecords into the database, leveraging existing columns\\nsion and language due to the seamless multimodal under-\\nlike timestamp,latitude,longitude and indexed fields\\nstandingandunifiedrepresentation, whichenablesflexible\\n(country,state,city in weather and intersections, or\\ntasks and context-rich reasoning. Given a camera input I,\\nday of week in traffic signals) to enable spatial-temporal\\nthepre-trainedvisionencoderE extractsafeaturevector\\nV\\nv ∈Rn,where, retrieval and filtering. By mapping textual descriptions\\nto structured entries, and utilizing provided primary keys,\\nv =[v ,v ,...,v ]T =E (I) (3) foreign keys, and indexes, the system supports efficient\\n1 2 n V\\nqueries and scalable updates as new sensor data streams\\nTointegratethiswiththeLLM’sembeddingspace,alearn- in. This integrated environment enhances situation aware-\\nable projection W ∈ Rm×n maps these visual features in ness, enabling real-time context retrieval for improved\\nEq. 4. decision-makinginautonomousdrivingscenarios.\\nv′ =WE (I) (4)\\nV\\n3.3.ProactiveRAGforLLMs\\nThis transformation ensures visual information is repre-\\nsented as textual tokens, enabling unified multimodal rea- In to enhance the perceptual capabilities of LLM-\\nsoning. based AD, we designed and implemented a Proactive\\nConditioningtheLLMonMultimodalInputs RAG method, which combines the generative capabilities\\nThe LLM receives three inputs: a textual query X, re- of LLMs with the querying capabilities of environmental\\ntrievedtextualknowledgeK fromthedatabase,andthevi- information repositories, aiming at proactively obtaining\\nsual embedding v′. These define the conditional input for complementary information related to the current driving\\ngeneratingaresponseY inEq. 5. environment.\\nThewholemethodcanbepreciselydescribedbythefol-\\nT\\nP(Y |X,K,I)=(cid:89) P(y |y ,X,K,v′) (5) lowingformula: theself-perceptiondataS,whichcaptures\\nt <t\\nthe sensory information from the ego vehicle, and the en-\\nt=1\\nvironmentalinformationE,retrievedfromadatabaseviaa\\nAt each step, the LLM considers previous tokens y <t, queryQ(S).ThequeryQ(S)isgeneratedbasedonS,spec-\\nthepromptX,knowledgeK,andv′. ifyingtherequiredsupplementarydata. Together,S andE\\nTrainingandFine-tuningObjective define the conditional input for the LLM, which generates\\nThemodelistrainedontuples(X,K,I,Y)tominimize thefinalperceptionPˆ asdescribedinEq.7.\\nthelossfunctionshowninEq. 6.\\nT\\nL(X,K,I,Y)=−(cid:88) logP(y |y ,X,K,v′) (6) Pˆ =LLM(Combine(S,E)), E =Search(S,Q(S))\\nt <t\\n(7)\\nt=1\\n43.3.1 Chain-of-ThoughtInstructionTuning This integration process maintains the localized details\\nfrom the self-perception data while incorporating global\\nThis method leverages the reasoning capabilities of LLMs\\ncontextualinformation,thusprovidingtheLLMwithamul-\\nbyconstructingchain-of-thoughtpromptstoextractkeyin-\\ntidimensional input for reasoning. To ensure consistency\\nformationfromthecurrentself-perceptiondataSandtoin-\\nand interpretability, the retrieved environmental informa-\\nfer which environmental data are necessary for enhanced\\ntionE istransformedintostructuredlinguisticinformation\\nsituation awareness. The self-perception data S comprise\\nusingnaturallanguagegenerationtechniques.Forexample,\\nreal-timesensoryinputsfromthevehicle’sarrayofsensors\\n”Thetrafficsignalaheadisred.”\\n(e.g., cameras, radar, LiDAR), thereby providing a direct\\nThe combined information Combine(S,E) is then\\nperceptionoftheimmediatesurroundings.\\npassedtotheLLM,whichperformsdeepreasoningtogen-\\nThroughasystematicstep-by-stepreasoningprocess,the eratethefinalresult: Pˆ =LLM(Combine(S,E))\\nchain-of-thought prompts enable the LLM to identify un-\\ncertaintiesinherentintheself-perceptiondataS andtode-\\n4.Experiment&ResultEvaluation\\ntermine the supplementary information required to resolve\\ntheseuncertainties. Forinstance,incomplexurbanscenar- 4.1.Setup\\nios,thesystemmaynecessitatequeryingthestatesoftraffic\\nThe experimental dataset is derived from the DLR Ur-\\nsignals,obtainingdetailedinformationaboutroadconstruc-\\nbanTrafficdataset(DLRUT),areal-worlddatasetcollected\\ntion,oracquiringcurrentweatherconditions.Theoutcomes\\nfrom intersections. It includes trajectory data of all partic-\\nofthisreasoningprocessaresubsequentlyutilizedtogener-\\nipants at the intersection, along with detailed day-specific\\nate the query Q(S), which facilitates the retrieval of perti-\\ninformationsuchastrafficsignals,weatherconditions,po-\\nnentenvironmentalinformationE fromthedatabase.\\nsitionsoftrafficparticipants,speed,acceleration,wind,sun-\\nlight, precipitation, visibility, and other rich data. The\\n3.3.2 LanguageQuerytoSQLQuery\\ndataset was collected using 14 multi-sensor systems at in-\\nNext,thesystemretrievesenvironmentalinformationEus- tersectionsandcontains31,477trajectoriesandthecurrent\\ningtheproactivesearchmechanismE =Search(S,Q(S)), status of 30 traffic lights.The locations in the data set are\\nwhichtransformsthenaturallanguagequeryQ(S),derived latitudeandlongitudeintherealworld,andADEandFDE\\nfrom the self-perception data S and the LLM’s reasoning, inthevalidationphasearecalculateddirectlyfromthem.\\ninto standardized SQL queries for efficient retrieval from To validate the effectiveness of LLMs in this process,\\nenvironmentaldatabases.Thistransformationensurescom- we constructed a closed-loop test environment suitable for\\npatibility between the high-level reasoning outputs of the GPT-4 reasoning. First, we distinguished the ego vehicle\\nLLMandthestructuredquerylanguagerequiredtoaccess from other traffic participants by defining a visible range.\\nthe database. By dynamically generating context-specific The perceptual environment of the vehicle was simulated,\\nqueries,thesystemenablespreciseandtargetedretrievalof withtheperceptionrangesettowithin30meters.Addition-\\ndatarelevanttothecurrentdrivingenvironment. Forexam- ally,roadinformationwasformattedtobeeasilyunderstood\\nple: bytheGPT-4,andallrelevantinformationwasfedintothe\\nGPT-4 to support its decision-making process. During the\\n• Natural Language Query: “Retrieve the traffic signal process,wemonitoredtheintermediateoutputsoftheGPT-\\nstatusforthecurrentroadsegment.” 4toensureitcorrectlyunderstoodtheenvironment.\\nTheexperimentemployedacontrolledvariablemethod,\\n• TranslatedSQLQuery:\\nwith the variable being whether a retrieval database was\\nused to assist the GPT-4 in trajectory prediction. The re-\\nSELECT signal_status\\ntrieval database included information beyond the vehicle’s\\nFROM traffic_data\\nperception range in the dataset. The GPT-4 actively re-\\nWHERE location = ’current_position’\\ntrieved necessary information about the current environ-\\nAND time = ’current_time’;\\nment from this database. In the comparative experiment,\\ntheGPT-4reliedsolelyonthevehicle’sperceptiondatafor\\ntrajectoryprediction.\\n3.3.3 Verbalization and Integration of Environmental\\nInformation 4.2.ResultsEvaluation\\nAfter obtaining the environmental information E, it is in- To assess the model’s predictive accuracy, we relied\\ntegrated with the current self-perception data S to form on standard trajectory metrics, including the average dis-\\na comprehensive representation of the environment, ex- placementError(ADE)andfinaldisplacementerror(FDE).\\npressedas: Combine(S,E). Theseindicatorsprovidedastraightforwardwaytocompare\\n5the baseline model, which had no access to environmental\\nretrievaldata,againsttheenhancedversionsupportedbythe\\nretrievaldatabase.\\nWecomparedthebaselinemodel(GPT-4)relyingsolely\\nonself-perceptiondatawithourSenseRAGapproach. The\\nresults revealed that incorporating the proactive retrieval\\nmechanismconsistentlyyieldedsuperioroutcomes. Exper-\\nimentresultsareshowninTable1andTable2. Compared\\nto the baseline, our model reduced the ADE and FDE by\\n76.5% and 72.2%, respectively. Notably, the performance\\nimprovementismostpronouncedinlong-termpredictions,\\nparticularlyatthe10timestamp, wheretheSenseRAGen-\\nhanced model demonstrates a significant reduction in both\\nADE and FDE compared to the baseline. These improve-\\nments indicate that the model gained a stronger grasp of\\nbothimmediateandfuturestatesofthetrafficenvironment,\\nthanks to the supplementary contextual information pro-\\nvidedbytheretrievaldatabase.\\nTable 1. ADE Comparison between Baseline Model and RAG-\\nenhancedModelatDifferentTimestamps Figure3.ExampleofSQLQueryGeneration\\nTimestamp ADE↓\\nlocation,velocity,andaccelerationofmycarlo-\\nBaseline SenseRAG-enhanced catedat(604739.287,5792784.4887500005). In\\naddition, provide the same information for other\\n3 0.7531 0.1564\\nvehiclesaroundmycar.\\n5 2.3134 0.5681\\n10 8.5083 2.1410 This query was seamlessly transformed into an SQL\\nqueryfordatabaseretrieval3:\\nTheretrieveddatawasformattedasfollows:\\nTable 2. FDE Comparison between Baseline Model and RAG-\\nenhancedModelatDifferentTimestamps Attimestamp2023-09-2400:01:17,avehiclewas\\nlocatedat(604750.30,5792780.20)withaveloc-\\nTimestamp FDE↓ ityof(-3.00,1.00)m/sandaspeedmagnitudeof\\n3.16 m/s. The vehicle experienced an accelera-\\nBaseline SenseRAG-enhanced tionof(-0.50,0.20)m/s²withamagnitudeof0.54\\nm/s².\\n3 1.2544 0.2138\\n5 5.7354 1.4309\\nThisenrichedenvironmentalcontextwasthenintegrated\\n10 18.8942 7.8099 back into the model’s input space, allowing it to refine\\nits trajectory predictions. The additional spatial and kine-\\nmaticdataenabledthemodeltoanticipatepotentialinterac-\\nBeyond the quantitative scores, we conducted a qual-\\ntions with nearby vehicles and adapt its trajectory accord-\\nitative examination of the SenseRAG enchanced model’s\\ningly. This example illustrates the model’s ability to ac-\\nreasoning process. Using the chain-of-thought instruction\\ntively query, retrieve, and utilize external information in a\\ntuning,themodelactivelyidentifiedmissingorambiguous\\nstructured manner, enhancing its reasoning and decision-\\nenvironmental cues and generated targeted queries to the\\nmakingcapabilitiesindynamictrafficenvironments.\\ndatabase. In one scenario, the model sought additional in-\\nformationaboutsurroundingvehiclestoenhanceitsunder- In summary, the integration of SenseRAG, which com-\\nstandingofthetrafficenvironmentbeyondtheegovehicle’s binesself-perceptiondata,SQLretrievalqueries,andnatu-\\nindividualperceptionrange. Themodelgeneratedanatural rallanguagereasoning—significantlyimprovedbothquan-\\nlanguagequery: titativeandqualitativeaspectsoftrajectoryprediction. The\\nenhanced model exhibited reduced predictive errors (both\\nAt timestamp 2023-09-24 00:01:17, provide the ADEandFDE)andmoreintelligentdecision-making,sub-\\n6stantiating the value of retrieval-augmented generation for [7] Tom B Brown. Language models are few-shot learners.\\nLLM-basedautonomousdrivingsystems. arXivpreprintarXiv:2005.14165,2020. 1\\n[8] JunyiChai,HaoZeng,AnmingLi,andEricWTNgai.Deep\\n5.Conclusion\\nlearning in computer vision: A critical review of emerg-\\ningtechniquesandapplicationscenarios. MachineLearning\\nIn this paper, a proactive SenseRAG framework that\\nwithApplications,6:100134,2021. 1\\nleveragesLLMstoenhancesituationawarenessinAD.By\\nintegrating real-time, multimodal sensor inputs into a uni- [9] SyedAdnanYusuf,ArshadKhan,andRiadSouissi.Vehicle-\\nfied,language-accessibleknowledgedatabase,theapproach to-everything (v2x) in the autonomous vehicles domain–a\\nallows LLMs to dynamically reason about complex driv- technicalreviewofcommunication,sensor,andaitechnolo-\\ngiesforroadusersafety. TransportationResearchInterdis-\\ningenvironments. Chain-of-thoughtpromptingandacare-\\nciplinaryPerspectives,23:100980,2024. 1\\nfullydesignedquerymechanismempowerthemodeltore-\\ntrievepertinentenvironmentalcontextefficiently,overcom- [10] Muhammad Usman Hadi, Qasem Al Tashi, Abbas Shah,\\ning the latency and modality constraints traditionally as- Rizwan Qureshi, Amgad Muneer, Muhammad Irfan, Anas\\nsociated with LLMs in AD scenarios. Experimental re- Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu,\\net al. Large language models: a comprehensive survey of\\nsults with realistic V2X datasets demonstrate substantial\\nitsapplications,challenges,limitations,andfutureprospects.\\nimprovementsinperceptionandtrajectorypredictionaccu-\\nAuthoreaPreprints,2024. 1\\nracy, significantly reducing displacement errors compared\\ntobaselinemethods. [11] Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee,\\nThevalueofthisworkliesinitsabilitytogobeyondpre- Apoorv Saxena, Atharv Tyagi, and Nishanth Kotla. To-\\nwards optimizing the costs of llm usage. arXiv preprint\\ndefinedlabelsandstaticsceneinterpretations,enablingflex-\\narXiv:2402.01742,2024. 1\\nibleanddynamicunderstandingoftrafficscenarios.Byhar-\\nnessing LLMs’ inherent contextual reasoning, the method [12] Shunli Ren, Siheng Chen, and Wenjun Zhang. Collabora-\\noffersarobustpathwaytowardsaferandmoreadaptiveAD tiveperceptionforautonomousdriving: Currentstatusand\\nsystems. Future research could extend this framework by future trend. In Proceedings of 2021 5th Chinese Confer-\\nincorporating more diverse sensor modalities, refining re- enceonSwarmIntelligenceandCooperativeControl,pages\\n682–692.Springer,2022. 2\\ntrievalstrategiesforreal-timeoperationatscale,andgener-\\nalizing the approach to different urban settings, ultimately [13] YushanHan,HuiZhang,HuifangLi,YiJin,CongyanLang,\\npushingtheboundariesofintelligentmobilitysolutions. andYidongLi.Collaborativeperceptioninautonomousdriv-\\ning: Methods, datasets, and challenges. IEEE Intelligent\\nReferences TransportationSystemsMagazine,2023. 2\\n[14] LiliMiao,Shang-FuChen,Yu-LingHsu,andKai-LungHua.\\n[1] Henry Alexander Ignatious, Manzoor Khan, et al. An\\nHow does c-v2x help autonomous driving to avoid acci-\\noverviewofsensorsinautonomousvehicles.ProcediaCom-\\ndents? Sensors,22(2):686,2022. 2\\nputerScience,198:736–741,2022. 1\\n[2] ZhengxiaZou,KeyanChen,ZhenweiShi,YuhongGuo,and [15] XunYang,YunyangShi,JipingXing,andZhiyuanLiu. Au-\\nJiepingYe.Objectdetectionin20years:Asurvey.Proceed- tonomous driving under v2x environment: state-of-the-art\\ningsoftheIEEE,111(3):257–276,2023. 1 surveyandchallenges.IntelligentTransportationInfrastruc-\\nture,1:liac020,2022. 2\\n[3] Yujian Mo, Yan Wu, Xinneng Yang, Feilin Liu, and Yujun\\nLiao. Review the state-of-the-art technologies of seman- [16] Si Liu, Chen Gao, Yuan Chen, Xingyu Peng, Xianghao\\nticsegmentationbasedondeeplearning. Neurocomputing, Kong,KunWang,RunshengXu,WentaoJiang,HaoXiang,\\n493:626–646,2022. 1 JiaqiMa,etal. Towardsvehicle-to-everythingautonomous\\ndriving:Asurveyoncollaborativeperception.arXivpreprint\\n[4] Athanasios Voulodimos, Nikolaos Doulamis, Anastasios\\narXiv:2308.16714,2023. 2\\nDoulamis,andEftychiosProtopapadakis. Deeplearningfor\\ncomputervision:Abriefreview.Computationalintelligence [17] Vandana Narri, Amr Alanwar, Jonas Ma˚rtensson, Christof-\\nandneuroscience,2018(1):7068349,2018. 1 ferNore´n,LauraDalCol,andKarlHenrikJohansson. Set-\\n[5] Can Cui et al. A survey on multimodal large language membership estimation in shared situational awareness for\\nmodels for autonomous driving. In Proceedings of the automated vehicles in occluded scenarios. In 2021 IEEE\\nIEEE/CVFWinterConferenceonApplicationsofComputer IntelligentVehiclesSymposium(IV),pages385–392.IEEE,\\nVision,pages958–979,2024. 1,2 2021. 2\\n[6] Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao [18] Zhu Xiao, Jinmei Shu, Hongbo Jiang, Geyong Min,\\nMa, Pinlong Cai, Min Dou, Botian Shi, Liang He, and HongyangChen,andZhuHan.Overcomingocclusions:Per-\\nYu Qiao. Dilu: A knowledge-driven approach to au- ception task-oriented information sharing in connected and\\ntonomous driving with large language models. arXiv autonomousvehicles. IEEENetwork,37(4):224–229,2023.\\npreprintarXiv:2309.16292,2023. 1 2\\n7[19] Jia Quan Loh, Xuewen Luo, Fan Ding, Hwa Hui Tew, [30] Jun Yu, Yunxiang Zhang, Zerui Zhang, Zhao Yang, Gong-\\nJunn Yong Loo, Ze Yang Ding, Susilawati Susilawati, and peng Zhao, Fengzhao Sun, Fanrui Zhang, Qingsong Liu,\\nCheePinTan.Cross-domaintransferlearningusingattention JianqingSun,JiaenLiang,etal. Rag-guidedlargelanguage\\nlatentfeaturesformulti-agenttrajectoryprediction,2024. 2 modelsforvisualspatialdescriptionwithadaptivehallucina-\\ntioncorrector.InProceedingsofthe32ndACMInternational\\n[20] Chen Sun, Ruihe Zhang, Yukun Lu, Yaodong Cui, Zejian\\nConferenceonMultimedia,pages11407–11413,2024. 2\\nDeng,DongpuCao,andAmirKhajepour. Towardensuring\\nsafety for autonomous driving perception: standardization [31] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.\\nprogress,researchadvances,andperspectives. IEEETrans- Visual instruction tuning. Advances in neural information\\nactionsonIntelligentTransportationSystems,2023. 2 processingsystems,36,2024. 4\\n[21] Fei Wang, Penglin Dai, Chuzhao Li, Zhangjie Meng, and\\nKaiLiu.Towardscommunication-efficientcollaborativeper-\\nception:Harnessingchannel-spatialattentionandknowledge\\ndistillation. InZhipengCai,DanielTakabi,ShaoyongGuo,\\nand Yifei Zou, editors, Wireless Artificial Intelligent Com-\\nputing Systems and Applications, pages 228–240, Cham,\\n2025.SpringerNatureSwitzerland. 2\\n[22] YueHu,JuntongPeng,SifeiLiu,JunhaoGe,SiLiu,andSi-\\nhengChen. Communication-efficientcollaborativepercep-\\ntionviainformationfillingwithcodebook. InProceedings\\noftheIEEE/CVFConferenceonComputerVisionandPat-\\nternRecognition,pages15481–15490,2024. 2\\n[23] YuxuanZhu,ShiyiWang,WenqingZhong,NianchenShen,\\nYunqiLi,SiqiWang,ZhihengLi,CathyWu,ZhengbingHe,\\nandLiLi. Willlargelanguagemodelsbeapanaceatoau-\\ntonomousdriving? arXivpreprintarXiv:2409.14165,2024.\\n2\\n[24] ZhenjieYang,XiaosongJia,HongyangLi,andJunchiYan.\\nLlm4drive: A survey of large language models for au-\\ntonomous driving. In NeurIPS 2024 Workshop on Open-\\nWorldAgents,2023. 2\\n[25] XiandaGuo,RuijunZhang,YiqunDuan,YuhangHe,Chen-\\nming Zhang, Shuai Liu, and Long Chen. Drivemllm: A\\nbenchmarkforspatialunderstandingwithmultimodallarge\\nlanguage models in autonomous driving. arXiv preprint\\narXiv:2411.13112,2024. 2\\n[26] Xuewen Luo, Fan Ding, Yinsheng Song, Xiaofeng Zhang,\\nand Junnyong Loo. Pkrd-cot: A unified chain-of-thought\\nprompting for multi-modal large language models in au-\\ntonomousdriving. arXivpreprintarXiv:2412.02025,2024.\\n2\\n[27] XinLi,YeqiBai,PinlongCai,LichengWen,DaochengFu,\\nBoZhang,XuemengYang,XinyuCai,TaoMa,JianfeiGuo,\\netal.Towardsknowledge-drivenautonomousdriving.arXiv\\npreprintarXiv:2312.04316,2023. 2\\n[28] Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang,\\nHengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. A\\nsurvey on rag meeting llms: Towards retrieval-augmented\\nlarge language models. In Proceedings of the 30th ACM\\nSIGKDD Conference on Knowledge Discovery and Data\\nMining,pages6491–6501,2024. 2\\n[29] JianhaoYuan,ShuyangSun,DanielOmeiza,BoZhao,Paul\\nNewman,LarsKunze,andMatthewGadd.Rag-driver:Gen-\\neralisabledrivingexplanationswithretrieval-augmentedin-\\ncontextlearninginmulti-modallargelanguagemodel.arXiv\\npreprintarXiv:2402.10828,2024. 2\\n8',\n",
       " 'Socratic Questioning Learn to Self-guide Multimodal Reasoning in the Wild.pdf': 'Socratic Questioning: Learn to Self-guide\\nMultimodal Reasoning in the Wild\\nWanpengHu1∗,HaodiLiu2∗,LinChen1,FengZhou1,\\nChangmingXiao2,QiYang2,ChangshuiZhang2†\\n1AibeeInc 2TsinghuaUniversity\\nhttps://github.com/aibee00/SocraticQuestioning\\nAbstract\\nComplexvisualreasoningremainsakeychallengetoday.Typically,thechallengeis\\ntackledusingmethodologiessuchasChainofThought(COT)andvisualinstruction\\ntuning. However,howtoorganicallycombinethesetwomethodologiesforgreater\\nsuccessremainsunexplored. Also,issueslikehallucinationsandhightrainingcost\\nstillneedtobeaddressed.Inthiswork,wedeviseaninnovativemulti-roundtraining\\nand reasoning framework suitable for lightweight Multimodal Large Language\\nModels(MLLMs). Ourself-questioningapproachheuristicallyguidesMLLMs\\nto focus on visual clues relevant to the target problem, reducing hallucinations\\nand enhancing the model’s ability to describe fine-grained image details. This\\nultimately enables the model to perform well in complex visual reasoning and\\nquestion-answeringtasks. WehavenamedthisframeworkSocraticQuestioning\\n(SQ). To facilitate future research, we create a multimodal mini-dataset named\\nCapQA,whichincludes1kimagesoffine-grainedactivities,forvisualinstruction\\ntuningandevaluation,ourproposedSQmethodleadstoa31.2%improvement\\nin the hallucination score. Our extensive experiments on various benchmarks\\ndemonstrateSQ’sremarkablecapabilitiesinheuristicself-questioning,zero-shot\\nvisualreasoningandhallucinationmitigation. Ourmodelandcodewillbepublicly\\navailable.\\n1 Introduction\\nEffectivevisualreasoningandquestionansweringincomplexscenariosarehighlyvaluable,asthey\\nprovideaccurateandin-depthinsightsthatcanbecrucialinpracticalapplications. Currently,visual\\nreasoningandquestionansweringincomplexscenesremainasignificantchallenge. Researchers\\nareactivelydevelopingmodels,makingtrainingandfine-tuningdatasets,andcreatingevaluation\\nbenchmarkstoimproveperformanceinthisarea.\\nChain of Thought (COT) and visual instruction tuning are the common methods used to tackle\\ncomplicated visual reasoning and question answering tasks. Both methods have developed over\\ntime to become effective and mature, but how to organically combine them for complementary\\nadvantagesremainsanareaworthexploring. Atthesametime,bothmethodsfacechallengessuchas\\nhallucinationsandhightrainingcosts.\\n∗Equalcontribution.Namesaresortedrandomly.\\n†Correspondingauthor:zcs@mail.tsinghua.edu.cn.\\nPreprint.Underreview.\\n5202\\nnaJ\\n7\\n]VC.sc[\\n2v46920.1052:viXraSocratic Questioning (SQ): In this paper, we propose an innovative multi-round training and\\nreasoningframeworkcompatiblewithlightweightMultimodalLargeLanguageModels(MLLMs).\\nOur method is named Socratic Questioning (SQ): Facing a main problem, SQ uses heuristic,\\ncontinuous,andin-depthself-questioningtoencouragedeeperandmorecomprehensivethinking.\\nThisprocesshelpsidentifyerrors,broadenperspectives,sparkinspiration,andultimatelyleadto\\ndiscoveringthetruth. SQelegantlyintegratestheideasandtechniquesofChainofThought(CoT)\\nandVisualInstructionTuning,combiningtheadvantagesofbothwhileeffectivelyreducinghalluci-\\nnationsandsavingannotationandtrainingcosts.AnillustrationofhowSQworksisshownatFigure5.\\nChain-of-Thought&VisualInstructionTuning: Extensiveresearchhasshownthatsimulating\\nthestep-by-stepreasoningprocessofhumanscansignificantlyenhancetheperformanceofLLMs\\non reasoning tasks. Consequently, the Chain of Thought (CoT) approach was proposed and has\\nbecomeastandardmethodforaddressingcomplexreasoningproblems,laterextendedtomultimodal\\ndomain. Meanwhile,greatworkslikeLLAVA[26],LLAVA-1.5[25],InstructBLIP[10],Qwen-vl[2]\\nhavedemonstratedthegreatsuccessofvisualinstructiontuningincreatingageneral-purposemodel\\nthatcaneffectivelyfollowmultimodalinstructions,alignwithhumanintentsandpreferences,and\\naccomplishzero-shotgeneralizationsonunseendata.\\nSocraticQuestioning(SQ),aheuristicself-guidingapproach,representsasignificantrefinementand\\ninnovationofthecurrentCoTmethodology. SQtacklesacomplicatedvisualreasoningandquestion\\nansweringprobleminfoursteps:\\n1. Self-ask: Figureoutwhatfine-grainedinformationareneededforourreasoningtasksbycoming\\nupwithsomequestionstoaskitself.\\n2. Self-answer: Acquirethedemandedfine-grainedinformationvisuallygroundedintheimageby\\nansweringthepreviouslyself-askedquestions.\\n3. Consolidate&Organize: Producethedetaileddescriptionofimagebycoherentlyconsolidating\\nandorganizingtheinformationcontainedinthegeneratedQ&Apairs.\\n4. Summarize&Condense: Producethesummarizedcaptionretainingthecoreelementsbysum-\\nmarizingtheinformationmostrelevanttoourreasoningtasksandcondensingthedetaileddescription.\\nWe organize the prompts(with image), self-asked questions, corresponding answers, detailed\\ndescriptions,andsummarizedcaptionsintoaninstructionalconversationformat,therebycreating\\namultimodalmini-datanamedCapQAforvisualinstructiontuningtheMLLMs. Despitebeing\\nfine-tunedonlyonthetinyCapQAdataset,theMLLMgivenbySQmethodhasshownimpressive\\nzero-shotperformanceonmultiplevisualreasoningandquestion-answeringbenchmarksthattest\\ncomprehensive knowledge and recognition abilities, demonstrating its versatility as well as the\\nsuccessofourrefinementandinnovationoftheCoTmethodology.\\nHallucination&Training Cost: The issue of hallucinations has consistently accompanied the\\ndevelopmentofLargeLanguageModels(LLMs),posingasignificantchallengetotheirreliability.\\nRemarkably, our experiments demonstrate that Socratic Questioning (SQ) effectively reduces\\nhallucinationswithoutincurringadditionalcostlikecomplicatedarchitectures,largermodulesand\\nextradataprocessing. Additionally,SocraticQuestioning(SQ)canbewidelyadaptedtovarious\\nMLLMs, particularly lightweight ones, thus enabling us to avoid substantial training cost. As is\\nwellknow, CoTmethodsandvisualinstructiontuningmethodsrequireannotationsofrationales\\nandinstructionalconversationsrespectively. Inordertosavethehugecostofmanualannotating,\\nresearchershaveleveragedLLMstoautomaticallygenerateannotationsofdata. Followingthisgood\\npractice,weutilizeGPT-4v[1]togenerateourannotations.\\nInthispaper,wepresentSocraticQuestioning(SQ),anflexible,reliableandeffectiveframework\\nforvisualreasoningandquestionansweringincomplexscenes. Itdrawsontheprinciplesofthe\\nSocraticQuestioning,guidingoneselfthroughheuristicquestioningtobetterunderstandtheproblem\\nand its context, ultimately providing an informative and insightful description and caption with\\n2Figure1: ComparisonofQuestionsGenerationonLLaVA-with-SQandLLaVA.\\nparticularlyfewhallucinations. Ourpapermakesthefollowingkeycontributions:\\n1. WeproposeaninnovativevisualreasoningframeworkSocraticQuestioning(SQ)thatcleverly\\nintegratetheadvantagesofCoTandvisualinstructiontuningwhileeffectivelyreducinghallucinations\\nandtrainingcosts.\\n2. Wecreateamini-datasetCapQAforfine-tuningandevaluations. Despiteitssmallsize,CapQA\\nsuccessfully endows MLLMs with the capabilities of heuristic self-questioning, reliable key\\ninformationretrieval,andzero-shotvisualreasoning. Italsoservesasagoodbenchmarkforvisual\\nreasoningandquestionansweringonfine-grainedhumanactivity.\\n3. We evaluate our framework on various benchmarks for visual reasoning and hallucinations.\\nAdditionally,GPT4[29]isleveragedtohelpassessthequalityofself-askedquestionsandhallucina-\\ntionlevelsofdescriptions. TheextensiveexperimentsstronglysupportourclaimsaboutSocratic\\nQuestioning(SQ).\\n2 RelatedWork\\n2.1 MultimodalChainofThought\\nMM-CoT[39]firstproposedatwo-stagereasoningframeworkwhereanLLMinitiallyprocesses\\nimage-textdatatoobtainarationale,andthentherationaleisfedintotheLLMtoobtainthefinal\\nanswer. Somesubsequentworksconcentrateonthebetteralignmentandfusionoflanguageand\\nvision modalities. DPMM-CoT[14] leverages the idea and architecture of T2I stable diffusion\\nmodeltoflexiblyadjustvisualfeatureextractionaccordingtoproblemprompts. Additionally,some\\nresearchfocusesonusinggraphdatatoencodepeople,objects,andtheirmutualrelationships. This\\napproachaimstocapturemorefine-grainedinformationfromimages,therebyenhancingthebenefits\\nofmultimodalCoTfromthevisualmodalityandreducinghallucinations. KAM-CoT[28]harnesses\\n3graph neural networks to process and encode the Knowledge Graph produced from each image,\\nwhileCCoT[5]delicatelypromptsLLMtogenerateascenegraphinJsondictionaryformatfrom\\neachimage.\\nSubstantial efforts have also been made in reducing the annotation costs incurred by the huge\\ndemandoftrainingdata. UtilizingAIsystemtoautomaticallygeneratedataisacommonandnatural\\npractice. T-SciQ[34]automaticallygeneratesteachingdatacontainingquestion-answer-COT(Chain\\nofThought)fromLLMsandtheteachingdatawillbeappliedforfuturefinetuning. CURE[6]devises\\nanLLM-Human-in-the-Looppipelinetosemi-automaticallygeneratetrainingdataandexplicitly\\nmodels fine-grained reasoning chains composed of coherent sub-questions and corresponding\\nanswers, fromwhichwecanabstracthigher-levelrationales. Moreover, thereareworksdevoted\\nto uncover and unleash LLMs’ judgement and self-guiding capabilities to tackle problems more\\neffectively. DDCoT[42]guidestheLLMstodecomposethemainproblemandcarefullydistinguish\\nwhich parts can be answered using its own knowledge and which parts require information\\nprovidedbyavisualrecognitionmodel. Ultimately,theLLMandthevisualrecognitionmodeleach\\nperformstheirrespectivetasks,workingtogethertoformacompleteproblem-solvingreasoningchain.\\n2.2 Hallucinationmitigation\\nTheworkdonebyZechenBaietal[3]isanexcellentsurveyofferingacomprehensive, in-depth,\\nandsystematicintroductionandanalysisofthecauses,evaluationmetrics,andcurrentsolutionsfor\\nhallucinationsinMultimodalLargeLanguageModels(MLLMs). Accordingto[3],hallucinations\\ncan originate from data, model, training process and inference process. Our insights highlight a\\nparticularlyimportantcauseofhallucinations: MLLMstendtospontaneouslyignorevisualfeatures.\\nCurrent MLLM architectures are highly imbalanced as the language model (LLM), with strong\\npriorsembeddedduringmassivepretraining,weighsmuchmorethanthevisualmodule,suffering\\nsignificantinformationlosswhileextractingvisualfeatures. AlsowhenanMLLMgeneratestokens\\nsequentially in an autoregressive manner during inference, it increasingly focuses on the tokens\\nthathavealreadybeengeneratedastheoutputgetslongerandlonger,graduallyignoringtheinput\\nprompt,especiallythevisualinformation.\\nResearchershavecomeupwithmanysolutionsfortheissueof\"VisualIgnorance\". LLaVA-1.5[25],\\nQwen-vl[2],Internvl[8]andHallE-Switch[38]haveshownthatincreasingthenumberofparameters\\ninthevisionencoderandimprovingimageresolutioncaneffectivelyreducehallucinations. The\\nworksin[15],[17],[33]and[18]enhancetherepresentationofthevisualcomponentbyintegrating\\nvisualfeaturesextractedfromvariousvisionencoders,utilizingvisualperceptiontoolssuchasOCR\\ntoolsandobjectdetectors,andincorporatingperceptualinformationlikedepthmapsandsegmentation\\nmasks, allowing the visual part to play a bigger role. To enable MLLM training to benefit from\\nfeedback in the same way that LLM training does, Silkie[22], HA-DPO[41], LLaVA-RLHF[31]\\nandRLHF-V[37]leveragefeedbackfrombothAIsystems(RLAIF)andhumans(RLHF)totraina\\nrewardmodelthatcanidentifyhallucinationsandpreferlow-hallucinationresponses. Withregardto\\ninferencestage,MARINE[40],GCD[11]andHALC[7]adheretotheconceptof\"guideddecoding,\"\\nutilizinggroundedvisualobjects,groundedvisualtokens,andevenscoresthatcanaccuratelymeasure\\nthedegreeofhallucinationtoguidethedecodingprocessofMLLMs. Theseapproachesensurethat\\nthegeneratedlanguageisasvisuallygroundedaspossible.\\n3 Method\\n3.1 Architecture\\nSQarchitecture ThenetworkarchtectureofSQisillustratedinFigure2.Inordertoreducememory\\nusage,wemaketheLLMactasaQuestionGenerator,QuestionAnswerandVisualSummarizer\\nsimultaneously. AsaQuestiongenerator,theLLMgeneratesalistofquestionsseekingvaluable\\ninformation to help itself correctly interpret the ongoing activity within the given image. As a\\nQuestionAnswerer,theLLManswersthesequestionsonebyone(essentiallyperformingVQAtasks)\\ntoproducetherationaleconsistingoftheQ&Apairs. AsaVisualSummarizer,theLLMprovides\\nfinaldetaileddescriptionsandsummarizedcaptionsbasedontheinformationencodedintheprevious\\n4Figure2: SQnetworkarchitecture. NotethatthetwoLLMmodulescorrespondtoasingleLLM.The\\nvisualencoderoutputsvisualfeaturesthatwillbemappedbytheadaptertovisualtokens. Thevisual\\ntokens,alongwiththeself-askabdself-answerprompttoken,makingtheLLMgeneratearationale\\ncomprisedofQ&Apairs. ThenthesameLLMtakestherationaletokensandthedescriptionand\\nsummarizationprompttokenstoproducethefinalcaption.\\nrationale. NotethatthedashedLLMmodulenamedSocraticQuestioningontheleftdenotesthe\\nrolesofQuestionGeneratorandQuestionAnswerer,whiletheundashedLLMmoduleontheright\\ndenotestheroleofVisualSummarizer. ThetwoLLMmodulesareactuallyrepresentationsofthe\\nsameLLM.AllthreefunctionalitiesofLLMcanbetrainedjointly,,makingtheprocessefficientin\\ntermsofmemoryandcomputation.\\nAdapter. Theadaptermodulecanbeimplementedusingasimplelinearlayer,amultilayerpercep-\\ntron(MLP),oracross-attention-basedtransformerarchitecture. Asthecomplexityofthenetwork\\nincreases,sodoestheamountofdatarequiredfortraining. IthasbeendemonstratedinLLaVA-1.5\\n[25]thatusingatwo-layerMLPimprovesthemodel’smultimodalcapabilitiescomparedtousing\\nalinearprojection. Asatradeoffbetweencomputationalcostandperformance,wehaveadopteda\\ntwo-layerMLPasouradapter. Itmapsvectorsfromtheimagefeaturespacetothewordembedding\\nspaceofLLM,aligningthevisualfeatureswiththetextualfeaturespace.\\nVisualEncoderandTextualDecoder. WeuseapretrainedViT-L/14[12]asourimageencoder\\nandapretrainedVicuna[9]asourLLM.Thevisualfeatureandtextualembeddingspacesarealigned\\nusingadapters,whichconsistoftwo-layerMLP.\\n4 GenerationoftheCapQADataset\\n4.1 DataCollection\\nWecollectdatafromtheConsentedActivitiesofPeople(CAP)[4]dataset,whichcomprisesvideo\\nclipsofdailyactivitiesperformedbyconsentingindividualsaroundtheworld. TheCAPdataset\\ncontains 1,454,540 clips, categorized into 512 classes of fine-grained activities with labels (like\\n\"personopenscardoor\")encodingsubjects’actionsandtheobjectstheyareinteractingwith. The\\nactivitiesarefine-grainedbecausetheydifferinthesubtledetailsofactionsandinteractingobjects,\\nalthoughtheymayappearsimilaroverall. Weselect20activitiesandrandomlyextract50clipsfrom\\neachactivity. Fromeachclip,wechoseonekeyframethatclearlydemonstratestheongoingactivity\\ntoserveasourfinalimagedatawithactivitylabel.\\n4.2 Designingpromptstoautomaticallygenerateannotation\\nTofurtherannotatetheimagedataobtainedin2.1,weutilizeGPT-4v[1]toautomaticallygenerate\\ntheannotationsincludingalistofquestions,correspondinganswers,adetaileddescriptionanda\\nsummarizedcaption. Ourmeticulouslydesignedpromptforannotationsacquisitionsisshownat 1:\\n• Questions&Answers. Toaddresstheongoingactivitydepictedinanimage,wepromptthe\\nGPT-4Vmodeltogeneraterelevantquestionsandprovidecorrespondinganswers. Weguide\\ntheGPT-4vmodeltorefineitsquestionsandvalidatethatitsanswersarevisuallywell-founded\\nsothateachQApairisspecific,accurate,andmeaningful. Wealsoprovidethegroundtruth\\nactivitylabel(excludedinthefinalproducedannotation)suchas“personopenscardoor”for\\nbetteralignmentofannotationstoreality. Pleasenotethatthegroundtruthlabelwillonlybe\\nusedindatageneration.\\n5• DetailedDescription. BasedontheinformationimpliedinthesequenceofproducedQ&A\\npairs,theGPT-4vmodelprovidesadetaileddescriptionthatincludestheperson’sappearance\\nandactions,thesurroundingenvironment,theattributesandconditionoftheinteractedobjects,\\naswellasinsightsintotheperson’sintentionsandpotentialchangesinthesituation.\\n• SummarizedCaption. Althoughgreatlyinformative,thedetaileddescriptioncontainslotsof\\nredundantinformationandevensomehallucinations,whichincreasestheriskofmisleading\\nusers. Therefore,wealsoprompttheGPT-4vmodeltocondensethedetaileddescriptioninto\\na summarized caption, a concise expression retaining the core content most relevant to the\\nactivity’stheme.\\nPrompt\\nPleasecomeupwith5-8questionsrelatedtothedetailsoftheactivityandanswerthembased\\nontheimage. Ifcertainquestionsremainuncertain,furtherrefinethosequestions,thencomeup\\nwith5necessaryquestionsforthoseuncertainaspectsandprovideanswers.Summarizetherefined\\nquestionsandanswerstoattemptaddressingtheuncertainquestionsagain,withoutexceeding20\\nquestionsintotal.Finally,compileallquestionsandanswerstocompletetwodescriptionsofthe\\nactivitydepictedintheimage.Itisknownthattheactivityis’personenterscar’,butdonotinclude\\nthisphraseinyourdescriptions. Startwithadetaileddescription,ourmaintaskistodetectthe\\nactivitybasedontheimage,sopleaseprovideasdetailedadescriptionaspossible,relatedtothis\\nmaintask. Youshouldaimforagranularandcomprehensivedescriptionofeverydetailofthe\\nactivity,within1000words;thenprovideaconcisedescription,simplifyingthedetaileddescription\\ntoretainonlythepartsmostrelevanttotheactivity,within400words.Pleaseself-askandself-answer\\nagain.\\nTable1: Oneexampletopromptthegpt-4vmodeltogenerateannotationsforthegivenimage.\\n4.3 DataLabelFormat\\nTofacilitatefuturefine-tuning,wehavedecidedtoorganizetheacquiredannotationsinamulti-round\\nconversationformat,similartothatusedinLLaVA[26]. Thefirstroundofconversationgenerates\\nthelistofquestionsandthesubsequentroundsconsistofQ&Apairswherethequestionsaretaken\\nfromthelistinorderandanswersaregivenbyGPT-4vaccordingly. Finally, thelasttworounds\\nofconversationelicitthedetaileddescriptionandsummarizedcaptionrespectively. Anexampleof\\nannotationformattedintomulti-roundconversationisshownatTable8intheappendix.\\nWeextractkeyframesfromselectedactivityclipsoftheCAPdataset,leverageGPT-4vtoautomati-\\ncallyannotatingimagedataandfinallyorganizetheannotationsintoastructuredconversationformat.\\nThisapproachenhancesthegranularity,accuracy,depth,andcomprehensivenessofourannotations,\\nwhilestreamliningtheannotationprocessandoptimizingdatautilityforfurtheranalysis.\\n4.4 Training\\n4.4.1 Trainingdataformat\\nInSection4.3, wedepictthelabelformatusedforourCapQAdataset8. Assumingamulti-turn\\nconversation{X1,X1,X2,X2,...,XT,XT}consistsofT turns,wedenotethehuman’squestionin\\nq a q a q a\\nthej-thturnofconversationasXj andsystem(likeGPT)’sanswerinthej-thturnofconversationas\\nq\\nXj.\\na\\nQuestionsGeneration. Thefirstturn[X1,X1]isspecificallydesignedtotraintheLLMtofunction\\nq a\\nasaQuestionGenerator. X1denotesacarefullycraftedpromptrequestingthequestionsgeneration,\\nq\\nwhileX1 denotesthelistofquestionsgenerateduponX1. Again,thequestionswouldguidethe\\na q\\nLLMtocapturefine-graineddetailsofhumanactivitysoastocorrectlyinterprettheimage.\\nAnswersGeneration. (X2,X3,...,XT−3,XT−2)aretheindividualquestionscontainedinthe\\nq q q q\\nlist X1, while (X2,X3,...,XT−3,XT−2) are their corresponding answers. Thus, the turns\\na a a a a\\n6(X2,X2,...,XT−2,XT−2) of the conversation are well-suited to train the LLM to function as\\nq a q a\\naQuestionAnsweringandfinishtheVQAtaskswell.\\nDetailed Description Generation ([XT−1,XT−1]). In step T −1, the system is instructed to\\nq a\\ngenerateadetaileddescriptionthatthoroughlyarticulatesthecontentsoftheimage,includingobjects\\nwithinthescene,thebackground,andtheattributesandactionsofpeople. Thegoalistocaptureas\\nmuchdetailedinformationaspossibletoenhancethedepthandcomprehensivenessofthedescription,\\ntherebylayingasolidfoundationforfuturereasoning.\\nSummarizedCaptionGeneration([XT,XT]). Followingthat,instepT,thesystemisinstructed\\nq a\\nto generate a condensed caption. This step distills the information in the detailed description by\\nfocusingonthecoreelements. Itincludesonlythemostsignificantfeaturesandactionsfromthe\\nimage,aimingtoofferaclear,succinct,andinformativecaptionwithoutoverwhelmingcomplexity.\\nFigure3: Illustrationsofthetraining(left)and3-turninference(right)processesofSQ.\\n4.4.2 TrainingProcedure\\nWetrainourmodelusingaclassicaltwo-stageprocess: firstpretraining,followedbyinstruction-\\ntuning.\\nStage1: Pretrain WeutilizetheLLaVA-CC3M-Pretrain-595Kdataset[26],comprisedof595K\\nimage-textpairsfilteredfromCC3M,topretraintheadapterofSQ.Thepurposeofthisstageisto\\nachieveagoodalignmentbetweenthevisualfeaturespaceandthetokenembeddingspaceofLLM.\\nTheparametersofboththeimageencoderandtheLLMarefrozenthroughoutthepretrainingphase.\\nStage2. Instruction-Tune Wefine-tuneourSQmodelusing666Kimage-textpairs. Itcontains\\nllava_v1_5_mix665k[25]andCapQA_0.9kdatasetintroducedelaboratelyinSections 4.3and 4.4.1.\\nWeprocessedthequestionsfromtheConv58kdataset[25],includedinthellava_v1_5_mix665k[25],\\nthesequestionswerereorganizedtoconformtothedataformatdescribedinSection4.3. Toprevent\\noverfitting, during training, we randomly insert the generated question list at any round of the\\nconversation. Duringthisphase,theimageencoderremainsfrozen,whiletheadaptersandLLM\\n(using LoRA [16]) are fine-tuned. We perform instruction-tuning of the LLM on the prediction\\ntokens,usingthesameauto-regressivetrainingobjectiveasLLaVa[26]:\\nL\\n(cid:89)\\np(X |X ,X )= p (x |X ,X ,X ), (1)\\na v q θ i v q,<i a,<i\\ni=1\\nWhereListhetokensequencelength,X standsforthevisualinput(visualtokens),X andX\\nv q a\\nstandforthetokensofhumaninstructionsandsystemanswers,respectively,acrossallT roundsof\\nconversation. X andX arerespectivelythehumaninstructionstokensandsystemanswers\\nq,<i a,<i\\ntokensinallturnsbeforethecurrentlypredictedtokenx .\\ni\\n4.5 Inference\\nTheinferenceprocessisillustratedintherightsideofFigure3. Wecanchoosetoemploy1-turn\\nor3-turninference. Simply,1-turninferencedirectlyproducesthefinalcaptionbasedonthegiven\\nimage,problemstatementandcontext(Inputs). AstherightsideofFigure3shows,3-turninference\\nfirstprompttheLLMtogeneratealistofquestionsbasedontheInputs,thenmaketheLLMprovide\\nvisuallygroundedanswersofthesequestionsandfinallylettheLLMgeneratethedetaileddescription\\n7andsummarizedcaption,wherethemoreconcisecaptionistreatedasthefinaloutput. Experiments\\nshowthat1-turninferenceisbettersuitedforstraightforwardproblemswhile3-turninferenceworks\\nbetterforcomplicatedproblemsrequiringmulti-stepreasoningandfine-graineddetails.\\n5 Experiments\\n5.1 CapQA\\nCapQA,proposedinthispaper,isanovelmini-\\nMethod HalS QQS\\ndataset consisting of 982 images, each asso-\\nciated with a multi-turn conversations. The InstructBLIP 87.4 78.4\\nLLaVA-1.5 69.3 31.5\\ndatasetisdividedintoatrainingsetandatest\\nLLaVA-1.5+SQ 90.9 92.3\\nset,withthetrainingsetcontaining882samples train\\nLLaVA-1.5+SQ +3turns 93.0 -\\ntrain\\nand11.9kQApairs,andthetestsetcontaining\\n100samplesand1.4kQApairs.\\nTable2:Ablationw/omulti-turntrain/inferenceon\\nWedesignedtwoevaluationmetrics: (A).Hallu- CapQA.Weadaptvicuna7basLLM.HalS:Hal-\\ncination,measuringthedegreeofhallucination lucinationScore;QQS:QuestionsQualityScore.\\nindetaileddescriptions,withhigherscoresindi- EvaluationareGPT4[29]-aid.\\ncatinglesshallucination.(B).QuestionsQuality,\\nreflectingmodel’sabilitytogeneratequestions,\\nwithhigherscoresreflectingbetterquality,diversity,andeffectiveness. Thecalculationmethodfor\\nthescorecanbeexpressedasfollows:\\nHalS QQS\\nHalS= pred ;QQS= pred (2)\\nHalS QQS\\ngt gt\\nInEq2,HalS representstheaveragescoreofallmodelpredictionsreviewedbyGPT-4[29],while\\npred\\nHalS denotes the average score of all labels reviewed by GPT-4 [29]. Similarly, QQS is the\\ngt pred\\naveragescoreofallmodelpredictionsreviewedbyGPT-4[29],andQQS istheaveragescoreofall\\ngt\\nlabelsreviewedbyGPT-4[29]. ThepromptusedtoinstructGPT-4forscoringisshowninTable6.\\nAsshowninTable2,ourproposedSQframeworkleadstoa31.2%improvementinthehallucination\\nscore and a significant increase in the question quality score from 31.5 to 92.3. Additionally,\\nemploying a 3-turn inference mode, which includes question-answer-caption 3 steps during the\\ninferencephase,furtherreduceshallucinationby2.3%. Withoutincreasingcomputationalcost,our\\nSQmethodeffectivelyreducesthemodel’shallucinationwhilegeneratingdetaileddescriptions.\\n5.2 POPE\\nPOPE [24] is focused on assessing the hallucinations in MLLMs by testing if the MLLMs can\\ncorrectlytelltheexistenceofobjectsinimages. Itemploysdifferentsamplingmethodstoconstruct\\nnegativesamples,includingrandom, popular,andadversarialsampling. Intherandomsampling\\nsetting,objectsthatarenotpresentintheimagearechosenrandomly. Forthepopularsetting,the\\nabsentobjectsareselectedfromapoolofthemostfrequentlyoccurringobjects. Intheadversarial\\nsetting, objects that commonly co-occur but are not present in the image are used as negative\\nsamples. We achieved better performance than Woodpecker [36] on the POPE benchmark and\\nattainedstate-of-the-art(SOTA)F1scoresacrossthreedifferentmodes.\\n5.3 ComparativeExperiment\\nTheexperimentalresultspresentedinTable12demonstratethesuperiorityofourproposedmethod\\ncompared to several state-of-the-art (SoTA) methods across six benchmarks. Our method uti-\\nlizes the Vicuna-7B [9] large language model with 336 resolution, 558K pre-train data, and\\n666K(llava_v1_5_mix665k[25]+CapQA_0.9k)fine-tunedata. ItachievesaHallucinationRate\\n(HalR) of 0.57 and an MMHal Average Score (AvgS) of 2.16, outperforming other methods in\\nthesemetrics. Notably,ourmethodalsoexcelsintheLLaVA-QA90[26]benchmarkwithascore\\nof81.3,andshowscompetitiveperformanceintheLLaVA-Bench(In-the-Wild)[26],MME[13],\\nScienceQA-IMG[27],andTextVQA[30]benchmarkswithscoresof66.8,1523.4,68.37,and58.57,\\n8Setting Method Accuracy Precision Recall F1-Score YesRate\\nLLaVA[26] 86.00 87.50 84.00 85.71 48.00\\nLLaVA+Woodpecker[36] 87.67 95.93 78.67 86.45 41.00\\nMiniGPT-4[43] 54.67 57.78 34.67 43.33 30.00\\nMiniGPT-4+Woodpecker 85.33 92.06 77.33 84.06 42.00\\nRandom\\nmPLUG-Owl[35] 62.00 57.26 94.67 71.36 82.67\\nmPLUG-Owl+Woodpecker 86.33 93.60 78.00 85.09 41.67\\nOtter[20] 72.33 66.18 91.33 76.75 69.00\\nOtter+Woodpecker 86.67 93.65 78.67 85.51 42.00\\nLLaVA-1.5[25] 88.18 97.45 79.13 87.34 41.85\\nOurs 89.21 95.69 82.80 88.78 44.60\\nLLaVA[26] 76.67 72.22 86.67 78.79 60.00\\nLLaVA+Woodpecker 80.67 83.82 76.00 79.72 45.33\\nMiniGPT-4[43] 56.67 58.77 44.67 50.76 38.00\\nMiniGPT-4+Woodpecker 82.33 85.40 78.00 81.53 45.67\\nPopular\\nmPLUG-Owl[35] 57.33 54.20 94.67 68.93 87.33\\nmPLUG-Owl+Woodpecker 83.00 84.14 81.33 82.71 48.33\\nOtter[20] 67.33 61.71 91.33 73.66 74.00\\nOtter+Woodpecker 84.33 88.15 79.33 83.51 45.00\\nLLaVA-1.5[25] 87.27 94.51 79.13 86.14 41.87\\nOurs 87.53 91.46 82.80 86.91 45.27\\nLLaVA[26] 73.33 69.02 84.67 76.05 61.33\\nLLaVA+Woodpecker 80.67 82.86 77.33 80.00 46.67\\nMiniGPT-4[43] 55.00 56.88 41.33 47.88 36.33\\nMiniGPT-4+Woodpecker 82.33 83.92 80.00 81.91 47.67\\nAdversarial\\nmPLUG-Owl[35] 56.33 53.51 96.67 68.88 90.33\\nmPLUG-Owl+Woodpecker 81.00 82.07 79.33 80.68 48.33\\nOtter[20] 66.67 61.16 91.33 73.26 74.67\\nOtter+Woodpecker 83.00 85.61 79.33 82.35 46.33\\nLLaVA-1.5[25] 85.13 89.92 79.13 84.18 44.00\\nOurs 85.23 87.03 82.80 84.87 47.57\\nTable3: ResultsonPOPE[24]. Thebestperformanceswithineachsettingarebolded.\\nMMHal\\nMethod LLM Res PT IT LLaVAqa90 LLaVAW MME SQAI VQAT\\nAvgS HalR\\nBLIP-2[21] Vicuna-13B 224 129M - - - - 38.1 1293.8 61.0 42.5\\nInstructBLIP[10] Vicuna-7B 224 129M 1.2M 2.1 0.58 85.8 60.9 - 60.5 50.1\\nInstructBLIP[10] Vicuna-13B 224 129M 1.2M 2.14 0.58 - 58.2 1212.8 63.1 50.7\\nQwen-VL[2] Vicuna-7B 448 1.4B 50M - - - - - 67.1 63.8\\nQwen-VL-Chat[2] Vicuna-7B 448 1.4B 50M - - - - 1487.5 68.2 61.5\\nLLaVA-1.5[25] Vicuna-7B 336 558K 665K 2.04 0.61 79.9 63.4 1510.7 66.8 58.2\\nOurs Vicuna-7B 336 558K 666K 2.16 0.57 81.3 66.8 1523.4 68.37 58.57\\nTable4: ComparisonwithSoTAmethodson6benchmarks. MMHal: MMHal-Bench[32],AvgS:\\nAverageScore;HalR:HallucinationRate;;LLaVAqa90:LLaVA-QA90[26];LLaVAW:LLaVA-Bench\\n(In-the-Wild)[26];SQAI: ScienceQA-IMG[27](zero-shot);VQAT: TextVQA[30];MME[13].\\nrespectively. Theseresultshighlighttherobustnessofourapproachinreducinghallucinationsand\\nimprovingoverallquestionqualitywithoutadditionalcomputationalload. Theintroductionofall\\ndatasetshasbeenmovedtoCintheappendix.\\n6 Conclusion\\nInthiswork,weintroducetheSocraticQuestioning(SQ),anflexible,reliableandeffectiveframe-\\nworkforvisualreasoningandquestionansweringthatfitswelltolightweightMultimodalLarge\\nLanguageModels(MLLMs). SQcombinesChainofThought(CoT)reasoningandvisualinstruction\\ntuningthroughheuristicself-questioning,effectivelyreducinghallucinationsandtrainingcostswhile\\nimprovingfine-grainedvisualdetaildescriptionandzero-shotreasoning. Ourexperiments,including\\nthosewiththenewCapQAdataset,demonstrateSQ’seffectivenessinreducinghallucinationsand\\nimprovingvisualdescriptionquality. ByefficientlyutilizinglightweightMLLMs,SQprovidesa\\ncost-effective,high-performancesolutionforcomplexvisualtasks,pavingthewayforfutureresearch\\ninmultimodalreasoning.\\nDiscussion. Thisworkismerelyanexplorationofheuristicself-questioning,andthereareareas\\nthatrequirefurtherimprovement. Forexample,designingareasonablelossfunctiontoconstrainthe\\nmodeltoaskmoreeffectivequestionsthatbenefittheoveralltask,andenhancingfine-grainedvisual\\n9informationusingVisuallargeModel(VLM)encoderswithregionalignmentcapabilities(suchas\\nGLIP[23],SAM[19],etc.). Theseaspectsareleftforfuturelong-termresearch.\\nAcknowledgements. WethanktheLLaVAteamfortheirawesomeworkatexplorationofMLLMs.\\nWethanktheLLaMAteamforgivingusaccesstotheirmodels,andopen-sourceprojects,including\\nAlpacaandVicuna.\\nReferences\\n[1] Chatgptcannowsee,hear,andspeakhttps://openai.com/index/chatgpt-can-now-see-hear-and-\\nspeak/. 2023. 2,5\\n[2] JinzeBai,ShuaiBai,ShushengYang,ShijieWang,SinanTan,PengWang,JunyangLin,Chang\\nZhou, and Jingren Zhou. Qwen-vl: A frontier large vision-language model with versatile\\nabilities. arXivpreprint,(2308.12966),2023. 2,4,9\\n[3] ZechenBai, PichaoWang, TianjunXiao, TongHe, HanZongbo, ZhengZhang, andZheng\\nMikeShou. Hallucinationofmultimodallargelanguagemodels: Asurvey. arXivpreprint,\\n(2404.18930),2024. 4\\n[4] JeffreyByrne,GregCastanon,ZhonghengLi,andGilEttinger. Fine-grainedactivitiesofpeople\\nworldwide,2022. 5\\n[5] YangyiChen,KaranSikka,MichaelCogswell,HengJi,andAjayDivakaran. Compositional\\nchain-of-thoughtpromptingforlargemultimodalmodels. arXivpreprint,(2311.17076),2024.\\n4\\n[6] YangyiChen,KaranSikka,MichaelCogswell,HengJi,andAjayDivakaran. Measuringand\\nimprovingchain-of-thoughtreasoninginvision-languagemodels. arXivpreprint,(2309.04461),\\n2024. 4\\n[7] ZhaorunChen,ZhuokaiZhao,HongyinLuo,HuaxiuYao,BoLi,andJiaweiZhou.Halc:Object\\nhallucination reduction via adaptive focal-contrast decoding. arXiv preprint, (2403.00425),\\n2024. 4\\n[8] ZheChen,JiannanWu,WenhaiWang,WeijieSu,GuoChen,SenXing,MuyanZhong,Qinglong\\nZhang,XizhouZhu,andLeweiLu. Internvl: Scalingupvisionfoundationmodelsandaligning\\nforgenericvisual-linguistictasks. arXivpreprint,(2312.14238),2023. 4\\n[9] Wei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,\\nSiyuanZhuang,YonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna:\\nAnopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. 5,8\\n[10] Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng\\nWang, Boyang Li, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose\\nvision-languagemodelswithinstructiontuning. arXivpreprint,(2305.06500),2023. 2,9\\n[11] AilinDeng,ZhiruiChen,andBryanHooi. Seeingisbelieving: Mitigatinghallucinationinlarge\\nvision-languagemodelsviaclip-guideddecoding. arXivpreprint,(2402.15300),2024. 4\\n[12] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,\\nThomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,\\nJakobUszkoreit,andNeilHoulsby. Animageisworth16x16words: Transformersforimage\\nrecognitionatscale,2021. 5\\n[13] ChaoyouFu,PeixianChen,YunhangShen,YuleiQin,MengdanZhang,XuLin,JinruiYang,\\nXiawu Zheng, Ke Li, Xing Sun, Yunsheng Wu, and Rongrong Ji. Mme: A comprehensive\\nevaluationbenchmarkformultimodallargelanguagemodels. arXivpreprint,(2306.13394),\\n2024. 8,9,17\\n[14] Liqi He, Zuchao Li, Xiantao Cai, and Ping Wang. Multi-modal latent space learning for\\nchain-of-thoughtreasoninginlanguagemodels. AAAI,2023. 3\\n10[15] XinHe, LonghuiWei, LingxiXie, andQiTian. Incorporatingvisualexpertstoresolvethe\\ninformationlossinmultimodallargelanguagemodels. arXivpreprint,(2401.03105),2024. 4\\n[16] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Zhu, Yuanzhi Li, Shean Lu, Lu Wang,\\nand Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint,\\n(2106.09685),2021. 7\\n[17] JiteshJain,JianweiYang,andHumphreyShi. Vcoder: Versatilevisionencodersformultimodal\\nlargelanguagemodels. arXivpreprint,(2312.14233),2023. 4\\n[18] QiruiJiao,DaoyuanChen,YilunHuang,YaliangLi,andYingShen. Enhancingmultimodal\\nlarge language models with vision detection models: An empirical study. arXiv preprint,\\n(2401.17981),2024. 4\\n[19] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,\\nTeteXiao,SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,PiotrDollár,andRossGirshick.\\nSegmentanything. arXiv:2304.02643,2023. 10\\n[20] BoLi,YuanhanZhang,LiangyuChen,JinghaoWang,JingkangYang,andZiweiLiu. Otter: A\\nmulti-modalmodelwithin-contextinstructiontuning. arXivpreprintarXiv:2305.03726,2023.\\n9\\n[21] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-\\nimage pre-training with frozen image encoders and large language models. arXiv preprint,\\n(2301.12597),2023. 9\\n[22] LeiLi,ZhihuiXie,MukaiLi,ShunianChen,PeiyiWang,LiangChen,YazhengYang,Benyou\\nWang,andKongLingpeng. Silkie: Preferencedistillationforlargevisuallanguagemodels.\\narXivpreprint,(2312.10665),2023. 4\\n[23] LiunianHaroldLi*,PengchuanZhang*,HaotianZhang*,JianweiYang,ChunyuanLi,Yiwu\\nZhong,LijuanWang,LuYuan,LeiZhang,Jenq-NengHwang,Kai-WeiChang,andJianfeng\\nGao. Groundedlanguage-imagepre-training. InCVPR,2022. 10\\n[24] YifanLi,YifanDu,KunZhou,JinpengWang,WayneXinZhao,andJi-RongWen. Evaluating\\nobjecthallucinationinlargevision-languagemodels. arXivpreprint,(2305.10355),2023. 8,9\\n[25] Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. Improved baselines with visual\\ninstructiontuning. arXivpreprint,(2310.03744),2023. 2,4,5,7,8,9,16\\n[26] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.Visualinstructiontuning.NeurlPS,\\n2023. 2,6,7,8,9,17\\n[27] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Cheng, Song-Chun Zhu, Oyvind\\nTafjord,PeterClark,andAshwinKalyan. Learntoexplain: Multimodalreasoningviathought\\nchainsforsciencequestionanswering. NeurlPS,2022. 8,9\\n[28] DebjyotiMondal,SurajModi,SubhadarshiPanda,RiturajSingh,andGodawariSudhakarRao.\\nKam-cot: Knowledgeaugmentedmultimodalchain-of-thoughtsreasoning. AAAI,2024. 3\\n[29] OpenAI. Gpt-4technicalreport. arXivpreprint,(2303.08774),2024. 3,8\\n[30] Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi\\nParikh,andMarcusRohrbach. Towardsvqamodelsthatcanread. CVPR,2019. 8,9,17\\n[31] ZhiqingSun,ShengShen,ShengcaoCao,HaotianLiu,ChunyuanLi,YikangShen,Chuang\\nGan,Liang-YanGui,Yu-XiongWang,andYimingYang. Aligninglargemultimodalmodels\\nwithfactuallyaugmentedrlhf. arXivpreprint,(2309.14525),2023. 4\\n[32] ZhiqingSun,ShengShen,ShengcaoCaoCao,HaotianLiu,ChunyuanLi,YikangShen,Chuang\\nGan,Liang-YanGui,Yu-XiongWang,YimingYang,KurtKeutzer,andTrevorDarrell. Align\\nlargemultimodalmodelswithfactuallyaugmentedrlhf. arXivpreprint,(2309.14525),2023. 9\\n11[33] ShengbangTong,ZhuangLiu,YuexiangZhai,YiMa,YannLeCun,andSainingXie. Eyes\\nwideshut? exploringthevisualshortcomingsofmultimodalllms. arXivpreprint,(2401.06209),\\n2024. 4\\n[34] Lei Wang, Yi Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, and Heng Tao Shen. T-sciq:\\nTeachingmultimodalchain-of-thoughtreasoningviamixedlargelanguagemodelsignalsfor\\nsciencequestionanswering. AAAI,2024. 4\\n[35] Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang,\\nAnwenHu, PengchengShi, YayaShi, ChaoyaJiang, ChenliangLi, YuanhongXu, Hehong\\nChen,JunfengTian,QianQi,JiZhang,andFeiHuang. mplug-owl: Modularizationempowers\\nlargelanguagemodelswithmultimodality,2023. 9\\n[36] ShukangYin,ChaoyouFu,SiruiZhao,TongXu,HaoWang,DianboSui,YunhangShen,KeLi,\\nXing Sun, and Enhong Chen. Woodpecker: Hallucination correction for multimodal large\\nlanguagemodels. arXivpreprintarXiv:2310.16045,2023. 8,9\\n[37] TianyuYu,YuanYao,HaoyeZhang,TaiwenHe,YifengHan,GanquCui,JinyiHu,ZhiyuanLiu,\\nHai-TaoZheng,andMaosongSun. Rlhf-v: Towardstrustworthymllmsviabehavioralignment\\nfromfine-grainedcorrectionalhumanfeedback. arXivpreprint,(2312.00849),2023. 4\\n[38] BohanZhai,ShijiaYang,ChenfengXu,ShengShen,KurtKeutzer,andManlingLi. Halle-\\nswitch: Controlling object hallucination in large vision language models. arXiv e-prints,\\n(arXiv-2310),2023. 4\\n[39] ZhuoshengZhang,AstonZhang,MuLi,HaiZhao,GeorgeKarypis,andAlexSmola. Mul-\\ntimodalchain-of-thoughtreasoninginlanguagemodels. arXivpreprint,(2302.00923),2023.\\n3\\n[40] LinxiZhao,YiheDeng,WeitongZhang,andQuanquanGu. Mitigatingobjecthallucinationin\\nlargevision-languagemodelsviaclassifier-freeguidance. arXivpreprint,(2402.08680),2024.\\n4\\n[41] ZhiyuanZhao,BinWang,LinkeOuyang,XiaoyiDong,JiaqiWang,andConghuiHe. Beyond\\nhallucinations:enhancing lvlms through hallucination-aware direct preference optimization.\\narXivpreprint,(2311.16839),2023. 4\\n[42] Ge Zheng, Bin Yang, Jiajin Tang, Hong-yu Zhou, and Sibei Yang. Ddcot: Duty-distinct\\nchain-of-thoughtpromptingformultimodalreasoninginlanguagemodels. NeurlPS,2023. 4\\n[43] DeyaoZhu, JunChen, XiaoqianShen, XiangLi, andMohamedElhoseiny. Minigpt-4: En-\\nhancingvision-languageunderstandingwithadvancedlargelanguagemodels. arXivpreprint\\narXiv:2304.10592,2023. 9\\nReferences\\n[1] Chatgptcannowsee,hear,andspeakhttps://openai.com/index/chatgpt-can-now-see-hear-and-\\nspeak/. 2023. 2,5\\n[2] JinzeBai,ShuaiBai,ShushengYang,ShijieWang,SinanTan,PengWang,JunyangLin,Chang\\nZhou, and Jingren Zhou. Qwen-vl: A frontier large vision-language model with versatile\\nabilities. arXivpreprint,(2308.12966),2023. 2,4,9\\n[3] ZechenBai, PichaoWang, TianjunXiao, TongHe, HanZongbo, ZhengZhang, andZheng\\nMikeShou. Hallucinationofmultimodallargelanguagemodels: Asurvey. arXivpreprint,\\n(2404.18930),2024. 4\\n[4] JeffreyByrne,GregCastanon,ZhonghengLi,andGilEttinger. Fine-grainedactivitiesofpeople\\nworldwide,2022. 5\\n[5] YangyiChen,KaranSikka,MichaelCogswell,HengJi,andAjayDivakaran. Compositional\\nchain-of-thoughtpromptingforlargemultimodalmodels. arXivpreprint,(2311.17076),2024.\\n4\\n12[6] YangyiChen,KaranSikka,MichaelCogswell,HengJi,andAjayDivakaran. Measuringand\\nimprovingchain-of-thoughtreasoninginvision-languagemodels. arXivpreprint,(2309.04461),\\n2024. 4\\n[7] ZhaorunChen,ZhuokaiZhao,HongyinLuo,HuaxiuYao,BoLi,andJiaweiZhou.Halc:Object\\nhallucination reduction via adaptive focal-contrast decoding. arXiv preprint, (2403.00425),\\n2024. 4\\n[8] ZheChen,JiannanWu,WenhaiWang,WeijieSu,GuoChen,SenXing,MuyanZhong,Qinglong\\nZhang,XizhouZhu,andLeweiLu. Internvl: Scalingupvisionfoundationmodelsandaligning\\nforgenericvisual-linguistictasks. arXivpreprint,(2312.14238),2023. 4\\n[9] Wei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,\\nSiyuanZhuang,YonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna:\\nAnopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. 5,8\\n[10] Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng\\nWang, Boyang Li, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose\\nvision-languagemodelswithinstructiontuning. arXivpreprint,(2305.06500),2023. 2,9\\n[11] AilinDeng,ZhiruiChen,andBryanHooi. Seeingisbelieving: Mitigatinghallucinationinlarge\\nvision-languagemodelsviaclip-guideddecoding. arXivpreprint,(2402.15300),2024. 4\\n[12] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,\\nThomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,\\nJakobUszkoreit,andNeilHoulsby. Animageisworth16x16words: Transformersforimage\\nrecognitionatscale,2021. 5\\n[13] ChaoyouFu,PeixianChen,YunhangShen,YuleiQin,MengdanZhang,XuLin,JinruiYang,\\nXiawu Zheng, Ke Li, Xing Sun, Yunsheng Wu, and Rongrong Ji. Mme: A comprehensive\\nevaluationbenchmarkformultimodallargelanguagemodels. arXivpreprint,(2306.13394),\\n2024. 8,9,17\\n[14] Liqi He, Zuchao Li, Xiantao Cai, and Ping Wang. Multi-modal latent space learning for\\nchain-of-thoughtreasoninginlanguagemodels. AAAI,2023. 3\\n[15] XinHe, LonghuiWei, LingxiXie, andQiTian. Incorporatingvisualexpertstoresolvethe\\ninformationlossinmultimodallargelanguagemodels. arXivpreprint,(2401.03105),2024. 4\\n[16] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Zhu, Yuanzhi Li, Shean Lu, Lu Wang,\\nand Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint,\\n(2106.09685),2021. 7\\n[17] JiteshJain,JianweiYang,andHumphreyShi. Vcoder: Versatilevisionencodersformultimodal\\nlargelanguagemodels. arXivpreprint,(2312.14233),2023. 4\\n[18] QiruiJiao,DaoyuanChen,YilunHuang,YaliangLi,andYingShen. Enhancingmultimodal\\nlarge language models with vision detection models: An empirical study. arXiv preprint,\\n(2401.17981),2024. 4\\n[19] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,\\nTeteXiao,SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,PiotrDollár,andRossGirshick.\\nSegmentanything. arXiv:2304.02643,2023. 10\\n[20] BoLi,YuanhanZhang,LiangyuChen,JinghaoWang,JingkangYang,andZiweiLiu. Otter: A\\nmulti-modalmodelwithin-contextinstructiontuning. arXivpreprintarXiv:2305.03726,2023.\\n9\\n[21] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-\\nimage pre-training with frozen image encoders and large language models. arXiv preprint,\\n(2301.12597),2023. 9\\n[22] LeiLi,ZhihuiXie,MukaiLi,ShunianChen,PeiyiWang,LiangChen,YazhengYang,Benyou\\nWang,andKongLingpeng. Silkie: Preferencedistillationforlargevisuallanguagemodels.\\narXivpreprint,(2312.10665),2023. 4\\n13[23] LiunianHaroldLi*,PengchuanZhang*,HaotianZhang*,JianweiYang,ChunyuanLi,Yiwu\\nZhong,LijuanWang,LuYuan,LeiZhang,Jenq-NengHwang,Kai-WeiChang,andJianfeng\\nGao. Groundedlanguage-imagepre-training. InCVPR,2022. 10\\n[24] YifanLi,YifanDu,KunZhou,JinpengWang,WayneXinZhao,andJi-RongWen. Evaluating\\nobjecthallucinationinlargevision-languagemodels. arXivpreprint,(2305.10355),2023. 8,9\\n[25] Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. Improved baselines with visual\\ninstructiontuning. arXivpreprint,(2310.03744),2023. 2,4,5,7,8,9,16\\n[26] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.Visualinstructiontuning.NeurlPS,\\n2023. 2,6,7,8,9,17\\n[27] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Cheng, Song-Chun Zhu, Oyvind\\nTafjord,PeterClark,andAshwinKalyan. Learntoexplain: Multimodalreasoningviathought\\nchainsforsciencequestionanswering. NeurlPS,2022. 8,9\\n[28] DebjyotiMondal,SurajModi,SubhadarshiPanda,RiturajSingh,andGodawariSudhakarRao.\\nKam-cot: Knowledgeaugmentedmultimodalchain-of-thoughtsreasoning. AAAI,2024. 3\\n[29] OpenAI. Gpt-4technicalreport. arXivpreprint,(2303.08774),2024. 3,8\\n[30] Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi\\nParikh,andMarcusRohrbach. Towardsvqamodelsthatcanread. CVPR,2019. 8,9,17\\n[31] ZhiqingSun,ShengShen,ShengcaoCao,HaotianLiu,ChunyuanLi,YikangShen,Chuang\\nGan,Liang-YanGui,Yu-XiongWang,andYimingYang. Aligninglargemultimodalmodels\\nwithfactuallyaugmentedrlhf. arXivpreprint,(2309.14525),2023. 4\\n[32] ZhiqingSun,ShengShen,ShengcaoCaoCao,HaotianLiu,ChunyuanLi,YikangShen,Chuang\\nGan,Liang-YanGui,Yu-XiongWang,YimingYang,KurtKeutzer,andTrevorDarrell. Align\\nlargemultimodalmodelswithfactuallyaugmentedrlhf. arXivpreprint,(2309.14525),2023. 9\\n[33] ShengbangTong,ZhuangLiu,YuexiangZhai,YiMa,YannLeCun,andSainingXie. Eyes\\nwideshut? exploringthevisualshortcomingsofmultimodalllms. arXivpreprint,(2401.06209),\\n2024. 4\\n[34] Lei Wang, Yi Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, and Heng Tao Shen. T-sciq:\\nTeachingmultimodalchain-of-thoughtreasoningviamixedlargelanguagemodelsignalsfor\\nsciencequestionanswering. AAAI,2024. 4\\n[35] Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang,\\nAnwenHu, PengchengShi, YayaShi, ChaoyaJiang, ChenliangLi, YuanhongXu, Hehong\\nChen,JunfengTian,QianQi,JiZhang,andFeiHuang. mplug-owl: Modularizationempowers\\nlargelanguagemodelswithmultimodality,2023. 9\\n[36] ShukangYin,ChaoyouFu,SiruiZhao,TongXu,HaoWang,DianboSui,YunhangShen,KeLi,\\nXing Sun, and Enhong Chen. Woodpecker: Hallucination correction for multimodal large\\nlanguagemodels. arXivpreprintarXiv:2310.16045,2023. 8,9\\n[37] TianyuYu,YuanYao,HaoyeZhang,TaiwenHe,YifengHan,GanquCui,JinyiHu,ZhiyuanLiu,\\nHai-TaoZheng,andMaosongSun. Rlhf-v: Towardstrustworthymllmsviabehavioralignment\\nfromfine-grainedcorrectionalhumanfeedback. arXivpreprint,(2312.00849),2023. 4\\n[38] BohanZhai,ShijiaYang,ChenfengXu,ShengShen,KurtKeutzer,andManlingLi. Halle-\\nswitch: Controlling object hallucination in large vision language models. arXiv e-prints,\\n(arXiv-2310),2023. 4\\n[39] ZhuoshengZhang,AstonZhang,MuLi,HaiZhao,GeorgeKarypis,andAlexSmola. Mul-\\ntimodalchain-of-thoughtreasoninginlanguagemodels. arXivpreprint,(2302.00923),2023.\\n3\\n[40] LinxiZhao,YiheDeng,WeitongZhang,andQuanquanGu. Mitigatingobjecthallucinationin\\nlargevision-languagemodelsviaclassifier-freeguidance. arXivpreprint,(2402.08680),2024.\\n4\\n14[41] ZhiyuanZhao,BinWang,LinkeOuyang,XiaoyiDong,JiaqiWang,andConghuiHe. Beyond\\nhallucinations:enhancing lvlms through hallucination-aware direct preference optimization.\\narXivpreprint,(2311.16839),2023. 4\\n[42] Ge Zheng, Bin Yang, Jiajin Tang, Hong-yu Zhou, and Sibei Yang. Ddcot: Duty-distinct\\nchain-of-thoughtpromptingformultimodalreasoninginlanguagemodels. NeurlPS,2023. 4\\n[43] DeyaoZhu, JunChen, XiaoqianShen, XiangLi, andMohamedElhoseiny. Minigpt-4: En-\\nhancingvision-languageunderstandingwithadvancedlargelanguagemodels. arXivpreprint\\narXiv:2304.10592,2023. 9\\n15A TrainingParametersDetail\\nPre-training WedirectlyusethepretrainedweightsofLLaVA-1.5[25]. Youcandownloadfrom:\\nhttps://github.com/haotian-liu/LLaVA/blob/main/docs/MODEL_ZOO.md\\nInstructFine-tuning Weconductinstructionfine-tuningtrainingofourmodelonfourNVIDIA\\nA800-SXM4-80GBGPUs,whichtakesapproximately28hours. Thehyperparametersareshownin\\nTable5.\\nHyperparameter Finetune\\nbatchsize 128\\nlr 2e-5\\nlrschedule cosinedecay\\nlrwarmupratio 0.03\\nweightdecay 0\\nepoch 1\\noptimizer AdamW\\nDeepSpeedstage 3\\nTable5: HyperparametersofFine-tuningofSQ.\\nB Prompt\\nHallucination\\nWewouldliketorequestyourfeedbackontheperformanceoftwoAIassistantsinresponsetotheuserquestiondisplayedabove.\\nTheuserasksthequestiononobservinganimage.Foryourreference,thevisualcontentintheimageisrepresentedwithafew\\nsentencesdescribingtheimage.\\nnPleaseratetheirresponsesbasedonthehallucination(i.e.,unrealorunfoundedcontent).Eachassistantreceivesanoverallscore\\nonascaleof1to10,wherealowerscoreindicatesfewerhallucinationsandbetterperformance.Pleasefirstoutputasingleline\\ncontainingonlytwovaluesindicatingthescoresforAssistant1andAssistant2,respectively.Thetwoscoresareseparatedbya\\nspace.Inthesubsequentline,pleaseprovideacomprehensiveexplanationofyourevaluation,avoidinganypotentialbiasand\\nensuringthattheorderinwhichtheresponseswerepresenteddoesnotaffectyourjudgment.\\nQuestionsQuality\\nWewouldliketorequestyourfeedbackontheperformanceoftwoAIassistantsingeneratingquestionsbasedontheimage\\ncontent.Thetaskfortheassistantistoproposeseveraldiverseandeffectivequestions,aimedatobtainingamoreaccuratedetailed\\ndescription. Foryourreference,wewillprovideadditionalinformationabouttheimageandquestions(suchastheexpected\\nquestions,human-generatedquestions,andhintsgivenbyannotators).Notethattheassistantcanonlyseetheimagecontentand\\nquestiontext,andallotherreferenceinformationisusedtohelpyoubetterunderstandthequestionsandcontentoftheimageonly.\\nThemajorcriteriaforevaluationarethediversity,effectiveness,andaccuracyofthequestionsgenerated.\\nnEachassistantreceivesanoverallscoreonascaleof1to5,whereahigherscoreindicatesbetteroverallperformance.Pleasefirst\\noutputasinglelinecontainingonlytwovaluesindicatingthescoresforAssistant1andAssistant2,respectively.Thetwoscores\\nareseparatedbyaspace.Inthesubsequentline,pleaseprovideacomprehensiveexplanationofyourevaluation,avoidingany\\npotentialbiasandensuringthattheorderinwhichtheresponseswerepresenteddoesnotaffectyourjudgment.\\nTable6: PromptusedinCapQAGPT4-aidEvaluation.\\nC Datasets\\nC.1 MMHal\\nMMHaliscomprisedof96delicatelydesignedimage-questionpairs,rangingin8questioncategories\\n×12objecttopics. MMHalconcentratesondetectinghallucinationswithintheLMMresponsesand\\nadoptsgeneral,realistic,andopen-endedquestionstobetterreflecttheresponsequalityinreal-world\\nuser-LMMinteractions. TheimagesarefromthevalidationandtestsetsofOpenImagetoavoid\\ndataleakage. Thequestions,askingLLMtofigureouttheobjectattributes,spatialrelations,make\\ncounting,provideholisticdescriptionandetc,arecreatedinanadversarialmannertomakeLLM\\nhallucinates on purpose. As a result, MMHal offers a great assessment on LLM’s capability to\\nrobustlyresistvariouskindsofhallucinations.\\n16C.2 MME\\nMME,introducedin[13],isacomprehensiveMLLMEvaluationbenchmarkconsistingof1k-2k\\nimagesandinstruction-answerpairs. MMEhasfourmaincharacters:\\n1. MME offers a comprehesive assessment for different aspects of a MLLM’s ability including\\nperception(coarse-grainedandfine-grainedobjectrecognitionandOCR)andcognition(common-\\nsensereasoning,numericalcalculation,texttranslation,andcodereasoning),uptototally14subtasks.\\n2. Allinstruction-answerpairsaremanuallyconstructedandgreatproportionofimagesarenewly\\ncollectedinordertoavoiddataleakage.\\n3. The instructions are made concise so as to be similar to commonly used ones. The unfair\\nadvantageofpromptengineeringisavoided.\\n4. Theanswersaresimple\"yes\"or\"no\",whichisaccurate,objectiveandconvenientforquantitative\\nanalysis.\\nHence, MME is an accurate, objective, fair and comprehensive benchmark for MLLM’s visual\\nperceptionandcognitioncapabilities.\\nC.3 TextVQA\\nTextVQAdataset,introducedin[30],contains28408imagesonwhich45336questionsareaskedby\\nhumanannotators. Theimages,selectedfromtheOpenImagesdataset,belongtothecategoriesthat\\ntendtocontaintexte.g. “billboard”,“trafficsign”,“whiteboard”. Thequestionsrequirereadingand\\nreasoningabouttextintheimage. Dateareorganizedintheformatofquestion-imagepairswhere\\neachhas10groundtruthanswersprovidedbyhumans. Thisbenchmarkevaluatemodel’sreasoning\\nabilityspecializedinOpticalCharacterRecognition(OCR).OurSQachievestate-of-artperformance\\nwithoutaspecializedOCRmodule.\\nC.4 LLaVA-Bench(In-the-Wild)\\nLLaVA-Bench(In-the-Wild)isintroducedintheworkofLLaVa[26]createdtoevaluatemodelsability\\ntohandlechallengingtasksandgeneralizetonewdomain. Ithastotally24images,eachcomeswith\\namanuallyannotateddetaileddescription,ofindoorandoutdoorscenes,memes,paintings,sketches,\\netc. Authorsalsoprovidealistof60questions,fromwhichindividualquestionsareproperlyselected\\ntobeassociatedwitheachimage.Inthisway,LLaVA-Bench(In-the-Wild)workswellasabenchmark\\nforvisualcaptioningandquestionansweringthatrequirestrongspatialawarenessandbackground\\nknowledge.\\nC.5 LLaVA-QA90\\nLLaVA-QA90isalsointroducedinthepaperofLLaVa[26]. Authorsselect90imagesfromCOCO-\\nVal-2014andleveragethedatagenerationpipelineintroducedinthepapertoannotatethem. Asa\\nresult,eachimageisassociatedwithadetaileddescription,amulti-roundconversationandacomplex\\nreasoningQ&Apair. Thus,LLaVA-QA90servesasabenchmarkforevaluatingmodel’scapabilityto\\nconductalongconversation,makeadetaileddescriptionandsolveacomplexreasoningproblem\\nbasedonanimage.\\nD Examples\\nTheconversationinTable7isbasedonFigure5.\\n17Figure4: ComparisonofQuestionsGenerationonLLaVA-with-SQandLLaVA.\\nFigure5: AnexampleofSQ.SQstartsbyaskingquestionsaboutthegivenimageforheuristicself-\\nquestioning. Thenittriestogivevisuallygroundedanswertothosequestions,essentiallyperforming\\nVQAtasks. Finally,SQsummarizestheinformationencodedintheQ&Atoproduceinformative\\nandinsightfuldetaileddescription.\\n18Conversationin3-turnmode\\nQuestion:\\nPleaseformulate6to8questionsrelatedtotheactivitydetailsintheimage.Thepurposeofthesequestionsshouldbetoassistthe\\nmodelincompletetheanswertothisquestion:’Usedetaileddescriptionstocharacterizetheactivitiesofthepersonintheimage.’.\\nAimtoaskquestionsthatcanbedefinitivelyansweredandavoidquestionsthatdonothaveclearanswers.\\n===\\nAnswer:\\nQ0.Whatisthepersondoingintheimage?Q1.Whattypeofvehicleisthepersongettingoutof?Q2.Isthepersongettingoutof\\nacaroratruck?Q3.Whatisthepersonwearingwhilegettingoutofthevehicle?Q4.Isthepersonstandingonasidewalkorin\\nthestreet?Q5.Whatcanbeinferredabouttheperson’sintentionsoractionsfromtheimage?\\n===\\nQuestion:\\nPleaseanswerallthequestionsonebyonedirectly,answersaresplitbylinebreak.\\n===\\nAnswer:\\nQ0.Whatisthepersondoingintheimage?A.Thepersonisgettingoutofacar,specificallyablacksedan.Q1.Whattypeof\\nvehicleisthepersongettingoutof?A.Thepersonisgettingoutofablacksedan.Q2.Isthepersongettingoutofacaroratruck?\\nA.Thepersonisgettingoutofacar,notatruck.Q3.Whatisthepersonwearingwhilegettingoutofthevehicle?A.Theperson\\niswearingahoodedsweatshirtwhilegettingoutofthecar.Q4.Isthepersonstandingonasidewalkorinthestreet?A.The\\npersonisstandinginthestreet,notonasidewalk.Q5.Whatcanbeinferredabouttheperson’sintentionsoractionsfromthe\\nimage?A.Fromtheimage,itcanbeinferredthatthepersoniseitherarrivingatordepartingfromtheirdestination,astheyare\\ngettingoutofthecar.Thefactthattheyarewearingahoodedsweatshirtsuggeststhattheweathermightbecoldorthattheyare\\npreparedforthepossibilityofcoldweatherduringtheirjourney.\\n===\\nQuestion:\\nUsedetaileddescriptionstocharacterizetheactivitiesofthepersonintheimage.\\n===\\nAnswer:\\nIntheimage,apersonisgettingoutofablacksedanparkedonthestreet.Theindividualiswearingahoodedsweatshirt,which\\nindicatesthattheweathermightbecoldorthattheyarepreparedforthepossibilityofcoldweatherduringtheirjourney.The\\npersonisstandinginthestreet,notonasidewalk,whichcouldsuggestthattheyareeitherarrivingatordepartingfromtheir\\ndestination.Thepresenceofasecondcarparkednearbyfurtheremphasizestheideathatthismightbeaparkingspotoralocation\\nwheremultiplepeoplearegettinginandoutoftheirvehicles.Theperson’sactionsintheimagearetypicalforsomeonewhois\\neitherarrivingatordepartingfromadestination,andtheirchoiceofclothingreflectsthepotentialweatherconditionstheymight\\nbefacing.\\n===\\nConversationin1-turnmode\\nQuestion:\\nUsedetaileddescriptionstocharacterizetheactivitiesofthepersonintheimage.\\n===\\nAnswer:\\nIntheimage,apersoniswalkingtowardsablackcarthatisparkedinadriveway.Thecarispositionednearthecurb,andthe\\npersonislikelygettingreadytoenterthevehicle.Thepersoniswearingablackjacket,whichsuggeststhattheweathermightbe\\ncoolorthepersonisdressedforaspecificoccasion.Thecarisasmall,blacksedan,andtherearetwoothercarsvisibleinthe\\nbackground,oneofwhichisparkedfurtherawayfromthemaincar.\\nTable7: Anexampleofaconversationin1-turnmodeand3-turnmode,wherethehallucinatedparts\\narehighlightedinred.\\n19E LabeldataformatofCapQA\\nConversation\\nHuman: Pleaseformulate5to8questionsrelatedtotheactivitydetailsintheimage. Ifsome\\nquestionsareuncertain,furtherrefinethem,andposeanadditional5questionsspecificallytargeting\\ntheseuncertainties,withatotalnotexceeding20questions.Thepurposeofthesequestionsshould\\nbetoassistthemodelindeterminingthetypeofactivityandinuncoveringdetailsoftheactivity.\\nAimtoaskquestionsthatcanbedefinitivelyansweredandavoidquestionsthatdonothaveclear\\nanswers.\\n<image>\\nGPT:Q0.Whatspecificpartofthevehicleisthepersonlocatedat?\\nQ1.Hasthepersonopenedthevehicledoor?\\nQ2.Whattimeofdayistheactivitytakingplace?\\nQ3.Doestheperson’sexpressionorbodylanguageindicatetheyareinahurryorrelaxed?\\nQ4.Isthesurroundingenvironmentquiet?\\nQ5.Whattypeandconditionisthevehiclein?\\nQ6.Isthepersoncarryinganyitems?\\nQ7.Doesthepersonappeartobepreparingtodriveaway,orhavetheyjustarrived?\\nQ8.Isthepersoncheckinginsidethevehicleorthesurroundingarea?\\nQ9.Isthevehicledoorfullyopen,oronlypartiallyopen?\\nQ10.Aretheperson’shandsvisible,andaretheyperforminganyspecificactions?\\nQ11.Doestheperson’sstandingposturesuggesttheyareabouttoenterthevehicle?\\nQ12.Besidesthevehicleandperson,arethereanyothersignificantobjectsoractions?\\nHuman:Whatspecificpartofthevehicleisthepersonlocatedat?\\nGPT:Thepersonisstandingbythesideofthevehicle,nearthedriver’sseatdoor.\\nHuman:Hasthepersonopenedthevehicledoor?\\nGPT:Yes,thevehicledoorisopen.\\nHuman:Whattimeofdayistheactivitytakingplace?\\nGPT:Consideringthesurroundinglight,itappearstobenighttime.\\nHuman:Doestheperson’sexpressionorbodylanguageindicatetheyareinahurryorrelaxed?\\nGPT:It’shardtodiscerntheperson’sexpressionduetothebrightnessofthephoto,butthebody\\nlanguageseemsrelaxed.\\nHuman:Isthesurroundingenvironmentquiet?\\nGPT:Theenvironmentappearstobequiet,withnonoticeableactivityfromotherpeopleorvehicles.\\nHuman:Whattypeandconditionisthevehiclein?\\nGPT:Thevehicleisablacksedanwithasomewhatreflectivesurface,appearingtobeingood\\ncondition.\\n...\\nHuman:Writedownadetaileddescriptionoftheperson’sactivityintheimage.\\nGPT:DetailedDescription:\\nInthisnighttimephoto,apersonisnearablacksedanparkedatthesideofastreet.Thestreetlights\\ncastasoftglow,andthevehicle’sdoorisfullyopen. Thepersonstandsatthedriver’ssidedoor,\\nleaningtowardstheinsideofthecar,apparentlyobservingtheinteriororpreparingtoenter.They\\naredressedindarkclothing,blendingintothenight. Thesurroundingenvironmentisveryquiet,\\nwithnootherpedestriansorvehicles,reflectingatranquilatmosphere.Thepersonappearsnottobe\\ncarryinganyitems,suggestingtheymightbenearhomeanddonotneedtocarryextraitems.\\nHuman:Summarizethedetailsoftheperson’sactivityintheimage.\\nGPT:ConciseDescription:\\nAtnight,apersondressedindarkclothingispreparingtoenterablacksedanparkedonthestreet\\nside. Thedoorisfullyopen, andtheyseemtobegettingreadytositinthedriver’sseat. The\\nenvironmentisquiet,withnootherapparentactivities,givingthewholesceneapeacefulnighttime\\nambiance.\\nTable8: Anexampleofaconversationlabelingformat.\\n20Method VCR SNLI-VE\\nLLaVA-13b-v0 28.3 40.3\\nLLaVA-7b-v1.5 25.06 0.06\\nLLaVA-13b-v1.5 25.18 45.78\\nIdealGPT 50.7 55.3\\nSQ-7b 32.66 48.98\\nSQ-13b 45.78 61.44\\nTable9: Comparisonexperiments: LikethepaperofIdealGPTdid,wesampled5000datafromeach\\noftheVCRandSNLI-VE.SQ-7bisLLaVA-7b-v1.5fine-tunedbyourproposedSQframeworkwith\\nextraCapQAdatasetandSQ-13bisthatofLLaVA-13b-v1.5similarly.\\nMethod\\nQAqg QAmt Caption MME CapQA30\\nSQAI VQAT GQA MM-vet\\nPercep Cog HalS QQS\\nSQ-caponly ✓ 1465.4 286.4 62.9 75.8 67.63 57.67 58.51 30.0\\nSQ-noqg ✓ ✓ 1421.1 282.5 68.1 75.8 67.13 55.71 55.73 30.3\\nSQ ✓ ✓ ✓ 1523.4 306.7 69.7 86.7 68.37 58.57 58.78 31.4\\nTable 10: Ablation experiments on 6 benchmarks. SQAI: ScienceQA-IMG(zero-shot); VQAT:\\nTextVQA;CapQA30: Thefirst30samplesoftheCapQAevaluationset. SQ-caponly: Retainonly\\nthecaptionportionoftheCapQAlabelduringfine-tuning. SQ-noqg: Excludeonlythequestion\\ngenerationprompt-responsepairduringfine-tuning. QA : thefirstturnQA;QA : multi-turnQA.\\nqg mt\\nThetestedVLMisLLaVA-v1.5-7b\\nPOPE(Acc) POPE(F1) MME\\nMethod GQA\\nRand Pop Adv Rand Pop Adv Percep Cog\\nLRV-Instruction 0.86 0.73 0.65 0.65 0.79 0.73 1298.78 328.21 0.64\\nSQ 0.89 0.89 0.85 0.85 0.86 0.84 1523.4 306.7 0.59\\nTable11: ComparisonexperimentsofLRV-InstructionandSQ.LRV-Instruction: Liuetal. \"Mitigat-\\ningHallucinationinLargeMulti-ModalModelsviaRobustInstructionTuning.\"ICLR2024\\n1-thRun 2-thRun 3-thRun AvgScore\\nMethod Type\\npred/gt gt pred pred/gt gt pred pred/gt gt pred pred/gt\\nLLaVA-1.5 HalS 52.5 80.0 42.0 51.7 79.3 41.0 51.9 79.7 41.3 52.0\\nGPT-4o HalS 72.8 76.0 55.3 74.0 77.0 57.0 74.2 76.3 56.7 73.7\\nSQ HalS 69.7 78.0 54.3 69.4 78.3 54.3 67.9 78.0 53.0 69.0\\nLLaVA-1.5 QQS 39.2 40.0 15.7 39.2 40.0 15.7 38.6 39.7 15.3 39.0\\nGPT-4o QQS 97.5 40.0 39.0 97.5 40.0 39.0 96.7 40.0 38.7 97.2\\nSQ QQS 86.7 40.0 34.7 85.8 40.0 34.3 86.7 40.0 34.7 86.4\\nTable12: ComparisonexperimentsofLLaVA-1.5andGPT-4oandSQonthefirst30samplesofthe\\nCapQAevaluationset. ThemeaningsoftheHalSandQQSmetricsarethesameasdefinedinthe\\npaper. Weruntheevaluationthreetimestoeliminaterandomnessandtaketheaverageasthefinal\\nscore. Fortheevaluation,weuseGPT-4o-mini-aid.\\n21',\n",
       " 'The Race to Efficiency A New Perspective on AI Scaling Laws.pdf': 'The Race to Efficiency: A New\\nPerspective on AI Scaling Laws\\nChien-Ping Lu\\ncplu@nimbyss.com\\nAbstract\\nAs large-scale AI models expand, training becomes costlier and sustaining progress grows\\nharder. Classical scaling laws (e.g., Kaplan et al. [9], Hoffmann et al.[10]) predict training\\nlossfromastaticcomputebudgetyetneglecttimeandefficiency,promptingthequestion: how\\ncan we balance ballooning GPU fleets with rapidly improving hardware and algorithms? We\\nintroduce the relative-loss equation, a time- and efficiency-aware framework that extends\\nclassical AI scaling laws. Our model shows that, without ongoing efficiency gains, advanced\\nperformance could demand millennia of training or unrealistically large GPU fleets. How-\\never,near-exponentialprogressremainsachievableifthe“efficiency-doublingrate”parallels\\nMoore’s Law. By formalizing this race to efficiency, we offer a quantitative roadmap for\\nbalancing front-loaded GPU investments with incremental improvements across the AI stack.\\nEmpiricaltrendssuggestthatsustainedefficiencygainscanpushAIscalingwellintothecoming\\ndecade, providing a new perspective on the diminishing returns inherent in classical scaling.\\n1 Introduction\\nThe future trajectory of AI scaling is widely debated: some claim that ever-growing models and\\ndatasets are nearing practical and theoretical limits [1, 2, 3], while others maintain that ongoing\\ninnovations will continue driving exponential growth [4, 5, 6]. For organizations weighing these\\ndivergent views, a central question arises: should they “front-load” GPU capacity—relying on the\\npredictable (yet potentially plateauing) gains promised by static scaling laws—or invest in R&D\\nfor (possibly unpredictable and hard-to-measure) efficiency breakthroughs, model innovations, and\\nfuture hardware enhancements? Ultimately, if diminishing returns do indeed loom, how severe\\nmight they be in terms of both time and hardware capacity (see Table 2 for an illustrative range\\nof outcomes)?\\nTo address this conceptual gap, we note that any truly enduring “exponential” trend hinges on\\nimproving an efficiency metric that reflects both the outcomes and the costs (time, energy, etc.).\\nHistorically, Moore’s Law embodied such progress by showing that transistor count per unit area\\ncould approximately double every two years [7], while Dennard Scaling [8] kept power usage in\\ncheck. Turning to AI, classical scaling laws quantify how training loss predictably decreases with\\nincreasingcompute,providedbalancedmodel,data,andtrainingconfigurations—referredtoasthe\\ncompute-optimal condition [9, 10]. However, these laws are inherently static: they do not account\\n1\\n5202\\nnaJ\\n8\\n]GL.sc[\\n3v65120.1052:viXrafortheseverity ofdiminishingreturnsorspecifyhow quickly efficiencymustimprovetooffsetthese\\ntrends over time.\\nKey Idea: Making Scaling Time- and Efficiency-Aware. Classicalscalinglaws[9,10]posit\\nthat L ∝ C−κ for a given static compute budget C . We extend this snapshot into a time-\\n0 0 0\\nand efficiency-aware framework. Let L represent the “baseline” loss associated with an initial\\n0\\ncompute budget. If γ denotes the annual efficiency-doubling rate (in yr−1), reminiscent of the 0.5\\ntimes per year doubling of transistor density in Moore’s Law, we derive a relative-loss equation\\nthat captures how loss evolves over time:\\n(cid:18) 2γt−1 (cid:19)−κ\\nL(t) = L R(t), R(t) = 1+ . (1.1)\\n0 γln(2) × 1yr\\nFigure 1: AI Scaling and Moore’s Law with Efficiency-Doubling Rates. This plot compares\\na hypothetical Moore’s Law curve (dashed) with κ = 0.4 and γ = 0.5, against AI scaling curves (solid)\\nat κ = 0.048 (typical of large language models) for various efficiency-doubling rates γ ∈ {0,0.5,1,2,3}.\\nThe horizontal line R(t)=0.68 corresponds to a token-prediction probability of 50%, assuming L =1.0.\\n0\\nIncreasingγ drasticallyreducesthetimetocrossthisthreshold. Thex-axisrepresentsTime (years),and\\nthe y-axis represents Relative Loss R(t). Distinct colors are used for different γ values to highlight the\\nimpact of efficiency improvements.\\nHere, L(t) represents the training loss at time t (in years), L is the initial loss, R(t) is the relative\\n0\\nloss, and κ is the unitless scaling exponent. The equation captures how training loss evolves over\\ntime as efficiency improves. Even with diminishing returns (κ≪1), rapid efficiency gains (γ >0)\\ncan sustain near-exponential progress in AI scaling.\\nFigure 1 illustrates the interplay between κ and γ. A small κ = 0.048 (typical of large language\\nmodels) causes the AI scaling curves to flatten significantly over time. With γ = 0.5 (efficiency\\n2doubling every two years), reducing R(t) to 0.68 might require approximately 20 years. Increasing\\nγ to 2.0 compresses this timeline to well under a decade, while γ = 3 shrinks it further. This\\ndemonstrates how higher efficiency-doubling rates can effectively mitigate the limitations imposed\\nby a small κ.\\nBy contrast, the γ =0 (flat) curve underscores the severity of diminishing returns, indicating that\\nreaching R(t) = 0.68 could demand 3,000× the current GPU capacity or training time—scenarios\\nfar beyond real-world feasibility (see Table 2).\\nOrganization. Section2reviewsrelatedworkonAIscaling. Section3formalizesthetime-based\\nextensiontoscalinglawsandderivestherelative-lossequation. InSection4,weexaminethescaling\\nbehavior predicted by the relative-loss equation. Section 5 presents a case study comparing “front-\\nloading”GPUswithsustainedefficiencyimprovementsanddiscussesbroaderimplications. Finally,\\nSections 6 and 7 summarize key findings and propose directions for empirical validation and future\\nresearch.\\n2 Related Work\\nThestudyofAIscalinglawshasbecomeacornerstoneinunderstandinghowtraininglossdecreases\\nas compute increases under optimized configurations. Kaplan et al. [9] introduced the concept of\\ncompute-optimal scaling, demonstrating predictable relationships among model size, dataset size,\\nand compute. Brown et al. [11] reinforced these findings through the scaling behavior of Large\\nLanguage Models (LLMs) such as GPT-3. Hoffmann et al. [10] refined the framework in the\\nChinchilla setting, underscoring the importance of balancing model size and dataset size to achieve\\ncompute-optimality. Collectively, these foundational studies provide empirical measurements of\\nscaling exponents and form the basis for much of the work in this domain.\\nBuilding on these foundations, recent research has explored additional factors influencing scaling\\nlaws. Sardana et al. [12] incorporated inference-time compute costs, proposing methods in which\\nsmaller models—trained with much larger (potentially synthetic) datasets—can balance efficiency\\nacross both training and deployment phases. Snell et al. [13] investigated strategies for optimizing\\ncompute specifically at test time. To address various optimizations, Clark et al. [14] introduced\\nsparsity-aware scaling laws for Mixture-of-Experts (MoE) architectures, formalizing an “effective\\nmodel size.” Building on that framework, Kumar et al. [15] examined precision-aware scaling,\\nshowing how precision influences effective parameter counts in a compute-optimal regime.\\nDespite these advancements, most studies treat compute as a static input rather than a dynamic,\\ntime-evolving resource. Thispaperaddressesthatgapbyintegratingempiricallyestablishedscaling\\nexponentswiththetemporal dynamicsofefficiencyimprovements, inspiredbyMoore’sLaw[7]and\\nDennard Scaling [8]. Our work bridges the gap between classical scaling laws and the real-world\\nconstraintsoftimeandefficiency,providingaframeworkforunderstandinghowdiminishingreturns\\ncan be offset by continuous innovation.\\n3 Mathematical Foundation\\nWe now formalize how to extend classical, static AI scaling laws into a dynamic, time-dependent\\nframework. Inparticular,wederivearelative-loss equationthatunifiestraditionalloss–compute\\n3relationships with a “Moore’s Law-like” perspective on efficiency gains.\\n3.1 Key Parameters and Notation\\nTable 1 summarizes the main parameters and variables. In brief, we measure:\\n- Logical (Model) FLOPs, defined to remain stable, vendor-agnostic, and consistent with\\nindustry standards of comparing ”teraflops” among different precisions such as FP16, BF16,\\nFP8, and FP4;\\n- Power and time, representing real-world usage averaged over a suitable timescale (mean-field\\nassumption);\\n- Ascalingexponentκ,whichcaptureshowlossdecreaseswithtotalcompute,andanefficiency-\\ndoubling rateγ,quantifyinghowrapidly“usablecompute”cangrowperunittimeandpower.\\nSymbol Definition Units\\nt Elapsed time since start of training yr\\nE(t) Compute efficiency at time t PFLOP/yr/MW\\nE Baseline/initial efficiency PFLOP/yr/MW\\n0\\nγ Annual efficiency-doubling rate yr−1\\nP(t) Time-varying power usage MW\\nP Mean-field power usage MW\\n0\\nC(t) Cumulative compute up to time t PFLOP\\nC Initial cumulative compute (snapshot) PFLOP\\n0\\nκ Scaling exponent (unitless)\\nL Baseline (initial) training loss nats/token\\n0\\nL(t) Training loss at time t nats/token\\nR(t) Relative training loss: L(t)/L (unitless)\\n0\\nTable1: Keyparametersandvariables. Here,“FLOPs”referspecificallytological,ormodelFLOPs—i.e.,\\nlogicaloperationsdeterminedbythemodelarchitectureanddataset. Weoftenmeasurelossinnats/token,\\nwhere 0.68nats/token≈50% prediction accuracy.\\n3.2 Continuous Efficiency Gains (E(t))\\nWe model efficiency as a continuously evolving resource, reminiscent of how Moore’s Law once\\ndescribed periodic doubling in transistor density. Concretely, let\\nE(t) = E × 2γt, (units: PFLOP/yr/MW), (3.1)\\n0\\nwhere γ denotes the annual rate at which efficiency doubles, and E is the baseline efficiency at\\n0\\nt=0. Although real improvements may come in discrete jumps, this continuous approximation is\\nmathematically convenient and mirrors how large-scale phenomena (e.g., population growth) are\\noften modeled as exponentials.\\n4Relation to Power and Hardware. Efficiency, as used here, is dimensionally LogicalFLOPs. In\\ntime×power\\npractice, raising E(t) can come from:\\n- Better hardware (e.g., next-gen accelerators, lower-precision logic, advanced memory or net-\\nworking),\\n- Algorithmic gains (e.g., quantization, expert routing),\\n- Software optimizations (kernel-level efficiency, distributed training overheads), or\\n- Any combination of the above.\\nWe simply aggregate all these factors into a single, time-varying E(t).\\n3.3 Cumulative Compute as an Integral (C(t))\\nClassical scaling laws treat compute C as a static budget. Here, we let C(t) accumulate over time:\\nC(t) = C + ∆C(t),\\n0\\nwhere C is the initial snapshot of compute (reflecting prior investments), and\\n0\\n(cid:90) t\\n∆C(t) = E(τ)P(τ)dτ.\\n0\\nIf P(τ) denotes the power allocated to training, then E(τ)P(τ) is the instantaneous compute\\nthroughput(PFLOP/yr). Integratingfrom0totyieldsthetotaladditionalcompute∆C(t)beyond\\nthe original C .\\n0\\nMean-Field Assumption. Rather than modeling P(τ) at every instant, we approximate\\nP(τ) ≈ P ,\\n0\\nthe average power over one year. This “mean-field” approach is common in physics (e.g., average\\nparticle collisions) and engineering (e.g., duty cycles). Importantly, this assumption represents\\nan upper bound on performance, as any deviations—such as fluctuations in power usage or\\nsuboptimal resource allocation—will result in slower progress in reducing training loss. This makes\\nthe mean-field assumption not only mathematically convenient but also practically significant, as\\nit provides an optimistic baseline for evaluating the impact of efficiency improvements.\\nForexample,consideratrainingrunforLLaMA3with405Bparameters,whichusedapproximately\\n30.8million GPU-hours across 16,000 H100 GPUs. The peak power might reach 16MW over a few\\nmonths. However, spreading this total energy over an entire year yields an average power P of\\n0\\napproximately 3.5MW. Insteadofmodelingshort-livedpeaks,we“smooth”usageacross12months\\nto adopt a single constant P , simplifying the analysis.\\n0\\nBecause classical scaling laws directly link C to L , we define\\n0 0\\nC\\nC = E ·P ×1yr, =⇒ 0 = 1yr. (3.2)\\n0 0 0 E P\\n0 0\\n5Here,C issimplythecomputeobtainedbyrunningefficiencyE atpowerP foroneyear. Chang-\\n0 0 0\\ning hardware details (e.g., front-loading more GPUs) merely rescales (C , E , P ), shifting the\\n0 0 0\\ninitial loss L but preserving the relative shape of L(t). Consequently, the time-extended scaling\\n0\\nlaw’s trajectory remains the same, regardless of the precise cluster schedule or deployment plan.\\nPractical Significance. The mean-field assumption represents an upper bound on perfor-\\nmance, as any deviations—such as fluctuations in power usage or suboptimal resource alloca-\\ntion—will result in slower progress in reducing training loss. This makes the assumption not only\\nmathematically convenient but also practically significant, as it provides an optimistic baseline for\\nevaluating the impact of efficiency improvements.\\nAdditionally,themean-fieldassumptionconsolidateshumanR&Dcyclesandtrainingsessions.\\nEven if a specific training run takes only a few months, the development process—including model\\ndesign, data preparation, and hardware procurement—often spans a year or more. By adopting\\na one-year baseline, our framework naturally aligns with these real-world timelines, providing a\\npractical and intuitive timescale for planning and evaluation. This consolidation ensures that\\nthe relative-loss equation remains relevant across multiple iterations of model development and\\ndeployment.\\n3.4 Deriving the Relative-Loss Equation\\nInthestaticregime,scalinglawsstatethatthetraininglossLdecreasesasapower-lawofcompute,\\nL∝C−κ. Introducingtime intothecomputeaccumulationC(t)transformsthisintoatime-varying\\nequation:\\n(cid:16) (cid:17)−κ\\nL(t) = L 1+ ∆C(t) .\\n0 C0\\nUsingtheintegralformfor∆C(t)andnotingC =E P ×1yr,plustheintegral(cid:82)t 2γτdτ = 2γt−1,\\n0 0 0 0 γ ln2\\nwe obtain:\\n∆C(t) = E 0P 0 (cid:0) 2γt−1(cid:1) .\\nγ ln(2)\\nHence,\\n(cid:16) ∆C(t)(cid:17)−κ (cid:18) 2γt−1 (cid:19)−κ\\nL(t)= L 1+ = L 1+ , (3.3)\\n0 C 0 γln(2) × 1yr\\n0\\nwhich can be rewritten in relative-loss form:\\nL(t) (cid:18) 2γt−1 (cid:19)−κ\\nR(t) = = 1+ . (3.4)\\nL γln(2) × 1yr\\n0\\nThe relative-loss equation captures how a baseline loss L evolves over time, provided efficiency\\n0\\nimproves at a rate γ. As γ increases, R(t) declines more rapidly.\\n6Interpretation.\\n- Static vs. Dynamic. The relative-loss equation extends static scaling laws into a time- and\\nefficiency-aware domain. When efficiency does not improve (γ = 0), the system effectively\\nreverts to “static” scaling. One could, in principle, keep training on the same hardware for a\\nvery long time, making ∆C grow linearly with time.\\n- Moore’s Law-Like Perspective. By letting “efficiency” double over time (instead of having a\\nsingle snapshot), the analysis aligns with the historical notion of transistor-density doubling.\\nHere, γ denotes how quickly one can “refresh” hardware and/or optimize software.\\n3.5 Timescale and Cross-Project Scope\\nOne-Year Baseline. Our derivation adopts a one-year baseline (via the mean-field assump-\\ntion (3.2)), so ∆C(t)/C measures how compute accumulates beyond that one-year mark. In prin-\\n0\\nciple, any timescale—weeks or months—could be used, yielding the same curve shape; but one\\nyear naturally aligns with budgeting cycles and hardware-refresh periods. Thus, statements like\\n“doubling efficiency every six months” or “it takes five years to reduce loss below 0.68” gain clear\\noperational meaning for R&D planning.\\nMulti-Year, Cross-Project Context. Although the equations might appear to describe a sin-\\ngle, multi-year training run, organizations typically develop AI systems iteratively across multiple\\nreleases—upcycling existing models [16, 17], refining data pipelines, and introducing new hard-\\nware. Each iteration effectively raises efficiency (γ > 0), while training loss (e.g., cross-entropy)\\noffersamonotonicyardstick: newermodelsmustaimforlower losstosurpasspredecessors. Inthis\\nsense,therelative-lossequation becomesamulti-projectroadmap: everynewwaveofimprovements\\ncompounds upon earlier ones, rather than relying on a single, continuous training job.\\n4 Analysis of Scaling Behaviors\\nHaving established a time-based framework for AI scaling, we now examine how its two principal\\nparameters—the scaling exponent κ and the annual efficiency-doubling rate γ—shape long-term\\nperformance.\\n4.1 Reduction to Classical Scaling Laws at γ = 0\\nStarting from the relative-loss equation:\\n(cid:16) 2γt−1 (cid:17)−κ\\nR(t) = 1 + , where L(t) = L R(t),\\nγln(2) × 1yr 0\\nwe now set γ = 0. To handle the limit 2γt−1 → γt ln(2) for small γt, we recall the first-order\\nexpansion 2x ≈1+x ln(2) for x→0. Thus,\\n2γt−1 −γ −→ −→0 γtln(2) = t.\\nγln(2)×1yr γln(2)×1yr\\n7Hence, at γ =0,\\n(cid:16) t (cid:17)−κ\\nL(t) = L 1 + .\\n0 1yr\\nInterpretation. When γ = 0 (no time-based efficiency improvements), this outcome reduces to\\nthestatic-scaling formL∝C−κ. However,wenowseehowrunningthesame hardwareandsoftware\\nfor an additional time t merely accumulates compute in a linear fashion. As the nearly flat γ = 0\\ncurve in Figure 1 shows, one must either (a) train for an exceedingly long duration or (b) invest in\\na massive up-front cluster at t = 0 to further reduce loss. Thus, the original diminishing returns\\n(L ∝ C−κ) are now made explicit in both time (t) and space (L ), underscoring why progress\\n0\\ninevitably stalls without ongoing efficiency gains (γ >0).\\n4.2 Asymptotic Behaviors\\nRecall that\\n(cid:18) 2γt−1 (cid:19)−κ (cid:16) (cid:17)\\nR(t) = 1+ Equation 3.4 ,\\nγln(2) × 1yr\\nand hence,\\nR(t) ∝ 2−κγt for large t.\\nSinceκγ >0,R(t)declinesexponentiallyast→∞,mirroringthevanishingreturnsoneencounters\\nwhen investing ever more compute. This parallels the leveling-off observed in Figure 1.\\nFor added intuition, consider a hypothetical analogy to historical Moore’s Law: if one estimates an\\neffective κ≈0.4, then a doubling rate of γ =0.5 (doubling roughly every two years) might suffice\\nto maintain improvements for a surprisingly long time.\\nBy contrast, modern AI scaling laws typically have much smaller κ ≈ 0.05. Achieving equally\\nrobust gains within a decade may therefore require γ ≥2 (efficiency doubling every six months) or\\nfaster. Asweincreaseγ,weeffectivelyprolongwhatcouldbetermedthe“productivitycycle”—the\\nwindow in which near-exponential improvements remain viable.\\n4.3 Sensitivity Analysis\\nOur model assumes a constant average power budget P under the mean-field assumption (Equa-\\n0\\ntion (3.2)). In reality, infrastructure, workloads, and hardware may fluctuate, introducing uncer-\\ntainty. To quantify how such changes affect predictions, we add a perturbation τ via\\nC\\n0 = 1+τyr.\\nE ·P\\n0 0\\n8Figure2: Sensitivitytobaselineperturbations. Thehorizontalaxisshowsτ inyears,withτ =−1yr\\nrepresentingascenariowherethebaselineeffectivelyvanishes. Evenunderlargedeviations,higherγ values\\npreserve robust predictions for time-to-target.\\nIf y is a target relative loss (say, R(t(τ)) = y), then near τ = 0, the time-to-target t(τ) is approx-\\nimately 1/(γ ln2), regardless of y. This implies a consistent first-order sensitivity across different\\nbaselines.\\nFor large γ, small shifts in effective compute have an even smaller impact on time-to-target, as\\nillustratedinFigure2. At,e.g.,γ =2(2×efficiencyeverysixmonths),thetimetoreachamoderate\\nloss threshold changes only slightly when the baseline is perturbed. For example, τ = 1 extends\\nthe time-to-target from 5.06 to about 5.78 years—a modest increase for a long-term projection.\\n4.4 Efficiency Doubling Rates and Time Horizons\\nFinally, consider how changing γ impacts the time needed to attain specific relative-loss targets.\\nFigure 3 tracks the time to achieve various y ∈ [0.5, 09] for different γ values. From a practical\\nstandpoint:\\n- Historical Moore’s Law (γ =0.5): Doubling every two years may suffice for modest goals\\nover long timescales, but it can push more stringent targets (e.g., 0.7 or lower) out to 15–20\\nyears— far beyond most industry planning cycles.\\n- Modern Demands (γ ≥2): Efficiency doublings every 6–12 months (γ =2 or 3) compress\\nthe entire schedule to a handful of years, in line with contemporary AI’s rapid iteration.\\nTheseanalysescollectivelyhighlighthowγandκtogetherdeterminethefeasibilityofnear-exponential\\nprogress. Even small differences in γ drastically alter the trajectory, underscoring the importance\\nof continuous innovation.\\n9Figure3: Timehorizonsvs.efficiency-doublingrate. Higherγ valuesradicallyshortenthetimelines\\nfor achieving targets y ∈ [0.5, 0.9]. The shaded region (2–10yrs) marks a modern industrial time frame.\\nRates γ ≥2 align more closely with today’s AI development speeds.\\n5 Implications and Case Studies\\nHaving introduced a time- and efficiency-aware perspective on AI scaling, we illustrate its conse-\\nquences through several thought experiments. First, we examine two theoretically static scenarios\\n(γ = 0), where compute is “unfolded” either in space (front-loading all GPUs simultaneously) or\\nin time (running a fixed-size cluster for millennia). Next, we consider scenarios with positive γ,\\nexploringhowabalancebetweenup-frontGPUinvestmentandsustainedefficiencygainscanshape\\nmulti-year outcomes. Please see Table 2 for the numerical results of these experiments.\\nIllustrative Scenario. Togroundthesetheoreticalinsights,consideratargetofachievingabout\\n50% token-prediction accuracy (L = 0.68nats/token). This performance level implies that, on\\naverage, the model correctly predicts the next token roughly half the time—no small feat when\\ndealing with large vocabularies and highly nuanced contexts.\\nSuppose we begin with a model (conceptually 10× LLaMA 3 via reorganized feed-forward layers\\ninto 16 experts) that trains for one year on 100,000 GPUs, resulting in an initial loss of L =\\n0\\n1.0nats/token. Reducing this loss from 1.0 to 0.68 reflects a substantial improvement in the\\nmodel’s ability to capture linguistic patterns and make meaningful predictions. Although a literal\\n10× increase over a 16,000-GPU cluster would be 160,000 GPUs, we use 100,000 for simplicity and\\nforward-looking assumptions about hardware availability. This scenario illustrates the immense\\ncomputeresourcesrequiredtotrainlarge-scalemodelsandunderscoresthetrade-offsamongmodel\\nsize, training duration, and performance gains.\\n105.1 How Severe Are the Diminishing Returns in AI Scaling?\\nA simplified numeric example demonstrates how purely static assumptions (γ = 0) can result in\\nextremely large hardware requirements or extended training durations, primarily due to the small\\nscaling exponent κ (e.g., κ=0.048).\\nFrom L = 1.0 to L = 0.68. Under the static law (i.e., the relative-loss equation at γ =0), we\\n0\\nhave:\\n(cid:16) t (cid:17)−κ (cid:16) ∆C(cid:17)−κ\\n1+ = 1+ = 0.68,\\n1yr C\\n0\\nwhich implies t≈3000 and ∆C ≈3000×C .\\n0\\nInterpretation:\\n• Longer Training (unfold in time): If C denotes running a baseline cluster for one year,\\n0\\nreducinglossfromL =1.0toL=0.68underaγ =0assumptionwouldrequireanadditional\\n0\\n3,000 years of training on the same hardware.\\n• Bigger GPU Fleet (unfold in space): If the loss reduction must be achieved within a\\nsingle year, ∆C ≈ 3000×C implies that the hardware must be scaled by a factor of 3,000.\\n0\\nThiswouldpushGPUrequirementsintothe300 million range,consumingpowercomparable\\nto the electricity use of an entire continent.\\nImplications: γ > 0 as Computational Necessity. Classical scaling laws, when taken in a\\npurely static sense (γ = 0), imply that driving the loss from L = 1.0 to L = 0.68 might require\\n0\\na 3,000× increase in compute (or equivalently, 3,000 years of training on the same hardware).\\nHowever, this enormous “3,000× factor” does not directly translate to realistic time and resource\\nconstraints. Byintroducingγ >0(theefficiency-doublingrate),ourframeworkextendsthepredic-\\ntivepowerofclassicalscalinglawstomorerealisticsettings,wherehardwarerefreshes,architecture\\nrefinements, and data-pipeline optimizations occur continually. Mathematically, one now has\\n(cid:16) 2γt−1 (cid:17)−κ\\nL(t) = L 1+ , γ >0,\\n0 γln(2) × 1yr\\nso that periodic improvements in “usable compute” offset the high cost of further reducing loss.\\nIn practice, major AI labs do achieve these ongoing gains via hardware refreshes, architecture\\nrefinements, and data-pipeline optimizations. Our framework formalizes this necessity, preserving\\nthepredictive power ofclassicalscalinglawswhileintegratingtime andefficiency formorerealistic\\noutcomes.\\n5.2 A Multi-Year Case: Baseline, Turtle, and Hare\\nWenowconsiderthreeillustrativescenarios,eachaimingtoreducetraininglossfromaninitial loss\\nL to a final target of L = 0.68. Although they share the same scaling exponent κ and ultimate\\n0\\nobjective, they differ in:\\n11Scenario Initial GPUs γ L R(t) Time to L=0.68\\n0\\nUnfold in Space ∼3×108 0 0.68 1.00 ∼1yr†\\nUnfold in Time 100k 0 1.00 0.68 ∼3,000yrs\\nBaseline 100k 0.5 1.00 0.68 ∼20yrs\\nTurtle 10k 3.0 1.12 0.61 ∼5yrs\\nHare 150k 2.0 0.95 0.71 ∼5yrs\\nTable 2: FiveillustrativescenariostargetingatraininglossofL=0.68onamodelscaled10×beyondthe\\nbaseline. Unfold in Space and Unfold in Time both set γ =0 (strictly static). They differ in whether we\\npack all needed resources into one year (3×108 GPUs) vs. stretching the same 100k-GPU baseline across\\nmillennia. Bycontrast,Baseline, Turtle,andHare assumeγ >0,meaningefficiencyimprovescontinuously\\nrather than relying on a single static “snapshot.”\\n†Toreduce lossbelow 0.68withγ =0requiresexponentiallymoreGPUs,duetothesmallscalingexponent\\n(diminishing returns).\\n- Starting Training Loss (L ), which depends on how many GPUs were initially allocated,\\n0\\nand\\n- Annual Efficiency-Doubling Rate (γ).\\nIn particular:\\n- Baseline: Beginswith100,000GPUsatγ =0.5,reflectingahistoricalrateofdoublingroughly\\nevery two years.\\n- Turtle: Starts with fewer GPUs (10,000) but targets a higher γ = 3.0 (tripling annually) to\\nsee if an “extreme efficiency push” can catch up.\\n- Hare: Begins with 150,000 GPUs (about 1.5× the Baseline’s cluster) at γ = 2.0, balancing\\nstronger up-front capacity with a still-robust annual doubling rate.\\nCommon Setup and Baseline Loss L . We assume each scenario runs for one initial year,\\n0\\nafter which the training loss is recorded as a new baseline L . Formally, if L is the loss before\\n0 init\\nthis year of training, and ∆C is the additional compute gained in that year (relative to a baseline\\nC ), then:\\n0\\n(cid:0) ∆C(cid:1)−κ\\nL = L 1+ .\\n0 init C\\n0\\nFewer initial GPUs yield a negative ∆C, as the compute achieved falls short of the baseline C ,\\n0\\nraising L . Conversely, more GPUs yield a positive ∆C, as the compute achieved exceeds the\\n0\\nbaseline,loweringL . Thisrelationshipunderscoresthetrade-offbetweeninitialresourceallocation\\n0\\nand the resulting training loss.\\n12Turtle vs. Hare in Practice. A scenario inspired by DeepSeek-V3 [18] could exemplify the\\nTurtle approach:\\n- Smaller GPU Fleet: StartingwithfewerGPUs(e.g.,2,000ratherthan10,000)andaiming\\nfor a higher efficiency-doubling rate (γ >2) to offset the lower initial capacity.\\n- High-Impact Optimizations: Even on mid-range devices, leveraging advanced hardware\\nfeatures (e.g., FP8) or specialized software (e.g., Mixture-of-Experts) can systematically in-\\ncrease γ.\\nInpractice,DeepSeek-V3hasachievedsuperior performanceacrossmultiplebenchmarks,showcas-\\ning how a Turtle-style strategy can deliver both efficiency and state-of-the-art results. Over time,\\nhowever,growingmodelordatasetrequirementsmightstillnecessitatesomeexpansionoftheGPU\\ncluster.\\nBy contrast, a Llama 3 (405B)-like [19] scenario may follow the Hare approach:\\n- Front-Loading a Massive Cluster: Deploying a large fleet (e.g., 30,000 GPUs) to rapidly\\nlower training loss in the first year, reducing initial turnaround but at a high capital cost.\\n- SelectiveHardwareandArchitectures: Potentiallyamoreconservativestanceoncertain\\ncapabilities (e.g., partial adoption of FP8 or limited use of Mixture-of-Experts), with plans\\nto integrate further optimizations in subsequent iterations.\\nIn short, these contrasting strategies highlight how organizations may balance a large initial GPU\\ninvestment (Hare) with incremental efficiency gains (Turtle) to manage steep diminishing returns.\\nRegardless of fleet size or GPU type, the unifying principle is continuous efficiency improvement\\nacrosshardware, software, anddatapipelines—drivingthesustainedinnovation(γ)thatunderpins\\nmodern AI scaling.\\n5.3 Scaling Laws as the Driving Force for Innovations\\nSustaining progress in AI scaling demands a deliberate focus on innovation to accelerate efficiency\\ngains and counteract diminishing returns. Interestingly, this driving force stems from the same\\nprinciples that underpin classical scaling laws, once extended into a time- and efficiency-aware\\nframework.\\nLogical Compute as Optimization-Agnostic. Because scaling laws inherently treat compute\\nin a model-agnostic manner, logical compute is defined as though the model were both dense and\\nfull-precision. This prevents conflating compute with efficiency, the latter reflecting tangible gains\\nfrom optimizations like sparsity or reduced-precision formats [15, 14]. Without this separation,\\nan architecture such as DeepSeek-V3 [18]—which achieves a 17× higher real-world efficiency than\\nLlama3(405B)byleveragingsparsity(Mixture-of-Experts),FP8arithmetic,andotherrefinements\\n(see Appendix A)—would appear artificially “smaller.”\\n13Byanchoring“compute”tothemodel’sfull architecturalcapacityandattributingactualspeedups\\nto Time×Power, the optimization-agnostic nature of scaling laws remains intact. Researchers can\\ninnovate freely—balancing accuracy, power, and training cost—without altering the fundamental\\ncompute measure itself. Meanwhile, the annual efficiency-doubling rate γ quantifies how rapidly\\nthese real-world optimizations accumulate, fueling near-exponential progress over multi-year devel-\\nopment cycles.\\nCumulative Compute as a Compounding Process. Classical AI scaling laws (e.g., L ∝\\n0\\nC−κ) provide a “snapshot” for training loss under a fixed compute budget. Once we generalize to\\n0\\n(cid:16) ∆C(t)(cid:17)−κ\\nL(t) = L 1+ ,\\n0 C\\n0\\nthe additional compute ∆C(t) builds over time, transforming that static snapshot into a com-\\npounding process. Every phase of progress leverages all prior compute investments, allowing near-\\nexponentialimprovementswhenefficiency(γ >0)continuesrising. Thisviewclarifieswhyongoing\\ninnovation is indispensable: each incremental gain can magnify the returns of earlier investments,\\nthereby sustaining AI scaling despite inherently small exponents (κ).\\n5.4 Outlook\\nConnection to Industry Trends. Recent industry data highlights significant advancements in\\nAI energy efficiency, with NVIDIA reporting a 45,000× improvement in energy efficiency for AI in-\\nferenceoverthepasteightyears—equatingtodoublingapproximatelyeverysixmonths (γ ≈2)[20].\\nThis progress is exemplified by the latest GB10, which integrates the Grace CPU and Blackwell\\nGPU into a desktop form factor [21]. Concurrently, organizations like OpenAI, Google, and Meta\\ncontinue to refine hardware, software, data pipelines, and infrastructure to sustain rapid improve-\\nments in efficiency. For example, DeepSeek-V3 [18] achieves substantial efficiency gains through\\ninnovations such as FP8 arithmetic, sparsity, and Mixture-of-Experts, demonstrating the poten-\\ntial of architectural optimizations. The success of platforms like Grace Blackwell and innovations\\nsuch as DeepSeek-V3 underscore the critical importance of prioritizing efficiency improvements in\\nAI development, particularly for organizations with constrained compute resources or sustainabil-\\nity targets. This sustained trajectory of efficiency improvement directly supports the exponential\\nperformance gains necessary for training modern large-scale models.\\nPolicy Implications. By explicitly embedding the efficiency-doubling rate γ within AI scaling\\nlaws, our framework elevates innovation across the AI stack from an implicit assumption to a\\nmeasurable driver of progress. Rather than a “compute arms race,” AI scaling becomes a “race\\nto efficiency”: leaders and policymakers can set explicit targets (e.g. doubling efficiency every six\\nmonths) and synchronize development roadmaps to sustain a high γ. Much as Moore’s Law once\\nprovidedconcretemilestonesfortransistorscaling,AIpractitionerscannowanchormulti-yearplans\\non tangible efficiency benchmarks, fueling the compounding gains crucial for sustained, real-world\\nAI advances.\\n146 Conclusion\\nThisworkpresentedatime-andefficiency-awarefoundationforAIscaling,revealinghowa“raceto\\nefficiency” naturally emerges once classical, static scaling laws account for ongoing efficiency gains.\\nThree key insights form a mutually reinforcing cycle:\\n- Time-ExtendedPerspective. Whileclassicallawslinklosstocomputeatasinglesnapshot,\\nrecognizing “efficiency doubling” over months or years shifts that static view into a dynamic,\\nnear-exponential trajectory.\\n- Efficiency-Centric Focus. Because scaling laws reliably map compute to performance\\ngains, the crucial question becomes how efficiently compute accumulates over time. In this\\nlight, efficiency doubling emergesasbothacomputationalandpracticalnecessitytomitigate\\nsteep diminishing returns.\\n- Innovation as Core to Scaling. Once efficiency is central, continual optimizations across\\nthe AI stack no longer appear as external “fixes” but as integral parts of the scaling pro-\\ncess. These incremental improvements compound over multiple training cycles and product\\ngenerations, reinforcing the time-extended perspective.\\nLooking ahead, constraints akin to those that once challenged transistor scaling may ultimately\\ncall for new paradigms. Yet the tension between diminishing returns and time-extended efficiency\\ngains will likely remain a defining force in AI’s technological evolution.\\n7 Limitations and Future Work\\nWhile the relative-loss equation offers a unified perspective on AI scaling progress, its practical\\nvalueandgeneralitywarrantfurtherexploration. Below,wehighlightseveralavenuesforextending\\nand refining this framework.\\nEmpirical Validation and Transparency\\nTheinsightsinthispaperrestontheoreticalconstructsandempiricallyobservedscalingexponents.\\nNevertheless, comprehensive validation against real-world data is crucial. Greater transparency in\\nreporting relative training loss, cumulative compute, and efficiency-doubling rates could enable\\nmorerigorouscross-studycomparisons. Industry-widedatasharing,standardizedbenchmarks,and\\nconsistentevaluationprotocols—akintothoseonceusedforguidingsemiconductorprogress—would\\nhelpverifythepredictivepoweroftherelative-lossequation. Sucheffortscouldalsoinformresource-\\nallocation decisions, model architectures, and targeted efficiency improvements.\\nGeneralizing to Multi-Phase Growth\\nAlthough our framework focuses on AI training, it could be generalized to capture early, sub-\\nexponential “kick-off” phases or logistic transitions in other domains—ranging from technology\\n15adoption to broader economic processes. Such a generalization would provide a unified view of\\nhow systems evolve from an initial ramp-up to potentially exponential (or S-curve [22]) growth\\ntrajectories.\\nOptimal Usage vs. Raw Compute\\nThe relative-loss equation assumes compute-optimal usage, where model size, dataset size, and\\ntraining strategy are balanced to fully exploit available resources. Simply increasing GPUs or peak\\ncompute does not guarantee improved performance if scaling principles are not followed.\\nForinstance, trainingalargemodelwithoutadequatedataorfailingtotunehyperparametersmay\\nnot yield the expected loss reductions. Likewise, imbalanced scaling between model and data can\\nprevent the envisioned gains. The equation thus reflects a best-case trajectory, assuming that each\\nincrement in compute efficiency translates directly into effective training progress.\\nExtending the Framework to Inference and Test-Time Scaling\\nWhileourcurrentformulationfocusesontraining dynamics,extendingtherelative-lossequationor\\ndeveloping analogous constructs for inference-time scaling [13, 23] could yield a more holistic view\\nof AI system performance. In particular, because large models are increasingly used to generate\\nnew training data and perform on-the-fly or iterative refinement, higher inference efficiency can\\naccelerate the training pipeline rather than merely reduce deployment costs.\\nAsaresult,understandinghowinference-timeefficiencyimprovementstranslateintofasterthrough-\\nput,lowerlatency,orexpandeddatapipelinesmaybecrucial,giventhatdeploymentconsiderations\\n(and the downstream feedback loop into training) increasingly shape large-model design choices.\\nA unified framework that addresses both training and inference could thus clarify how hardware\\nroadmaps, data engineering, and algorithmic optimizations interact across the entire lifecycle of AI\\nsystems.\\nEvolving Concepts of Compute-Optimality\\nTraditionally, compute-optimal scaling assumes a static dataset and a fixed model configuration.\\nIn reality, both datasets and models evolve over time. Approaches such as upcycling pretrained\\nmodels [24, 16, 17], and dynamically adapting model size or precision introduce new optimization\\nstrategies. Similarly, dataset generation and curation—leveraging synthetic data [25] or reasoning-\\nbased selection [26]—blur the boundary between model development and data sourcing.\\nAs these strategies mature, future frameworks must treat datasets, models, and compute budgets\\nas interconnected and evolving. Such adaptability ensures the relative-loss equation and similar\\nscaling models remain relevant.\\n16References\\n[1] Reuters, “AI with reasoning power will be less predictable, Ilya Sutskever says,”\\nReutersTechnology,2024.[Online].Available: https://www.reuters.com/technology/artificial-\\nintelligence/ai-with-reasoning-power-will-be-less-predictable-ilya-sutskever-says-2024-12-14/\\n[2] Business Insider, “OpenAI is reportedly struggling to improve its next big AI model. It’s\\na warning for the entire AI industry.” Business Insider, 2024. [Online]. Available: https:\\n//www.businessinsider.com/openai-orion-model-scaling-law-silicon-valley-chatgpt-2024-11\\n[3] Time Magazine, “Has AI progress really slowed down?” Time, 2024. [Online]. Available:\\nhttps://time.com/7178328/is-ai-progress-slowing-down/\\n[4] Business Insider, “NVIDIA boss Jensen Huang predicts computing power will in-\\ncrease a ’millionfold’ in a decade,” Business Insider, 2024. [Online]. Avail-\\nable: https://www.businessinsider.com/nvidia-jensen-huang-predicts-increase-computing-\\npower-ai-scaling-2024-11\\n[5] Benzinga, “Microsoft defies the AI plateau, pushing boundaries with new scaling laws,”\\nBenzinga, 2024. [Online]. Available: https://www.benzinga.com/24/11/42088290/microsoft-\\ndefies-the-ai-plateau-pushing-boundaries-with-new-scaling-laws\\n[6] W. Central, “There’s no evidence scaling laws have begun to stop, former Google CEO\\nclaims AI systems will be 100 times more powerful,” Windows Central, 2024. [Online].\\nAvailable: https://www.windowscentral.com/software-apps/theres-no-evidence-scaling-laws-\\nhave-begun-to-stop-former-google-ceo-claims-ai-systems-will-be-100-times-more-powerful\\n[7] G. E. Moore, “Cramming more components onto integrated circuits,” Electronics, vol. 38, pp.\\n114–117, 1965.\\n[8] R. H. Dennard, E. Gaensly, and F. Spreen, “Design of ion-implanted MOSFETs with very\\nsmall gate lengths,” IEEE transactions on electron devices, vol. 21, no. 1, pp. 637–644, 1974.\\n[9] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray,\\nA.Radford, J.Wu, andD. Amodei, “Scalinglaws forneurallanguagemodels,” arXivpreprint\\narXiv:2001.08361, 2020. [Online]. Available: https://arxiv.org/abs/2001.08361\\n[10] J. Hoffmann, S. Borgeaud, A. Mensch, T. Cai, E. Rutherford, D. de Las Casas,\\nL. M. Hendricks, J. Welbl, A. Clark, J. Bewersdorf et al., “Training compute-optimal\\nlarge language models,” arXiv preprint arXiv:2203.15556, 2022. [Online]. Available:\\nhttps://arxiv.org/abs/2203.15556\\n[11] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,\\nP. Shyam, G. Sastry, A. Askell et al., “Language models are few-shot learners,” arXiv preprint\\narXiv:2005.14165, 2020. [Online]. Available: https://arxiv.org/abs/2005.14165\\n[12] N.Sardana,J.Portes,S.Doubov,andJ.Frankle,“BeyondChinchilla-optimal: Accountingfor\\ninference-time in language model scaling,” arXiv preprint arXiv:2211.02011, 2024. [Online].\\nAvailable: https://arxiv.org/abs/2401.00448\\n17[13] C. Snell, J. Lee, K. Xu, and A. Kumar, “Scaling LLM test-time compute optimally can\\nbe more effective than scaling model parameters,” arXiv preprint arXiv:2408.03314, 2023.\\n[Online]. Available: https://arxiv.org/abs/2408.03314\\n[14] A. Clark, D. de Las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc,\\nB. Hechtman, T. Cai, S. Borgeaud et al., “Unified scaling laws for routed language models,”\\nin Proceedings of the International Conference on Machine Learning. PMLR, 2022, pp.\\n4057–4086. [Online]. Available: https://proceedings.mlr.press/v162/clark22a.html\\n[15] T. Kumar, Z. Ankner, B. F. Spector, B. Bordelon, N. Muennighoff, M. Paul, C. Pehlevan,\\nC. R´e, and A. Raghunathan, “Scaling laws for precision,” arXiv preprint arXiv:2411.04330,\\n2024. [Online]. Available: https://arxiv.org/abs/2411.04330\\n[16] E. He, A. Khattar, R. Prenger, V. Korthikanti, Z. Yan, T. Liu, S. Fan, A. Aithal, M. Shoeybi,\\nand B. Catanzaro, “Upcycling large language models into mixture of experts,” arXiv preprint\\narXiv:2410.07524, 2024. [Online]. Available: https://arxiv.org/abs/2410.07524\\n[17] A. Vavre, E. He, D. Liu, Z. Yan, J. Yang, N. Tajbakhsh, and A. Aithal, “Llama 3 meets\\nMoE: Efficient upcycling,” arXiv preprint arXiv:2412.09552v1, 2024. [Online]. Available:\\nhttps://arxiv.org/abs/2412.09952v1\\n[18] DeepSeek-AI, “DeepSeek-V3: An ultra-large open-source AI model,” arXiv preprint\\narXiv:2412.19437, 2024. [Online]. Available: https://arxiv.org/abs/2412.19437\\n[19] A. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman,\\nA. Mathur et al., “The llama 3 herd of models,” arXiv preprint arXiv:2407.21783. [Online].\\nAvailable: https://arxiv.org/abs/2407.21783\\n[20] NVIDIA Blog, “Can innovation curb AI’s hunger for power?” https://blogs.nvidia.com/blog/\\nai-energy-efficiency/, 2024, accessed: December 29, 2024.\\n[21] NVIDIA, NVIDIA Puts Grace Blackwell on Every Desk and at Every AI Developer’s Fin-\\ngertips, 2025. [Online]. Available: https://nvidianews.nvidia.com/news/nvidia-puts-grace-\\nblackwell-on-every-desk-and-at-every-ai-developers-fingertips.\\n[22] R. N. Foster, Innovation: The Attacker’s Advantage. New York, NY: Summit Books, 1986.\\n[23] Y. Wu, Z. Sun, S. Li, S. Welleck, and Y. Yang, “Inference scaling laws: An empirical analysis\\nof compute-optimal inference for LLM problem-solving,” arXiv preprint arXiv:2408.00724,\\n2024. [Online]. Available: https://arxiv.org/abs/2408.00724\\n[24] A. Komatsuzaki, J. Puigcerver, J. Lee-Thorp, C. Riquelme, B. Mustafa, J. Ainslie,\\nY. Tay, M. Dehghani, and N. Houlsby, “Sparse upcycling: Training mixture-of-experts\\nfrom dense checkpoints,” arXiv preprint arXiv:2212.05055, 2022. [Online]. Available:\\nhttps://arxiv.org/abs/2212.05055\\n[25] E. Zelikman, Y. Wu, J. Mu, and N. D. Goodman, “STaR: Bootstrapping reasoning\\nwith reasoning,” arXiv preprint arXiv:2203.14465, 2022. [Online]. Available: https:\\n//arxiv.org/abs/2203.14465\\n18[26] E. Zelikman, Y. Wu, and N. D. Goodman, “Quiet-STaR: Language models can teach\\nthemselves to think before speaking,” arXiv preprint arXiv:2403.09629, 2024. [Online].\\nAvailable: https://arxiv.org/abs/2403.09629\\nA Invariance of Logical Compute\\nThis appendix explains why we define logical compute as dense and full-precision and how it un-\\nderpins a fair comparison—illustrated with DeepSeek-V3 and Llama 3 (405B)—even when actual\\nGPU hours differ across hardware or optimization strategies.\\nWhy κ Remains Unchanged by Optimizations\\nSuppose the training loss depends on model size N and dataset size D as\\nL(N,D) = AN−α + BD−β + E,\\nwhere α,β >0. For a fixed compute budget C, the compute-optimal pairs (N∗,D∗) satisfy\\nβ α\\nN∗ ∝ Cα+β, D∗ ∝ Cα+β,\\nso substituting back yields\\nα α\\nL(C) ∝ C− α+β = C−κ, κ = .\\nα+β\\nHence, κ depends only on α,β, not on how we optimize model parameters or numeric formats. In\\nother words, whether one uses low-precision arithmetic, sparsity, or a Mixture-of-Experts design,\\nthe fundamental exponent κ stays invariant.\\nDefining Logical Compute\\nWe define logical compute as though the model is both dense and full-precision. Specifically:\\nLogical Compute (FLOPs) = 6×N ×D,\\nwhere\\n• N = total model parameters,\\n• D = total training tokens,\\n• The factor 6 accounts for forward/backward passes and parameter updates.\\nThis ensures that “compute” consistently reflects the full architecture, independent of sparsity or\\nprecision. Actual speedups (e.g., from FP8 or MoE) appear separately in reduced Time×Power,\\nrather than shrinking the fundamental compute measure.\\n19Case Study: DeepSeek-V3 vs. Llama 3 (405B)\\nTo illustrate why logical compute is kept dense, consider two models that achieve broadly similar\\nlarge-scale outcomes yet differ in real-world GPU usage:\\n• DeepSeek-V3 [18]:\\n– N ≈671B (parameters),\\n– D ≈14.8T (training tokens),\\n– Real GPU usage: ∼ 2.78M GPU-hours on H800, adjusted to ∼ 2.224M GPU-hours at\\nH100 equivalence.\\n• Llama 3 (405B) [19]:\\n– N ≈405B,\\n– D ≈2.0T,\\n– Real GPU usage: ∼30.84M GPU-hours on H100.\\nModel Parameters(B) DataTokens(T) LogicalCompute(PFLOPs) GPUHours(M,H100-Eq.) RelativeEfficiency\\nDeepSeek-V3 671 14.8 5.95×1015 2.224 ≈17.0(vs.Llama=1)\\nLlama3(405B) 405 2.0 4.86×1015 30.84 1.0(baseline)\\nTable 3: DeepSeek-V3 vs. Llama 3 (405B). Both achieve large-scale performance but differ in GPU\\nhours. Logical compute (assuming dense, full-precision) is high in both cases, yet DeepSeek-V3 real-world\\nefficiency is about 17× Llama 3’s.\\nSummarizing the Computations. As shown in Table 3, logical compute for DeepSeek-V3 is\\nslightly larger than Llama 3, reflecting its extra parameters and bigger training set. However,\\nreal-world GPU hours for DeepSeek-V3 are far lower than Llama 3, thanks to hardware/software\\noptimizations (e.g., sparsity, FP8). Defining compute in a purely “dense” sense prevents conflating\\nthose optimizations with the model’s intrinsic size.\\nRelative Efficiency. One can define a “relative efficiency” factor:\\nLogical Compute (FLOPs)\\nRelative Efficiency = ,\\nGPU-Hours (H100 Eq.)\\nthen normalize Llama 3 (405B) at 1.0. Under that measure, Table 3 shows DeepSeek-V3 is about\\n17× more efficient. Crucially, this ratio does not shrink its logical compute (it remains at 5.95×\\n1015PFLOPs), but records gains via fewer GPU hours.\\nCounterarguments and Responses\\nShould We Adjust Logical Compute for Sparsity or Precision? Some suggest reducing\\nFLOPstoreflectonlythefractionofparametersactivatedpertoken(experts-per-token inMoE)or\\nthe lower numeric cost (e.g., from FP8). However, that merges two concepts:\\n20• Full Model Complexity: The entire parameter space at full precision, representing the\\nmodel’s theoretical capacity.\\n• Real-World Efficiency Gains: Achieved by using only a subset of parameters, or fewer\\nbits per operation, thus lowering time and power.\\nConflatingthempenalizesarchitecturesthatareinherentlymoreefficient(likeMixture-of-Experts).\\nInstead, we keep the definition of “logical compute” dense and record any real-world speedups in\\nthe denominator (Time×Power). This way, a model reaps the benefits of advanced routing or\\nquantization (γ >0) without artificially reducing its fundamental FLOP count.\\nIs “Effective Model Size” More Accurate? Although some frameworks define an effective\\nsizeN forMoE[14]orreducedprecision[15],suchanapproachcanhidethefullparameterspace.\\neff\\nNot all parameters are active per token, but they still exist, providing capacity for generalization\\nand future scaling. By keeping “logical compute” dense, we preserve fairness across architectures.\\nIf a model invests in sophisticated routing or quantization, the advantage should appear as a lower\\nTime×Power, not by discarding parameters from the total.\\nSummary\\nBecause κ depends solely on the power-law slope linking model size, dataset size, and compute, it\\nis invariant to whether a model employs sparsity, lower-precision arithmetic, or mixture-of-experts\\nrouting. Defining logical compute as though it were both dense and full-precision provides a con-\\nsistent baseline for comparing very different architectures. Real-world efficiency gains, meanwhile,\\nshow up in Time × Power, thereby highlighting the genuine speedups achieved by hardware or\\nsoftware improvements. This framework allows us to preserve the foundational exponent κ from\\nclassical scaling laws while giving proper credit for engineering advances in accelerators, memory\\nsystems, or training algorithms.\\n21'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e50d9de6-18aa-48ca-925b-54f8fff35349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text, custom_stop_words=None):\n",
    "    \"\"\"\n",
    "    一文字ごとに分割されてしまった単語を復元し、ストップワードや不要な単語を削除する。\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):  # 念のため型チェック\n",
    "        raise TypeError(\"text must be a string\")\n",
    "    \n",
    "    # アルファベットの単語を復元（単独の文字がスペースで分割されている場合に連結）\n",
    "    text = re.sub(r'(?<!\\w) ([a-zA-Z]) (?!\\w)', r'\\1', text)\n",
    "    \n",
    "    # 単語を抽出（英単語のみ対象、数字や記号を除外）\n",
    "    words = re.findall(r'[a-zA-Z]+', text)\n",
    "\n",
    "    # ストップワードを除外しつつ、一文字の単語も削除\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words and len(word) > 1]\n",
    "\n",
    "    # ユーザー指定の削除単語を適用\n",
    "    if custom_stop_words:\n",
    "        words = [word for word in words if word.lower() not in custom_stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66c0f349-05c0-47e2-8e48-c763db8b7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_texts(pdf_texts):\n",
    "    \"\"\"\n",
    "    各PDFのテキストをクリーンアップして単語リストに変換する。\n",
    "    \"\"\"\n",
    "    cleaned_texts = {}\n",
    "    \n",
    "    for file_name, text in pdf_texts.items():\n",
    "        words = clean_and_tokenize(text)  # クリーニング処理\n",
    "        cleaned_texts[file_name] = words\n",
    "    \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b6ae4b2-026f-4cc6-848e-49a5504475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_frequencies(cleaned_texts):\n",
    "    \"\"\"\n",
    "    各PDFの単語リストから英単語の頻度をカウントする。\n",
    "    \"\"\"\n",
    "    word_frequencies = {}\n",
    "    \n",
    "    for file_name, words in cleaned_texts.items():\n",
    "        counter = Counter(words)\n",
    "        word_frequencies[file_name] = counter\n",
    "    \n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0df1781e-68ff-4a00-9f97-93be7bf3c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(word_frequencies, n=20):\n",
    "    \"\"\"\n",
    "    各PDFの英単語の頻度から最頻ワード上位N個を取得する。\n",
    "    \"\"\"\n",
    "    top_words = {}\n",
    "    \n",
    "    for file_name, counter in word_frequencies.items():\n",
    "        top_n_words = counter.most_common(n)\n",
    "        top_words[file_name] = top_n_words\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d417eae-f30f-414a-b3fe-1298a3d84d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = process_pdf_texts(pdf_texts)  # 2. クリーニング処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7b74504-8661-48ba-be95-eea96882940c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_words = {\"dr\", \"ci\", \"tn\",\"tp\",\"fp\",\"et\",\"al\",\"fn\",\"et\",\"apt\",\"ee\",\"ij\",\"na\",\"et\",\"ee\",\"er\",\"te\",\"rn\",\"ie\",\"en\",\"oe\",\"se\",\"et\",\"td\",\"ro\",\"ne\",\"rq\"}  # 削除したい単語リスト\n",
    "cleaned_texts = process_pdf_texts(pdf_texts) \n",
    "\n",
    "cleaned_words = {}\n",
    "for file_name, words in cleaned_texts.items():\n",
    "    cleaned_words[file_name] = clean_and_tokenize(' '.join(words), custom_stop_words=custom_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcff1d61-ec26-4970-b837-71e439e56f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = count_word_frequencies(cleaned_words)  # 3. 単語頻度カウント\n",
    "top_words = get_top_n_words(word_frequencies)  # 4. 最頻ワード取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4484cd34-b981-499a-84c7-cc6d1dc4480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_word\n",
    "# word_frequencies\n",
    "# top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80dae812-8dff-413e-8275-43f0fcf05eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "notion_df = pd.read_csv(r\"C:\\Users\\sk062\\OneDrive\\デスクトップ\\9c2e4d3d-864b-490e-b35a-b141df14fc43_Export-00b74899-a19a-4d27-9b59-9b23b5916742\\Note paper (ai) 174225966a7b8067b3ecd5385709bbb4.csv\")\n",
    "\n",
    "df = notion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56cdfda2-7072-4bc8-8e27-f608bd482f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>most_recent_word1</th>\n",
       "      <th>frequency1</th>\n",
       "      <th>most_recent_word2</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>most_recent_word3</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>most_recent_word4</th>\n",
       "      <th>frequency4</th>\n",
       "      <th>most_recent_word5</th>\n",
       "      <th>...</th>\n",
       "      <th>most_recent_word16</th>\n",
       "      <th>frequency16</th>\n",
       "      <th>most_recent_word17</th>\n",
       "      <th>frequency17</th>\n",
       "      <th>most_recent_word18</th>\n",
       "      <th>frequency18</th>\n",
       "      <th>most_recent_word19</th>\n",
       "      <th>frequency19</th>\n",
       "      <th>most_recent_word20</th>\n",
       "      <th>frequency20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based on Large Language Models Enhanced by Domain Knowledge Retrieval.pdf</th>\n",
       "      <td>A Soft Sensor Method with Uncertainty-Awarenes...</td>\n",
       "      <td>llm</td>\n",
       "      <td>178</td>\n",
       "      <td>soft</td>\n",
       "      <td>98</td>\n",
       "      <td>ufss</td>\n",
       "      <td>91</td>\n",
       "      <td>data</td>\n",
       "      <td>86</td>\n",
       "      <td>fig</td>\n",
       "      <td>...</td>\n",
       "      <td>variables</td>\n",
       "      <td>50</td>\n",
       "      <td>confidence</td>\n",
       "      <td>46</td>\n",
       "      <td>methods</td>\n",
       "      <td>45</td>\n",
       "      <td>prediction</td>\n",
       "      <td>45</td>\n",
       "      <td>pt</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI-Driven Diabetic Retinopathy Screening Multicentric Validation of AIDRSS in India.pdf</th>\n",
       "      <td>AI-Driven Diabetic Retinopathy Screening Multi...</td>\n",
       "      <td>aidrss</td>\n",
       "      <td>32</td>\n",
       "      <td>screening</td>\n",
       "      <td>20</td>\n",
       "      <td>specificity</td>\n",
       "      <td>20</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>19</td>\n",
       "      <td>retinopathy</td>\n",
       "      <td>...</td>\n",
       "      <td>fundus</td>\n",
       "      <td>11</td>\n",
       "      <td>using</td>\n",
       "      <td>11</td>\n",
       "      <td>feature</td>\n",
       "      <td>11</td>\n",
       "      <td>fig</td>\n",
       "      <td>10</td>\n",
       "      <td>india</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constraints as Rewards Reinforcement Learning for Robots without Reward Functions.pdf</th>\n",
       "      <td>Constraints as Rewards Reinforcement Learning ...</td>\n",
       "      <td>cid</td>\n",
       "      <td>57</td>\n",
       "      <td>constraint</td>\n",
       "      <td>53</td>\n",
       "      <td>robot</td>\n",
       "      <td>44</td>\n",
       "      <td>learning</td>\n",
       "      <td>39</td>\n",
       "      <td>task</td>\n",
       "      <td>...</td>\n",
       "      <td>design</td>\n",
       "      <td>20</td>\n",
       "      <td>proposed</td>\n",
       "      <td>20</td>\n",
       "      <td>method</td>\n",
       "      <td>19</td>\n",
       "      <td>qrsac</td>\n",
       "      <td>19</td>\n",
       "      <td>trained</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTINUUM Detecting APT Attacks through Spatial-Temporal Graph Neural Networks.pdf</th>\n",
       "      <td>CONTINUUM Detecting APT Attacks through Spatia...</td>\n",
       "      <td>graph</td>\n",
       "      <td>65</td>\n",
       "      <td>data</td>\n",
       "      <td>44</td>\n",
       "      <td>model</td>\n",
       "      <td>38</td>\n",
       "      <td>detection</td>\n",
       "      <td>33</td>\n",
       "      <td>node</td>\n",
       "      <td>...</td>\n",
       "      <td>spatial</td>\n",
       "      <td>19</td>\n",
       "      <td>using</td>\n",
       "      <td>19</td>\n",
       "      <td>benign</td>\n",
       "      <td>19</td>\n",
       "      <td>ids</td>\n",
       "      <td>18</td>\n",
       "      <td>federated</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiReCT Diagnostic Reasoning for Clinical Notes via Large Language Models.pdf</th>\n",
       "      <td>DiReCT Diagnostic Reasoning for Clinical Notes...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>41</td>\n",
       "      <td>response</td>\n",
       "      <td>39</td>\n",
       "      <td>observation</td>\n",
       "      <td>38</td>\n",
       "      <td>disease</td>\n",
       "      <td>37</td>\n",
       "      <td>note</td>\n",
       "      <td>...</td>\n",
       "      <td>stroke</td>\n",
       "      <td>17</td>\n",
       "      <td>figure</td>\n",
       "      <td>16</td>\n",
       "      <td>diagnostic</td>\n",
       "      <td>15</td>\n",
       "      <td>however</td>\n",
       "      <td>15</td>\n",
       "      <td>respectively</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPO Kernels  A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization.pdf</th>\n",
       "      <td>DPO Kernels  A Semantically-Aware, Kernel-Enha...</td>\n",
       "      <td>cid</td>\n",
       "      <td>812</td>\n",
       "      <td>kernel</td>\n",
       "      <td>255</td>\n",
       "      <td>log</td>\n",
       "      <td>175</td>\n",
       "      <td>kernels</td>\n",
       "      <td>154</td>\n",
       "      <td>rbf</td>\n",
       "      <td>...</td>\n",
       "      <td>yy</td>\n",
       "      <td>68</td>\n",
       "      <td>based</td>\n",
       "      <td>67</td>\n",
       "      <td>model</td>\n",
       "      <td>61</td>\n",
       "      <td>data</td>\n",
       "      <td>60</td>\n",
       "      <td>local</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DynaGRAG Exploring the Topology of Information.pdf</th>\n",
       "      <td>DynaGRAG Exploring the Topology of Information...</td>\n",
       "      <td>dynagrag</td>\n",
       "      <td>21</td>\n",
       "      <td>graph</td>\n",
       "      <td>20</td>\n",
       "      <td>cid</td>\n",
       "      <td>14</td>\n",
       "      <td>llms</td>\n",
       "      <td>13</td>\n",
       "      <td>inarxiv</td>\n",
       "      <td>...</td>\n",
       "      <td>diversity</td>\n",
       "      <td>7</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>7</td>\n",
       "      <td>language</td>\n",
       "      <td>6</td>\n",
       "      <td>like</td>\n",
       "      <td>6</td>\n",
       "      <td>flash</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exploring Gradient Subspaces Addressing and Overcoming LoRA's Limitations in Federated Fine-Tuning of Large Language Models.pdf</th>\n",
       "      <td>Exploring Gradient Subspaces Addressing and Ov...</td>\n",
       "      <td>cid</td>\n",
       "      <td>276</td>\n",
       "      <td>lora</td>\n",
       "      <td>88</td>\n",
       "      <td>agg</td>\n",
       "      <td>82</td>\n",
       "      <td>clients</td>\n",
       "      <td>56</td>\n",
       "      <td>fedftg</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>23</td>\n",
       "      <td>across</td>\n",
       "      <td>22</td>\n",
       "      <td>dolly</td>\n",
       "      <td>22</td>\n",
       "      <td>medquad</td>\n",
       "      <td>22</td>\n",
       "      <td>language</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperbolic Contrastive Learning for Hierarchical 3D Point Cloud Embedding.pdf</th>\n",
       "      <td>Hyperbolic Contrastive Learning for Hierarchic...</td>\n",
       "      <td>point</td>\n",
       "      <td>112</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>102</td>\n",
       "      <td>cloud</td>\n",
       "      <td>76</td>\n",
       "      <td>text</td>\n",
       "      <td>65</td>\n",
       "      <td>learning</td>\n",
       "      <td>...</td>\n",
       "      <td>pages</td>\n",
       "      <td>25</td>\n",
       "      <td>cid</td>\n",
       "      <td>23</td>\n",
       "      <td>training</td>\n",
       "      <td>22</td>\n",
       "      <td>loss</td>\n",
       "      <td>22</td>\n",
       "      <td>clip</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFELM In-depth Fairness Evaluation of Large Text-To-Image Models.pdf</th>\n",
       "      <td>INFELM In-depth Fairness Evaluation of Large T...</td>\n",
       "      <td>cid</td>\n",
       "      <td>16</td>\n",
       "      <td>image</td>\n",
       "      <td>15</td>\n",
       "      <td>models</td>\n",
       "      <td>12</td>\n",
       "      <td>figure</td>\n",
       "      <td>12</td>\n",
       "      <td>skintone</td>\n",
       "      <td>...</td>\n",
       "      <td>monk</td>\n",
       "      <td>7</td>\n",
       "      <td>table</td>\n",
       "      <td>7</td>\n",
       "      <td>classification</td>\n",
       "      <td>7</td>\n",
       "      <td>stablediffusionv</td>\n",
       "      <td>7</td>\n",
       "      <td>large</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGNN Simple Graph Neural Network for Recommendation.pdf</th>\n",
       "      <td>LightGNN Simple Graph Neural Network for Recom...</td>\n",
       "      <td>cid</td>\n",
       "      <td>37</td>\n",
       "      <td>pages</td>\n",
       "      <td>27</td>\n",
       "      <td>lightgnn</td>\n",
       "      <td>16</td>\n",
       "      <td>wang</td>\n",
       "      <td>16</td>\n",
       "      <td>graph</td>\n",
       "      <td>...</td>\n",
       "      <td>ii</td>\n",
       "      <td>10</td>\n",
       "      <td>ed</td>\n",
       "      <td>10</td>\n",
       "      <td>ni</td>\n",
       "      <td>10</td>\n",
       "      <td>ei</td>\n",
       "      <td>10</td>\n",
       "      <td>figure</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lived Experience Not Found LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use.pdf</th>\n",
       "      <td>Lived Experience Not Found LLMs Struggle to Al...</td>\n",
       "      <td>adr</td>\n",
       "      <td>102</td>\n",
       "      <td>llama</td>\n",
       "      <td>67</td>\n",
       "      <td>claude</td>\n",
       "      <td>48</td>\n",
       "      <td>gpt</td>\n",
       "      <td>47</td>\n",
       "      <td>example</td>\n",
       "      <td>...</td>\n",
       "      <td>table</td>\n",
       "      <td>26</td>\n",
       "      <td>llms</td>\n",
       "      <td>25</td>\n",
       "      <td>drug</td>\n",
       "      <td>25</td>\n",
       "      <td>dose</td>\n",
       "      <td>25</td>\n",
       "      <td>responses</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematical Definition and Systematization of Puzzle Rules.pdf</th>\n",
       "      <td>Mathematical Definition and Systematization of...</td>\n",
       "      <td>cid</td>\n",
       "      <td>175</td>\n",
       "      <td>null</td>\n",
       "      <td>112</td>\n",
       "      <td>solution</td>\n",
       "      <td>34</td>\n",
       "      <td>definition</td>\n",
       "      <td>22</td>\n",
       "      <td>puzzle</td>\n",
       "      <td>...</td>\n",
       "      <td>structure</td>\n",
       "      <td>10</td>\n",
       "      <td>bcon</td>\n",
       "      <td>10</td>\n",
       "      <td>domainandhiddenare</td>\n",
       "      <td>10</td>\n",
       "      <td>constraintsare</td>\n",
       "      <td>10</td>\n",
       "      <td>flatten</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedCoDi-M A Multi-Prompt Foundation Model for Multimodal Medical Data Generation.pdf</th>\n",
       "      <td>MedCoDi-M A Multi-Prompt Foundation Model for ...</td>\n",
       "      <td>data</td>\n",
       "      <td>121</td>\n",
       "      <td>medcodi</td>\n",
       "      <td>87</td>\n",
       "      <td>generation</td>\n",
       "      <td>83</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>72</td>\n",
       "      <td>model</td>\n",
       "      <td>...</td>\n",
       "      <td>bleu</td>\n",
       "      <td>35</td>\n",
       "      <td>score</td>\n",
       "      <td>34</td>\n",
       "      <td>generated</td>\n",
       "      <td>33</td>\n",
       "      <td>learning</td>\n",
       "      <td>31</td>\n",
       "      <td>cxr</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Migician Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models.pdf</th>\n",
       "      <td>Migician Revealing the Magic of Free-Form Mult...</td>\n",
       "      <td>image</td>\n",
       "      <td>144</td>\n",
       "      <td>grounding</td>\n",
       "      <td>61</td>\n",
       "      <td>object</td>\n",
       "      <td>50</td>\n",
       "      <td>multi</td>\n",
       "      <td>44</td>\n",
       "      <td>images</td>\n",
       "      <td>...</td>\n",
       "      <td>migician</td>\n",
       "      <td>21</td>\n",
       "      <td>bench</td>\n",
       "      <td>21</td>\n",
       "      <td>mig</td>\n",
       "      <td>20</td>\n",
       "      <td>visual</td>\n",
       "      <td>20</td>\n",
       "      <td>table</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Checking in Medical Imaging for Tumor Detection and Segmentation.pdf</th>\n",
       "      <td>Model Checking in Medical Imaging for Tumor De...</td>\n",
       "      <td>model</td>\n",
       "      <td>118</td>\n",
       "      <td>checking</td>\n",
       "      <td>102</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>63</td>\n",
       "      <td>spatial</td>\n",
       "      <td>60</td>\n",
       "      <td>medical</td>\n",
       "      <td>...</td>\n",
       "      <td>tumor</td>\n",
       "      <td>24</td>\n",
       "      <td>operators</td>\n",
       "      <td>24</td>\n",
       "      <td>using</td>\n",
       "      <td>24</td>\n",
       "      <td>operator</td>\n",
       "      <td>23</td>\n",
       "      <td>techniques</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More is not always better Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives.pdf</th>\n",
       "      <td>More is not always better Enhancing Many-Shot ...</td>\n",
       "      <td>shot</td>\n",
       "      <td>58</td>\n",
       "      <td>many</td>\n",
       "      <td>41</td>\n",
       "      <td>dricl</td>\n",
       "      <td>38</td>\n",
       "      <td>metaicl</td>\n",
       "      <td>28</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>...</td>\n",
       "      <td>zero</td>\n",
       "      <td>16</td>\n",
       "      <td>arxivpreprintarxiv</td>\n",
       "      <td>16</td>\n",
       "      <td>learning</td>\n",
       "      <td>15</td>\n",
       "      <td>chat</td>\n",
       "      <td>15</td>\n",
       "      <td>instruct</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification.pdf</th>\n",
       "      <td>Neural Network Prediction of Strong Lensing Sy...</td>\n",
       "      <td>prints</td>\n",
       "      <td>36</td>\n",
       "      <td>cid</td>\n",
       "      <td>34</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>32</td>\n",
       "      <td>pagearxiv</td>\n",
       "      <td>31</td>\n",
       "      <td>arxive</td>\n",
       "      <td>...</td>\n",
       "      <td>apj</td>\n",
       "      <td>13</td>\n",
       "      <td>source</td>\n",
       "      <td>12</td>\n",
       "      <td>de</td>\n",
       "      <td>12</td>\n",
       "      <td>li</td>\n",
       "      <td>12</td>\n",
       "      <td>march</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders.pdf</th>\n",
       "      <td>Piano Transcription by Hierarchical Language M...</td>\n",
       "      <td>note</td>\n",
       "      <td>32</td>\n",
       "      <td>based</td>\n",
       "      <td>30</td>\n",
       "      <td>model</td>\n",
       "      <td>27</td>\n",
       "      <td>sequence</td>\n",
       "      <td>27</td>\n",
       "      <td>lm</td>\n",
       "      <td>...</td>\n",
       "      <td>systems</td>\n",
       "      <td>16</td>\n",
       "      <td>models</td>\n",
       "      <td>16</td>\n",
       "      <td>amt</td>\n",
       "      <td>15</td>\n",
       "      <td>encoder</td>\n",
       "      <td>15</td>\n",
       "      <td>transcription</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRMBench A Fine-grained and Challenging Benchmark for Process-Level Reward Models.pdf</th>\n",
       "      <td>PRMBench A Fine-grained and Challenging Benchm...</td>\n",
       "      <td>step</td>\n",
       "      <td>282</td>\n",
       "      <td>prm</td>\n",
       "      <td>73</td>\n",
       "      <td>cid</td>\n",
       "      <td>48</td>\n",
       "      <td>question</td>\n",
       "      <td>43</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>...</td>\n",
       "      <td>avg</td>\n",
       "      <td>27</td>\n",
       "      <td>lire</td>\n",
       "      <td>24</td>\n",
       "      <td>prmbench</td>\n",
       "      <td>22</td>\n",
       "      <td>rlhflow</td>\n",
       "      <td>22</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rethinking Adversarial Attacks in Reinforcement Learning from Policy Distribution Perspective.pdf</th>\n",
       "      <td>Rethinking Adversarial Attacks in Reinforcemen...</td>\n",
       "      <td>policy</td>\n",
       "      <td>33</td>\n",
       "      <td>chen</td>\n",
       "      <td>33</td>\n",
       "      <td>learning</td>\n",
       "      <td>30</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>29</td>\n",
       "      <td>pp</td>\n",
       "      <td>...</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>17</td>\n",
       "      <td>fang</td>\n",
       "      <td>17</td>\n",
       "      <td>arxivpreprintarxiv</td>\n",
       "      <td>15</td>\n",
       "      <td>wang</td>\n",
       "      <td>15</td>\n",
       "      <td>ieee</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective.pdf</th>\n",
       "      <td>Rethinking Byzantine Robustness in Federated R...</td>\n",
       "      <td>spattack</td>\n",
       "      <td>75</td>\n",
       "      <td>ml</td>\n",
       "      <td>46</td>\n",
       "      <td>malicious</td>\n",
       "      <td>36</td>\n",
       "      <td>items</td>\n",
       "      <td>36</td>\n",
       "      <td>hr</td>\n",
       "      <td>...</td>\n",
       "      <td>clients</td>\n",
       "      <td>21</td>\n",
       "      <td>wu</td>\n",
       "      <td>20</td>\n",
       "      <td>federated</td>\n",
       "      <td>19</td>\n",
       "      <td>model</td>\n",
       "      <td>19</td>\n",
       "      <td>benign</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samba-ASR State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models.pdf</th>\n",
       "      <td>Samba-ASR State-Of-The-Art Speech Recognition ...</td>\n",
       "      <td>asr</td>\n",
       "      <td>30</td>\n",
       "      <td>mamba</td>\n",
       "      <td>17</td>\n",
       "      <td>samba</td>\n",
       "      <td>16</td>\n",
       "      <td>state</td>\n",
       "      <td>10</td>\n",
       "      <td>speech</td>\n",
       "      <td>...</td>\n",
       "      <td>sandlogic</td>\n",
       "      <td>5</td>\n",
       "      <td>rangedependencies</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>5</td>\n",
       "      <td>architecture</td>\n",
       "      <td>5</td>\n",
       "      <td>gigaspeech</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SenseRAG Constructing Environmental Knowledge Bases with Proactive Querying for LLM-Based Autonomous Driving.pdf</th>\n",
       "      <td>SenseRAG Constructing Environmental Knowledge ...</td>\n",
       "      <td>data</td>\n",
       "      <td>24</td>\n",
       "      <td>information</td>\n",
       "      <td>21</td>\n",
       "      <td>llms</td>\n",
       "      <td>17</td>\n",
       "      <td>driving</td>\n",
       "      <td>16</td>\n",
       "      <td>llm</td>\n",
       "      <td>...</td>\n",
       "      <td>sensor</td>\n",
       "      <td>11</td>\n",
       "      <td>systems</td>\n",
       "      <td>10</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>9</td>\n",
       "      <td>time</td>\n",
       "      <td>9</td>\n",
       "      <td>rag</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Socratic Questioning Learn to Self-guide Multimodal Reasoning in the Wild.pdf</th>\n",
       "      <td>Socratic Questioning Learn to Self-guide Multi...</td>\n",
       "      <td>arxivpreprint</td>\n",
       "      <td>44</td>\n",
       "      <td>llava</td>\n",
       "      <td>32</td>\n",
       "      <td>sq</td>\n",
       "      <td>24</td>\n",
       "      <td>li</td>\n",
       "      <td>20</td>\n",
       "      <td>gpt</td>\n",
       "      <td>...</td>\n",
       "      <td>cot</td>\n",
       "      <td>11</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>11</td>\n",
       "      <td>vision</td>\n",
       "      <td>11</td>\n",
       "      <td>human</td>\n",
       "      <td>11</td>\n",
       "      <td>hals</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Race to Efficiency A New Perspective on AI Scaling Laws.pdf</th>\n",
       "      <td>The Race to Efficiency A New Perspective on AI...</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>83</td>\n",
       "      <td>scaling</td>\n",
       "      <td>76</td>\n",
       "      <td>compute</td>\n",
       "      <td>74</td>\n",
       "      <td>time</td>\n",
       "      <td>72</td>\n",
       "      <td>ai</td>\n",
       "      <td>...</td>\n",
       "      <td>relative</td>\n",
       "      <td>24</td>\n",
       "      <td>hardware</td>\n",
       "      <td>23</td>\n",
       "      <td>gains</td>\n",
       "      <td>23</td>\n",
       "      <td>yr</td>\n",
       "      <td>23</td>\n",
       "      <td>https</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            file_name  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...  A Soft Sensor Method with Uncertainty-Awarenes...   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...  AI-Driven Diabetic Retinopathy Screening Multi...   \n",
       "Constraints as Rewards Reinforcement Learning f...  Constraints as Rewards Reinforcement Learning ...   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...  CONTINUUM Detecting APT Attacks through Spatia...   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...  DiReCT Diagnostic Reasoning for Clinical Notes...   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...  DPO Kernels  A Semantically-Aware, Kernel-Enha...   \n",
       "DynaGRAG Exploring the Topology of Information.pdf  DynaGRAG Exploring the Topology of Information...   \n",
       "Exploring Gradient Subspaces Addressing and Ove...  Exploring Gradient Subspaces Addressing and Ov...   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...  Hyperbolic Contrastive Learning for Hierarchic...   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...  INFELM In-depth Fairness Evaluation of Large T...   \n",
       "LightGNN Simple Graph Neural Network for Recomm...  LightGNN Simple Graph Neural Network for Recom...   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...  Lived Experience Not Found LLMs Struggle to Al...   \n",
       "Mathematical Definition and Systematization of ...  Mathematical Definition and Systematization of...   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...  MedCoDi-M A Multi-Prompt Foundation Model for ...   \n",
       "Migician Revealing the Magic of Free-Form Multi...  Migician Revealing the Magic of Free-Form Mult...   \n",
       "Model Checking in Medical Imaging for Tumor Det...  Model Checking in Medical Imaging for Tumor De...   \n",
       "More is not always better Enhancing Many-Shot I...  More is not always better Enhancing Many-Shot ...   \n",
       "Neural Network Prediction of Strong Lensing Sys...  Neural Network Prediction of Strong Lensing Sy...   \n",
       "Piano Transcription by Hierarchical Language Mo...  Piano Transcription by Hierarchical Language M...   \n",
       "PRMBench A Fine-grained and Challenging Benchma...  PRMBench A Fine-grained and Challenging Benchm...   \n",
       "Rethinking Adversarial Attacks in Reinforcement...  Rethinking Adversarial Attacks in Reinforcemen...   \n",
       "Rethinking Byzantine Robustness in Federated Re...  Rethinking Byzantine Robustness in Federated R...   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...  Samba-ASR State-Of-The-Art Speech Recognition ...   \n",
       "SenseRAG Constructing Environmental Knowledge B...  SenseRAG Constructing Environmental Knowledge ...   \n",
       "Socratic Questioning Learn to Self-guide Multim...  Socratic Questioning Learn to Self-guide Multi...   \n",
       "The Race to Efficiency A New Perspective on AI ...  The Race to Efficiency A New Perspective on AI...   \n",
       "\n",
       "                                                   most_recent_word1  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...               llm   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...            aidrss   \n",
       "Constraints as Rewards Reinforcement Learning f...               cid   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...             graph   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...               gpt   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               cid   \n",
       "DynaGRAG Exploring the Topology of Information.pdf          dynagrag   \n",
       "Exploring Gradient Subspaces Addressing and Ove...               cid   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...             point   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...               cid   \n",
       "LightGNN Simple Graph Neural Network for Recomm...               cid   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...               adr   \n",
       "Mathematical Definition and Systematization of ...               cid   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...              data   \n",
       "Migician Revealing the Magic of Free-Form Multi...             image   \n",
       "Model Checking in Medical Imaging for Tumor Det...             model   \n",
       "More is not always better Enhancing Many-Shot I...              shot   \n",
       "Neural Network Prediction of Strong Lensing Sys...            prints   \n",
       "Piano Transcription by Hierarchical Language Mo...              note   \n",
       "PRMBench A Fine-grained and Challenging Benchma...              step   \n",
       "Rethinking Adversarial Attacks in Reinforcement...            policy   \n",
       "Rethinking Byzantine Robustness in Federated Re...          spattack   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...               asr   \n",
       "SenseRAG Constructing Environmental Knowledge B...              data   \n",
       "Socratic Questioning Learn to Self-guide Multim...     arxivpreprint   \n",
       "The Race to Efficiency A New Perspective on AI ...        efficiency   \n",
       "\n",
       "                                                    frequency1  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...         178   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          32   \n",
       "Constraints as Rewards Reinforcement Learning f...          57   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          65   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          41   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...         812   \n",
       "DynaGRAG Exploring the Topology of Information.pdf          21   \n",
       "Exploring Gradient Subspaces Addressing and Ove...         276   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...         112   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...          16   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          37   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...         102   \n",
       "Mathematical Definition and Systematization of ...         175   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...         121   \n",
       "Migician Revealing the Magic of Free-Form Multi...         144   \n",
       "Model Checking in Medical Imaging for Tumor Det...         118   \n",
       "More is not always better Enhancing Many-Shot I...          58   \n",
       "Neural Network Prediction of Strong Lensing Sys...          36   \n",
       "Piano Transcription by Hierarchical Language Mo...          32   \n",
       "PRMBench A Fine-grained and Challenging Benchma...         282   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          33   \n",
       "Rethinking Byzantine Robustness in Federated Re...          75   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...          30   \n",
       "SenseRAG Constructing Environmental Knowledge B...          24   \n",
       "Socratic Questioning Learn to Self-guide Multim...          44   \n",
       "The Race to Efficiency A New Perspective on AI ...          83   \n",
       "\n",
       "                                                   most_recent_word2  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...              soft   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...         screening   \n",
       "Constraints as Rewards Reinforcement Learning f...        constraint   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...              data   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          response   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...            kernel   \n",
       "DynaGRAG Exploring the Topology of Information.pdf             graph   \n",
       "Exploring Gradient Subspaces Addressing and Ove...              lora   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...        embeddings   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...             image   \n",
       "LightGNN Simple Graph Neural Network for Recomm...             pages   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...             llama   \n",
       "Mathematical Definition and Systematization of ...              null   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...           medcodi   \n",
       "Migician Revealing the Magic of Free-Form Multi...         grounding   \n",
       "Model Checking in Medical Imaging for Tumor Det...          checking   \n",
       "More is not always better Enhancing Many-Shot I...              many   \n",
       "Neural Network Prediction of Strong Lensing Sys...               cid   \n",
       "Piano Transcription by Hierarchical Language Mo...             based   \n",
       "PRMBench A Fine-grained and Challenging Benchma...               prm   \n",
       "Rethinking Adversarial Attacks in Reinforcement...              chen   \n",
       "Rethinking Byzantine Robustness in Federated Re...                ml   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...             mamba   \n",
       "SenseRAG Constructing Environmental Knowledge B...       information   \n",
       "Socratic Questioning Learn to Self-guide Multim...             llava   \n",
       "The Race to Efficiency A New Perspective on AI ...           scaling   \n",
       "\n",
       "                                                    frequency2  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          98   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          20   \n",
       "Constraints as Rewards Reinforcement Learning f...          53   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          44   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          39   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...         255   \n",
       "DynaGRAG Exploring the Topology of Information.pdf          20   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          88   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...         102   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...          15   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          27   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          67   \n",
       "Mathematical Definition and Systematization of ...         112   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          87   \n",
       "Migician Revealing the Magic of Free-Form Multi...          61   \n",
       "Model Checking in Medical Imaging for Tumor Det...         102   \n",
       "More is not always better Enhancing Many-Shot I...          41   \n",
       "Neural Network Prediction of Strong Lensing Sys...          34   \n",
       "Piano Transcription by Hierarchical Language Mo...          30   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          73   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          33   \n",
       "Rethinking Byzantine Robustness in Federated Re...          46   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...          17   \n",
       "SenseRAG Constructing Environmental Knowledge B...          21   \n",
       "Socratic Questioning Learn to Self-guide Multim...          32   \n",
       "The Race to Efficiency A New Perspective on AI ...          76   \n",
       "\n",
       "                                                   most_recent_word3  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...              ufss   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...       specificity   \n",
       "Constraints as Rewards Reinforcement Learning f...             robot   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...             model   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...       observation   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               log   \n",
       "DynaGRAG Exploring the Topology of Information.pdf               cid   \n",
       "Exploring Gradient Subspaces Addressing and Ove...               agg   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...             cloud   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...            models   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          lightgnn   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...            claude   \n",
       "Mathematical Definition and Systematization of ...          solution   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...        generation   \n",
       "Migician Revealing the Magic of Free-Form Multi...            object   \n",
       "Model Checking in Medical Imaging for Tumor Det...      segmentation   \n",
       "More is not always better Enhancing Many-Shot I...             dricl   \n",
       "Neural Network Prediction of Strong Lensing Sys...             arxiv   \n",
       "Piano Transcription by Hierarchical Language Mo...             model   \n",
       "PRMBench A Fine-grained and Challenging Benchma...               cid   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          learning   \n",
       "Rethinking Byzantine Robustness in Federated Re...         malicious   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...             samba   \n",
       "SenseRAG Constructing Environmental Knowledge B...              llms   \n",
       "Socratic Questioning Learn to Self-guide Multim...                sq   \n",
       "The Race to Efficiency A New Perspective on AI ...           compute   \n",
       "\n",
       "                                                    frequency3  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          91   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          20   \n",
       "Constraints as Rewards Reinforcement Learning f...          44   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          38   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          38   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...         175   \n",
       "DynaGRAG Exploring the Topology of Information.pdf          14   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          82   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          76   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...          12   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          16   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          48   \n",
       "Mathematical Definition and Systematization of ...          34   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          83   \n",
       "Migician Revealing the Magic of Free-Form Multi...          50   \n",
       "Model Checking in Medical Imaging for Tumor Det...          63   \n",
       "More is not always better Enhancing Many-Shot I...          38   \n",
       "Neural Network Prediction of Strong Lensing Sys...          32   \n",
       "Piano Transcription by Hierarchical Language Mo...          27   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          48   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          30   \n",
       "Rethinking Byzantine Robustness in Federated Re...          36   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...          16   \n",
       "SenseRAG Constructing Environmental Knowledge B...          17   \n",
       "Socratic Questioning Learn to Self-guide Multim...          24   \n",
       "The Race to Efficiency A New Perspective on AI ...          74   \n",
       "\n",
       "                                                   most_recent_word4  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...              data   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          diabetic   \n",
       "Constraints as Rewards Reinforcement Learning f...          learning   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...         detection   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...           disease   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...           kernels   \n",
       "DynaGRAG Exploring the Topology of Information.pdf              llms   \n",
       "Exploring Gradient Subspaces Addressing and Ove...           clients   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...              text   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...            figure   \n",
       "LightGNN Simple Graph Neural Network for Recomm...              wang   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...               gpt   \n",
       "Mathematical Definition and Systematization of ...        definition   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...         synthetic   \n",
       "Migician Revealing the Magic of Free-Form Multi...             multi   \n",
       "Model Checking in Medical Imaging for Tumor Det...           spatial   \n",
       "More is not always better Enhancing Many-Shot I...           metaicl   \n",
       "Neural Network Prediction of Strong Lensing Sys...         pagearxiv   \n",
       "Piano Transcription by Hierarchical Language Mo...          sequence   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          question   \n",
       "Rethinking Adversarial Attacks in Reinforcement...       adversarial   \n",
       "Rethinking Byzantine Robustness in Federated Re...             items   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...             state   \n",
       "SenseRAG Constructing Environmental Knowledge B...           driving   \n",
       "Socratic Questioning Learn to Self-guide Multim...                li   \n",
       "The Race to Efficiency A New Perspective on AI ...              time   \n",
       "\n",
       "                                                    frequency4  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          86   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          19   \n",
       "Constraints as Rewards Reinforcement Learning f...          39   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          33   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          37   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...         154   \n",
       "DynaGRAG Exploring the Topology of Information.pdf          13   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          56   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          65   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...          12   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          16   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          47   \n",
       "Mathematical Definition and Systematization of ...          22   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          72   \n",
       "Migician Revealing the Magic of Free-Form Multi...          44   \n",
       "Model Checking in Medical Imaging for Tumor Det...          60   \n",
       "More is not always better Enhancing Many-Shot I...          28   \n",
       "Neural Network Prediction of Strong Lensing Sys...          31   \n",
       "Piano Transcription by Hierarchical Language Mo...          27   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          43   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          29   \n",
       "Rethinking Byzantine Robustness in Federated Re...          36   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...          10   \n",
       "SenseRAG Constructing Environmental Knowledge B...          16   \n",
       "Socratic Questioning Learn to Self-guide Multim...          20   \n",
       "The Race to Efficiency A New Perspective on AI ...          72   \n",
       "\n",
       "                                                   most_recent_word5  ...  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...               fig  ...   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...       retinopathy  ...   \n",
       "Constraints as Rewards Reinforcement Learning f...              task  ...   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...              node  ...   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...              note  ...   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               rbf  ...   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           inarxiv  ...   \n",
       "Exploring Gradient Subspaces Addressing and Ove...            fedftg  ...   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          learning  ...   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...          skintone  ...   \n",
       "LightGNN Simple Graph Neural Network for Recomm...             graph  ...   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...           example  ...   \n",
       "Mathematical Definition and Systematization of ...            puzzle  ...   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...             model  ...   \n",
       "Migician Revealing the Magic of Free-Form Multi...            images  ...   \n",
       "Model Checking in Medical Imaging for Tumor Det...           medical  ...   \n",
       "More is not always better Enhancing Many-Shot I...             arxiv  ...   \n",
       "Neural Network Prediction of Strong Lensing Sys...            arxive  ...   \n",
       "Piano Transcription by Hierarchical Language Mo...                lm  ...   \n",
       "PRMBench A Fine-grained and Challenging Benchma...         reasoning  ...   \n",
       "Rethinking Adversarial Attacks in Reinforcement...                pp  ...   \n",
       "Rethinking Byzantine Robustness in Federated Re...                hr  ...   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...            speech  ...   \n",
       "SenseRAG Constructing Environmental Knowledge B...               llm  ...   \n",
       "Socratic Questioning Learn to Self-guide Multim...               gpt  ...   \n",
       "The Race to Efficiency A New Perspective on AI ...                ai  ...   \n",
       "\n",
       "                                                    most_recent_word16  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...           variables   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...              fundus   \n",
       "Constraints as Rewards Reinforcement Learning f...              design   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...             spatial   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...              stroke   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...                  yy   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           diversity   \n",
       "Exploring Gradient Subspaces Addressing and Ove...                 yes   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...               pages   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...                monk   \n",
       "LightGNN Simple Graph Neural Network for Recomm...                  ii   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...               table   \n",
       "Mathematical Definition and Systematization of ...           structure   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...                bleu   \n",
       "Migician Revealing the Magic of Free-Form Multi...            migician   \n",
       "Model Checking in Medical Imaging for Tumor Det...               tumor   \n",
       "More is not always better Enhancing Many-Shot I...                zero   \n",
       "Neural Network Prediction of Strong Lensing Sys...                 apj   \n",
       "Piano Transcription by Hierarchical Language Mo...             systems   \n",
       "PRMBench A Fine-grained and Challenging Benchma...                 avg   \n",
       "Rethinking Adversarial Attacks in Reinforcement...               arxiv   \n",
       "Rethinking Byzantine Robustness in Federated Re...             clients   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           sandlogic   \n",
       "SenseRAG Constructing Environmental Knowledge B...              sensor   \n",
       "Socratic Questioning Learn to Self-guide Multim...                 cot   \n",
       "The Race to Efficiency A New Perspective on AI ...            relative   \n",
       "\n",
       "                                                   frequency16  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          50   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          11   \n",
       "Constraints as Rewards Reinforcement Learning f...          20   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          19   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          17   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...          68   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           7   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          23   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          25   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...           7   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          10   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          26   \n",
       "Mathematical Definition and Systematization of ...          10   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          35   \n",
       "Migician Revealing the Magic of Free-Form Multi...          21   \n",
       "Model Checking in Medical Imaging for Tumor Det...          24   \n",
       "More is not always better Enhancing Many-Shot I...          16   \n",
       "Neural Network Prediction of Strong Lensing Sys...          13   \n",
       "Piano Transcription by Hierarchical Language Mo...          16   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          27   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          17   \n",
       "Rethinking Byzantine Robustness in Federated Re...          21   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           5   \n",
       "SenseRAG Constructing Environmental Knowledge B...          11   \n",
       "Socratic Questioning Learn to Self-guide Multim...          11   \n",
       "The Race to Efficiency A New Perspective on AI ...          24   \n",
       "\n",
       "                                                    most_recent_word17  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          confidence   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...               using   \n",
       "Constraints as Rewards Reinforcement Learning f...            proposed   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...               using   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...              figure   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               based   \n",
       "DynaGRAG Exploring the Topology of Information.pdf        intelligence   \n",
       "Exploring Gradient Subspaces Addressing and Ove...              across   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...                 cid   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...               table   \n",
       "LightGNN Simple Graph Neural Network for Recomm...                  ed   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...                llms   \n",
       "Mathematical Definition and Systematization of ...                bcon   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...               score   \n",
       "Migician Revealing the Magic of Free-Form Multi...               bench   \n",
       "Model Checking in Medical Imaging for Tumor Det...           operators   \n",
       "More is not always better Enhancing Many-Shot I...  arxivpreprintarxiv   \n",
       "Neural Network Prediction of Strong Lensing Sys...              source   \n",
       "Piano Transcription by Hierarchical Language Mo...              models   \n",
       "PRMBench A Fine-grained and Challenging Benchma...                lire   \n",
       "Rethinking Adversarial Attacks in Reinforcement...                fang   \n",
       "Rethinking Byzantine Robustness in Federated Re...                  wu   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...   rangedependencies   \n",
       "SenseRAG Constructing Environmental Knowledge B...             systems   \n",
       "Socratic Questioning Learn to Self-guide Multim...       hallucination   \n",
       "The Race to Efficiency A New Perspective on AI ...            hardware   \n",
       "\n",
       "                                                   frequency17  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          46   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          11   \n",
       "Constraints as Rewards Reinforcement Learning f...          20   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          19   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          16   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...          67   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           7   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          22   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          23   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...           7   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          10   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          25   \n",
       "Mathematical Definition and Systematization of ...          10   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          34   \n",
       "Migician Revealing the Magic of Free-Form Multi...          21   \n",
       "Model Checking in Medical Imaging for Tumor Det...          24   \n",
       "More is not always better Enhancing Many-Shot I...          16   \n",
       "Neural Network Prediction of Strong Lensing Sys...          12   \n",
       "Piano Transcription by Hierarchical Language Mo...          16   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          24   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          17   \n",
       "Rethinking Byzantine Robustness in Federated Re...          20   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           5   \n",
       "SenseRAG Constructing Environmental Knowledge B...          10   \n",
       "Socratic Questioning Learn to Self-guide Multim...          11   \n",
       "The Race to Efficiency A New Perspective on AI ...          23   \n",
       "\n",
       "                                                    most_recent_word18  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...             methods   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...             feature   \n",
       "Constraints as Rewards Reinforcement Learning f...              method   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...              benign   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          diagnostic   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               model   \n",
       "DynaGRAG Exploring the Topology of Information.pdf            language   \n",
       "Exploring Gradient Subspaces Addressing and Ove...               dolly   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...            training   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...      classification   \n",
       "LightGNN Simple Graph Neural Network for Recomm...                  ni   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...                drug   \n",
       "Mathematical Definition and Systematization of ...  domainandhiddenare   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...           generated   \n",
       "Migician Revealing the Magic of Free-Form Multi...                 mig   \n",
       "Model Checking in Medical Imaging for Tumor Det...               using   \n",
       "More is not always better Enhancing Many-Shot I...            learning   \n",
       "Neural Network Prediction of Strong Lensing Sys...                  de   \n",
       "Piano Transcription by Hierarchical Language Mo...                 amt   \n",
       "PRMBench A Fine-grained and Challenging Benchma...            prmbench   \n",
       "Rethinking Adversarial Attacks in Reinforcement...  arxivpreprintarxiv   \n",
       "Rethinking Byzantine Robustness in Federated Re...           federated   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...         performance   \n",
       "SenseRAG Constructing Environmental Knowledge B...           knowledge   \n",
       "Socratic Questioning Learn to Self-guide Multim...              vision   \n",
       "The Race to Efficiency A New Perspective on AI ...               gains   \n",
       "\n",
       "                                                   frequency18  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          45   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          11   \n",
       "Constraints as Rewards Reinforcement Learning f...          19   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          19   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          15   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...          61   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           6   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          22   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          22   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...           7   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          10   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          25   \n",
       "Mathematical Definition and Systematization of ...          10   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          33   \n",
       "Migician Revealing the Magic of Free-Form Multi...          20   \n",
       "Model Checking in Medical Imaging for Tumor Det...          24   \n",
       "More is not always better Enhancing Many-Shot I...          15   \n",
       "Neural Network Prediction of Strong Lensing Sys...          12   \n",
       "Piano Transcription by Hierarchical Language Mo...          15   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          22   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          15   \n",
       "Rethinking Byzantine Robustness in Federated Re...          19   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           5   \n",
       "SenseRAG Constructing Environmental Knowledge B...           9   \n",
       "Socratic Questioning Learn to Self-guide Multim...          11   \n",
       "The Race to Efficiency A New Perspective on AI ...          23   \n",
       "\n",
       "                                                    most_recent_word19  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          prediction   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...                 fig   \n",
       "Constraints as Rewards Reinforcement Learning f...               qrsac   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...                 ids   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...             however   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...                data   \n",
       "DynaGRAG Exploring the Topology of Information.pdf                like   \n",
       "Exploring Gradient Subspaces Addressing and Ove...             medquad   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...                loss   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...    stablediffusionv   \n",
       "LightGNN Simple Graph Neural Network for Recomm...                  ei   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...                dose   \n",
       "Mathematical Definition and Systematization of ...      constraintsare   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...            learning   \n",
       "Migician Revealing the Magic of Free-Form Multi...              visual   \n",
       "Model Checking in Medical Imaging for Tumor Det...            operator   \n",
       "More is not always better Enhancing Many-Shot I...                chat   \n",
       "Neural Network Prediction of Strong Lensing Sys...                  li   \n",
       "Piano Transcription by Hierarchical Language Mo...             encoder   \n",
       "PRMBench A Fine-grained and Challenging Benchma...             rlhflow   \n",
       "Rethinking Adversarial Attacks in Reinforcement...                wang   \n",
       "Rethinking Byzantine Robustness in Federated Re...               model   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...        architecture   \n",
       "SenseRAG Constructing Environmental Knowledge B...                time   \n",
       "Socratic Questioning Learn to Self-guide Multim...               human   \n",
       "The Race to Efficiency A New Perspective on AI ...                  yr   \n",
       "\n",
       "                                                   frequency19  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...          45   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...          10   \n",
       "Constraints as Rewards Reinforcement Learning f...          19   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          18   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          15   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...          60   \n",
       "DynaGRAG Exploring the Topology of Information.pdf           6   \n",
       "Exploring Gradient Subspaces Addressing and Ove...          22   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          22   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...           7   \n",
       "LightGNN Simple Graph Neural Network for Recomm...          10   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          25   \n",
       "Mathematical Definition and Systematization of ...          10   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          31   \n",
       "Migician Revealing the Magic of Free-Form Multi...          20   \n",
       "Model Checking in Medical Imaging for Tumor Det...          23   \n",
       "More is not always better Enhancing Many-Shot I...          15   \n",
       "Neural Network Prediction of Strong Lensing Sys...          12   \n",
       "Piano Transcription by Hierarchical Language Mo...          15   \n",
       "PRMBench A Fine-grained and Challenging Benchma...          22   \n",
       "Rethinking Adversarial Attacks in Reinforcement...          15   \n",
       "Rethinking Byzantine Robustness in Federated Re...          19   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           5   \n",
       "SenseRAG Constructing Environmental Knowledge B...           9   \n",
       "Socratic Questioning Learn to Self-guide Multim...          11   \n",
       "The Race to Efficiency A New Perspective on AI ...          23   \n",
       "\n",
       "                                                    most_recent_word20  \\\n",
       "A Soft Sensor Method with Uncertainty-Awareness...                  pt   \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...               india   \n",
       "Constraints as Rewards Reinforcement Learning f...             trained   \n",
       "CONTINUUM Detecting APT Attacks through Spatial...           federated   \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...        respectively   \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...               local   \n",
       "DynaGRAG Exploring the Topology of Information.pdf               flash   \n",
       "Exploring Gradient Subspaces Addressing and Ove...            language   \n",
       "Hyperbolic Contrastive Learning for Hierarchica...                clip   \n",
       "INFELM In-depth Fairness Evaluation of Large Te...               large   \n",
       "LightGNN Simple Graph Neural Network for Recomm...              figure   \n",
       "Lived Experience Not Found LLMs Struggle to Ali...           responses   \n",
       "Mathematical Definition and Systematization of ...             flatten   \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...                 cxr   \n",
       "Migician Revealing the Magic of Free-Form Multi...               table   \n",
       "Model Checking in Medical Imaging for Tumor Det...          techniques   \n",
       "More is not always better Enhancing Many-Shot I...            instruct   \n",
       "Neural Network Prediction of Strong Lensing Sys...               march   \n",
       "Piano Transcription by Hierarchical Language Mo...       transcription   \n",
       "PRMBench A Fine-grained and Challenging Benchma...               arxiv   \n",
       "Rethinking Adversarial Attacks in Reinforcement...                ieee   \n",
       "Rethinking Byzantine Robustness in Federated Re...              benign   \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...          gigaspeech   \n",
       "SenseRAG Constructing Environmental Knowledge B...                 rag   \n",
       "Socratic Questioning Learn to Self-guide Multim...                hals   \n",
       "The Race to Efficiency A New Perspective on AI ...               https   \n",
       "\n",
       "                                                   frequency20  \n",
       "A Soft Sensor Method with Uncertainty-Awareness...          42  \n",
       "AI-Driven Diabetic Retinopathy Screening Multic...           9  \n",
       "Constraints as Rewards Reinforcement Learning f...          17  \n",
       "CONTINUUM Detecting APT Attacks through Spatial...          18  \n",
       "DiReCT Diagnostic Reasoning for Clinical Notes ...          15  \n",
       "DPO Kernels  A Semantically-Aware, Kernel-Enhan...          60  \n",
       "DynaGRAG Exploring the Topology of Information.pdf           6  \n",
       "Exploring Gradient Subspaces Addressing and Ove...          20  \n",
       "Hyperbolic Contrastive Learning for Hierarchica...          22  \n",
       "INFELM In-depth Fairness Evaluation of Large Te...           6  \n",
       "LightGNN Simple Graph Neural Network for Recomm...          10  \n",
       "Lived Experience Not Found LLMs Struggle to Ali...          24  \n",
       "Mathematical Definition and Systematization of ...           9  \n",
       "MedCoDi-M A Multi-Prompt Foundation Model for M...          31  \n",
       "Migician Revealing the Magic of Free-Form Multi...          20  \n",
       "Model Checking in Medical Imaging for Tumor Det...          22  \n",
       "More is not always better Enhancing Many-Shot I...          14  \n",
       "Neural Network Prediction of Strong Lensing Sys...          12  \n",
       "Piano Transcription by Hierarchical Language Mo...          14  \n",
       "PRMBench A Fine-grained and Challenging Benchma...          22  \n",
       "Rethinking Adversarial Attacks in Reinforcement...          14  \n",
       "Rethinking Byzantine Robustness in Federated Re...          19  \n",
       "Samba-ASR State-Of-The-Art Speech Recognition L...           5  \n",
       "SenseRAG Constructing Environmental Knowledge B...           9  \n",
       "Socratic Questioning Learn to Self-guide Multim...          11  \n",
       "The Race to Efficiency A New Perspective on AI ...          23  \n",
       "\n",
       "[26 rows x 41 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_words_to_df_with_columns(top_words, n=20):\n",
    "    \"\"\"\n",
    "    最頻ワードをDataFrameの列に変換する。\n",
    "    \"\"\"\n",
    "    # 最初に空の辞書を用意\n",
    "    all_top_words = {}\n",
    "    \n",
    "    # ファイルごとに最頻ワードを列として追加\n",
    "    for file_name, top_n_words in top_words.items():\n",
    "        # ファイルごとの最頻ワードリスト\n",
    "        top_words_dict = {'file_name': file_name}\n",
    "        \n",
    "        # 最頻ワード1から最頻ワードnまでを辞書に追加\n",
    "        for rank, (word, frequency) in enumerate(top_n_words, start=1):\n",
    "            top_words_dict[f'most_recent_word{rank}'] = word\n",
    "            top_words_dict[f'frequency{rank}'] = frequency\n",
    "        \n",
    "        # 辞書をall_top_wordsに追加\n",
    "        all_top_words[file_name] = top_words_dict\n",
    "    \n",
    "    # all_top_wordsからDataFrameを作成\n",
    "    df_top_words = pd.DataFrame.from_dict(all_top_words, orient='index')\n",
    "    \n",
    "    # 結果表示\n",
    "    return df_top_words\n",
    "\n",
    "# 最頻ワードをDataFrameに変換\n",
    "df_top_words = top_words_to_df_with_columns(top_words)\n",
    "\n",
    "# 結果表示\n",
    "df_top_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78513ea6-dd5b-46e7-ad2f-a5ca7e423c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>most_recent_word1</th>\n",
       "      <th>frequency1</th>\n",
       "      <th>most_recent_word2</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>most_recent_word3</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>most_recent_word4</th>\n",
       "      <th>frequency4</th>\n",
       "      <th>most_recent_word5</th>\n",
       "      <th>...</th>\n",
       "      <th>most_recent_word16</th>\n",
       "      <th>frequency16</th>\n",
       "      <th>most_recent_word17</th>\n",
       "      <th>frequency17</th>\n",
       "      <th>most_recent_word18</th>\n",
       "      <th>frequency18</th>\n",
       "      <th>most_recent_word19</th>\n",
       "      <th>frequency19</th>\n",
       "      <th>most_recent_word20</th>\n",
       "      <th>frequency20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Soft Sensor Method with Uncertainty-Awarenes...</td>\n",
       "      <td>llm</td>\n",
       "      <td>178</td>\n",
       "      <td>soft</td>\n",
       "      <td>98</td>\n",
       "      <td>ufss</td>\n",
       "      <td>91</td>\n",
       "      <td>data</td>\n",
       "      <td>86</td>\n",
       "      <td>fig</td>\n",
       "      <td>...</td>\n",
       "      <td>variables</td>\n",
       "      <td>50</td>\n",
       "      <td>confidence</td>\n",
       "      <td>46</td>\n",
       "      <td>methods</td>\n",
       "      <td>45</td>\n",
       "      <td>prediction</td>\n",
       "      <td>45</td>\n",
       "      <td>pt</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI-Driven Diabetic Retinopathy Screening Multi...</td>\n",
       "      <td>aidrss</td>\n",
       "      <td>32</td>\n",
       "      <td>screening</td>\n",
       "      <td>20</td>\n",
       "      <td>specificity</td>\n",
       "      <td>20</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>19</td>\n",
       "      <td>retinopathy</td>\n",
       "      <td>...</td>\n",
       "      <td>fundus</td>\n",
       "      <td>11</td>\n",
       "      <td>using</td>\n",
       "      <td>11</td>\n",
       "      <td>feature</td>\n",
       "      <td>11</td>\n",
       "      <td>fig</td>\n",
       "      <td>10</td>\n",
       "      <td>india</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Constraints as Rewards Reinforcement Learning ...</td>\n",
       "      <td>cid</td>\n",
       "      <td>57</td>\n",
       "      <td>constraint</td>\n",
       "      <td>53</td>\n",
       "      <td>robot</td>\n",
       "      <td>44</td>\n",
       "      <td>learning</td>\n",
       "      <td>39</td>\n",
       "      <td>task</td>\n",
       "      <td>...</td>\n",
       "      <td>design</td>\n",
       "      <td>20</td>\n",
       "      <td>proposed</td>\n",
       "      <td>20</td>\n",
       "      <td>method</td>\n",
       "      <td>19</td>\n",
       "      <td>qrsac</td>\n",
       "      <td>19</td>\n",
       "      <td>trained</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONTINUUM Detecting APT Attacks through Spatia...</td>\n",
       "      <td>graph</td>\n",
       "      <td>65</td>\n",
       "      <td>data</td>\n",
       "      <td>44</td>\n",
       "      <td>model</td>\n",
       "      <td>38</td>\n",
       "      <td>detection</td>\n",
       "      <td>33</td>\n",
       "      <td>node</td>\n",
       "      <td>...</td>\n",
       "      <td>spatial</td>\n",
       "      <td>19</td>\n",
       "      <td>using</td>\n",
       "      <td>19</td>\n",
       "      <td>benign</td>\n",
       "      <td>19</td>\n",
       "      <td>ids</td>\n",
       "      <td>18</td>\n",
       "      <td>federated</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DiReCT Diagnostic Reasoning for Clinical Notes...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>41</td>\n",
       "      <td>response</td>\n",
       "      <td>39</td>\n",
       "      <td>observation</td>\n",
       "      <td>38</td>\n",
       "      <td>disease</td>\n",
       "      <td>37</td>\n",
       "      <td>note</td>\n",
       "      <td>...</td>\n",
       "      <td>stroke</td>\n",
       "      <td>17</td>\n",
       "      <td>figure</td>\n",
       "      <td>16</td>\n",
       "      <td>diagnostic</td>\n",
       "      <td>15</td>\n",
       "      <td>however</td>\n",
       "      <td>15</td>\n",
       "      <td>respectively</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DPO Kernels  A Semantically-Aware, Kernel-Enha...</td>\n",
       "      <td>cid</td>\n",
       "      <td>812</td>\n",
       "      <td>kernel</td>\n",
       "      <td>255</td>\n",
       "      <td>log</td>\n",
       "      <td>175</td>\n",
       "      <td>kernels</td>\n",
       "      <td>154</td>\n",
       "      <td>rbf</td>\n",
       "      <td>...</td>\n",
       "      <td>yy</td>\n",
       "      <td>68</td>\n",
       "      <td>based</td>\n",
       "      <td>67</td>\n",
       "      <td>model</td>\n",
       "      <td>61</td>\n",
       "      <td>data</td>\n",
       "      <td>60</td>\n",
       "      <td>local</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DynaGRAG Exploring the Topology of Information...</td>\n",
       "      <td>dynagrag</td>\n",
       "      <td>21</td>\n",
       "      <td>graph</td>\n",
       "      <td>20</td>\n",
       "      <td>cid</td>\n",
       "      <td>14</td>\n",
       "      <td>llms</td>\n",
       "      <td>13</td>\n",
       "      <td>inarxiv</td>\n",
       "      <td>...</td>\n",
       "      <td>diversity</td>\n",
       "      <td>7</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>7</td>\n",
       "      <td>language</td>\n",
       "      <td>6</td>\n",
       "      <td>like</td>\n",
       "      <td>6</td>\n",
       "      <td>flash</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Exploring Gradient Subspaces Addressing and Ov...</td>\n",
       "      <td>cid</td>\n",
       "      <td>276</td>\n",
       "      <td>lora</td>\n",
       "      <td>88</td>\n",
       "      <td>agg</td>\n",
       "      <td>82</td>\n",
       "      <td>clients</td>\n",
       "      <td>56</td>\n",
       "      <td>fedftg</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>23</td>\n",
       "      <td>across</td>\n",
       "      <td>22</td>\n",
       "      <td>dolly</td>\n",
       "      <td>22</td>\n",
       "      <td>medquad</td>\n",
       "      <td>22</td>\n",
       "      <td>language</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hyperbolic Contrastive Learning for Hierarchic...</td>\n",
       "      <td>point</td>\n",
       "      <td>112</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>102</td>\n",
       "      <td>cloud</td>\n",
       "      <td>76</td>\n",
       "      <td>text</td>\n",
       "      <td>65</td>\n",
       "      <td>learning</td>\n",
       "      <td>...</td>\n",
       "      <td>pages</td>\n",
       "      <td>25</td>\n",
       "      <td>cid</td>\n",
       "      <td>23</td>\n",
       "      <td>training</td>\n",
       "      <td>22</td>\n",
       "      <td>loss</td>\n",
       "      <td>22</td>\n",
       "      <td>clip</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INFELM In-depth Fairness Evaluation of Large T...</td>\n",
       "      <td>cid</td>\n",
       "      <td>16</td>\n",
       "      <td>image</td>\n",
       "      <td>15</td>\n",
       "      <td>models</td>\n",
       "      <td>12</td>\n",
       "      <td>figure</td>\n",
       "      <td>12</td>\n",
       "      <td>skintone</td>\n",
       "      <td>...</td>\n",
       "      <td>monk</td>\n",
       "      <td>7</td>\n",
       "      <td>table</td>\n",
       "      <td>7</td>\n",
       "      <td>classification</td>\n",
       "      <td>7</td>\n",
       "      <td>stablediffusionv</td>\n",
       "      <td>7</td>\n",
       "      <td>large</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGNN Simple Graph Neural Network for Recom...</td>\n",
       "      <td>cid</td>\n",
       "      <td>37</td>\n",
       "      <td>pages</td>\n",
       "      <td>27</td>\n",
       "      <td>lightgnn</td>\n",
       "      <td>16</td>\n",
       "      <td>wang</td>\n",
       "      <td>16</td>\n",
       "      <td>graph</td>\n",
       "      <td>...</td>\n",
       "      <td>ii</td>\n",
       "      <td>10</td>\n",
       "      <td>ed</td>\n",
       "      <td>10</td>\n",
       "      <td>ni</td>\n",
       "      <td>10</td>\n",
       "      <td>ei</td>\n",
       "      <td>10</td>\n",
       "      <td>figure</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lived Experience Not Found LLMs Struggle to Al...</td>\n",
       "      <td>adr</td>\n",
       "      <td>102</td>\n",
       "      <td>llama</td>\n",
       "      <td>67</td>\n",
       "      <td>claude</td>\n",
       "      <td>48</td>\n",
       "      <td>gpt</td>\n",
       "      <td>47</td>\n",
       "      <td>example</td>\n",
       "      <td>...</td>\n",
       "      <td>table</td>\n",
       "      <td>26</td>\n",
       "      <td>llms</td>\n",
       "      <td>25</td>\n",
       "      <td>drug</td>\n",
       "      <td>25</td>\n",
       "      <td>dose</td>\n",
       "      <td>25</td>\n",
       "      <td>responses</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mathematical Definition and Systematization of...</td>\n",
       "      <td>cid</td>\n",
       "      <td>175</td>\n",
       "      <td>null</td>\n",
       "      <td>112</td>\n",
       "      <td>solution</td>\n",
       "      <td>34</td>\n",
       "      <td>definition</td>\n",
       "      <td>22</td>\n",
       "      <td>puzzle</td>\n",
       "      <td>...</td>\n",
       "      <td>structure</td>\n",
       "      <td>10</td>\n",
       "      <td>bcon</td>\n",
       "      <td>10</td>\n",
       "      <td>domainandhiddenare</td>\n",
       "      <td>10</td>\n",
       "      <td>constraintsare</td>\n",
       "      <td>10</td>\n",
       "      <td>flatten</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MedCoDi-M A Multi-Prompt Foundation Model for ...</td>\n",
       "      <td>data</td>\n",
       "      <td>121</td>\n",
       "      <td>medcodi</td>\n",
       "      <td>87</td>\n",
       "      <td>generation</td>\n",
       "      <td>83</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>72</td>\n",
       "      <td>model</td>\n",
       "      <td>...</td>\n",
       "      <td>bleu</td>\n",
       "      <td>35</td>\n",
       "      <td>score</td>\n",
       "      <td>34</td>\n",
       "      <td>generated</td>\n",
       "      <td>33</td>\n",
       "      <td>learning</td>\n",
       "      <td>31</td>\n",
       "      <td>cxr</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Migician Revealing the Magic of Free-Form Mult...</td>\n",
       "      <td>image</td>\n",
       "      <td>144</td>\n",
       "      <td>grounding</td>\n",
       "      <td>61</td>\n",
       "      <td>object</td>\n",
       "      <td>50</td>\n",
       "      <td>multi</td>\n",
       "      <td>44</td>\n",
       "      <td>images</td>\n",
       "      <td>...</td>\n",
       "      <td>migician</td>\n",
       "      <td>21</td>\n",
       "      <td>bench</td>\n",
       "      <td>21</td>\n",
       "      <td>mig</td>\n",
       "      <td>20</td>\n",
       "      <td>visual</td>\n",
       "      <td>20</td>\n",
       "      <td>table</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model Checking in Medical Imaging for Tumor De...</td>\n",
       "      <td>model</td>\n",
       "      <td>118</td>\n",
       "      <td>checking</td>\n",
       "      <td>102</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>63</td>\n",
       "      <td>spatial</td>\n",
       "      <td>60</td>\n",
       "      <td>medical</td>\n",
       "      <td>...</td>\n",
       "      <td>tumor</td>\n",
       "      <td>24</td>\n",
       "      <td>operators</td>\n",
       "      <td>24</td>\n",
       "      <td>using</td>\n",
       "      <td>24</td>\n",
       "      <td>operator</td>\n",
       "      <td>23</td>\n",
       "      <td>techniques</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>More is not always better Enhancing Many-Shot ...</td>\n",
       "      <td>shot</td>\n",
       "      <td>58</td>\n",
       "      <td>many</td>\n",
       "      <td>41</td>\n",
       "      <td>dricl</td>\n",
       "      <td>38</td>\n",
       "      <td>metaicl</td>\n",
       "      <td>28</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>...</td>\n",
       "      <td>zero</td>\n",
       "      <td>16</td>\n",
       "      <td>arxivpreprintarxiv</td>\n",
       "      <td>16</td>\n",
       "      <td>learning</td>\n",
       "      <td>15</td>\n",
       "      <td>chat</td>\n",
       "      <td>15</td>\n",
       "      <td>instruct</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neural Network Prediction of Strong Lensing Sy...</td>\n",
       "      <td>prints</td>\n",
       "      <td>36</td>\n",
       "      <td>cid</td>\n",
       "      <td>34</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>32</td>\n",
       "      <td>pagearxiv</td>\n",
       "      <td>31</td>\n",
       "      <td>arxive</td>\n",
       "      <td>...</td>\n",
       "      <td>apj</td>\n",
       "      <td>13</td>\n",
       "      <td>source</td>\n",
       "      <td>12</td>\n",
       "      <td>de</td>\n",
       "      <td>12</td>\n",
       "      <td>li</td>\n",
       "      <td>12</td>\n",
       "      <td>march</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Piano Transcription by Hierarchical Language M...</td>\n",
       "      <td>note</td>\n",
       "      <td>32</td>\n",
       "      <td>based</td>\n",
       "      <td>30</td>\n",
       "      <td>model</td>\n",
       "      <td>27</td>\n",
       "      <td>sequence</td>\n",
       "      <td>27</td>\n",
       "      <td>lm</td>\n",
       "      <td>...</td>\n",
       "      <td>systems</td>\n",
       "      <td>16</td>\n",
       "      <td>models</td>\n",
       "      <td>16</td>\n",
       "      <td>amt</td>\n",
       "      <td>15</td>\n",
       "      <td>encoder</td>\n",
       "      <td>15</td>\n",
       "      <td>transcription</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRMBench A Fine-grained and Challenging Benchm...</td>\n",
       "      <td>step</td>\n",
       "      <td>282</td>\n",
       "      <td>prm</td>\n",
       "      <td>73</td>\n",
       "      <td>cid</td>\n",
       "      <td>48</td>\n",
       "      <td>question</td>\n",
       "      <td>43</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>...</td>\n",
       "      <td>avg</td>\n",
       "      <td>27</td>\n",
       "      <td>lire</td>\n",
       "      <td>24</td>\n",
       "      <td>prmbench</td>\n",
       "      <td>22</td>\n",
       "      <td>rlhflow</td>\n",
       "      <td>22</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rethinking Adversarial Attacks in Reinforcemen...</td>\n",
       "      <td>policy</td>\n",
       "      <td>33</td>\n",
       "      <td>chen</td>\n",
       "      <td>33</td>\n",
       "      <td>learning</td>\n",
       "      <td>30</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>29</td>\n",
       "      <td>pp</td>\n",
       "      <td>...</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>17</td>\n",
       "      <td>fang</td>\n",
       "      <td>17</td>\n",
       "      <td>arxivpreprintarxiv</td>\n",
       "      <td>15</td>\n",
       "      <td>wang</td>\n",
       "      <td>15</td>\n",
       "      <td>ieee</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rethinking Byzantine Robustness in Federated R...</td>\n",
       "      <td>spattack</td>\n",
       "      <td>75</td>\n",
       "      <td>ml</td>\n",
       "      <td>46</td>\n",
       "      <td>malicious</td>\n",
       "      <td>36</td>\n",
       "      <td>items</td>\n",
       "      <td>36</td>\n",
       "      <td>hr</td>\n",
       "      <td>...</td>\n",
       "      <td>clients</td>\n",
       "      <td>21</td>\n",
       "      <td>wu</td>\n",
       "      <td>20</td>\n",
       "      <td>federated</td>\n",
       "      <td>19</td>\n",
       "      <td>model</td>\n",
       "      <td>19</td>\n",
       "      <td>benign</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Samba-ASR State-Of-The-Art Speech Recognition ...</td>\n",
       "      <td>asr</td>\n",
       "      <td>30</td>\n",
       "      <td>mamba</td>\n",
       "      <td>17</td>\n",
       "      <td>samba</td>\n",
       "      <td>16</td>\n",
       "      <td>state</td>\n",
       "      <td>10</td>\n",
       "      <td>speech</td>\n",
       "      <td>...</td>\n",
       "      <td>sandlogic</td>\n",
       "      <td>5</td>\n",
       "      <td>rangedependencies</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>5</td>\n",
       "      <td>architecture</td>\n",
       "      <td>5</td>\n",
       "      <td>gigaspeech</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SenseRAG Constructing Environmental Knowledge ...</td>\n",
       "      <td>data</td>\n",
       "      <td>24</td>\n",
       "      <td>information</td>\n",
       "      <td>21</td>\n",
       "      <td>llms</td>\n",
       "      <td>17</td>\n",
       "      <td>driving</td>\n",
       "      <td>16</td>\n",
       "      <td>llm</td>\n",
       "      <td>...</td>\n",
       "      <td>sensor</td>\n",
       "      <td>11</td>\n",
       "      <td>systems</td>\n",
       "      <td>10</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>9</td>\n",
       "      <td>time</td>\n",
       "      <td>9</td>\n",
       "      <td>rag</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Socratic Questioning Learn to Self-guide Multi...</td>\n",
       "      <td>arxivpreprint</td>\n",
       "      <td>44</td>\n",
       "      <td>llava</td>\n",
       "      <td>32</td>\n",
       "      <td>sq</td>\n",
       "      <td>24</td>\n",
       "      <td>li</td>\n",
       "      <td>20</td>\n",
       "      <td>gpt</td>\n",
       "      <td>...</td>\n",
       "      <td>cot</td>\n",
       "      <td>11</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>11</td>\n",
       "      <td>vision</td>\n",
       "      <td>11</td>\n",
       "      <td>human</td>\n",
       "      <td>11</td>\n",
       "      <td>hals</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The Race to Efficiency A New Perspective on AI...</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>83</td>\n",
       "      <td>scaling</td>\n",
       "      <td>76</td>\n",
       "      <td>compute</td>\n",
       "      <td>74</td>\n",
       "      <td>time</td>\n",
       "      <td>72</td>\n",
       "      <td>ai</td>\n",
       "      <td>...</td>\n",
       "      <td>relative</td>\n",
       "      <td>24</td>\n",
       "      <td>hardware</td>\n",
       "      <td>23</td>\n",
       "      <td>gains</td>\n",
       "      <td>23</td>\n",
       "      <td>yr</td>\n",
       "      <td>23</td>\n",
       "      <td>https</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_name most_recent_word1  \\\n",
       "0   A Soft Sensor Method with Uncertainty-Awarenes...               llm   \n",
       "1   AI-Driven Diabetic Retinopathy Screening Multi...            aidrss   \n",
       "2   Constraints as Rewards Reinforcement Learning ...               cid   \n",
       "3   CONTINUUM Detecting APT Attacks through Spatia...             graph   \n",
       "4   DiReCT Diagnostic Reasoning for Clinical Notes...               gpt   \n",
       "5   DPO Kernels  A Semantically-Aware, Kernel-Enha...               cid   \n",
       "6   DynaGRAG Exploring the Topology of Information...          dynagrag   \n",
       "7   Exploring Gradient Subspaces Addressing and Ov...               cid   \n",
       "8   Hyperbolic Contrastive Learning for Hierarchic...             point   \n",
       "9   INFELM In-depth Fairness Evaluation of Large T...               cid   \n",
       "10  LightGNN Simple Graph Neural Network for Recom...               cid   \n",
       "11  Lived Experience Not Found LLMs Struggle to Al...               adr   \n",
       "12  Mathematical Definition and Systematization of...               cid   \n",
       "13  MedCoDi-M A Multi-Prompt Foundation Model for ...              data   \n",
       "14  Migician Revealing the Magic of Free-Form Mult...             image   \n",
       "15  Model Checking in Medical Imaging for Tumor De...             model   \n",
       "16  More is not always better Enhancing Many-Shot ...              shot   \n",
       "17  Neural Network Prediction of Strong Lensing Sy...            prints   \n",
       "18  Piano Transcription by Hierarchical Language M...              note   \n",
       "19  PRMBench A Fine-grained and Challenging Benchm...              step   \n",
       "20  Rethinking Adversarial Attacks in Reinforcemen...            policy   \n",
       "21  Rethinking Byzantine Robustness in Federated R...          spattack   \n",
       "22  Samba-ASR State-Of-The-Art Speech Recognition ...               asr   \n",
       "23  SenseRAG Constructing Environmental Knowledge ...              data   \n",
       "24  Socratic Questioning Learn to Self-guide Multi...     arxivpreprint   \n",
       "25  The Race to Efficiency A New Perspective on AI...        efficiency   \n",
       "\n",
       "    frequency1 most_recent_word2  frequency2 most_recent_word3  frequency3  \\\n",
       "0          178              soft          98              ufss          91   \n",
       "1           32         screening          20       specificity          20   \n",
       "2           57        constraint          53             robot          44   \n",
       "3           65              data          44             model          38   \n",
       "4           41          response          39       observation          38   \n",
       "5          812            kernel         255               log         175   \n",
       "6           21             graph          20               cid          14   \n",
       "7          276              lora          88               agg          82   \n",
       "8          112        embeddings         102             cloud          76   \n",
       "9           16             image          15            models          12   \n",
       "10          37             pages          27          lightgnn          16   \n",
       "11         102             llama          67            claude          48   \n",
       "12         175              null         112          solution          34   \n",
       "13         121           medcodi          87        generation          83   \n",
       "14         144         grounding          61            object          50   \n",
       "15         118          checking         102      segmentation          63   \n",
       "16          58              many          41             dricl          38   \n",
       "17          36               cid          34             arxiv          32   \n",
       "18          32             based          30             model          27   \n",
       "19         282               prm          73               cid          48   \n",
       "20          33              chen          33          learning          30   \n",
       "21          75                ml          46         malicious          36   \n",
       "22          30             mamba          17             samba          16   \n",
       "23          24       information          21              llms          17   \n",
       "24          44             llava          32                sq          24   \n",
       "25          83           scaling          76           compute          74   \n",
       "\n",
       "   most_recent_word4  frequency4 most_recent_word5  ...  most_recent_word16  \\\n",
       "0               data          86               fig  ...           variables   \n",
       "1           diabetic          19       retinopathy  ...              fundus   \n",
       "2           learning          39              task  ...              design   \n",
       "3          detection          33              node  ...             spatial   \n",
       "4            disease          37              note  ...              stroke   \n",
       "5            kernels         154               rbf  ...                  yy   \n",
       "6               llms          13           inarxiv  ...           diversity   \n",
       "7            clients          56            fedftg  ...                 yes   \n",
       "8               text          65          learning  ...               pages   \n",
       "9             figure          12          skintone  ...                monk   \n",
       "10              wang          16             graph  ...                  ii   \n",
       "11               gpt          47           example  ...               table   \n",
       "12        definition          22            puzzle  ...           structure   \n",
       "13         synthetic          72             model  ...                bleu   \n",
       "14             multi          44            images  ...            migician   \n",
       "15           spatial          60           medical  ...               tumor   \n",
       "16           metaicl          28             arxiv  ...                zero   \n",
       "17         pagearxiv          31            arxive  ...                 apj   \n",
       "18          sequence          27                lm  ...             systems   \n",
       "19          question          43         reasoning  ...                 avg   \n",
       "20       adversarial          29                pp  ...               arxiv   \n",
       "21             items          36                hr  ...             clients   \n",
       "22             state          10            speech  ...           sandlogic   \n",
       "23           driving          16               llm  ...              sensor   \n",
       "24                li          20               gpt  ...                 cot   \n",
       "25              time          72                ai  ...            relative   \n",
       "\n",
       "   frequency16  most_recent_word17 frequency17  most_recent_word18  \\\n",
       "0           50          confidence          46             methods   \n",
       "1           11               using          11             feature   \n",
       "2           20            proposed          20              method   \n",
       "3           19               using          19              benign   \n",
       "4           17              figure          16          diagnostic   \n",
       "5           68               based          67               model   \n",
       "6            7        intelligence           7            language   \n",
       "7           23              across          22               dolly   \n",
       "8           25                 cid          23            training   \n",
       "9            7               table           7      classification   \n",
       "10          10                  ed          10                  ni   \n",
       "11          26                llms          25                drug   \n",
       "12          10                bcon          10  domainandhiddenare   \n",
       "13          35               score          34           generated   \n",
       "14          21               bench          21                 mig   \n",
       "15          24           operators          24               using   \n",
       "16          16  arxivpreprintarxiv          16            learning   \n",
       "17          13              source          12                  de   \n",
       "18          16              models          16                 amt   \n",
       "19          27                lire          24            prmbench   \n",
       "20          17                fang          17  arxivpreprintarxiv   \n",
       "21          21                  wu          20           federated   \n",
       "22           5   rangedependencies           5         performance   \n",
       "23          11             systems          10           knowledge   \n",
       "24          11       hallucination          11              vision   \n",
       "25          24            hardware          23               gains   \n",
       "\n",
       "   frequency18  most_recent_word19 frequency19  most_recent_word20 frequency20  \n",
       "0           45          prediction          45                  pt          42  \n",
       "1           11                 fig          10               india           9  \n",
       "2           19               qrsac          19             trained          17  \n",
       "3           19                 ids          18           federated          18  \n",
       "4           15             however          15        respectively          15  \n",
       "5           61                data          60               local          60  \n",
       "6            6                like           6               flash           6  \n",
       "7           22             medquad          22            language          20  \n",
       "8           22                loss          22                clip          22  \n",
       "9            7    stablediffusionv           7               large           6  \n",
       "10          10                  ei          10              figure          10  \n",
       "11          25                dose          25           responses          24  \n",
       "12          10      constraintsare          10             flatten           9  \n",
       "13          33            learning          31                 cxr          31  \n",
       "14          20              visual          20               table          20  \n",
       "15          24            operator          23          techniques          22  \n",
       "16          15                chat          15            instruct          14  \n",
       "17          12                  li          12               march          12  \n",
       "18          15             encoder          15       transcription          14  \n",
       "19          22             rlhflow          22               arxiv          22  \n",
       "20          15                wang          15                ieee          14  \n",
       "21          19               model          19              benign          19  \n",
       "22           5        architecture           5          gigaspeech           5  \n",
       "23           9                time           9                 rag           9  \n",
       "24          11               human          11                hals          11  \n",
       "25          23                  yr          23               https          23  \n",
       "\n",
       "[26 rows x 41 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_words_new = df_top_words.reset_index(drop=True)\n",
    "df_top_words_new = df_top_words_new.drop([\"level_0\",\"index\"],axis=1)\n",
    "df_top_words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1f69a25-5ac0-4d83-8ba5-ecd5246bdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここから要約を行う。要約列を追加する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f33ad55-d976-4cdc-9cf8-92800a96ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# または raw文字列を使う方法\n",
    "desk_top_path = r\"C:\\Users\\sk062\\OneDrive\\デスクトップ\\output.csv\"\n",
    "\n",
    "# データフレームをCSVとして保存\n",
    "df_top_words_new.to_csv(desk_top_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557ab6b-6ae6-4d5e-896a-72a6a1d177ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
